{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1FlECwKofre3ajscaENQLZc4CCyaHsA70","authorship_tag":"ABX9TyNTTXk6/5O/J/xOGYSxlOc3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# üìù Projeto: Chatbot de Atendimento ao Cliente com Mem√≥ria (RAG + Chat History)\n","\n","*   **Autor:** Victor Alexandre\n","*   **Metodologia:** Aprender Construindo\n","\n","---\n","\n","## 1. Objetivo Principal\n","\n","Construir um assistente virtual inteligente (chatbot) capaz de responder a perguntas sobre uma base de conhecimento espec√≠fica. O diferencial deste projeto √© a implementa√ß√£o de **mem√≥ria conversacional**, permitindo que o chatbot entenda o contexto de perguntas anteriores e responda a intera√ß√µes de acompanhamento de forma coesa e natural.\n","\n","---\n","\n","## 2. Arquitetura da Solu√ß√£o\n","\n","Utilizamos o padr√£o **RAG (Retrieval-Augmented Generation)**, que funciona em duas grandes etapas:\n","\n","1.  **Recupera√ß√£o (Retrieval):** A pergunta do usu√°rio √© usada para buscar os trechos mais relevantes de informa√ß√£o dentro do nosso documento. Isso √© feito transformando o texto em vetores num√©ricos e encontrando os mais similares √† pergunta.\n","2.  **Gera√ß√£o (Generation):** Os trechos recuperados, juntamente com a pergunta original e o hist√≥rico da conversa, s√£o enviados a um Grande Modelo de Linguagem (LLM), que gera uma resposta final em linguagem natural.\n","\n","O fluxo √© orquestrado pela biblioteca `LangChain`, conectando uma interface de usu√°rio criada com `Streamlit` a uma base de vetorial `FAISS` e a um LLM.\n","\n","---\n","\n","## 3. Fonte de Dados (Dataset)\n","\n","*   **Documento:** Manual do Usu√°rio do WordPress\n","*   **Origem:** Universidade Federal de Juiz de Fora (UFJF)\n","*   **Formato:** PDF\n","*   **Tamanho:** 33 p√°ginas\n","*   **Descri√ß√£o:** Um documento denso, com instru√ß√µes t√©cnicas, guias passo a passo e imagens, simulando um desafio de atendimento ao cliente do mundo real.\n","\n","---\n","\n","## 4. Stack de Tecnologias\n","\n","| Componente | Tecnologia | Prop√≥sito |\n","| :--- | :--- | :--- |\n","| **Interface do Usu√°rio** | `Streamlit` | Criar uma aplica√ß√£o web interativa para o chat. |\n","| **Orquestra√ß√£o** | `LangChain` | A \"cola\" que conecta todos os componentes do sistema. |\n","| **Base de Vetores** | `FAISS` | Armazenar e buscar eficientemente os vetores do documento. |\n","| **Processamento de PDF** | `PyPDFLoader` | Carregar e extrair o texto do nosso documento base. |\n","| **Modelos de IA (LLM)** | `Google AI / OpenAI` | Gerar as respostas com base no contexto fornecido. |\n","| **Ambiente de Dev** | `Google Colab` | Nosso ambiente de desenvolvimento e experimenta√ß√£o. |\n","| **Deploy (App)** | `Ngrok` | Expor nossa aplica√ß√£o Streamlit do Colab para a web. |"],"metadata":{"id":"fPSI0GCfs28A"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"Y0r02zFZszTC","executionInfo":{"status":"ok","timestamp":1759977506529,"user_tz":180,"elapsed":7934,"user":{"displayName":"VICTOR","userId":"15376073746806575044"}}},"outputs":[],"source":["# C√âLULA 1: INSTALA√á√ÉO DE TODAS AS DEPEND√äNCIAS (VERS√ÉO CORRIGIDA 2)\n","!pip install -q -U langchain langchain-community streamlit langchain_google_genai faiss-cpu pypdf pyngrok google-ai-generativelanguage==0.6.15"]},{"cell_type":"code","source":["# C√âLULA 2: AUTENTICA√á√ÉO E CONFIGURA√á√ÉO DA API (VERS√ÉO CORRIGIDA)\n","\n","import os\n","from google.colab import userdata, auth\n","import google.generativeai as genai\n","\n","# 1. Pega a API Key dos Segredos do Colab\n","try:\n","    api_key = userdata.get('GOOGLE_API_KEY')\n","    os.environ['GOOGLE_API_KEY'] = api_key\n","except userdata.SecretNotFoundError:\n","    print(\"ERRO: O segredo 'GOOGLE_API_KEY' n√£o foi encontrado.\")\n","    # Interrompe a execu√ß√£o se a chave n√£o for encontrada\n","    raise ValueError(\"Configure o segredo 'GOOGLE_API_KEY' no painel do Colab.\")\n","\n","# 2. Autentica o usu√°rio no ambiente do Colab\n","#    Este √© o passo crucial que resolve o erro de metadados.\n","#    Uma janela de autentica√ß√£o do Google pode aparecer. Siga os passos.\n","try:\n","    auth.authenticate_user()\n","    print(\"‚úÖ Usu√°rio autenticado com sucesso.\")\n","except Exception as e:\n","    print(f\"‚ùå ERRO: Falha na autentica√ß√£o do usu√°rio. Detalhe: {e}\")\n","    raise\n","\n","# 3. Configura a biblioteca do GenAI com a chave\n","try:\n","    genai.configure(api_key=api_key)\n","    print(\"‚úÖ Biblioteca Google Generative AI configurada com sucesso.\")\n","except Exception as e:\n","    print(f\"‚ùå ERRO: Falha ao configurar a biblioteca GenAI. Detalhe: {e}\")\n","    raise"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I2m07-hHwRWk","executionInfo":{"status":"ok","timestamp":1759978107511,"user_tz":180,"elapsed":1282,"user":{"displayName":"VICTOR","userId":"15376073746806575044"}},"outputId":"53221008-98e7-46aa-8dc0-d165236782a6"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ Usu√°rio autenticado com sucesso.\n","‚úÖ Biblioteca Google Generative AI configurada com sucesso.\n"]}]},{"cell_type":"code","source":["# C√âLULA 3: CARREGAMENTO E PROCESSAMENTO DO PDF (VERS√ÉO CORRIGIDA)\n","\n","from google.colab import drive\n","from langchain_community.document_loaders import PyPDFLoader\n","from langchain.text_splitter import RecursiveCharacterTextSplitter\n","\n","# 1. Monta o Google Drive (se j√° montado, n√£o faz nada)\n","drive.mount('/content/drive', force_remount=False)\n","\n","# 2. Define o caminho para o seu arquivo PDF\n","#    USE O M√âTODO \"COPIAR CAMINHO\" PARA GARANTIR QUE EST√Å CORRETO\n","pdf_path = \"/content/drive/MyDrive/Projetos/Projetos - Engenharia de IA/Chatbot de Atendimento ao Cliente com MemoÃÅria (RAG + Chat History)/manualWP_4.2.pdf\" # <-- COLE O CAMINHO COPIADO AQUI\n","\n","# 3. Carrega o documento PDF\n","try:\n","    loader = PyPDFLoader(pdf_path)\n","    docs_raw = loader.load()\n","    print(f\"Documento de {len(docs_raw)} p√°gina(s) carregado com sucesso.\")\n","\n","    # 4. Divide o documento em chunks\n","    text_splitter = RecursiveCharacterTextSplitter(\n","        chunk_size=1000,\n","        chunk_overlap=200,\n","        add_start_index=True\n","    )\n","    docs_processed = text_splitter.split_documents(docs_raw)\n","\n","    print(f\"O documento foi dividido em {len(docs_processed)} chunks para processamento.\")\n","\n","except Exception as e:\n","    print(f\"Ocorreu um erro ao carregar o PDF: {e}\")\n","    print(\"\\nVERIFIQUE SE O CAMINHO ACIMA EST√Å 100% CORRETO.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0trMfF2rwRT8","executionInfo":{"status":"ok","timestamp":1759978113636,"user_tz":180,"elapsed":2683,"user":{"displayName":"VICTOR","userId":"15376073746806575044"}},"outputId":"61e78a02-0430-45d5-fad6-db1e13385e31"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Documento de 30 p√°gina(s) carregado com sucesso.\n","O documento foi dividido em 32 chunks para processamento.\n"]}]},{"cell_type":"code","source":["# C√âLULA 4: CRIA√á√ÉO DA BASE DE VETORES (EMBEDDINGS & FAISS)\n","\n","from langchain_google_genai import GoogleGenerativeAIEmbeddings\n","from langchain_community.vectorstores import FAISS\n","\n","# 1. Crie o modelo de embeddings\n","embeddings_model = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n","\n","# 2. Crie a base de vetores com o FAISS\n","print(\"Criando a base de vetores (isso pode levar alguns segundos)...\")\n","vector_store = FAISS.from_documents(docs_processed, embeddings_model)\n","print(\"Base de vetores criada com sucesso!\")\n","\n","# 3. Salve o √≠ndice localmente\n","vector_store.save_local(\"faiss_index_wordpress\")\n","print(\"√çndice FAISS salvo localmente na pasta 'faiss_index_wordpress'.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PqBzhhwOwRQ7","executionInfo":{"status":"ok","timestamp":1759978116332,"user_tz":180,"elapsed":741,"user":{"displayName":"VICTOR","userId":"15376073746806575044"}},"outputId":"67246bc4-5cd7-4f3a-f7ef-654bab1fb62b"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Criando a base de vetores (isso pode levar alguns segundos)...\n","Base de vetores criada com sucesso!\n","√çndice FAISS salvo localmente na pasta 'faiss_index_wordpress'.\n"]}]},{"cell_type":"code","source":["# C√âLULA DE DESCOBERTA: Listando os modelos de IA dispon√≠veis\n","\n","import google.generativeai as genai\n","\n","print(\"Modelos de IA dispon√≠veis para sua API Key:\")\n","for m in genai.list_models():\n","  if 'generateContent' in m.supported_generation_methods:\n","    print(f\"  - {m.name}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":767},"id":"2Ns14WJq5ltJ","executionInfo":{"status":"ok","timestamp":1759978614130,"user_tz":180,"elapsed":2051,"user":{"displayName":"VICTOR","userId":"15376073746806575044"}},"outputId":"fd488235-ef94-4394-d17f-ebce47d25607"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Modelos de IA dispon√≠veis para sua API Key:\n","  - models/gemini-2.5-pro-preview-03-25\n","  - models/gemini-2.5-flash-preview-05-20\n","  - models/gemini-2.5-flash\n","  - models/gemini-2.5-flash-lite-preview-06-17\n","  - models/gemini-2.5-pro-preview-05-06\n","  - models/gemini-2.5-pro-preview-06-05\n","  - models/gemini-2.5-pro\n","  - models/gemini-2.0-flash-exp\n","  - models/gemini-2.0-flash\n","  - models/gemini-2.0-flash-001\n","  - models/gemini-2.0-flash-exp-image-generation\n","  - models/gemini-2.0-flash-lite-001\n","  - models/gemini-2.0-flash-lite\n","  - models/gemini-2.0-flash-preview-image-generation\n","  - models/gemini-2.0-flash-lite-preview-02-05\n","  - models/gemini-2.0-flash-lite-preview\n","  - models/gemini-2.0-pro-exp\n","  - models/gemini-2.0-pro-exp-02-05\n","  - models/gemini-exp-1206\n","  - models/gemini-2.0-flash-thinking-exp-01-21\n","  - models/gemini-2.0-flash-thinking-exp\n","  - models/gemini-2.0-flash-thinking-exp-1219\n","  - models/gemini-2.5-flash-preview-tts\n","  - models/gemini-2.5-pro-preview-tts\n","  - models/learnlm-2.0-flash-experimental\n","  - models/gemma-3-1b-it\n","  - models/gemma-3-4b-it\n","  - models/gemma-3-12b-it\n","  - models/gemma-3-27b-it\n","  - models/gemma-3n-e4b-it\n","  - models/gemma-3n-e2b-it\n","  - models/gemini-flash-latest\n","  - models/gemini-flash-lite-latest\n","  - models/gemini-pro-latest\n","  - models/gemini-2.5-flash-lite\n","  - models/gemini-2.5-flash-image-preview\n","  - models/gemini-2.5-flash-image\n","  - models/gemini-2.5-flash-preview-09-2025\n","  - models/gemini-2.5-flash-lite-preview-09-2025\n","  - models/gemini-robotics-er-1.5-preview\n","  - models/gemini-2.5-computer-use-preview-10-2025\n"]}]},{"cell_type":"code","source":["# C√âLULA 5: CRIA√á√ÉO DA CADEIA CONVERSACIONAL (VERS√ÉO FINAL)\n","\n","from langchain_google_genai import ChatGoogleGenerativeAI\n","from langchain.chains import ConversationalRetrievalChain\n","from langchain.memory import ConversationBufferMemory\n","\n","# CORRE√á√ÉO: Usando o alias est√°vel da sua lista de modelos\n","llm = ChatGoogleGenerativeAI(model=\"gemini-pro-latest\", temperature=0.3)\n","\n","retriever = vector_store.as_retriever(search_kwargs={\"k\": 5})\n","memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n","\n","chatbot_chain = ConversationalRetrievalChain.from_llm(\n","    llm=llm,\n","    retriever=retriever,\n","    memory=memory,\n","    verbose=False\n",")\n","print(\"‚úÖ Chatbot (cadeia conversacional) montado e pronto para uso.\")\n","\n","# --- Teste r√°pido ---\n","print(\"\\n--- Teste R√°pido no Colab ---\")\n","try:\n","    question = \"Como eu acesso o painel administrativo?\"\n","    response = chatbot_chain.invoke({\"question\": question})\n","    print(f\"Pergunta: {question}\")\n","    print(f\"Resposta: {response['answer']}\")\n","    print(\"\\n‚úÖ Teste r√°pido conclu√≠do com sucesso!\")\n","except Exception as e:\n","    print(f\"‚ùå ERRO durante o teste r√°pido: {e}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"blD08wJrwRN-","executionInfo":{"status":"ok","timestamp":1759978683100,"user_tz":180,"elapsed":5056,"user":{"displayName":"VICTOR","userId":"15376073746806575044"}},"outputId":"c483d9b1-9728-4382-c7d0-d70da14a6bfb"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ Chatbot (cadeia conversacional) montado e pronto para uso.\n","\n","--- Teste R√°pido no Colab ---\n","Pergunta: Como eu acesso o painel administrativo?\n","Resposta: Para acessar o painel administrativo do site, voc√™ deve digitar o seguinte endere√ßo no seu navegador: `http://www.ufjf.br/seusite/wp-admin/`.\n","\n","Lembre-se de substituir \"seusite\" pelo nome do seu site.\n","\n","Ap√≥s acessar o endere√ßo, aparecer√° uma tela de login onde voc√™ dever√° inserir seu \"Nome de usu√°rio\" e \"Senha\".\n","\n","‚úÖ Teste r√°pido conclu√≠do com sucesso!\n"]}]},{"cell_type":"code","source":["# C√âLULA 6: CRIA√á√ÉO DO ARQUIVO DA APLICA√á√ÉO (app.py) (VERS√ÉO FINAL)\n","%%writefile app.py\n","\n","import streamlit as st\n","from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n","from langchain.chains import ConversationalRetrievalChain\n","from langchain.memory import ConversationBufferMemory\n","from langchain_community.vectorstores import FAISS\n","import os\n","\n","# --- CONFIGURA√á√ÉO DA P√ÅGINA ---\n","st.set_page_config(page_title=\"Assistente WordPress\", page_icon=\"üß†\", layout=\"centered\")\n","st.markdown(\"<h1 style='text-align: center; color: #E8E8E8;'>üß† Assistente Virtual WordPress</h1>\", unsafe_allow_html=True)\n","st.markdown(\"<p style='text-align: center; color: #A0A0A0;'>Seu copiloto para tirar d√∫vidas sobre o manual da UFJF.</p>\", unsafe_allow_html=True)\n","st.divider() # Adiciona uma linha divis√≥ria\n","\n","# --- FUN√á√ïES CORE (COM CACHING) ---\n","@st.cache_resource\n","def load_components():\n","    \"\"\" Carrega os componentes pesados (LLM, Embeddings, Vector Store) uma √∫nica vez. \"\"\"\n","    if not os.getenv(\"GOOGLE_API_KEY\"):\n","        st.error(\"Chave de API do Google n√£o encontrada. Configure o segredo 'GOOGLE_API_KEY' no Colab.\")\n","        st.stop()\n","\n","    # CORRE√á√ÉO: Usando o alias est√°vel da sua lista de modelos\n","    llm = ChatGoogleGenerativeAI(model=\"gemini-pro-latest\", temperature=0.3)\n","\n","    embeddings_model = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n","    vector_store = FAISS.load_local(\n","        \"faiss_index_wordpress\",\n","        embeddings_model,\n","        allow_dangerous_deserialization=True\n","    )\n","    return llm, vector_store.as_retriever(search_kwargs={\"k\": 5})\n","\n","def create_conversational_chain(_llm, _retriever):\n","    \"\"\" Cria a cadeia conversacional com mem√≥ria. \"\"\"\n","    memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n","    chain = ConversationalRetrievalChain.from_llm(llm=_llm, retriever=_retriever, memory=memory)\n","    return chain\n","\n","# --- INICIALIZA√á√ÉO DA APLICA√á√ÉO ---\n","llm, retriever = load_components()\n","\n","if 'chain' not in st.session_state:\n","    st.session_state.chain = create_conversational_chain(llm, retriever)\n","\n","if \"messages\" not in st.session_state:\n","    st.session_state.messages = [{\"role\": \"assistant\", \"content\": \"Ol√°! Como posso ajudar com o manual do WordPress?\"}]\n","\n","# --- L√ìGICA DO CHAT ---\n","for message in st.session_state.messages:\n","    with st.chat_message(message[\"role\"]):\n","        st.markdown(message[\"content\"])\n","\n","if prompt := st.chat_input(\"Qual √© a sua d√∫vida?\"):\n","    st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n","    with st.chat_message(\"user\"):\n","        st.markdown(prompt)\n","\n","    with st.chat_message(\"assistant\"):\n","        with st.spinner(\"Analisando o documento...\"):\n","            result = st.session_state.chain.invoke({\"question\": prompt})\n","            response = result[\"answer\"]\n","            st.markdown(response)\n","            st.session_state.messages.append({\"role\": \"assistant\", \"content\": response})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"leZh0VcswRGD","executionInfo":{"status":"ok","timestamp":1759979952458,"user_tz":180,"elapsed":49,"user":{"displayName":"VICTOR","userId":"15376073746806575044"}},"outputId":"b47de0b8-0ad1-42c6-d957-070569182ba2"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting app.py\n"]}]},{"cell_type":"code","source":["# C√âLULA 7: EXECU√á√ÉO DO STREAMLIT COM NGROK (VERS√ÉO FINAL AUTENTICADA)\n","\n","from pyngrok import ngrok\n","from google.colab import userdata\n","import os\n","\n","# 1. Pega o authtoken do ngrok dos segredos do Colab\n","try:\n","    ngrok_authtoken = userdata.get('ngrok_key')\n","    # 2. Autentica o ngrok\n","    ngrok.set_auth_token(ngrok_authtoken)\n","    print(\"‚úÖ Authtoken do Ngrok configurado com sucesso.\")\n","except userdata.SecretNotFoundError:\n","    print(\"‚ùå ERRO: O segredo 'ngrok_key' n√£o foi encontrado.\")\n","    raise ValueError(\"Configure o segredo 'ngrok_key' no painel do Colab.\")\n","except Exception as e:\n","    print(f\"‚ùå ERRO ao configurar o Ngrok: {e}\")\n","    raise\n","\n","# Mata qualquer processo do streamlit que possa estar rodando\n","!killall streamlit\n","\n","# Define a porta\n","port = 8501\n","\n","# Executa o Streamlit em background\n","os.system(f\"streamlit run app.py --server.port {port} &\")\n","\n","# 3. Cria o t√∫nel p√∫blico (agora autenticado)\n","try:\n","    public_url = ngrok.connect(port)\n","    print(\"=\"*60)\n","    print(f\"üöÄ SEU CHATBOT EST√Å NO AR! ACESSE ATRAV√âS DESTE LINK:\")\n","    print(public_url)\n","    print(\"=\"*60)\n","except Exception as e:\n","    print(f\"‚ùå ERRO ao criar o t√∫nel do Ngrok: {e}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BjCTliXTwwTI","executionInfo":{"status":"ok","timestamp":1759979956391,"user_tz":180,"elapsed":1355,"user":{"displayName":"VICTOR","userId":"15376073746806575044"}},"outputId":"71caca27-3046-40c6-d4ed-6ecfdc51a0ab"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ Authtoken do Ngrok configurado com sucesso.\n","============================================================\n","üöÄ SEU CHATBOT EST√Å NO AR! ACESSE ATRAV√âS DESTE LINK:\n","NgrokTunnel: \"https://preneural-nonascendently-rosy.ngrok-free.dev\" -> \"http://localhost:8501\"\n","============================================================\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"gXyVBgRSwwLE"},"execution_count":null,"outputs":[]}]}