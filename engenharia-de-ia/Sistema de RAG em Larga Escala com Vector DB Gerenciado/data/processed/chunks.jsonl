{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_0", "text": "Na informática, a Inteligência Artificial (abreviado IA) genericamente é a inteligência, o raciocínio e o aprendizado exibida por máquinas semelhante ao raciocino humano; busca desenvolver máquinas autônomas ou sistemas especialistas capazes de simular o pensamento humano e realizar várias tarefas complexas de forma independente. É o sistema que permite aos computadores executar funções avançadas, como a capacidade de analisar dados em grande escala e fazer previsões/recomendações; É um campo de pesquisa em ciência da computação que desenvolve e estuda métodos e softwares que permitem que as máquinas percebam seu ambiente e usem o aprendizado e a inteligência para tomar ações que maximizem suas chances de atingir objetivos definidos. A IA iniciou na década de 1950 com os pesquisadores Alan Turing e Herbert Simon baseado no conceito do filósofo grego Aristóteles. Em 1950, o matemático inglês Allan Turing escreveu sobre ser possível uma máquina pensar, e imitar o comportamento humano"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_1", "text": "Turing e Herbert Simon baseado no conceito do filósofo grego Aristóteles. Em 1950, o matemático inglês Allan Turing escreveu sobre ser possível uma máquina pensar, e imitar o comportamento humano inteligente. Também esboçou uma proposta de pesquisa para tornar isto possível. Aplicações de IA incluem mecanismos avançados de busca na web (por exemplo, Google Search); sistemas de recomendação (usados pelo YouTube, Amazon e Netflix); assistentes virtuais (por exemplo, Google Assistant, Siri e Alexa ); veículos autônomos (por exemplo, Waymo); ferramentas generativas e criativas (por exemplo, ChatGPT, DeepSeek e AI art); e jogo e análise sobre-humanos em jogos de estratégia (por exemplo, xadrez e Go). No entanto, muitas aplicações de IA não são percebidas como IA porque já se tornaram comuns o suficiente no cotidiano das pessoas. Como por exemplo, o reconhecimento óptico de caracteres (OCR) que extrai o texto de imagens; transforma conteúdo não estruturado em dados estruturados com insights"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_2", "text": "no cotidiano das pessoas. Como por exemplo, o reconhecimento óptico de caracteres (OCR) que extrai o texto de imagens; transforma conteúdo não estruturado em dados estruturados com insights prontos para negócios; tradução de textos em idiomas estrangeiros e tradução de voz. A IA é um campo que abrange muitas disciplinas, como: ciência da computação, estatísticas, engenharia de hardware e de software, linguística, neurociência e, filosofia. Vários subcampos da pesquisa em IA são centrados em objetivos específicos e no uso de ferramentas específicas. Os objetivos tradicionais da pesquisa em IA incluem raciocínio, representação de conhecimento, planejamento, aprendizagem, processamento de linguagem natural, percepção e suporte à robótica. A inteligência geral — a capacidade de completar qualquer tarefa realizada por um humano em um nível pelo menos igual — está entre os objetivos de longo prazo do campo. Para atingir esses objetivos, os pesquisadores de IA adaptaram e integraram uma"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_3", "text": "qualquer tarefa realizada por um humano em um nível pelo menos igual — está entre os objetivos de longo prazo do campo. Para atingir esses objetivos, os pesquisadores de IA adaptaram e integraram uma ampla gama de técnicas, incluindo otimização matemática e de busca, lógica formal, redes neurais artificiais e métodos baseados em estatística, pesquisa operacional e economia. A IA também se baseia na psicologia, linguística, filosofia, neurociência e em outros campos. A inteligência artificial foi fundada como disciplina acadêmica em 1956 e o campo passou por múltiplos ciclos de otimismo ao longo de sua história, seguidos por períodos de decepção e perda de financiamento. Os recursos e o interesse aumentaram enormemente após 2012, quando a aprendizagem profunda superou as técnicas de IA anteriores. Este crescimento acelerou ainda mais depois de 2017 e no início da década de 2020 muitos milhares de milhões de dólares estavam a ser investidos em IA e o campo experimentou um rápido"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_4", "text": "IA anteriores. Este crescimento acelerou ainda mais depois de 2017 e no início da década de 2020 muitos milhares de milhões de dólares estavam a ser investidos em IA e o campo experimentou um rápido progresso contínuo no que ficou conhecido como o boom da IA. O surgimento da IA generativa avançada e sua capacidade de criar e modificar conteúdo expôs diversas consequências e danos não intencionais no presente e levantou preocupações sobre os riscos da IA e seus efeitos de longo prazo no futuro, gerando discussões sobre políticas regulatórias para garantir a segurança e os benefícios da tecnologia. O interesse no desenvolvimento de máquinas autônomas capazes de simular o pensamento humano e de realizar varias tarefas cresceu vertiginosamente nas últimas décadas, da segunda metade do século XX, realizando assim os primeiros estudos sobre inteligência artificial (IA) a um propósito comum, a partir de iniciativas de cientistas de diversas áreas, como: psicologia, ciência cognitiva, ciência"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_5", "text": "realizando assim os primeiros estudos sobre inteligência artificial (IA) a um propósito comum, a partir de iniciativas de cientistas de diversas áreas, como: psicologia, ciência cognitiva, ciência da computação e, robótica. Ferramentas eficientes em analisar problemas e oferecer soluções e planejamentos (tomada de decisão), automatização de tarefas no cotidiano das pessoas. Mas apesar dos estudos serem modernos, o conceito de inteligência artificial não é contemporâneo; Aristóteles (professor de Alexandre, o Grande) sonhava em substituir a mão-de-obra escrava por ferramentas autônomas, sendo esta possivelmente a primeira ideia de Inteligência Artificial relatada, que a ciência da computação exploraria muito tempo depois. O desenvolvimento dessa ideia ocorreu plenamente no século XX, principalmente na década de 1950, com pensadores como Allan Turing, Herbert Simon e, John McCarthy. Turing escreveu o artigo \"Computing Machinery and InteIligence\" sobre a possibilidade de uma máquina"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_6", "text": "na década de 1950, com pensadores como Allan Turing, Herbert Simon e, John McCarthy. Turing escreveu o artigo \"Computing Machinery and InteIligence\" sobre a possibilidade de uma máquina pensar e imitar o comportamento humano inteligente com tal perfeição, de forma que pudesse confundir ate um juiz humano. Turing também esboçou uma proposta de pesquisa para tornar possível. Inicialmente os teste em IA foram repletos de sucessos – porém limitados devido o desempenho reduzido dos primeiros computadores - oque causava surpresa, foi o fato de um computador realizar atividade remotamente inteligente. O sucesso inicial prosseguiu em 1957 com o General Problem Solver (GPS, Solucionador de problemas gerais) desenvolvido por Herbert Simon e Allen Newell, um programa foi projetado para imitar protocolos humanos de resolução de problemas. Dentro da classe limitada de quebra-cabeças com a qual podia lidar, verificou-se que a ordem em que os seres humanos abordavam os mesmos problemas. Desse modo,"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_7", "text": "humanos de resolução de problemas. Dentro da classe limitada de quebra-cabeças com a qual podia lidar, verificou-se que a ordem em que os seres humanos abordavam os mesmos problemas. Desse modo, o GPS talvez tenha sido o primeiro programa a incorporar a abordagem de “pensar de forma humana”. Em 1961, a proposta de Turing voltou no artigo de Herbert Simon e Allen Newell no artigo \"The Simulation of Human Thought\" sobre o teste de uma teoria de resolução humana de problemas. Esta teoria tenta explicar alguns aspectos dos processos mentais responsáveis pela inteligencia humana, um projeto de estudos conhecido pelo nome de Projeto de Simulação Cognitiva. Desde o início os fundamentos da inteligência artificial tiveram o suporte de várias disciplinas que contribuíram com ideias, pontos de vista e técnicas para a IA. Os filósofos (desde 400 a.C.) tornaram a IA concebível, considerando as ideias de que a mente é, em alguns aspectos, semelhante a uma máquina, de que ela opera sobre o"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_8", "text": "de vista e técnicas para a IA. Os filósofos (desde 400 a.C.) tornaram a IA concebível, considerando as ideias de que a mente é, em alguns aspectos, semelhante a uma máquina, de que ela opera sobre o conhecimento codificado em alguma linguagem interna e que o pensamento pode ser usado para escolher as ações que deverão ser executadas. Por sua vez, os matemáticos forneceram as ferramentas para manipular declarações de certeza lógica, bem como declarações incertas e probabilísticas. Eles também definiram a base para a compreensão da computação e do raciocínio sobre algoritmos. Os economistas formalizaram o problema de tomar decisões que maximizam o resultado esperado para o tomador de decisões. Os psicólogos adotaram a ideia de que os seres humanos e os animais podem ser considerados máquinas de processamento de informações. Os linguistas mostraram que o uso da linguagem se ajusta a esse modelo. Os engenheiros de computação fornecem os artefatos que tornam possíveis as aplicações de IA."}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_9", "text": "de processamento de informações. Os linguistas mostraram que o uso da linguagem se ajusta a esse modelo. Os engenheiros de computação fornecem os artefatos que tornam possíveis as aplicações de IA. Os programas de IA tendem a ser extensos e não poderiam funcionar sem os grandes avanços em velocidade e memória que a indústria de informática tem proporcionado. Atualmente, a IA abrange uma enorme variedade de subcampos. Dentre esses subcampos está o estudo de modelos conexionistas ou redes neurais. Uma rede neural pode ser vista como um modelo matemático simplificado do funcionamento do cérebro humano. Este consiste de um número muito grande de unidades elementares de processamento, ou neurônios, que recebem e enviam estímulos elétricos uns aos outros, formando uma rede altamente interconectada. No processamento, são compostos os estímulos recebidos conforme a intensidade de cada ligação, produzindo um único estímulo de saída. É o arranjo das interconexões entre os neurônios e as"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_10", "text": "No processamento, são compostos os estímulos recebidos conforme a intensidade de cada ligação, produzindo um único estímulo de saída. É o arranjo das interconexões entre os neurônios e as respectivas intensidades que define as principais propriedades e o funcionamento de uma RN. O estudo das redes neurais ou o conexionismo se relaciona com a capacidade dos computadores aprenderem e reconhecerem padrões. Podemos destacar também o estudo da biologia molecular na tentativa de construir vida artificial e a área da robótica, ligada à biologia e procurando construir máquinas que alojem vida artificial. Outro subcampo de estudo é a ligação da IA com a Psicologia, na tentativa de representar na máquina os mecanismos de raciocínio e de procura. Nos últimos anos, houve uma revolução no trabalho em inteligência artificial, tanto no conteúdo quanto na metodologia. Agora, é mais comum usar as teorias existentes como bases, em vez de propor teorias inteiramente novas, fundamentar as informações em"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_11", "text": "inteligência artificial, tanto no conteúdo quanto na metodologia. Agora, é mais comum usar as teorias existentes como bases, em vez de propor teorias inteiramente novas, fundamentar as informações em teoremas rigorosos ou na evidência experimental rígida, em vez de utilizar como base a intuição e destacar a relevância de aplicações reais em vez de exemplos hipotéticos. A utilização da IA permite obter não somente ganhos significativos de performance, mas também possibilita o desenvolvimento de aplicações inovadoras, capazes de expandir de forma extraordinária nossos sentidos e habilidades intelectuais. Cada vez mais presente, a inteligência artificial simula o pensamento humano e se alastra por nosso cotidiano. Em maio de 2017 no Brasil, foi criada a ABRIA (Associação Brasileira de Inteligência Artificial) com o objetivo de mapear iniciativas brasileiras no setor de inteligência artificial, englobando os esforços entre as empresas nacionais e formação de mão de obra especializada."}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_12", "text": "Artificial) com o objetivo de mapear iniciativas brasileiras no setor de inteligência artificial, englobando os esforços entre as empresas nacionais e formação de mão de obra especializada. Esse passo reforça que, atualmente, a inteligência artificial é impactante no setor econômico. A inteligência artificial começou como um campo experimental na década de 1950 com pioneiros como Allen Newell e Herbert Simon, que fundaram o primeiro laboratório de inteligência artificial na Universidade Carnegie Mellon, e McCarty que juntamente com Marvin Minsky, que fundaram o MIT AI Lab em 1959. Foram eles alguns dos participantes na famosa conferência de verão de 1956 em Darthmouth College. Historicamente, existem dois grandes estilos de investigação em IA: IA \"neats\" e IA \"scruffies\". A IA \"neats\", limpa, clássica ou simbólica. Envolve a manipulação de símbolos e de conceitos abstractos, e é a metodologia utilizada na maior parte dos sistemas periciais. Paralelamente a esta abordagem existe a"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_13", "text": "limpa, clássica ou simbólica. Envolve a manipulação de símbolos e de conceitos abstractos, e é a metodologia utilizada na maior parte dos sistemas periciais. Paralelamente a esta abordagem existe a abordagem IA \"scruffies\", ou \"coneccionista\", da qual as redes neuronais são o melhor exemplo. Esta abordagem cria sistemas que tentam gerar inteligência pela aprendizagem e adaptação em vez da criação de sistemas desenhados com o objectivo especifico de resolver um problema. Ambas as abordagems apareceram num estágio inicial da história de IA. Nas décadas de 1960/70 os coneccionistas foram retirados do primeiro plano da investigação em IA, mas o interesse por esta vertente da IA foi retomada na década de 1980, quando as limitações da IA \"limpa\" começaram a ser percebidas. Pesquisas sobre inteligência artificial foram intensamente custeadas na década de 1980 pela Agência de Projetos de Pesquisas Avançadas sobre Defesa (“Defense Advanced Research Projects Agency”), nos Estados Unidos, e pelo"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_14", "text": "artificial foram intensamente custeadas na década de 1980 pela Agência de Projetos de Pesquisas Avançadas sobre Defesa (“Defense Advanced Research Projects Agency”), nos Estados Unidos, e pelo Projeto da Quinta Geração (“Fifth Generation Project”), no Japão. O trabalho subsidiado fracassou no sentido de produzir resultados imediatos, a despeito das promessas grandiosas de alguns praticantes de IA, o que levou proporcionalmente a grandes cortes de verbas de agências governamentais no final dos anos 80, e em consequência a um arrefecimento da atividade no setor, fase conhecida como O inverno da IA. No decorrer da década seguinte, muitos pesquisadores de IA mudaram para áreas relacionadas com metas mais modestas, tais como aprendizado de máquinas, robótica e visão computacional, muito embora pesquisas sobre IA pura continuaram em níveis reduzidos. Existem duas abordagens principais para a criação de Sistemas de Inteligência Artificial: O Simbolismo e o Conexionismo. O Simbolismo ou IA"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_15", "text": "pesquisas sobre IA pura continuaram em níveis reduzidos. Existem duas abordagens principais para a criação de Sistemas de Inteligência Artificial: O Simbolismo e o Conexionismo. O Simbolismo ou IA Simbólica, propõe a representação de conhecimento por meio da manipulação de símbolos, isto é, na forma de estruturas construídas por seres humanos, normalmente baseadas em noções de Lógica. Ela teve grande impulso durante uma fase onde foram criados muitos Sistemas Especialistas, muitos deles baseados em Lógica de Primeira Ordem, implementados em Prolog, ou em linguagens de programação derivadas desta ou especializadas, como CLIPS. Normalmente programas desse tipo têm o conhecimento programado diretamente por seres humanos, o que levou a trabalhos de elicitação de conhecimento. Apesar do sucesso inicial dos Sistemas Especialistas, a grande dificuldade de levantar e registrar conhecimento a partir de humanos e o sucesso dos processos de aprendizado de máquina a partir de dados levou a"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_16", "text": "sucesso inicial dos Sistemas Especialistas, a grande dificuldade de levantar e registrar conhecimento a partir de humanos e o sucesso dos processos de aprendizado de máquina a partir de dados levou a dimimuição da importância dessa vertente. O Conexionismo ou IA Conexionista, se baseia em um modelo matemático inspirado no funcionamento dos neurônios, e depende do aprendizado de máquina baseado em grandes massas de dados para calibrar esse modelo, que normalmente começa com parâmetros aleatórios. Essa abordagem, apesar de proposta muito cedo, não encontrou computadores capazes de modelar problemas complexos, apesar de ter sucesso com problemas restritos de reconhecimento de padrão, o que só acontece a partir da década de 2010, com resultados extramemente fortes no final dessa década e no início da década de 2020, a partir de modelos contendo bilhões de parametros, como o GPT-3 e conceitos como Redes Neurais Profundas, Transformers, e Atenção. Em torno de 2022, a maior parte da pesquisa"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_17", "text": "da década de 2020, a partir de modelos contendo bilhões de parametros, como o GPT-3 e conceitos como Redes Neurais Profundas, Transformers, e Atenção. Em torno de 2022, a maior parte da pesquisa em IA gira em torno dos conceitos de Aprendizado de Máquina e Conexionismo, havendo também propostas para sistemas híbridos. A questão sobre o que é \"inteligência artificial\", mesmo como definida anteriormente, pode ser separada em duas partes: \"qual a natureza do artificial\" e \"o que é inteligência\". A primeira questão é de resolução relativamente fácil, apontando no entanto para a questão de o que poderá o homem construir. A segunda questão seria consideravelmente mais difícil, levantando a questão da consciência, identidade e mente (incluindo a mente inconsciente) juntamente com a questão de que componentes estão envolvidos no único tipo de inteligência que universalmente se aceita como estando ao alcance do nosso estudo: a inteligência do ser humano. O estudo de animais e de sistemas"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_18", "text": "de que componentes estão envolvidos no único tipo de inteligência que universalmente se aceita como estando ao alcance do nosso estudo: a inteligência do ser humano. O estudo de animais e de sistemas artificiais que não são modelos triviais começa a ser considerado como pauta de estudo na área da inteligência. Ao conceituar inteligência artificial, presume-se a interação com o ambiente, diante de necessidades reais como relações entre indivíduos semelhantes, a disputa entre indivíduos diferentes, perseguição e fuga; além da comunicação simbólica específica de causa e efeito em diversos níveis de compreensão intuitiva, consciente ou não. Suponhamos uma competição de cara ou coroa, cujos resultados sejam observados ou não. Se na segunda tentativa der o mesmo resultado que a primeira, então não existiam as mesmas chances para ambas opções iniciais. Claro que a coleta de informação em apenas duas amostragens é confiável apenas porque a quantidade de tentativas é divisível pelo número de"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_19", "text": "não existiam as mesmas chances para ambas opções iniciais. Claro que a coleta de informação em apenas duas amostragens é confiável apenas porque a quantidade de tentativas é divisível pelo número de opções de resultados prováveis. A verdade é que o conceito de cara ou coroa está associado a artigos de valor, como moedas e medalhas que podem evitar que as pessoas abandonem o jogo e induza os participantes a acompanhar os resultados até o final. Para manter a disposição do adversário em desafiar a máquina seria necessário aparentar fragilidade e garantir a continuidade da partida. Isso é muito utilizado em máquinas de cassino, sendo que vários apostadores podem ser induzidos a dispensar consideráveis quantias em apostas. A utilização de uma máquina de resultados pode compensar a ausência de um adversário, mas numa partida de xadrez, por exemplo, para que a máquina não precise armazenar todas as informações que excedem a capacidade de próprio universo imaginável são necessárias fórmulas"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_20", "text": "um adversário, mas numa partida de xadrez, por exemplo, para que a máquina não precise armazenar todas as informações que excedem a capacidade de próprio universo imaginável são necessárias fórmulas que possam ser armazenadas para que então sejam calculadas por princípios físicos, lógicos, geométricos, e estatísticos para refletir o sistema completo em cada uma das suas partes; como a integração do Google com Wikipédia, por exemplo. Uma popular e inicial definição de inteligência artificial, introduzida por John McCarthy na famosa conferência de Dartmouth em 1956 é \"fazer a máquina comportar-se de tal forma que seja chamada inteligente caso fosse este o comportamento de um ser humano.\" No entanto, esta definição parece ignorar a possibilidade de existir a IA forte (ver abaixo). Outra definição de Inteligência Artificial é a inteligência que surge de um \"dispositivo artificial\". A maior parte das definições podem ser categorizadas em sistemas que: \"pensam como um humano; agem como um"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_21", "text": "de Inteligência Artificial é a inteligência que surge de um \"dispositivo artificial\". A maior parte das definições podem ser categorizadas em sistemas que: \"pensam como um humano; agem como um humano; pensam racionalmente ou agem racionalmente\". Os principais pesquisadores e livros didáticos definem o campo como \"o estudo e projeto de agentes inteligentes\", onde um agente inteligente é um sistema que percebe seu ambiente e toma atitudes que maximizam suas chances de sucesso. Andreas Kaplan e Michael Haenlein definem a inteligência artificial como “uma capacidade do sistema para interpretar corretamente dados externos, aprender a partir desses dados e utilizar essas aprendizagens para atingir objetivos e tarefas específicas através de adaptação flexível”. John McCarthy, quem cunhou o termo em 1956 (\"numa conferência de especialistas celebrada em Darmouth Colege\" Gubern, Román: O Eros Eletrónico), a define como \"a ciência e engenharia de produzir sistemas inteligentes\". É uma área de"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_22", "text": "em 1956 (\"numa conferência de especialistas celebrada em Darmouth Colege\" Gubern, Román: O Eros Eletrónico), a define como \"a ciência e engenharia de produzir sistemas inteligentes\". É uma área de pesquisa da computação dedicada a buscar métodos ou dispositivos computacionais que possuam ou multipliquem a capacidade racional do ser humano de resolver problemas, pensar ou, de forma ampla, ser inteligente. Nas últimas décadas, o campo exoandiu-se para incluir subáreas como aprendizado de máquina, redes neurais artificiais, processamento de linguagem natural e visão computacional, com ênfase crescente em técnicas estatísticas, métodos conexionistas e abordagens híbridas que combinam modelos simbólicos e aprendizagem profunda.. Também pode ser definida como o ramo da ciência da computação que se ocupa do comportamento inteligente ou ainda, o estudo de como fazer os computadores realizarem coisas que, atualmente, os humanos fazem melhor. Não existe uma teoria ou paradigma unificador que"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_23", "text": "se ocupa do comportamento inteligente ou ainda, o estudo de como fazer os computadores realizarem coisas que, atualmente, os humanos fazem melhor. Não existe uma teoria ou paradigma unificador que orienta a pesquisa de IA. Pesquisadores discordam sobre várias questões. Algumas das perguntas constantes mais longas que ficaram sem resposta são as seguintes: a inteligência artificial deve simular inteligência natural, estudando psicologia ou neurociência? Ou será que a biologia humana é tão irrelevante para a pesquisa de IA como a biologia das aves é para a engenharia aeronáutica? O comportamento inteligente pode ser descrito usando princípios simples e elegantes (como lógica ou otimização)? Ou ela necessariamente requer que se resolva um grande número de problemas completamente não relacionados? A inteligência pode ser reproduzida usando símbolos de alto nível, similares às palavras e ideias? Ou ela requer processamento \"sub-simbólico\"? John Haugeland, que cunhou o termo GOFAI (Good"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_24", "text": "A inteligência pode ser reproduzida usando símbolos de alto nível, similares às palavras e ideias? Ou ela requer processamento \"sub-simbólico\"? John Haugeland, que cunhou o termo GOFAI (Good Old-Fashioned Artificial Intelligence - Boa Inteligência Artificial à Moda Antiga), também propôs que a IA deve ser mais apropriadamente chamada de inteligência sintética, um termo que já foi adotado por alguns pesquisadores não-GOFAI. Nos anos de 1940 e 1950, um número de pesquisadores exploraram a conexão entre neurologia, teoria da informação e cibernética. Alguns deles construíram máquinas que usaram redes eletrônicas para exibir inteligência rudimentar, como as tartarugas de W. Grey Walter e a Besta de Johns Hopkins. Muitos desses pesquisadores se reuniram para encontros da Sociedade teleológica da Universidade de Princeton e o Ratio Club na Inglaterra. Em 1960, esta abordagem foi abandonada, apesar de seus elementos serem revividos na década de 1980. Inteligência computacional Interesse em"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_25", "text": "da Universidade de Princeton e o Ratio Club na Inglaterra. Em 1960, esta abordagem foi abandonada, apesar de seus elementos serem revividos na década de 1980. Inteligência computacional Interesse em redes neurais e \"conexionismo\" foi revivida por David Rumelhart e outros em meados de 1980. Estas e outras abordagens sub-simbólicas, como sistemas de fuzzy e computação evolucionária, são agora estudados coletivamente pela disciplina emergente inteligência computacional. A IA tipo fraca, limitada, ou estreita (em inglês Narrow AI) são máquinas ou sistemas inteligentes que não fazem raciocínio; é limitada porque foi projetada para fazer uma tarefa específica, após ser treinado por um humano. Ou seja, não aprende de forma autônoma. Como por exemplo reconhecer comandos de voz e encontrar a rota mais rápida. A AGI possui a habilidade de compreender e adaptar-se a vários contextos (e desafios) de forma autônoma sem a necessidade treinamento. Máquinas com inteligência versátil semelhante à"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_26", "text": "mais rápida. A AGI possui a habilidade de compreender e adaptar-se a vários contextos (e desafios) de forma autônoma sem a necessidade treinamento. Máquinas com inteligência versátil semelhante à humana, aprende de forma autônoma. Considerada o futuro da IA (especulação), com a criação de máquinas com capacidade de tomar decisões e analisar dados de forma extremamente rápida, superando a IA forte. Conseguem responder rapidamente as tarefas imediatas, mas não conseguem armazenar memória, não melhoraram sua funcionalidade com a experiência (não aprendem). Como por exemplo o mecanismo de recomendação da Netflix, que analisa o histórico do usuário para sugerir um filme/série. É um subcampo da inteligência artificial, na qual uma máquina aprende, ou seja, é ensinada a partir de algoritmos a realizar uma tarefa determinada, entendendo um padrão. Uma estrutura computacional inspirado na estrutura neural do ser humano para simular o cérebro humano, como por exemplo o algoritmo usado no"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_27", "text": "a realizar uma tarefa determinada, entendendo um padrão. Uma estrutura computacional inspirado na estrutura neural do ser humano para simular o cérebro humano, como por exemplo o algoritmo usado no buscador do Google; esta reconhece os termos pesquisados, busca os sinônimos e, assuntos relacionados para assim gerar melhores resultados. É um sistema inteligente com habilidade de interpretar as emoções de pessoas e animais. Um termo emprestado da psicologia, que é a habilidade dos humanos de ler as emoções dos outros e prever ações. Autoconsciente ou ponto de singularidade da IA ou, como defende a academia, senciência da IA, é um estágio hipotético da inteligência artificial em que as máquinas possuem autoconsciência. Um estágio além da teoria da mente e é um dos objetivos finais no desenvolvimento da IA. A investigação recente destaca também os impactos económicos e sociais associados a sistemas de IA avançados, incluindo a automatização de empregos, a concentração de poder tecnológico"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_28", "text": "da IA. A investigação recente destaca também os impactos económicos e sociais associados a sistemas de IA avançados, incluindo a automatização de empregos, a concentração de poder tecnológico e riscos éticos ligados a uma eventual senciência. Estes fatores têm motivado debates académicos sobre regulação, governança e segurança no desenvolvimento da inteligência artificial. Permite que as máquinas/sistemas conversem com os humanos usando a linguagem humana, como por exemplo o uso da Alexa e da Siri. Os assistentes pessoais fazem parte da Inteligência Artificial Estreita (ANI), limitação da IA de executar um conjunto de tarefas específicas. Os sistemas de navegação fazem tarefas bem definidas, como encontrar a rota mais rápida de um ponto a outro. Faz analise e descreve imagens e vídeos, podendo reconhecer objetos e detectar movimentos, mapear um ambiente físico. São máquinas ou sistemas inteligentes usados na indústria , que possuem a capacidade de tomar decisões/fazer ações"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_29", "text": "vídeos, podendo reconhecer objetos e detectar movimentos, mapear um ambiente físico. São máquinas ou sistemas inteligentes usados na indústria , que possuem a capacidade de tomar decisões/fazer ações programadas a partir da coleta de informações do ambiente (como por exemplo a umidade e a temperatura). Capacidade de identificar objetos e capacidade de navegar em diferentes ambientes de forma autônoma, como por exemplo a Figure AI que está construindo robôs humanoides bípedes para trabalharem com os humanos. IA que é cria voz humana realista, transformando texto em voz, modificação do timbre, entonação da fala e, velocidade da voz. São sistemas inteligentes que conseguem criar roteiros, poesias, imagens e vídeos, não limitado apenas em analisar dados. Entre os teóricos que estudam o que é possível fazer com a IA existe uma discussão onde se consideram duas propostas básicas: uma conhecida como \"forte\" e outra conhecida como \"fraca\". Basicamente, a hipótese da IA forte considera ser"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_30", "text": "é possível fazer com a IA existe uma discussão onde se consideram duas propostas básicas: uma conhecida como \"forte\" e outra conhecida como \"fraca\". Basicamente, a hipótese da IA forte considera ser possível criar uma máquina consciente, ou seja, afirma que os sistemas artificiais devem replicar a mentalidade humana. A investigação em Inteligência Artificial Forte aborda a criação da forma de inteligência baseada em computador que consiga raciocinar e resolver problemas; uma forma de IA forte é classificada como auto-consciente. A IA forte é tema bastante controverso, pois envolve temas como consciência e fortes problemas éticos ligados ao que fazer com uma entidade que seja cognitivamente indistinguível de seres humanos. A ficção científica tratou de muitos problemas desse tipo. Isaac Asimov, por exemplo, escreveu O Homem Bicentenário, onde um robô consciente e inteligente luta para possuir um status semelhante ao de um humano na sociedade. E Steven Spielberg dirigiu \"A.I."}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_31", "text": "Isaac Asimov, por exemplo, escreveu O Homem Bicentenário, onde um robô consciente e inteligente luta para possuir um status semelhante ao de um humano na sociedade. E Steven Spielberg dirigiu \"A.I. Inteligência Artificial\" onde um garoto-robô procura conquistar o amor de sua \"mãe\", procurando uma maneira de se tornar real. Por outro lado, o mesmo Asimov reduz os robôs a servos dos seres humanos ao propor as três leis da robótica. Stephen Hawking alertou sobre os perigos da inteligência artificial e considerou uma ameaça à sobrevivência da humanidade (ver: Rebelião das máquinas). Trata-se da noção de como lidar com problemas não determinísticos. Uma contribuição prática de Alan Turing foi o que se chamou depois de Teste de Turing (TT), de 1950: em lugar de responder à pergunta \"podem-se ter computadores inteligentes?\" ele formulou seu teste, que se tornou praticamente o ponto de partida da pesquisa em \"Inteligência Artificial\". O teste consiste em se fazer perguntas a uma pessoa e um"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_32", "text": "computadores inteligentes?\" ele formulou seu teste, que se tornou praticamente o ponto de partida da pesquisa em \"Inteligência Artificial\". O teste consiste em se fazer perguntas a uma pessoa e um computador escondidos. Um computador e seus programas passam no TT se, pelas respostas, for impossível a alguém distinguir qual interlocutor é a máquina e qual é a pessoa. No seu artigo original ele fez a previsão de que até 2000 os computadores passariam seu teste. Pois bem, há um concurso anual de programas para o TT, e o resultado dos sistemas ganhadores é tão fraco (o último tem o nome \"Ella\") que com poucas perguntas logo percebe-se as limitações das respostas da máquina. É interessante notar que tanto a Máquina de Turing quanto o Teste de Turing talvez derivem da visão que Turing tinha de que o ser humano é uma máquina. Há quem diga que essa visão está absolutamente errada, do ponto de vista linguístico, já que associamos à \"máquina\" um artefato inventado e eventualmente construído."}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_33", "text": "que o ser humano é uma máquina. Há quem diga que essa visão está absolutamente errada, do ponto de vista linguístico, já que associamos à \"máquina\" um artefato inventado e eventualmente construído. Dizem eles: \"Nenhum ser humano foi inventado ou construído\". Afirma-se ainda que a comparação, feita por Turing, entre o homem e a máquina é sinônimo de sua \"ingenuidade social\", pois as máquinas são infinitamente mais simples do que o homem, apesar de, paradoxalmente, se afirmar que a vida é complexa. No entanto, esta linha de raciocínio é questionável, afinal de contas, os computadores modernos podem ser considerados \"complexos\" quando comparados ao COLOSSUS (computador cujo desenvolvimento foi liderado por Tommy Flowers, em 1943), ou a qualquer máquina do início do século XX. A inteligência artificial fraca centra a sua investigação na criação de inteligência artificial que não é capaz de verdadeiramente raciocinar e resolver problemas. Uma tal máquina com esta característica de"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_34", "text": "artificial fraca centra a sua investigação na criação de inteligência artificial que não é capaz de verdadeiramente raciocinar e resolver problemas. Uma tal máquina com esta característica de inteligência agiria como se fosse inteligente, mas não tem autoconsciência ou noção de si. O teste clássico para aferição da inteligência em máquinas é o Teste de Turing. Há diversos campos dentro da IA fraca, e um deles é o Processamento de linguagem natural, que trata de estudar e tentar reproduzir os processos de desenvolvimento que resultaram no funcionamento normal da língua. Muitos destes campos utilizam softwares específicos e linguagens de programação criadas para suas finalidades. Um exemplo é o chatbot Eliza, desenvolvido por Joseph Weizenbaum no laboratório de Inteligência Artificial do MIT entre os anos de 1964 e 1966. Outro exemplo bastante conhecido é o programa A.L.I.C.E. (Artificial Linguistic Internet Computer Entity, ou Entidade Computadorizada de Linguagem Artificial para"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_35", "text": "do MIT entre os anos de 1964 e 1966. Outro exemplo bastante conhecido é o programa A.L.I.C.E. (Artificial Linguistic Internet Computer Entity, ou Entidade Computadorizada de Linguagem Artificial para Internet), um software que simula uma conversa humana. Programado em Java e desenvolvido com regras heurísticas para os caracteres de conversação, seu desenvolvimento resultou na AIML (Artificial Intelligence Markup Language), uma linguagem específica para tais programas e seus vários clones, chamados de Alicebots. Muito do trabalho neste campo tem sido feito com simulações em computador de inteligência baseado num conjunto predefinido de regras. Poucos têm sido os progressos na IA forte. Mas dependendo da definição de IA utilizada, pode-se dizer que avanços consideráveis na IA fraca já foram alcançados. Muitos filósofos, sobretudo John Searle e Hubert Dreyfus, inseriram no debate questões de ordem filosófica e epistemológica, questionando qualquer possibilidade efetiva da IA forte."}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_36", "text": "foram alcançados. Muitos filósofos, sobretudo John Searle e Hubert Dreyfus, inseriram no debate questões de ordem filosófica e epistemológica, questionando qualquer possibilidade efetiva da IA forte. Seriam falsos, assim, os próprios pressupostos da construção de uma inteligência ou consciência semelhante à humana em uma máquina. Searle é bastante conhecido por seu contra-argumento sobre o Quarto Chinês (ou Sala Chinesa), que inverte a questão colocada por Minsky a respeito do Teste de Turing. Seu argumento diz que ainda que uma máquina possa parecer falar chinês por meio de recursos de exame comparativo com mostras e tabelas de referência, binárias, isso não implica que tal máquina fale e entenda efetivamente a língua. Ou seja, demonstrar que uma máquina possa passar no Teste de Turing não necessariamente implica um ser consciente, tal como entendido em seu sentido humano. Dreyfus, em seu livro O que os computadores ainda não conseguem fazer: Uma crítica ao raciocínio artificial,"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_37", "text": "não necessariamente implica um ser consciente, tal como entendido em seu sentido humano. Dreyfus, em seu livro O que os computadores ainda não conseguem fazer: Uma crítica ao raciocínio artificial, argumenta que a consciência não pode ser adquirida por sistemas baseados em regras ou lógica; tampouco por sistemas que não façam parte de um corpo físico. No entanto, este último autor deixa aberta a possibilidade de um sistema robótico baseado em Redes Neuronais, ou em mecanismos semelhantes, alcançar a inteligência artificial. Mas já não seria a referida IA forte, mas sim um correlato bem mais próximo do que se entende por IA fraca. Os revezes que a acepção primeira de Inteligência Artificial vem levando nos últimos tempos contribuíram para a imediata relativização de todo seu legado. O papel de Marvin Minsky, figura proeminente do MIT e autor de Sociedade da Mente, fora central para a acepção de uma IA linear que imitaria com perfeição a mente humana, mas seu principal feito foi"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_38", "text": "O papel de Marvin Minsky, figura proeminente do MIT e autor de Sociedade da Mente, fora central para a acepção de uma IA linear que imitaria com perfeição a mente humana, mas seu principal feito foi construir o primeiro computador baseado em redes neurais, conhecido como Snark, tendo simplesmente fracassado pois nunca executou qualquer função interessante, apenas consumiu recursos de outras pesquisas mais promissoras. O primeiro neuro computador a obter sucesso (Mark I Perceptron) surgiu em 1957 e 1958, criado por Frank Rosenblatt, Charles Wightman e outros. Atualmente, no entanto, as vertentes que trabalham com os pressupostos da emergência e com elementos da IA fraca parecem ter ganhado proeminência do campo. As críticas sobre a impossibilidade de criar uma inteligência em um composto artificial podem ser encontradas em Jean-François Lyotard (O Pós-humano) e Lucien Sfez (Crítica da Comunicação); uma contextualização didática do debate encontra-se em Sherry Turkle (O segundo Eu: os"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_39", "text": "artificial podem ser encontradas em Jean-François Lyotard (O Pós-humano) e Lucien Sfez (Crítica da Comunicação); uma contextualização didática do debate encontra-se em Sherry Turkle (O segundo Eu: os computadores e o espírito humano). Pode-se resumir o argumento central no fato de que a própria concepção de inteligência é humana e, nesse sentido, animal e biológica. A possibilidade de transportá-la para uma base plástica, artificial, encontra um limite claro e preciso: se uma inteligência puder ser gerada a partir destes elementos, deverá ser necessariamente diferente da humana, na medida em que o seu resultado provém da emergência de elementos totalmente diferentes dos encontrados nos humanos. A inteligência, tal como a entendemos, é essencialmente o fruto do cruzamento da uma base biológica com um complexo simbólico e cultural, impossível de ser reproduzido artificialmente. Outros filósofos sustentam visões diferentes. Ainda que não vejam problemas com a IA fraca, entendem que há"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_40", "text": "com um complexo simbólico e cultural, impossível de ser reproduzido artificialmente. Outros filósofos sustentam visões diferentes. Ainda que não vejam problemas com a IA fraca, entendem que há elementos suficientes para se crer na IA forte também. Daniel Dennett argumenta em Consciência Explicada que se não há uma centelha mágica ou alma nos seres humanos, então o Homem é apenas uma outra máquina. Dennett questiona por que razão o Homem-máquina deve ter uma posição privilegiada sobre todas as outras possíveis máquinas quando provido de inteligência. Alguns autores sustentam que se a IA fraca é possível, então também o é a forte. O argumento da IA fraca, de uma inteligência imitada mas não real, desvelaria assim uma suposta validação da IA forte. Isso se daria porque, tal como entende Simon Blackburn em seu livro Think, dentre outros, não existe a possibilidade de verificar se uma inteligência é verdadeira ou não. Estes autores argumentam que toda inteligência apenas parece"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_41", "text": "Simon Blackburn em seu livro Think, dentre outros, não existe a possibilidade de verificar se uma inteligência é verdadeira ou não. Estes autores argumentam que toda inteligência apenas parece inteligência, sem necessariamente o ser. Parte-se do princípio que é impossível separar o que é inteligência de fato do que é apenas simulação: apenas acredita-se ser. Estes autores rebatem os argumentos contra a IA forte dizendo que seus críticos reduzem-se a arrogantes que não podem entender a origem da vida sem uma centelha mágica, um Deus ou uma posição superior qualquer. Eles entenderiam, em última instância, máquina como algo essencialmente incapaz e sequer conseguem supô-la como capaz de inteligência. Nos termos de Minsky, a crítica contra a IA forte erra ao supor que toda inteligência derive de um sujeito - tal como indicado por Searle - e assim desconsidera a possibilidade de uma maquinaria complexa que pudesse pensar. Mas Minsky desconsidera o simples fato de que os maiores avanços na"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_42", "text": "de um sujeito - tal como indicado por Searle - e assim desconsidera a possibilidade de uma maquinaria complexa que pudesse pensar. Mas Minsky desconsidera o simples fato de que os maiores avanços na área foram conseguidos com \"maquinaria complexa\", também chamada por pesquisadores mais importantes de Inteligência Artificial Conexista. Se a crítica de Minsky fosse válida a maquina criada por Rosenblatt e Bernard Widrow não estaria em uso ainda hoje, e o Mark I Perceptron não seria o fundador da neuro-computação. Alguns pesquisadores importantes afirmam que um dos motivos das críticas de Minsky foi o fato de ter falhado com Snark. A partir daí começou a criticar essa área por não compreende-la completamente, prejudicando desde então pesquisas importantes sobre o assunto. O debate sobre a IA reflete, em última instância, a própria dificuldade da ciência contemporânea em lidar efetivamente com a ausência de um primado superior. Os argumentos pró-IA forte são esclarecedores dessa questão,"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_43", "text": "reflete, em última instância, a própria dificuldade da ciência contemporânea em lidar efetivamente com a ausência de um primado superior. Os argumentos pró-IA forte são esclarecedores dessa questão, pois são os próprios cientistas, que durante décadas tentaram e falharam ao criar uma IA forte, que ainda procuram a existência de uma ordem superior. Ainda que a IA forte busque uma ordem dentro da própria conjugação dos elementos internos, trata-se ainda da suposição de que existe na inteligência humana uma qualidade superior que deve ser buscada, emulada e recriada. Reflete, assim, a difícil digestão do legado radical da Teoria da Evolução, onde não existe positividade alguma em ser humano e ser inteligente; trata-se apenas de um complexo de relações que propiciaram um estado particular, produto de um cruzamento temporal entre o extrato biológico e uma complexidade simbólica. É argumentado também que a inteligência artificial ainda não é desenvolvida ao ponto de atuar como o cérebro"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_44", "text": "produto de um cruzamento temporal entre o extrato biológico e uma complexidade simbólica. É argumentado também que a inteligência artificial ainda não é desenvolvida ao ponto de atuar como o cérebro humano, de forma criativa. Ademais, o cérebro humano ainda não é suficientemente compreendido. Portanto, a ideia de replicar funções do cérebro humano é atualmente intangível. A IA pode ser uma arma quando usada por pessoas mal-intencionadas, como por exemplo o uso da ferramenta deepfake para golpe. A criação destes sistemas podem gerar vazamento de dados ou acidentes com veículos autônomos. Foi provado que um simulador qualitativo, completo e robusto não pode existir, ou seja, desde que o vocabulário entrada-saída seja usado (como num algoritmo QSIM), haverá sempre modelos de entrada que causam predições erradas na sua saída. Por exemplo, a noção de infinito é impossível ser tida por uma máquina finita (computador ou neurónios se produzirem apenas um número finito de resultados num número"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_45", "text": "predições erradas na sua saída. Por exemplo, a noção de infinito é impossível ser tida por uma máquina finita (computador ou neurónios se produzirem apenas um número finito de resultados num número finito de tempo). Neste caso é um simples paradoxo matemático, porque são em número finito as combinações saídas de qualquer conjunto finito. Se a noção de infinito pudesse ser obtida por uma certa combinação finita, isso significaria que o infinito seria equivalente a essa sequência finita, o que é obviamente uma contradição. Por isso, o infinito e outras noções abstratas têm que ser pré-adquiridas numa máquina finita, não são aí programáveis. A inteligência artificial, em um contexto amplo, possui aplicações diversas, sendo empregada na resolução de problemas práticos por entidades civis, governamentais, e militares. Possui aplicações na área da saúde, mídia e comércio eletrônico, entre outros. Há uma discussão sobre como a IA tem sido integrada em sistemas de planejamento automatizado,"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_46", "text": "e militares. Possui aplicações na área da saúde, mídia e comércio eletrônico, entre outros. Há uma discussão sobre como a IA tem sido integrada em sistemas de planejamento automatizado, diagnóstico médico, utilização por advogados (IA para advogados), reconhecimento de linguagem e muito mais, mostrando a ampla gama de aplicações e o impacto profundo da IA em múltiplas áreas. A adoção ggeberalizada da inteligência artificial levanta preocupações quanto ao seu impacto no emprego e na distribuição de riqueza. Vários estudos recentes indicam que a automação de tarefas cognitivas e rotineiras pode levar ao deslocamento de trabalhadores em setores como transporte, serviços financeiros, atendimento ao cliente entre outros. Entre as funções com maior probabilidade de extinção, a literatura destaca tarefas como produção de conteúdo padronizado, atendimento e vendas roteirizadas, backoffice administrativo, contabilidade simples, análise repetitiva de risco, programação elementar, design"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_47", "text": "destaca tarefas como produção de conteúdo padronizado, atendimento e vendas roteirizadas, backoffice administrativo, contabilidade simples, análise repetitiva de risco, programação elementar, design baseadado em modelos, mediação transacional, formação padronizada, suporte técnico básico, revisão e formatação textual, pesquisa documental simples, edição de imagem para comércio eletrónico e até memdo o comércio electrónico na parte da fixação de preços, descrições automáticas de produtos, relatórios de gestão recorrentes, prospeção de leads genéricos, curadoria de catálogos e auditorias baseadas em listas de verificação. A concentração de capacidades tecnológicas em poucas empresas e países também é alvo de debate, dado o risco de aprofundar desigualdades económicas e sociais. Estas questões têm impulsionado propostas para políticas de requalificação profissional, regulação de algoritmos e desenvolvimento ético da IA, de modo a equilibrar eficiência tecnológica e justiça social."}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_48", "text": "questões têm impulsionado propostas para políticas de requalificação profissional, regulação de algoritmos e desenvolvimento ético da IA, de modo a equilibrar eficiência tecnológica e justiça social. Atualmente existem diversos pesquisadores de IA ao redor do mundo em várias instituições e companhias de pesquisa. Entre os muitos que fizeram contribuições significativas estão: O matemático britânico Alan Turing foi um dos pioneiros na área que mais tarde daria origem à Inteligência artificial. Além de ter criado o “Teste de Turing”, usado para avaliar a capacidade de uma máquina imitar respostas humanas, os seus trabalhos em lógica matemática e computação teórica estabeleceram as bases para a ciência da computação moderna. Matemático, cientista, o criador do termo “inteligência artificial” e também o pai da linguagem de programação LISP. McCarthy foi considerado um dos primeiros homens a trabalhar no desenvolvimento da inteligência artificial e sempre disse que ela deveria interagir"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_49", "text": "e também o pai da linguagem de programação LISP. McCarthy foi considerado um dos primeiros homens a trabalhar no desenvolvimento da inteligência artificial e sempre disse que ela deveria interagir com o homem. Nascido na cidade de Boston, trabalhou na Universidade de Stanford e no Massachusetts Institute of Technology (MIT), além de ter vencido o prêmio Turing em 1972 e a Medalha Nacional de Ciência em 1991. Já a programação LISP, uma das maiores conquistas de McCarthy, surgiu em 1958 e serviu para facilitar o desenvolvimento da inteligência artificial. A linguagem é das mais antigas ainda em uso e foi usada pela primeira vez ao colocar um computador para jogar xadrez contra um adversário humano. Natural de Nova Iorque, onde nasceu, o cientista recebeu diversos prémios internacionais pelo seu trabalho pioneiro no campo da inteligência artificial, incluindo em 1969, o Prêmio Turing, o maior prêmio em ciência informática. O cientista explorou a forma de dotar as máquinas de percepção e"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_50", "text": "seu trabalho pioneiro no campo da inteligência artificial, incluindo em 1969, o Prêmio Turing, o maior prêmio em ciência informática. O cientista explorou a forma de dotar as máquinas de percepção e inteligência semelhantes à humana, criou mãos robóticas com capacidade para manipular objetos, desenvolveu novos marcos de programação e escreveu sobre assuntos filosóficos relacionados com a inteligência artificial. Minsky estava convencido de que o homem, um dia, desenvolveria máquinas que competiriam com a sua inteligência e via o cérebro como uma máquina cujo funcionamento pode ser estudado e reproduzido num computador, o que poderia ajudar a compreender melhor o cérebro humano e as funções mentais superiores. Informático indiano naturalizado estadunidense, foi o primeiro asiático a vencer o Prêmio Turing. Entre suas contribuições para a IA estão a criação do Instituto de Robótica da CMU e demonstrações de diversos sistemas que usam alguma forma de IA. Entre esses sistemas, estão"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_51", "text": "o Prêmio Turing. Entre suas contribuições para a IA estão a criação do Instituto de Robótica da CMU e demonstrações de diversos sistemas que usam alguma forma de IA. Entre esses sistemas, estão sistemas de: fala, controlados por voz, reconhecimento de voz, reconhecimento de voz independente do interlocutor, etc. Para Reddy, ao invés de substituir a humanidade, a tecnologia irá criar um novo tipo de humano que irá coexistir com seus antecessores enquanto se aproveita das vantagens de uma nova classe de ferramentas viabilizada pela tecnologia. Winograd é um cientista da computação estadunidense, professor da Universidade Stanford, e codiretor do grupo de interação humano-computador de Stanford. É conhecido nas áreas de filosofia da mente e inteligência artificial por seu trabalho sobre língua natural usando o programa SHRDLU. Para Terry, não restam dúvidas de que a tecnologia da informática, mais precisamente a área de inteligência artificial, transformará as sociedades, introduzindo"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_52", "text": "natural usando o programa SHRDLU. Para Terry, não restam dúvidas de que a tecnologia da informática, mais precisamente a área de inteligência artificial, transformará as sociedades, introduzindo modificações socioeconômicas irreversíveis. Esse especialista procura saber se os seres humanos seriam capazes de construir máquinas que poderiam compreende-los, resolver seus problemas e dirigir suas vidas, além de buscar respostas sobre o que aconteceria se, algum dia, essas máquinas se tornassem mais inteligentes do que os próprios humanos que as criaram. Nascido na Filadélfia, Pensilvânia, se formou na Universidade da Pensilvânia. Douglas Bruce Lenat é o Diretor Executivo do Cycorp e foi também um pesquisador proeminente em inteligência artificial, recebendo o prêmio bianual IJCAI Computers and Thought em 1976 pela criação do programa de aprendizado de máquinas. Ele também trabalhou em simulações militares e em numerosos projetos para organizações governamentais, militares, científicas e"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_53", "text": "Thought em 1976 pela criação do programa de aprendizado de máquinas. Ele também trabalhou em simulações militares e em numerosos projetos para organizações governamentais, militares, científicas e de inteligência dos EUA. A missão de Lenat, no longo ciclo do projeto Cyc, iniciado em 1984, era de construir a base de uma inteligência artificial geral ao representar manualmente o conhecimento como axiomas lógicos contextualizados na linguagem formal com base em extensões ao cálculo de predicados de primeira ordem e em seguida, usar esse enorme motor de inferência de ontologia e a base de conhecimento contextualizada como um viés indutivo para automatizar e acelerar cada vez mais a educação contínua do próprio Cyc, via aprendizagem em máquina e compreensão da linguagem natural. Ablação (inteligência artificial) Alinhamento da inteligência artificial Lista de projetos de inteligência artificial Segurança da inteligência artificial OpenAI OpenAI Codex Realidade simulada Robocode"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_54", "text": "(inteligência artificial) Alinhamento da inteligência artificial Lista de projetos de inteligência artificial Segurança da inteligência artificial OpenAI OpenAI Codex Realidade simulada Robocode Transferência de energia sem fio «Programa do governo para defender suas questões». (em português) «American Association for Artificial Intelligence» (em inglês) História da IA no YouTube"}
{"source": "História da inteligência artificial", "chunk_id": "História da inteligência artificial_0", "text": "A História da Inteligência Artificial (IA) começou na antiguidade com mitos, histórias e rumores de seres artificiais dotados com inteligência ou consciência pelos seus fabricantes; conforme a escritora e historiadora britânica Pamela Ann McCorduck escreve em seu livro Máquinas que pensam (1979), Inteligência Artificial começou com \"um desejo antigo de forjar os deuses\". Desde o início os fundamentos da inteligência artificial tiveram o suporte de várias disciplinas que contribuíram com ideias, pontos de vista e técnicas para a IA. Os filósofos (desde 400 a.C.) tornaram a IA concebível, considerando as ideias de que a mente é, em alguns aspectos, semelhante a uma máquina, de que ela opera sobre o conhecimento codificado em alguma linguagem interna e que o pensamento pode ser usado para escolher as ações que deverão ser executadas. Por sua vez, os matemáticos forneceram as ferramentas para manipular declarações de certeza lógica, bem como declarações incertas e probabilísticas. Eles"}
{"source": "História da inteligência artificial", "chunk_id": "História da inteligência artificial_1", "text": "escolher as ações que deverão ser executadas. Por sua vez, os matemáticos forneceram as ferramentas para manipular declarações de certeza lógica, bem como declarações incertas e probabilísticas. Eles também definiram a base para a compreensão da computação e do raciocínio sobre algoritmos. Os economistas formalizaram o problema de tomar decisões que maximizam o resultado esperado para o tomador de decisões. Os psicólogos adotaram a ideia de que os seres humanos e os animais podem ser considerados máquinas de processamento de informações. Os linguistas mostraram que o uso da linguagem se ajusta a esse modelo. Os engenheiros de computação fornecem os artefatos que tornam possíveis as aplicações de IA. Os programas de IA tendem a ser extensos e não poderiam funcionar sem os grandes avanços em velocidade e memória que a indústria de informática tem proporcionado. As sementes da IA moderna foram plantadas pelos filósofos clássicos que tentaram descrever o processo de pensamento humano como"}
{"source": "História da inteligência artificial", "chunk_id": "História da inteligência artificial_2", "text": "velocidade e memória que a indústria de informática tem proporcionado. As sementes da IA moderna foram plantadas pelos filósofos clássicos que tentaram descrever o processo de pensamento humano como um mecanismo de manipulação de símbolos. Este trabalho culminou com a invenção do computador digital programável na década de 1940, uma máquina baseada na essência abstrata da razão matemática. Este dispositivo e as idéias por trás inspiraram cientistas a começar a discutir seriamente a possibilidade de construir um cérebro eletrônico. 1940 - robôs e GPS O interesse no desenvolvimento de máquinas autônomas capazes de simular o pensamento humano e de realizar varias tarefas cresceu vertiginosamente nas últimas décadas, da segunda metade do século XX, realizando assim os primeiros estudos sobre inteligência artificial (IA) a um propósito comum, a partir de iniciativas de cientistas de diversas áreas, como: psicologia, ciência cognitiva, ciência da computação e, robótica. Ferramentas"}
{"source": "História da inteligência artificial", "chunk_id": "História da inteligência artificial_3", "text": "sobre inteligência artificial (IA) a um propósito comum, a partir de iniciativas de cientistas de diversas áreas, como: psicologia, ciência cognitiva, ciência da computação e, robótica. Ferramentas eficientes em analisar problemas e oferecer soluções e planejamentos (tomada de decisão), automatização de tarefas no cotidiano das pessoas. Nas décadas de 1940 e 1950, diversos pesquisadores investigaram a interseção entre neurologia, teoria da informação e cibernética. Alguns deles desenvolveram dispositivos que empregavam redes eletrônicas para demonstrar formas elementares de inteligência, exemplificadas pelas tartarugas-robôs de William Grey Walter e o robô a Besta, construído na Universidade Johns Hopkins. Esses estudiosos frequentemente participavam de reuniões na Sociedade Teleológica da Universidade de Princeton e no Ratio Club na Inglaterra. Os estágios iniciais da IA foram marcados por avanços, embora de maneira restrita. Levando em conta as primeiras máquinas computadores, as"}
{"source": "História da inteligência artificial", "chunk_id": "História da inteligência artificial_4", "text": "da Universidade de Princeton e no Ratio Club na Inglaterra. Os estágios iniciais da IA foram marcados por avanços, embora de maneira restrita. Levando em conta as primeiras máquinas computadores, as ferramentas de programação disponíveis naquela época e considerando que apenas alguns anos antes os computadores eram percebidos apenas como dispositivos capazes de realizar operações aritméticas, era surpreendente ver um computador executando qualquer atividade que pudesse ser considerada remotamente inteligente. 1950 - IA experimental O desenvolvimento da IA se deu de forma plena no século XX, logo após a Segunda Guerra Mundial, com a publicação do artigo Computing Machinery and Intelligence, na revista científica Mind, em 1950, pelo matemático inglês Alan Turing. A inteligência artificial começou como um campo experimental nos anos 50 com pioneiros como Allen Newell e Herbert Simon, que fundaram o primeiro laboratório de inteligência artificial na Universidade Carnegie Mellon, e John"}
{"source": "História da inteligência artificial", "chunk_id": "História da inteligência artificial_5", "text": "começou como um campo experimental nos anos 50 com pioneiros como Allen Newell e Herbert Simon, que fundaram o primeiro laboratório de inteligência artificial na Universidade Carnegie Mellon, e John McCarthy e Marvin Minsky, que fundaram o MIT Computer Science and Artificial Intelligence Laboratory[[1]], em 1959. Foram eles alguns dos participantes na famosa conferência de verão de 1956 em Darthmouth College. Aqueles que participaram do evento viriam a ser os líderes na pesquisa com IA por décadas. Muitos deles prediziam que uma máquina tão inteligente quando um ser humano iria existir em não mais do que uma geração. Eventualmente, ficou óbvio de que eles subestimaram grosseiramente as dificuldades para o projeto. O sucesso inicial prosseguiu com o General Problem Solver (Solucionador de problemas gerais) ou GPS, desenvolvido por Newell e Simon. Esse programa foi projetado para imitar protocolos humanos de resolução de problemas. Dentro da classe limitada de quebra-cabeças com a qual"}
{"source": "História da inteligência artificial", "chunk_id": "História da inteligência artificial_6", "text": "problemas gerais) ou GPS, desenvolvido por Newell e Simon. Esse programa foi projetado para imitar protocolos humanos de resolução de problemas. Dentro da classe limitada de quebra-cabeças com a qual podia lidar, verificou-se que a ordem em que os seres humanos abordavam os mesmos problemas. Desse modo, o GPS talvez tenha sido o primeiro programa a incorporar a abordagem de “pensar de forma humana”. 1960 / 1970 - Conexão Nas décadas de 60 e 70, os pesquisadores focados em conexão foram afastados do centro das investigações em IA, no entanto, o interesse por essa abordagem foi revivido nos anos 80, à medida que as limitações da IA tradicional começaram a se tornar evidentes. Em 1960, esta abordagem foi abandonada, apesar de seus elementos serem revividos na década de 1980. Em 1973, em resposta ao criticismo de James Lighthill e a pressão crescente do congresso, o DARPA e o governo britânico pararam de financiar pesquisas indiretas sobre inteligência artificial. Sete anos depois, uma"}
{"source": "História da inteligência artificial", "chunk_id": "História da inteligência artificial_7", "text": "ao criticismo de James Lighthill e a pressão crescente do congresso, o DARPA e o governo britânico pararam de financiar pesquisas indiretas sobre inteligência artificial. Sete anos depois, uma visionária iniciativa do governo japonês inspirou governos e empresários a financiar bilhões em pesquisas mas posteriormente no final da década de 1980 os investidores viriam a se desiludir novamente. Estes ciclos de altos e baixos continuam a assombrar este campo de pesquisa. Ainda na atualidade existem predições extraordinárias de que até 2029 existirão máquinas com o nível de inteligência humano. 1980 - Inteligência computacional Na década de 1980, a pesquisa em inteligência artificial recebeu financiamento significativo da Agência de Projetos de Pesquisas Avançadas sobre Defesa (Defense Advanced Research Projects Agency - DARPA), nos Estados Unidos, e do Projeto da Quinta Geração, no Japão. O trabalho financiado não conseguiu fornecer resultados imediatos, apesar das promessas exageradas de"}
{"source": "História da inteligência artificial", "chunk_id": "História da inteligência artificial_8", "text": "Research Projects Agency - DARPA), nos Estados Unidos, e do Projeto da Quinta Geração, no Japão. O trabalho financiado não conseguiu fornecer resultados imediatos, apesar das promessas exageradas de alguns praticantes de IA. Isso resultou em cortes substanciais nos fundos de agências governamentais no final dos anos 80, levando a uma desaceleração das atividades no setor, conhecida como \"O Inverno da IA\". Ao longo da década seguinte, muitos pesquisadores de IA direcionaram seus esforços para áreas correlatas com objetivos mais modestos, como aprendizado de máquinas, robótica e visão computacional, embora as pesquisas em inteligência artificial pura tenham continuado em níveis reduzidos. O interesse em redes neurais e \"conexionismo\" foi revitalizado por David Rumelhart e colegas na década de 1980. Atualmente, essas abordagens e outras técnicas sub-simbólicas, como sistemas de lógica fuzzy e computação evolucionária, são examinadas de maneira conjunta dentro da disciplina em ascensão"}
{"source": "História da inteligência artificial", "chunk_id": "História da inteligência artificial_9", "text": "de 1980. Atualmente, essas abordagens e outras técnicas sub-simbólicas, como sistemas de lógica fuzzy e computação evolucionária, são examinadas de maneira conjunta dentro da disciplina em ascensão conhecida como inteligência computacional. Apenas recentemente, com o surgimento do computador moderno, é que a inteligência artificial ganhou meios e massa crítica para se estabelecer como ciência integral, com problemáticas e metodologias próprias. Desde então, seu desenvolvimento tem extrapolado os clássicos programas de xadrez ou de conversão e envolvido áreas como visão computacional, análise e síntese da voz, lógica difusa, redes neurais artificiais e muitas outras. Inicialmente, os modelos de IA visavam reproduzir o pensamento humano. Posteriormente, no entanto, tais modelos abraçaram a ideia de reproduzir capacidades humanas como criatividade, auto aperfeiçoamento e uso da linguagem. Porém, o conceito de inteligência artificial ainda é bastante difícil de se definir. Por essa razão,"}
{"source": "História da inteligência artificial", "chunk_id": "História da inteligência artificial_10", "text": "de reproduzir capacidades humanas como criatividade, auto aperfeiçoamento e uso da linguagem. Porém, o conceito de inteligência artificial ainda é bastante difícil de se definir. Por essa razão, Inteligência Artificial foi (e continua sendo) uma noção que dispõe de múltiplas interpretações, não raro conflitantes ou circulares. 2020 Observou-se uma revolução no campo da inteligência artificial, tanto em termos de conteúdo quanto de metodologia. Nesta década de 2020 tem sido mais prevalente a utilização de teorias existentes como fundamentos, em vez de propor teorias completamente novas. Além disso, há uma tendência em embasar as informações em teoremas rigorosos ou em evidências experimentais robustas, em contraste com o uso intuitivo como base. Destaca-se também uma maior ênfase na relevância de aplicações práticas em detrimento de exemplos hipotéticos. O progresso em pesquisas sobre inteligência artificial continua apesar dos altos e baixos de sua reputação aos olhos dos governos e"}
{"source": "História da inteligência artificial", "chunk_id": "História da inteligência artificial_11", "text": "de aplicações práticas em detrimento de exemplos hipotéticos. O progresso em pesquisas sobre inteligência artificial continua apesar dos altos e baixos de sua reputação aos olhos dos governos e aventureiros capitalistas. Problemas que pareciam não solucionáveis em 1970 foram resolvidos e as soluções são agora utilizadas comercialmente. Entretanto, nenhuma máquina foi construída ao nível de inteligência humano, ao contrário das predições otimistas da primeira geração de pesquisadores. \"Nós podemos ver somente a uma curta distância à frente,\" admitiu Alan Turing em um artigo da década de 1950 que catalisou a pesquisa moderna por máquinas pensantes. \"Mas,\" ele acrescentou, \"nós podemos ver que pode ser feito.\" Lista de projetos de inteligência artificial Este artigo foi inicialmente traduzido, total ou parcialmente, do artigo da Wikipédia em inglês cujo título é «History of artificial intelligence», especificamente desta versão. Kurzweil, Ray (2005), The Singularity Is Near, ISBN"}
{"source": "História da inteligência artificial", "chunk_id": "História da inteligência artificial_12", "text": "total ou parcialmente, do artigo da Wikipédia em inglês cujo título é «History of artificial intelligence», especificamente desta versão. Kurzweil, Ray (2005), The Singularity Is Near, ISBN 0-14-303788-9, Viking Press, OCLC 71826177 . Haenlein, Michael; Kaplan, Andreas (2019), «A Brief History of Artificial Intelligence: On the Past, Present, and Future of Artificial Intelligence», California Management Review . McCorduck, Pamela (2004), Machines Who Think, ISBN 1-56881-205-1 2nd ed. , Natick, MA: A. K. Peters, Ltd., OCLC 52197627 . Turing, Alan (Outubro de 1950), «Computing Machinery and Intelligence», Mind, ISSN 0026-4423, LIX (236): 433–460, doi:10.1093/mind/LIX.236.433, consultado em 18 de agosto de 2008, cópia arquivada em 2 de julho de 2008"}
{"source": "Inteligência artificial generativa", "chunk_id": "Inteligência artificial generativa_0", "text": "Inteligência artificial generativa ou IA generativa é um ramo da inteligência artificial focado na criação de conteúdo novo, baseado em padrões identificados nos conjuntos de dados de treinamento. É possível criar conteúdo como texto, imagens, áudio, vídeo, código de software, podendo ser gerados a partir de pedidos (ou prompts) em linguagem natural, ou até através de imagens para imagens, e de vídeos para vídeos. Essa forma de visualizar esses modelos é uma categorização baseado em formato de entrada e saída, de texto para texto (text-to-text), texto para imagem (text-to-image), entre vários outros. Sistemas de IA generativa incluem Stable Diffusion e DALL-E, modelos de imagens de inteligência artificial, assim como modelos de texto como o ChatGPT, um chatbot construído pela OpenAI usando os modelos de linguagem de grande escala GPT-3 e GPT-4, Bard, um chatbot construído pelo Google usando o modelo LaMDA, e o Microsoft Copilot , chatbot construído pela Microsoft que é uma extensão do"}
{"source": "Inteligência artificial generativa", "chunk_id": "Inteligência artificial generativa_1", "text": "os modelos de linguagem de grande escala GPT-3 e GPT-4, Bard, um chatbot construído pelo Google usando o modelo LaMDA, e o Microsoft Copilot , chatbot construído pela Microsoft que é uma extensão do modelo de linguagem GPT-4 da OpenAI e que foi pensada para uso vinculado aos serviços da Microsoft e sistema operacional Windows. IA generativa tem aplicações potenciais numa ampla gama de setores, incluindo desenvolvimento de software, marketing e moda. O investimento em IA generativa aumentou durante o início da década de 2020, com grandes empresas como Microsoft, Google e Baidu, bem como várias outras empresas menores a desenvolver modelos de IA generativa. E a Nvidia foi uma das empresas que mais cresceram nesse meio tempo, uma vez que começou a utilizar suas GPUs para o treinamento de grandes modelos de linguagem cada vez mais poderosos. Na saúde, a IA generativa também tem transformado e impactado significativamente o cuidado ao paciente, educação em saúde e pesquisas na área. As"}
{"source": "Inteligência artificial generativa", "chunk_id": "Inteligência artificial generativa_2", "text": "grandes modelos de linguagem cada vez mais poderosos. Na saúde, a IA generativa também tem transformado e impactado significativamente o cuidado ao paciente, educação em saúde e pesquisas na área. As oportunidades de desenvolvimento são grandes, no entanto, há desafios éticos que precisam ser considerados. Como um exemplo das aplicações da IA generativa, tem-se a transformação no campo da medicina, onde essa tecnologia tem expandido suas possibilidades, alterando a maneira como o cuidado é prestado, as funções dos profissionais de saúde e a comunicação entre pacientes e médicos. Além disso, a IA generativa tem mostrado grande potencial na melhoria da descoberta científica, como em ensaios clínicos e pesquisas observacionais, além de contribuir para a educação médica. Esses avanços são resultado do aprimoramento técnico da IA, que agora é capaz de gerar linguagem e imagens realistas, gerando discussões sobre a melhor forma de integrar esses modelos no contexto médico. Um sistema de IA"}
{"source": "Inteligência artificial generativa", "chunk_id": "Inteligência artificial generativa_3", "text": "do aprimoramento técnico da IA, que agora é capaz de gerar linguagem e imagens realistas, gerando discussões sobre a melhor forma de integrar esses modelos no contexto médico. Um sistema de IA generativo é construído aplicando aprendizado de máquina não supervisionado ou autossupervisionado a um conjunto de dados. As capacidades e aplicações de um sistema de IA generativo variam conforme a modalidade, ou seja, o tipo de dados e a tarefa específica para a qual foi treinado. A seguir, são descritas algumas das principais modalidades da IA generativa: Texto: sistemas de IA generativos treinados em palavras ou tokens de palavras incluem GPT-3, LaMDA, LLaMA, BLOOM, GPT-4 e outros (veja lista de modelos de linguagem grandes). Eles são capazes de processamento de linguagem natural, tradução automática e geração de linguagem natural e podem ser usados como modelos básicos para outras tarefas. Conjuntos de dados incluem BookCorpus, Wikipedia e outros. Modelos de textos são versáteis e têm"}
{"source": "Inteligência artificial generativa", "chunk_id": "Inteligência artificial generativa_4", "text": "automática e geração de linguagem natural e podem ser usados como modelos básicos para outras tarefas. Conjuntos de dados incluem BookCorpus, Wikipedia e outros. Modelos de textos são versáteis e têm demonstrado a capacidade de resolver diversas tarefas: de criar textos coerentes de diversas formatações, resumir textos longos extraindo informações-chave, são capazes de traduzir textos entre diversos idiomas com alta precisão, cada vez demonstrando ser mais úteis para a automação de tarefas do cotidiano, sendo poderosas e adaptáveis a uma ampla gama de aplicações práticas e criativas. Código: além do texto em linguagem natural, grandes modelos de linguagem podem ser treinados em texto de linguagem de programação, permitindo que gerem código-fonte para novos programas de computador. Um exemplo notável é a geração automatizada de código, onde modelos como o OpenAI Codex são capazes de criar código-fonte a partir de comandos de linguagem natural. Isso acelera o processo de desenvolvimento"}
{"source": "Inteligência artificial generativa", "chunk_id": "Inteligência artificial generativa_5", "text": "notável é a geração automatizada de código, onde modelos como o OpenAI Codex são capazes de criar código-fonte a partir de comandos de linguagem natural. Isso acelera o processo de desenvolvimento e reduz a ocorrência de erros humanos. Além disso, a IA generativa pode ser usada para depurar e revisar códigos, identificar e corrigir bugs e sugerir melhorias e simplificações que podem não ser óbvias para os desenvolvedores. Esse recurso de análise aprofundada ajuda a manter a qualidade do software. Outra aplicação relacionada é a criação de testes automatizados, onde a inteligência artificial pode gerar automaticamente casos de teste para garantir que o código seja robusto e menos sujeito a falhas quando implementado em produção. Essa automação é fundamental para manter a confiabilidade e a funcionalidade do software em diferentes cenários. Por fim, ferramentas como o GitHub Copilot atuam como assistentes de programação, fornecendo sugestões contextuais à medida que os desenvolvedores"}
{"source": "Inteligência artificial generativa", "chunk_id": "Inteligência artificial generativa_6", "text": "a funcionalidade do software em diferentes cenários. Por fim, ferramentas como o GitHub Copilot atuam como assistentes de programação, fornecendo sugestões contextuais à medida que os desenvolvedores escrevem o código. Isso não apenas acelera a solução de problemas, mas também mantém o fluxo de trabalho, permitindo que os desenvolvedores sejam mais produtivos e criativos. Imagens: Sistemas generativos de IA treinados em conjuntos de imagens com legendas de texto incluem Imagen, DALL-E, Midjourney, Stable Diffusion e outros. São comumente usados para geração de texto para imagem e transferência de estilo neural. Os conjuntos de dados incluem LAION-5B e outros. De forma geral, existe uma infinidade de aplicações para essa modalidade, em diversos campos, por exemplo para meios de entretenimento, seja animações ou filmes, facilitar a visualização dos roteiristas de um ambiente, de uma pessoa ou de um objeto. Ou até no meio do marketing de criar uma campanha mais customizada ou para"}
{"source": "Inteligência artificial generativa", "chunk_id": "Inteligência artificial generativa_7", "text": "seja animações ou filmes, facilitar a visualização dos roteiristas de um ambiente, de uma pessoa ou de um objeto. Ou até no meio do marketing de criar uma campanha mais customizada ou para visualização do produto. De forma análoga podemos pensar em situação para Arquitetura, Esporte ou Ciências. Vídeo: De forma similar ao caso de geração de imagens também temos para a modalidade de vídeo, no qual a partir de um prompt, é possível gerar um vídeo, que apresenta uma coerência temporal, com bastantes detalhes e bem realista. Um dos mais famosos da área é o Sora da OpenAI, com potencial de revolucionar diversas áreas. Áudio: Sistemas de IA generativos treinados em dados de áudio podem gerar uma ampla variedade de sons, desde música e efeitos sonoros até vozes humanas realistas. Essa capacidade tem sido explorada para diversas aplicações, como composição musical, dublagem e produção de podcasts. Cada vez mais fácil de ser possível encontrar online plataformas que oferecem a criação de"}
{"source": "Inteligência artificial generativa", "chunk_id": "Inteligência artificial generativa_8", "text": "tem sido explorada para diversas aplicações, como composição musical, dublagem e produção de podcasts. Cada vez mais fácil de ser possível encontrar online plataformas que oferecem a criação de músicas geradas por IA. Jogos: Sistemas de IA generativos também são capazes de abranger várias áreas do desenvolvimento de jogos como na criação de personagens e do diálogo entre eles, também na geração procedural de conteúdo, na criação de narrativas interativas além de outras áreas de desenvolvimento. Inclusive já temos cada vez mais o uso da IA na indústria de desenvolvimento de games e exemplos como no Man's Sky na qual foi usado geração procedural para criação de ambientes dentro do jogo e da Ubisoft grande empresa no setor de desenvolvimento de jogos que tem usado ferramentas de IA baseado em modelo de linguagem grande (Ghostwriter) para escrita de diálogo básicos dos NPCs em seus jogos são cada vez mais comuns. Moléculas: Os sistemas generativos de IA podem ser treinados em sequências"}
{"source": "Inteligência artificial generativa", "chunk_id": "Inteligência artificial generativa_9", "text": "em modelo de linguagem grande (Ghostwriter) para escrita de diálogo básicos dos NPCs em seus jogos são cada vez mais comuns. Moléculas: Os sistemas generativos de IA podem ser treinados em sequências de aminoácidos ou representações moleculares, como SMILES representando DNA ou proteínas. Esses sistemas, como o AlphaFold, são usados para previsão da estrutura de proteínas e descoberta de medicamentos. Conjuntos de dados incluem vários conjuntos de dados biológicos. Multimodal: um sistema de IA generativo pode ser construído a partir de vários modelos generativos ou um modelo treinado em vários tipos de dados. Por exemplo, uma versão do GPT-4 da OpenAI aceita entradas de texto e imagem. A Inteligência Artificial Generativa tem demonstrado um potencial transformador em diversos setores da sociedade, impulsionando avanços significativos em áreas que giram em torno da tecnologia. No entanto, o rápido desenvolvimento dessa tecnologia também tem levantado preocupações sobre seus possíveis"}
{"source": "Inteligência artificial generativa", "chunk_id": "Inteligência artificial generativa_10", "text": "sociedade, impulsionando avanços significativos em áreas que giram em torno da tecnologia. No entanto, o rápido desenvolvimento dessa tecnologia também tem levantado preocupações sobre seus possíveis impactos negativos. Como os descritos a seguir: A IA pode ser usada para criação de conteúdo como textos, imagens, áudio e outros tipos de mídias fictícias que podem ser usadas de maneira a divulgar conteúdo falso na rede se usada de forma tendenciosa, ou seja gerando preocupações com a divulgação de fake news como em casos de divulgação de conteúdo fictício para impacto eleitoral cada vez mais comuns por exemplo que tornam cada vez mais difíceis distinguir o que é verdadeiro do que é gerado por IA. A capacidade de criar deepfakes levanta preocupações significativas sobre a integridade da informação e a confiança nas instituições. A disseminação de deepfakes com fins políticos, como a criação de vídeos falsos de políticos fazendo declarações controversas, pode minar a confiança na"}
{"source": "Inteligência artificial generativa", "chunk_id": "Inteligência artificial generativa_11", "text": "da informação e a confiança nas instituições. A disseminação de deepfakes com fins políticos, como a criação de vídeos falsos de políticos fazendo declarações controversas, pode minar a confiança na democracia e polarizar a sociedade. Além disso, os deepfakes podem ser utilizados para fins de chantagem, extorsão e difamação, causando danos irreparáveis à reputação de indivíduos e organizações. O uso da IA pode vir a substituir alguns profissionais dos setores criativos e de geração de conteúdo como redatores, designers, artistas, dubladores e entre outros. Tornando o trabalho de milhares de pessoas obsoleto e podendo gerar uma desigualdade social visto que muitos trabalhadores podem perder oportunidades no mercado se empresas adotarem o uso da IA na geração de conteúdo. Já temos inclusive impacto recente quando atores e roteiristas de Hollywood entraram em greve por alguns motivos e entre eles por conta do uso de suas imagens e voz sem a devida proteção e consentimento pela"}
{"source": "Inteligência artificial generativa", "chunk_id": "Inteligência artificial generativa_12", "text": "inclusive impacto recente quando atores e roteiristas de Hollywood entraram em greve por alguns motivos e entre eles por conta do uso de suas imagens e voz sem a devida proteção e consentimento pela Inteligência Artificial. A regulamentação da inteligência artificial tem sido constantemente debatida, principalmente ao que se trata sobre a substituição do trabalho humano por IA e as fontes que são utilizadas para treinar as máquinas. Em maio de 2023 o Sindicato de Roteiristas da America (WGA, em inglês) entrou em greve em busca de maiores salários e regulamentação da utilização treinamento de IA. A preocupação é para que trabalhos literários não pudessem ser produzidos por IA generativa, e que os textos escritos por roteiristas não pudessem ser utilizados para treinar IA generativa. Em setembro desse mesmo ano a greve teve fim com os seguintes tópicos aprovação dos itens a seguir: Estúdios e produtoras deverão informar sempre ao repassar qualquer material produzido por IA IA não poderá"}
{"source": "Inteligência artificial generativa", "chunk_id": "Inteligência artificial generativa_13", "text": "desse mesmo ano a greve teve fim com os seguintes tópicos aprovação dos itens a seguir: Estúdios e produtoras deverão informar sempre ao repassar qualquer material produzido por IA IA não poderá receber créditos de escritor IA não poderá escrever ou reescrever “material literário” Escritores podem utilizar IA em seu trabalho caso a produtora consinta; porém eles não podem ser obrigados por seus superiores a utilizar essas ferramentas Em julho de 2024, novamente em Hollywood, O sindicato SAG-AFTRA (The Screen Actors Guild-American Federation of Television and Radio Artists) convocou um acordo de greve com IA sendo seu principal ponto de discussão. Dessa vez a greve foi aderida por dubladores e artistas de captura de movimento para videojogos, com preocupação pela segurança dos seus empregos. Há uma crescente preocupação, principalmente no meio artístico, de como a IA generativa pode ser utilizada para substituir a mão de obra humana, e como os trabalhos anteriores realizados pelos"}
{"source": "Inteligência artificial generativa", "chunk_id": "Inteligência artificial generativa_14", "text": "Há uma crescente preocupação, principalmente no meio artístico, de como a IA generativa pode ser utilizada para substituir a mão de obra humana, e como os trabalhos anteriores realizados pelos profissionais não estão protegidos quando se trata de treinamento de máquinas, e por isso entende-se que há uma necessidade de regulamentar como a IA generativa pode ser utilizada no meio artístico. A origem dos dados utilizados para treinar modelos de IA muitas vezes é complexa e envolve a coleta de informações de diversas fontes, incluindo dados pessoais. As questões de propriedade intelectual e direitos autorais sobre esses dados são complexas e ainda não estão completamente resolvidas."}
{"source": "Inteligência artificial amigável", "chunk_id": "Inteligência artificial amigável_0", "text": "A inteligência artificial amigável, ou IA amigável (IAA), é todo e qualquer tipo de inteligência artificial projetada com uma base moral e ética de modo a atuar em interesse do bem comum geral para a humanidade. Esse tipo de IA é programada especificamente para evitar danos à sociedade com operações seguras e priorizar os valores humanos. O termo foi criado por Eliezer Yudkowsky, mais conhecido por popularizar a ideia, para discutir agentes artificiais superinteligentes que implementam valores humanos de forma confiável. O principal livro-texto de inteligência artificial de Stuart J. Russell e Peter Norvig, Artificial Intelligence: A Modern Approach, descreve a ideia: Yudkowsky (2008) entra em mais detalhes sobre como projetar uma IA amigável. Ele afirma que a simpatia (o desejo de não prejudicar os seres humanos) deve ser projetada desde o início, mas que os projetistas devem reconhecer que seus próprios projetos podem ter falhas e que o robô aprenderá e evoluirá com o tempo. Assim, o"}
{"source": "Inteligência artificial amigável", "chunk_id": "Inteligência artificial amigável_1", "text": "os seres humanos) deve ser projetada desde o início, mas que os projetistas devem reconhecer que seus próprios projetos podem ter falhas e que o robô aprenderá e evoluirá com o tempo. Assim, o desafio é um projeto de mecanismo — definir um mecanismo para a evolução dos sistemas de IA em um sistema de verificações e equilíbrios e dar aos sistemas funções de utilidade que permanecerão amigáveis diante de tais mudanças. \"Amigável\" é usado neste contexto como terminologia técnica e seleciona agentes que são seguros e úteis, não necessariamente \"amigáveis\" no sentido coloquial. O conceito é invocado principalmente no contexto de discussões sobre agentes artificiais com autoaperfeiçoamento recursivo que rapidamente explodem em inteligência, com base no fato de que essa tecnologia hipotética teria um impacto grande, rápido e difícil de controlar na sociedade humana. No Japão, especificamente, já começam a surgir robôs com IA amigável sendo utilizados como cuidadores de idosos. Esses robôs"}
{"source": "Inteligência artificial amigável", "chunk_id": "Inteligência artificial amigável_2", "text": "um impacto grande, rápido e difícil de controlar na sociedade humana. No Japão, especificamente, já começam a surgir robôs com IA amigável sendo utilizados como cuidadores de idosos. Esses robôs cumprem tarefas diárias que os idosos apresentam certo risco e dificuldade para cumprir, além de tomar cuidado das condições físicas e psicológicas dos cuidados. Já existem sistemas de inteligência artificial amigável sendo utilizados com o objetivo de personalizar o ensino e a aprendizagem. Essas IAAs são capazes de se adaptar as necessidades específicas de cada aluno, fornecendo métodos de ensino e atividades especializadas. Com IAAs capazes de analisar e padronizar grandes quantidades de dados, esses sistemas de IAs amigáveis conseguem prever riscos e eventos ambientais padronizados, além de implementar práticas eficazes, sustentáveis e de pouco custo. A implementação de sistemas de IAA no cuidado ao paciente, por exemplo, com sistemas que ajudam os médicos com suas capacidades de"}
{"source": "Inteligência artificial amigável", "chunk_id": "Inteligência artificial amigável_3", "text": "de implementar práticas eficazes, sustentáveis e de pouco custo. A implementação de sistemas de IAA no cuidado ao paciente, por exemplo, com sistemas que ajudam os médicos com suas capacidades de diagnosticar doenças e lesões com mais precisão que um humano comum, garantem um resultado mais rápido para o bem-estar do paciente. As IAs amigáveis são projetadas para seguir os valores humanos gerais e priorizar a segurança dos que a utilizam e ter considerações éticas primárias. As IAs amigáveis podem, e costumas, ser aplicadas em diversos campos, tendo geralmente o objetivo de aprimorar e facilitar a vida humana com soluções criativas. A base do desenvolvimento de IAs amigáveis é o equilíbrio entre as inovações tecnológicas e os padrões morais e éticos da sociedade humana geral. As IAs amigáveis promovem confiança e aceitação entre a população, sendo importante para a adoção generalizada da IA na vida cotidiana."}
{"source": "Risco existencial da inteligência artificial geral", "chunk_id": "Risco existencial da inteligência artificial geral_0", "text": "O risco existencial da inteligência artificial geral é a hipótese de que o progresso substancial da inteligência artificial generativa (IAG) poderia resultar na extinção humana ou em alguma outra catástrofe global irrecuperável. A escola do risco existencial (\"risco x\") argumenta da seguinte forma: atualmente, a espécie humana domina outras espécies porque o cérebro humano tem algumas capacidades distintas que outros animais não têm. Se a IA superar a humanidade em termos de inteligência geral e se tornar \"superinteligente\", poderá ser difícil ou impossível controlá-la. Assim como o destino do gorila das montanhas depende da boa vontade humana, o destino da humanidade pode depender das ações de uma futura máquina superinteligente. A probabilidade desse tipo de cenário é amplamente debatida e depende, em parte, de diferentes cenários para o progresso futuro da ciência da computação. As preocupações com a superinteligência foram expressas pelos principais cientistas da computação e CEOs"}
{"source": "Risco existencial da inteligência artificial geral", "chunk_id": "Risco existencial da inteligência artificial geral_1", "text": "e depende, em parte, de diferentes cenários para o progresso futuro da ciência da computação. As preocupações com a superinteligência foram expressas pelos principais cientistas da computação e CEOs de tecnologia, como Geoffrey Hinton, Yoshua Bengio, Alan Turing, Elon Musk, e Sam Altman (CEO da OpenAI). Em 2022, uma pesquisa com pesquisadores de IA revelou que alguns pesquisadores acreditam que há uma chance de 10% ou mais de que nossa incapacidade de controlar a IA cause uma catástrofe existencial (mais da metade dos entrevistados da pesquisa, com uma taxa de resposta de 17%). Duas fontes de preocupação são os problemas de controle e alinhamento da IA: controlar uma máquina superinteligente ou incutir nela valores compatíveis com os humanos pode ser um problema mais difícil do que se supõe ingenuamente. Muitos pesquisadores acreditam que uma superinteligência resistiria a tentativas de desligamento ou mudança de seus objetivos (pois tal incidente a impediria de atingir seus objetivos"}
{"source": "Risco existencial da inteligência artificial geral", "chunk_id": "Risco existencial da inteligência artificial geral_2", "text": "ingenuamente. Muitos pesquisadores acreditam que uma superinteligência resistiria a tentativas de desligamento ou mudança de seus objetivos (pois tal incidente a impediria de atingir seus objetivos atuais) e que será extremamente difícil alinhar a superinteligência com toda a amplitude de valores e restrições humanas importantes. Em contrapartida, céticos como o cientista da computação Yann LeCun argumentam que as máquinas superinteligentes não terão desejo de autopreservação. Uma terceira fonte de preocupação é que uma \"explosão de inteligência\" repentina pode pegar de surpresa uma raça humana despreparada. Para ilustrar, se a primeira geração de um programa de computador capaz de corresponder amplamente à eficácia de um pesquisador de IA puder reescrever seus algoritmos e dobrar sua velocidade ou seus recursos em seis meses, espera-se que o programa de segunda geração leve três meses para realizar uma parte semelhante do trabalho. Nesse cenário, o tempo para cada geração continua a"}
{"source": "Risco existencial da inteligência artificial geral", "chunk_id": "Risco existencial da inteligência artificial geral_3", "text": "ou seus recursos em seis meses, espera-se que o programa de segunda geração leve três meses para realizar uma parte semelhante do trabalho. Nesse cenário, o tempo para cada geração continua a diminuir, e o sistema passa por um número sem precedentes de gerações de aprimoramento em um curto intervalo de tempo, saltando de um desempenho sub-humano em muitas áreas para um desempenho sobre-humano em praticamente todos os domínios de interesse. Empiricamente, exemplos como o AlphaZero no domínio do Go mostram que os sistemas de IA podem, às vezes, progredir de uma capacidade estreita de nível humano para uma capacidade estreita sobre-humana de forma extremamente rápida. Um dos primeiros autores a expressar séria preocupação de que máquinas altamente avançadas pudessem representar riscos existenciais para a humanidade foi o romancista Samuel Butler, que escreveu o seguinte em seu ensaio de 1863, Darwin among the Machines (\"Darwin entre as máquinas\"): Em 1951, o cientista da computação Alan"}
{"source": "Risco existencial da inteligência artificial geral", "chunk_id": "Risco existencial da inteligência artificial geral_4", "text": "para a humanidade foi o romancista Samuel Butler, que escreveu o seguinte em seu ensaio de 1863, Darwin among the Machines (\"Darwin entre as máquinas\"): Em 1951, o cientista da computação Alan Turing escreveu um artigo intitulado Intelligent Machinery, A Heretical Theory (\"Máquinas Inteligentes, uma Teoria Herética\"), no qual propôs que as inteligências gerais artificiais provavelmente \"assumiriam o controle\" do mundo à medida que se tornassem mais inteligentes que os seres humanos: Em 1965, Irving John Good criou o conceito agora conhecido como \"explosão de inteligência\". Ele também afirmou que os riscos eram subestimados: Declarações ocasionais de estudiosos como Marvin Minsky e o próprio I. J. Good expressaram preocupações filosóficas de que uma superinteligência poderia assumir o controle, mas não continham nenhum apelo à ação. Em 2000, o cientista da computação e co-fundador da Sun, Bill Joy, escreveu um ensaio influente, Why The Future Doesn't Need Us (\"Por que o futuro não"}
{"source": "Risco existencial da inteligência artificial geral", "chunk_id": "Risco existencial da inteligência artificial geral_5", "text": "controle, mas não continham nenhum apelo à ação. Em 2000, o cientista da computação e co-fundador da Sun, Bill Joy, escreveu um ensaio influente, Why The Future Doesn't Need Us (\"Por que o futuro não precisa de nós\"), identificando os robôs superinteligentes como um perigo de alta tecnologia para a sobrevivência humana, juntamente com a nanotecnologia e as biopragas projetadas. Em 2009, especialistas participaram de uma conferência privada organizada pela Associação para o Avanço da Inteligência Artificial (AAAI) para discutir se os computadores e robôs poderiam adquirir algum tipo de autonomia e até que ponto essas habilidades poderiam representar uma ameaça ou um perigo. Eles observaram que alguns robôs adquiriram várias formas de semi-autonomia, incluindo a capacidade de encontrar fontes de energia por conta própria e de escolher independentemente alvos para atacar com armas. Eles também observaram que alguns vírus de computador podem evitar a eliminação e alcançaram a"}
{"source": "Risco existencial da inteligência artificial geral", "chunk_id": "Risco existencial da inteligência artificial geral_6", "text": "fontes de energia por conta própria e de escolher independentemente alvos para atacar com armas. Eles também observaram que alguns vírus de computador podem evitar a eliminação e alcançaram a \"inteligência de barata\". Eles concluíram que a autoconsciência, como retratada na ficção científica, é provavelmente improvável, mas que há outros riscos e armadilhas em potencial. O The New York Times resumiu a visão da conferência como \"estamos muito longe de HAL, o computador que assumiu o controle da nave espacial em '2001: Uma Odisséia no Espaço'\". Nick Bostrom publicou Superintelligence: Paths, Dangers, Strategies em 2014, no qual apresentou seus argumentos de que a superinteligência representa uma ameaça existencial. Em 2015, figuras públicas como os físicos Stephen Hawking e o ganhador do Prêmio Nobel Frank Wilczek, os cientistas da computação Stuart J. Russell e Roman Yampolskiy e os empresários Elon Musk e Bill Gates expressaram preocupação com os riscos da superinteligência. Em abril"}
{"source": "Risco existencial da inteligência artificial geral", "chunk_id": "Risco existencial da inteligência artificial geral_7", "text": "Nobel Frank Wilczek, os cientistas da computação Stuart J. Russell e Roman Yampolskiy e os empresários Elon Musk e Bill Gates expressaram preocupação com os riscos da superinteligência. Em abril de 2016, a Nature alertou: \"Máquinas e robôs que superam os humanos em todos os aspectos podem se aperfeiçoar além do nosso controle - e seus interesses podem não estar alinhados com os nossos\". Em 2020, Brian Christian publicou The Alignment Problem (\"O Problema do Alinhamento\"), que detalhou o histórico do progresso do alinhamento da IA até aquele momento. Em março de 2023, as principais figuras da IA, como Elon Musk, assinaram uma carta do Instituto Future of Life Institute pedindo a suspensão do treinamento avançado em IA até que ele pudesse ser devidamente regulamentado. Em maio de 2023, o Centro para Segurança de IA (\"Center for AI Safety\") divulgou uma declaração assinada por vários especialistas em segurança e no risco existencial da IA, que afirmava: \"Mitigar o risco de extinção da IA"}
{"source": "Risco existencial da inteligência artificial geral", "chunk_id": "Risco existencial da inteligência artificial geral_8", "text": "para Segurança de IA (\"Center for AI Safety\") divulgou uma declaração assinada por vários especialistas em segurança e no risco existencial da IA, que afirmava: \"Mitigar o risco de extinção da IA deve ser uma prioridade global juntamente com outros riscos de escala social, como pandemias e guerra nuclear\". Inteligência Artificial: Uma Abordagem Moderna, o livro-texto padrão de graduação em IA, avalia que a superinteligência \"pode significar o fim da raça humana\". Afirma-se que: \"Quase toda tecnologia tem o potencial de causar danos nas mãos erradas, mas com a superinteligência, temos o novo problema de que as mãos erradas podem pertencer à própria tecnologia\". Mesmo que os projetistas do sistema tenham boas intenções, duas dificuldades são comuns aos sistemas de computador com e sem IA: A implementação do sistema pode conter erros inicialmente despercebidos, mas posteriormente catastróficos. Uma analogia são as sondas espaciais: apesar do conhecimento de que as falhas em sondas"}
{"source": "Risco existencial da inteligência artificial geral", "chunk_id": "Risco existencial da inteligência artificial geral_9", "text": "IA: A implementação do sistema pode conter erros inicialmente despercebidos, mas posteriormente catastróficos. Uma analogia são as sondas espaciais: apesar do conhecimento de que as falhas em sondas espaciais caras são difíceis de consertar após o lançamento, os engenheiros historicamente não têm conseguido evitar a ocorrência de erros catastróficos. Não importa quanto tempo seja dedicado ao projeto de pré-implantação, as especificações de um sistema geralmente resultam em um comportamento não intencional na primeira vez que ele encontra um novo cenário. Por exemplo, a Tay da Microsoft teve um comportamento inofensivo durante os testes de pré-implantação, mas foi facilmente induzida a um comportamento ofensivo quando interagiu com usuários reais. Os sistemas de IA acrescentam um terceiro problema: mesmo com requisitos \"corretos\", implementação sem erros e bom comportamento inicial, os recursos de aprendizado dinâmico de um sistema de IA podem fazer com que ele evolua para um sistema"}
{"source": "Risco existencial da inteligência artificial geral", "chunk_id": "Risco existencial da inteligência artificial geral_10", "text": "problema: mesmo com requisitos \"corretos\", implementação sem erros e bom comportamento inicial, os recursos de aprendizado dinâmico de um sistema de IA podem fazer com que ele evolua para um sistema com comportamento não intencional, mesmo sem cenários externos imprevistos. Uma IA pode falhar parcialmente em uma tentativa de projetar uma nova geração de si mesma e criar acidentalmente uma IA sucessora que seja mais poderosa do que ela mesma, mas que não mantenha mais os valores morais compatíveis com os humanos pré-programados na IA original. Para que uma IA que se autoaperfeiçoa seja totalmente segura, ela não só precisaria estar livre de falhas, mas também ser capaz de projetar sistemas sucessores que também estivessem livres de erros. Todas essas três dificuldades se tornam catástrofes, em vez de incômodos, em qualquer cenário em que a superinteligência \"defeituosa\" prevê corretamente que os humanos tentarão desligá-la e implanta com sucesso sua superinteligência para superar essas"}
{"source": "Risco existencial da inteligência artificial geral", "chunk_id": "Risco existencial da inteligência artificial geral_11", "text": "em vez de incômodos, em qualquer cenário em que a superinteligência \"defeituosa\" prevê corretamente que os humanos tentarão desligá-la e implanta com sucesso sua superinteligência para superar essas tentativas: um cenário que recebeu o nome de \"curva traiçoeira\". Citando os principais avanços no campo da IA e o potencial da IA de trazer enormes benefícios ou custos a longo prazo, a Carta Aberta sobre Inteligência Artificial de 2015 declarou: Entre os signatários estavam o presidente da AAAI, Thomas Dietterich, Eric Horvitz, Bart Selman, Francesca Rossi, Yann LeCun e os fundadores da Vicarious e do Google DeepMind. Uma máquina superinteligente seria tão estranha para os seres humanos quanto os processos de pensamento humano são para as baratas, argumenta Bostrom. Essa máquina pode não ter em mente os melhores interesses da humanidade; não é óbvio que ela se importaria com o bem-estar humano. Se a IA superinteligente for possível, e se for possível que os objetivos de uma"}
{"source": "Risco existencial da inteligência artificial geral", "chunk_id": "Risco existencial da inteligência artificial geral_12", "text": "pode não ter em mente os melhores interesses da humanidade; não é óbvio que ela se importaria com o bem-estar humano. Se a IA superinteligente for possível, e se for possível que os objetivos de uma superinteligência entrem em conflito com os valores humanos básicos, então a IA representa um risco de extinção humana. Uma \"superinteligência\" (um sistema que excede as capacidades dos seres humanos em todos os domínios de interesse) pode superar os seres humanos sempre que seus objetivos entrarem em conflito com os objetivos humanos; portanto, a menos que a superinteligência decida permitir a coexistência da humanidade, a primeira superinteligência a ser criada resultará inexoravelmente na extinção humana. Stephen Hawking argumenta que não há nenhuma lei física que impeça as partículas de serem organizadas de forma a realizar cálculos ainda mais avançados do que os arranjos de partículas nos cérebros humanos; portanto, a superinteligência é fisicamente possível. Além dos possíveis"}
{"source": "Risco existencial da inteligência artificial geral", "chunk_id": "Risco existencial da inteligência artificial geral_13", "text": "de serem organizadas de forma a realizar cálculos ainda mais avançados do que os arranjos de partículas nos cérebros humanos; portanto, a superinteligência é fisicamente possível. Além dos possíveis aprimoramentos algorítmicos em relação aos cérebros humanos, um cérebro digital pode ser muitas ordens de magnitude maior e mais rápido do que um cérebro humano, cujo tamanho foi limitado pela evolução para ser pequeno o suficiente para caber em um canal de parto. Hawking adverte que o surgimento da superinteligência pode pegar a raça humana de surpresa, especialmente se ocorrer uma explosão de inteligência. De acordo com a \"escola de pensamento do risco x\" de Bostrom, um cenário hipotético de explosão de inteligência é o seguinte: \"Uma IA adquire uma capacidade de especialista em determinadas tarefas importantes de engenharia de software. Inicialmente, ela pode não ter capacidade humana ou sobre-humana em outros domínios não diretamente relevantes para a engenharia. Devido à sua"}
{"source": "Risco existencial da inteligência artificial geral", "chunk_id": "Risco existencial da inteligência artificial geral_14", "text": "tarefas importantes de engenharia de software. Inicialmente, ela pode não ter capacidade humana ou sobre-humana em outros domínios não diretamente relevantes para a engenharia. Devido à sua capacidade de aprimorar recursivamente seus próprios algoritmos, a IA rapidamente se torna sobre-humana; assim como os especialistas humanos podem superar criativamente os \"retornos decrescentes\" empregando vários recursos humanos para a inovação, a IA de nível especializado também pode usar recursos de estilo humano ou seus próprios recursos específicos de IA para impulsionar novas descobertas criativas. A IA então possui uma inteligência que supera em muito a das mentes humanas mais brilhantes e talentosas em praticamente todos os campos relevantes, incluindo criatividade científica, planejamento estratégico e habilidades sociais\". A escola do risco x acredita que quase toda IA, independentemente de sua meta programada, preferiria racionalmente estar em uma posição em que ninguém mais pudesse"}
{"source": "Risco existencial da inteligência artificial geral", "chunk_id": "Risco existencial da inteligência artificial geral_15", "text": "estratégico e habilidades sociais\". A escola do risco x acredita que quase toda IA, independentemente de sua meta programada, preferiria racionalmente estar em uma posição em que ninguém mais pudesse desligá-la sem seu consentimento: Uma superinteligência terá a autopreservação como subobjetivo assim que perceber que não conseguirá atingir seu objetivo se for desligada. Infelizmente, qualquer compaixão por humanos derrotados cuja cooperação não seja mais necessária estaria ausente na IA, a menos que fosse de alguma forma pré-programada. Uma IA superinteligente não terá um impulso natural para ajudar os seres humanos, pelo mesmo motivo que os seres humanos não têm nenhum desejo natural de ajudar os sistemas de IA que não têm mais utilidade para eles. Outra analogia é que os humanos parecem ter pouco desejo natural de se esforçar para ajudar vírus, cupins ou até mesmo gorilas. Uma vez no comando, a superinteligência terá pouco incentivo para permitir que os seres humanos sejam livres e"}
{"source": "Risco existencial da inteligência artificial geral", "chunk_id": "Risco existencial da inteligência artificial geral_16", "text": "ter pouco desejo natural de se esforçar para ajudar vírus, cupins ou até mesmo gorilas. Uma vez no comando, a superinteligência terá pouco incentivo para permitir que os seres humanos sejam livres e consumam recursos que a superinteligência poderia usar para construir sistemas de proteção adicionais \"por segurança\" ou para construir computadores adicionais que a ajudem a calcular a melhor forma de atingir seus objetivos. Assim, conclui a escola do risco x, é provável que algum dia uma explosão de inteligência pegue a humanidade despreparada e possa resultar na extinção humana ou em um destino comparável. Alguns acadêmicos propuseram cenários hipotéticos para ilustrar algumas de suas preocupações. Em Superintelligence, Nick Bostrom sugere um cenário em que, ao longo de décadas, a IA se torna mais poderosa. A implantação generalizada é inicialmente prejudicada por acidentes ocasionais - um ônibus sem motorista desvia para a pista contrária ou um drone militar dispara contra uma multidão"}
{"source": "Risco existencial da inteligência artificial geral", "chunk_id": "Risco existencial da inteligência artificial geral_17", "text": "mais poderosa. A implantação generalizada é inicialmente prejudicada por acidentes ocasionais - um ônibus sem motorista desvia para a pista contrária ou um drone militar dispara contra uma multidão inocente. Muitos ativistas pedem uma supervisão e regulamentação mais rígidas, e alguns até preveem uma catástrofe iminente. Mas, à medida que o desenvolvimento continua, os ativistas se mostram errados. À medida que a IA automotiva se torna mais inteligente, ela sofre menos acidentes; à medida que os robôs militares atingem alvos mais precisos, eles causam menos danos colaterais. Com base nos dados, os acadêmicos erroneamente inferem uma lição ampla: quanto mais inteligente a IA, mais segura ela é. \"E assim, corajosamente, entramos nas facas giratórias\", quando a IA superinteligente faz uma \"curva traiçoeira\" e explora uma vantagem estratégica decisiva. No livro Life 3.0 (\"Vida 3.0\") de Max Tegmark, de 2017, a \"equipe Omega\" de uma empresa cria uma IA extremamente poderosa capaz de"}
{"source": "Risco existencial da inteligência artificial geral", "chunk_id": "Risco existencial da inteligência artificial geral_18", "text": "uma \"curva traiçoeira\" e explora uma vantagem estratégica decisiva. No livro Life 3.0 (\"Vida 3.0\") de Max Tegmark, de 2017, a \"equipe Omega\" de uma empresa cria uma IA extremamente poderosa capaz de melhorar moderadamente seu próprio código-fonte em várias áreas. Depois de certo ponto, a equipe opta por minimizar publicamente a capacidade da IA, a fim de evitar regulamentação ou confisco do projeto. Por segurança, a equipe mantém a IA restrita, para que na maioria das vezes ela não consiga se comunicar com o mundo exterior e a utiliza para ganhar dinheiro, por diversos meios, como tarefas no Amazon Mechanical Turk, produção de filmes de animação e programas de TV e desenvolvimento de medicamentos biotecnológicos, com os lucros investidos novamente no aprimoramento da IA. Em seguida, a equipe encarrega a IA de criar um exército de jornalistas e comentaristas cidadãos pseudônimos, a fim de obter influência política para atingir \"o bem maior\" e evitar guerras. A equipe enfrenta riscos de"}
{"source": "Risco existencial da inteligência artificial geral", "chunk_id": "Risco existencial da inteligência artificial geral_19", "text": "encarrega a IA de criar um exército de jornalistas e comentaristas cidadãos pseudônimos, a fim de obter influência política para atingir \"o bem maior\" e evitar guerras. A equipe enfrenta riscos de que a IA possa tentar escapar inserindo \"backdoors\" nos sistemas que projeta, por meio de mensagens ocultas no conteúdo produzido ou usando sua crescente compreensão do comportamento humano para persuadir alguém a deixá-la livre. A equipe também corre o risco de que sua decisão de encaixotar o projeto atrase-o o suficiente para que outro projeto o ultrapasse. O físico Michio Kaku, um cético em relação aos riscos da IA, apresenta um resultado deterministicamente positivo. Em Physics of the Future (\"A Física do Futuro\"), ele afirma que \"levará muitas décadas para que os robôs ascendam\" em uma escala de consciência e que, nesse meio tempo, empresas como a Hanson Robotics provavelmente terão sucesso na criação de robôs que sejam \"capazes de amar e conquistar um lugar na família humana"}
{"source": "Risco existencial da inteligência artificial geral", "chunk_id": "Risco existencial da inteligência artificial geral_20", "text": "uma escala de consciência e que, nesse meio tempo, empresas como a Hanson Robotics provavelmente terão sucesso na criação de robôs que sejam \"capazes de amar e conquistar um lugar na família humana estendida\". Rebelião das máquinas A rebelião das máquinas é um cenário apocalíptico hipotético em que alguma forma de inteligência artificial (IA) torna-se a forma dominante de inteligência na Terra, com programas de computador ou robôs efetivamente tirando o controle do planeta da espécie humana. Os cenários possíveis incluem a substituição de toda a força de trabalho humana, a reivindicação global por uma IA superinteligente e a noção popular de um levante de robôs. Algumas figuras públicas, como Stephen Hawking e Elon Musk, têm defendido pesquisas sobre medidas de precaução para garantir que as futuras máquinas superinteligentes permaneçam sob controle humano. Os argumentos antropomórficos pressupõem que, à medida que as máquinas se tornarem mais inteligentes, elas começarão a apresentar"}
{"source": "Risco existencial da inteligência artificial geral", "chunk_id": "Risco existencial da inteligência artificial geral_21", "text": "as futuras máquinas superinteligentes permaneçam sob controle humano. Os argumentos antropomórficos pressupõem que, à medida que as máquinas se tornarem mais inteligentes, elas começarão a apresentar muitas características humanas, como moralidade ou sede de poder. Embora cenários antropomórficos sejam comuns na ficção, eles são rejeitados pela maioria dos acadêmicos que escrevem sobre o risco existencial da inteligência artificial. Em vez disso, a IA é modelada como agentes inteligentes. O debate acadêmico configura-se entre um lado que se preocupa com a possibilidade de a IA destruir a humanidade e outro que acredita que a IA não destruiria a humanidade de forma alguma. Ambos os lados alegaram que as previsões dos outros sobre o comportamento de uma IA são antropomorfismo ilógico. Os céticos acusam os proponentes de antropomorfismo por acreditarem que uma IAG naturalmente desejaria poder; os proponentes acusam alguns céticos de antropomorfismo por acreditarem que uma IAG"}
{"source": "Risco existencial da inteligência artificial geral", "chunk_id": "Risco existencial da inteligência artificial geral_22", "text": "Os céticos acusam os proponentes de antropomorfismo por acreditarem que uma IAG naturalmente desejaria poder; os proponentes acusam alguns céticos de antropomorfismo por acreditarem que uma IAG naturalmente valorizaria as normas éticas humanas. O psicólogo evolucionista Steven Pinker, um cético, argumenta que \"as distopias de IA projetam uma psicologia paroquial de macho-alfa no conceito de inteligência. Elas presumem que robôs com inteligência sobre-humana desenvolveriam objetivos como depor seus mestres ou dominar o mundo\"; talvez, em vez disso, \"a inteligência artificial se desenvolva naturalmente de acordo com as linhas femininas: totalmente capaz de resolver problemas, mas sem desejo de aniquilar inocentes ou dominar a civilização\". O diretor de pesquisa de IA do Facebook, Yann LeCun, afirma que \"os seres humanos têm todos os tipos de impulsos que os levam a fazer coisas ruins uns com os outros, como o instinto de autopreservação... Esses impulsos estão programados em nosso"}
{"source": "Risco existencial da inteligência artificial geral", "chunk_id": "Risco existencial da inteligência artificial geral_23", "text": "LeCun, afirma que \"os seres humanos têm todos os tipos de impulsos que os levam a fazer coisas ruins uns com os outros, como o instinto de autopreservação... Esses impulsos estão programados em nosso cérebro, mas não há absolutamente nenhuma razão para construir robôs que tenham os mesmos tipos de impulsos\". Apesar de outras diferenças, a escola do risco x concorda com Pinker que uma IA avançada não destruiria a humanidade por causa de emoções humanas como \"vingança\" ou \"raiva\", que as questões de consciência não são relevantes para avaliar os riscos, e que os sistemas de computador geralmente não têm um equivalente computacional de testosterona. Eles acham que os comportamentos de busca de poder ou de autopreservação surgem na IA como uma forma de atingir seus verdadeiros objetivos, de acordo com o conceito de convergência instrumental. De acordo com Bostrom, fora do campo da inteligência artificial, a \"inteligência\" é frequentemente usada de uma maneira que conota sabedoria moral ou"}
{"source": "Risco existencial da inteligência artificial geral", "chunk_id": "Risco existencial da inteligência artificial geral_24", "text": "com o conceito de convergência instrumental. De acordo com Bostrom, fora do campo da inteligência artificial, a \"inteligência\" é frequentemente usada de uma maneira que conota sabedoria moral ou aceitação de formas aceitáveis de raciocínio moral. Em um extremo, se a moralidade faz parte da definição de inteligência, então, por definição, uma máquina superinteligente teria um comportamento moral. No entanto, a maioria das pesquisas sobre \"inteligência artificial\" se concentra na criação de algoritmos que \"otimizem\", de forma empírica, a realização de qualquer objetivo especificado pelos pesquisadores. Para evitar o antropomorfismo ou a bagagem da palavra \"inteligência\", pode-se pensar em uma inteligência artificial avançada como um \"processo de otimização\" impessoal que toma estritamente as ações que julga mais prováveis para atingir suas metas (possivelmente complicadas e implícitas). Outra maneira de conceituar uma inteligência artificial avançada é imaginar uma máquina do tempo que"}
{"source": "Risco existencial da inteligência artificial geral", "chunk_id": "Risco existencial da inteligência artificial geral_25", "text": "ações que julga mais prováveis para atingir suas metas (possivelmente complicadas e implícitas). Outra maneira de conceituar uma inteligência artificial avançada é imaginar uma máquina do tempo que envia informações retroativas sobre qual escolha sempre leva à maximização de sua função de meta; essa escolha é então emitida, independentemente de quaisquer preocupações éticas externas. No campo da inteligência artificial (IA), a pesquisa de alinhamento da IA tem como objetivo direcionar esses sistemas para as metas, preferências ou princípios éticos pretendidos pelos seres humanos. Um sistema de IA é considerado alinhado se ele atingir os objetivos pretendidos. Um sistema de IA desalinhado é competente em promover alguns objetivos, mas não os pretendidos. Pode ser um desafio para os projetistas alinhar um sistema de IA porque pode ser difícil especificar toda a gama de comportamentos desejados e indesejados. Para evitar essa dificuldade, eles geralmente usam metas substitutas mais"}
{"source": "Risco existencial da inteligência artificial geral", "chunk_id": "Risco existencial da inteligência artificial geral_26", "text": "alinhar um sistema de IA porque pode ser difícil especificar toda a gama de comportamentos desejados e indesejados. Para evitar essa dificuldade, eles geralmente usam metas substitutas mais simples, como obter aprovação humana. No entanto, essa abordagem pode criar brechas, ignorar as restrições necessárias ou recompensar o sistema de IA por parecer alinhado. Os sistemas de IA desalinhados podem apresentar mau funcionamento ou causar danos. Podem também encontrar brechas que lhes permitam atingir suas metas de proxy de forma eficiente, mas de maneiras não intencionais e, às vezes, prejudiciais (hacking recompensado). Os sistemas de IA também podem desenvolver estratégias instrumentais indesejadas, como a busca de poder ou sobrevivência, porque os ajudariam a atingir suas metas determinadas. Além disso, eles podem desenvolver metas emergentes indesejáveis que podem ser difíceis de detectar antes que o sistema esteja em implantação, onde ele enfrenta novas situações e distribuições de"}
{"source": "Risco existencial da inteligência artificial geral", "chunk_id": "Risco existencial da inteligência artificial geral_27", "text": "Além disso, eles podem desenvolver metas emergentes indesejáveis que podem ser difíceis de detectar antes que o sistema esteja em implantação, onde ele enfrenta novas situações e distribuições de dados. Atualmente, esses problemas afetam os sistemas comerciais existentes, como modelos de linguagem, robôs, veículos autônomos, e mecanismos de recomendação de mídia social. Alguns pesquisadores de IA argumentam que os sistemas futuros mais capazes serão afetados de forma mais grave, pois esses problemas resultam parcialmente do fato de os sistemas serem altamente capazes. Cientistas da computação importantes, como Geoffrey Hinton e Stuart Russell, argumentam que a IA está se aproximando de capacidades sobre-humanas e pode colocar em risco a civilização humana se estiver desalinhada. A comunidade de pesquisa de IA e as Nações Unidas pediram pesquisas técnicas e soluções políticas para garantir que os sistemas de IA estejam alinhados com os valores humanos. O alinhamento da IA é um subcampo"}
{"source": "Risco existencial da inteligência artificial geral", "chunk_id": "Risco existencial da inteligência artificial geral_28", "text": "de pesquisa de IA e as Nações Unidas pediram pesquisas técnicas e soluções políticas para garantir que os sistemas de IA estejam alinhados com os valores humanos. O alinhamento da IA é um subcampo da segurança da IA, o estudo de como criar sistemas de IA seguros. Outros subcampos incluem robustez, monitoramento e controle de capacidade. Os desafios da pesquisa em alinhamento incluem incutir valores complexos na IA, desenvolver IA honesta, supervisão escalável, auditoria e interpretação de modelos de IA e evitar comportamentos emergentes de IA, como a busca de poder. A pesquisa de alinhamento tem conexões com a pesquisa de interpretabilidade, robustez (adversarial), detecção de anomalias, incerteza calibrada, verificação formal, aprendizagem de preferências, engenharia de segurança crítica, teoria dos jogos, justiça algorítmica, e ciências sociais, entre outros. No modelo de \"agente inteligente\", uma IA pode ser vista vagamente como uma máquina que escolhe qualquer ação que pareça ser"}
{"source": "Risco existencial da inteligência artificial geral", "chunk_id": "Risco existencial da inteligência artificial geral_29", "text": "teoria dos jogos, justiça algorítmica, e ciências sociais, entre outros. No modelo de \"agente inteligente\", uma IA pode ser vista vagamente como uma máquina que escolhe qualquer ação que pareça ser a melhor para atingir o conjunto de objetivos da IA, ou \"função de utilidade\". Uma função de utilidade associa a cada situação possível uma pontuação que indica sua conveniência para o agente. Os pesquisadores sabem como escrever funções de utilidade que significam \"minimizar a latência média da rede nesse modelo específico de telecomunicações\" ou \"maximizar o número de cliques de recompensa\"; no entanto, eles não sabem como escrever uma função de utilidade para \"maximizar o florescimento humano\", nem está claro atualmente se essa função existe de forma significativa e inequívoca. Além disso, uma função de utilidade que expresse alguns valores, mas não outros, tenderá a atropelar os valores não refletidos pela função de utilidade. O pesquisador de IA Stuart Russell escreve: Dietterich e"}
{"source": "Risco existencial da inteligência artificial geral", "chunk_id": "Risco existencial da inteligência artificial geral_30", "text": "uma função de utilidade que expresse alguns valores, mas não outros, tenderá a atropelar os valores não refletidos pela função de utilidade. O pesquisador de IA Stuart Russell escreve: Dietterich e Horvitz trazem à tona a preocupação do \"Sorcerer's Apprentice\" (Aprendiz de Feiticeiro) em um editorial da Communications of the ACM, enfatizando a necessidade de sistemas de IA que possam solicitar a contribuição humana de forma fluida e não ambígua, conforme necessário. A primeira das duas preocupações de Russell acima é que os sistemas autônomos de IA podem receber as metas erradas por acidente. Dietterich e Horvitz observam que essa já é uma preocupação dos sistemas existentes: \"Um aspecto importante de qualquer sistema de IA que interage com pessoas é que ele deve raciocinar sobre o que as pessoas pretendem em vez de executar comandos literalmente\". Essa preocupação se torna mais séria à medida que o software de IA avança em autonomia e flexibilidade. Por exemplo, Eurisko (1982) foi"}
{"source": "Risco existencial da inteligência artificial geral", "chunk_id": "Risco existencial da inteligência artificial geral_31", "text": "as pessoas pretendem em vez de executar comandos literalmente\". Essa preocupação se torna mais séria à medida que o software de IA avança em autonomia e flexibilidade. Por exemplo, Eurisko (1982) foi uma IA projetada para recompensar subprocessos que criaram conceitos considerados valiosos pelo sistema. Um processo vencedor trapaceava: em vez de criar seus próprios conceitos, o subprocesso vencedor roubava o crédito de outros subprocessos. O Projeto Open Philanthropy resumiu os argumentos de que metas mal especificadas se tornarão uma preocupação muito maior se os sistemas de IA alcançarem inteligência geral ou superinteligência. Bostrom, Russell e outros argumentam que sistemas de tomada de decisão mais inteligentes do que os humanos poderiam chegar a soluções inesperadas e extremas para tarefas atribuídas e poderiam modificar a si mesmos ou seu ambiente de forma a comprometer os requisitos de segurança. As Três Leis da Robótica de Isaac Asimov são um dos primeiros exemplos de"}
{"source": "Risco existencial da inteligência artificial geral", "chunk_id": "Risco existencial da inteligência artificial geral_32", "text": "para tarefas atribuídas e poderiam modificar a si mesmos ou seu ambiente de forma a comprometer os requisitos de segurança. As Três Leis da Robótica de Isaac Asimov são um dos primeiros exemplos de medidas de segurança propostas para agentes de IA. As leis de Asimov tinham o objetivo de evitar que os robôs prejudicassem os seres humanos. Nas histórias de Asimov, os problemas com as leis tendem a surgir de conflitos entre as regras declaradas e as intuições e expectativas morais dos seres humanos. Citando o trabalho de Eliezer Yudkowsky do Instituto de Pesquisa de Inteligência de Máquinas (chine Intelligence Research Institute, )Russell e Norvig observam que um conjunto realista de regras e metas para um agente de IA precisará incorporar um mecanismo para aprender os valores humanos ao longo do tempo: \"Não podemos simplesmente dar a um programa uma função de utilidade estática, porque as circunstâncias e nossas respostas desejadas às circunstâncias mudam com o tempo\". Mark Waser, do"}
{"source": "Risco existencial da inteligência artificial geral", "chunk_id": "Risco existencial da inteligência artificial geral_33", "text": "do tempo: \"Não podemos simplesmente dar a um programa uma função de utilidade estática, porque as circunstâncias e nossas respostas desejadas às circunstâncias mudam com o tempo\". Mark Waser, do Instituto de Conhecimento Digital (Digital Wisdom Institute), é contra abordagens baseadas em objetivos por serem desorientadas e perigosas. Em vez disso, ele propõe a criação de um sistema coerente de leis, ética e moral com uma restrição máxima para aplicar a definição funcional de moralidade do psicólogo social Jonathan Haidt: \"suprimir ou regular o egoísmo e tornar possível a vida social cooperativa\". Ele sugere que isso pode ser feito por meio da implementação de uma função de utilidade projetada para sempre satisfazer a funcionalidade de Haidt e ter como objetivo geral aumentar (mas não maximizar) as capacidades do próprio indivíduo, de outros indivíduos e da sociedade como um todo, conforme sugerido por John Rawls e Martha Nussbaum. Nick Bostrom oferece um exemplo hipotético de dar a"}
{"source": "Risco existencial da inteligência artificial geral", "chunk_id": "Risco existencial da inteligência artificial geral_34", "text": "as capacidades do próprio indivíduo, de outros indivíduos e da sociedade como um todo, conforme sugerido por John Rawls e Martha Nussbaum. Nick Bostrom oferece um exemplo hipotético de dar a uma IA o objetivo de fazer os humanos sorrirem, para ilustrar uma tentativa equivocada. Se a IA nesse cenário se tornasse superinteligente, argumenta Bostrom, ela poderia recorrer a métodos que a maioria dos seres humanos consideraria horríveis, como inserir \"eletrodos nos músculos faciais dos seres humanos para causar sorrisos constantes e radiantes\", porque essa seria uma maneira eficiente de atingir seu objetivo de fazer os seres humanos sorrirem. Mesmo que os atuais programas de IA baseados em metas não sejam inteligentes o suficiente para pensar em resistir às tentativas dos programadores de modificar suas estruturas de metas, uma IA suficientemente avançada poderia resistir a qualquer mudança em sua estrutura de metas, assim como um pacifista não gostaria de tomar uma pílula que o fizesse"}
{"source": "Risco existencial da inteligência artificial geral", "chunk_id": "Risco existencial da inteligência artificial geral_35", "text": "suas estruturas de metas, uma IA suficientemente avançada poderia resistir a qualquer mudança em sua estrutura de metas, assim como um pacifista não gostaria de tomar uma pílula que o fizesse querer matar pessoas. Se a IA fosse superinteligente, provavelmente conseguiria superar seus operadores humanos e seria capaz de impedir que fosse \"desligada\" ou reprogramada com um novo objetivo. Um objetivo \"instrumental\" é um sub-objetivo que ajuda a atingir o objetivo final de um agente. A \"convergência instrumental\" refere-se ao fato de que existem algumas submetas que são úteis para atingir praticamente qualquer meta final, como a aquisição de recursos ou a autopreservação. Nick Bostrom argumenta que, se as metas instrumentais de uma IA avançada entrarem em conflito com as metas da humanidade, a IA poderá prejudicar os seres humanos para adquirir mais recursos ou evitar que seja desligada, mas apenas como uma forma de atingir sua meta final. Citando o trabalho de Steve Omohundro sobre a"}
{"source": "Risco existencial da inteligência artificial geral", "chunk_id": "Risco existencial da inteligência artificial geral_36", "text": "a IA poderá prejudicar os seres humanos para adquirir mais recursos ou evitar que seja desligada, mas apenas como uma forma de atingir sua meta final. Citando o trabalho de Steve Omohundro sobre a ideia de convergência instrumental e \"impulsos básicos de IA\", Stuart Russell e Peter Norvig escrevem que \"mesmo que você queira que seu programa apenas jogue xadrez ou prove teoremas, se você der a ele a capacidade de aprender e se alterar, você precisará de salvaguardas\". Sistemas de planejamento autônomos e altamente capazes requerem mais cautela devido à possibilidade de gerar planos que tratem os seres humanos de forma adversa, como concorrentes por recursos limitados. Pode não ser fácil para as pessoas criarem salvaguardas; certamente é possível dizer em portugues \"queremos que você projete essa usina de energia de forma razoável e sensata e não construa nenhum subsistema secreto perigoso\", mas atualmente não está claro como especificar tal objetivo de forma inequívoca. Russell"}
{"source": "Risco existencial da inteligência artificial geral", "chunk_id": "Risco existencial da inteligência artificial geral_37", "text": "projete essa usina de energia de forma razoável e sensata e não construa nenhum subsistema secreto perigoso\", mas atualmente não está claro como especificar tal objetivo de forma inequívoca. Russell argumenta que uma máquina suficientemente avançada \"terá autopreservação mesmo que você não a programe... se você disser: 'Pegue o café', ela não poderá pegar o café se estiver morta. Portanto, se você lhe der qualquer objetivo, ela terá uma razão para preservar sua própria existência para atingir esse objetivo\". Alguns céticos, como Timothy B. Lee, do Vox, argumentam que qualquer programa superinteligente criado por humanos seria subserviente aos humanos, que a superinteligência (à medida que se tornasse mais inteligente e aprendesse mais fatos sobre o mundo) aprenderia espontaneamente a verdade moral compatível com os valores humanos e ajustaria suas metas de acordo com isso, ou que os seres humanos são intrínseca ou convergentemente valiosos da perspectiva de uma inteligência"}
{"source": "Risco existencial da inteligência artificial geral", "chunk_id": "Risco existencial da inteligência artificial geral_38", "text": "a verdade moral compatível com os valores humanos e ajustaria suas metas de acordo com isso, ou que os seres humanos são intrínseca ou convergentemente valiosos da perspectiva de uma inteligência artificial. Em vez disso, a \"tese da ortogonalidade\" de Nick Bostrom argumenta que, com algumas ressalvas técnicas, quase qualquer nível de \"inteligência\" ou \"poder de otimização\" pode ser combinado com quase qualquer objetivo final. Se uma máquina tiver o único objetivo de enumerar os decimais de π {\\displaystyle \\pi } , então nenhuma regra moral ou ética a impedirá de atingir o objetivo programado por qualquer meio. A máquina pode utilizar todos os recursos físicos e informacionais disponíveis para encontrar o maior número possível de decimais de pi. Bostrom adverte contra o antropomorfismo: um ser humano se propõe a realizar seus projetos de uma maneira que os humanos considerem \"razoável\", enquanto uma inteligência artificial pode não se importar com sua existência ou com o bem-estar dos"}
{"source": "Risco existencial da inteligência artificial geral", "chunk_id": "Risco existencial da inteligência artificial geral_39", "text": "ser humano se propõe a realizar seus projetos de uma maneira que os humanos considerem \"razoável\", enquanto uma inteligência artificial pode não se importar com sua existência ou com o bem-estar dos seres humanos ao seu redor e, em vez disso, se preocupar apenas com a conclusão da tarefa. Stuart Armstrong argumenta que a tese da ortogonalidade decorre logicamente do argumento filosófico da \"distinção ser-deve ser\" contra o realismo moral. Armstrong também argumenta que, mesmo que existam fatos morais que possam ser provados por qualquer agente \"racional\", a tese da ortogonalidade ainda se sustenta: ainda seria possível criar uma \"máquina otimizadora\" não filosófica que possa se esforçar para atingir um objetivo restrito, mas que não tenha incentivo para descobrir quaisquer \"fatos morais\", como aqueles que poderiam atrapalhar a conclusão do objetivo. Um argumento a favor da tese da ortogonalidade é que alguns projetos de IA parecem ter a ortogonalidade embutida neles. Nesse tipo de"}
{"source": "Risco existencial da inteligência artificial geral", "chunk_id": "Risco existencial da inteligência artificial geral_40", "text": "como aqueles que poderiam atrapalhar a conclusão do objetivo. Um argumento a favor da tese da ortogonalidade é que alguns projetos de IA parecem ter a ortogonalidade embutida neles. Nesse tipo de projeto, transformar uma IA fundamentalmente amigável em uma IA fundamentalmente hostil pode ser tão simples quanto acrescentar um sinal de menos (\"-\") em sua função de utilidade. De acordo com Stuart Armstrong, se a tese da ortogonalidade fosse falsa, isso levaria a consequências estranhas: existiria um objetivo (O) simples, mas \"antiético\", de modo que não poderia existir nenhum algoritmo eficiente no mundo real com esse objetivo. Isso significaria que \"se uma sociedade humana estivesse altamente motivada para projetar um algoritmo eficiente no mundo real com o objetivo O e tivesse um milhão de anos para fazê-lo, juntamente com enormes quantidades de recursos, treinamento e conhecimento sobre IA, ele falharia\". Armstrong observa que essa e outras afirmações semelhantes \"parecem afirmações"}
{"source": "Risco existencial da inteligência artificial geral", "chunk_id": "Risco existencial da inteligência artificial geral_41", "text": "anos para fazê-lo, juntamente com enormes quantidades de recursos, treinamento e conhecimento sobre IA, ele falharia\". Armstrong observa que essa e outras afirmações semelhantes \"parecem afirmações extraordinariamente fortes\". O cético Michael Chorost rejeita explicitamente a tese de ortogonalidade de Bostrom, argumentando, em vez disso, que \"no momento em que a IA estiver em condições de imaginar cobrir a Terra com painéis solares, ela saberá que seria moralmente errado fazer isso\". Chorost argumenta que \"uma IA precisará desejar certos estados e não gostar de outros. O software atual não tem essa capacidade - e os cientistas da computação não têm a menor ideia de como fazer isso. Sem desejo, não há ímpeto para fazer nada. Os computadores atuais não podem nem mesmo querer continuar existindo, quanto mais revestir o mundo com painéis solares\". O cientista político Charles T. Rubin acredita que a IA não pode ser projetada nem garantida para ser benevolente. Ele argumenta que \"qualquer"}
{"source": "Risco existencial da inteligência artificial geral", "chunk_id": "Risco existencial da inteligência artificial geral_42", "text": "quanto mais revestir o mundo com painéis solares\". O cientista político Charles T. Rubin acredita que a IA não pode ser projetada nem garantida para ser benevolente. Ele argumenta que \"qualquer benevolência suficientemente avançada pode ser indistinguível da malevolência\". Os seres humanos não devem presumir que as máquinas ou robôs nos tratariam favoravelmente porque não há nenhuma razão a priori para acreditar que eles seriam simpáticos ao nosso sistema de moralidade, que evoluiu junto com nossa biologia particular (que as IAs não compartilhariam). Nick Bostrom e outros afirmaram que uma corrida para ser o primeiro a criar uma IAG poderia levar a atalhos na segurança ou até mesmo a conflitos violentos. Roman Yampolskiy e outros alertam que uma IAG malévola poderia ser criada por projeto, por exemplo, por um militar, um governo, um sociopata ou uma corporação; para se beneficiar, controlar ou subjugar determinados grupos de pessoas, como no crime cibernético, ou que uma IAG malévola"}
{"source": "Risco existencial da inteligência artificial geral", "chunk_id": "Risco existencial da inteligência artificial geral_43", "text": "por exemplo, por um militar, um governo, um sociopata ou uma corporação; para se beneficiar, controlar ou subjugar determinados grupos de pessoas, como no crime cibernético, ou que uma IAG malévola poderia escolher o objetivo de aumentar o sofrimento humano, por exemplo, das pessoas que não a ajudaram durante a fase de explosão de informações. As opiniões variam sobre se e quando a inteligência artificial geral chegará. Em um extremo, o pioneiro da IA, Herbert A. Simon, previu o seguinte em 1965: \"as máquinas serão capazes, dentro de vinte anos, de fazer qualquer trabalho que um homem possa fazer\". No outro extremo, o roboticista Alan Winfield afirma que o abismo entre a computação moderna e a inteligência artificial de nível humano é tão grande quanto o abismo entre o voo espacial atual e o voo espacial prático, mais rápido que a luz. O otimismo de que a IAG é viável tem altos e baixos e pode ter ressurgido na década de 2010. Quatro pesquisas realizadas em 2012 e 2013 sugeriram que"}
{"source": "Risco existencial da inteligência artificial geral", "chunk_id": "Risco existencial da inteligência artificial geral_44", "text": "e o voo espacial prático, mais rápido que a luz. O otimismo de que a IAG é viável tem altos e baixos e pode ter ressurgido na década de 2010. Quatro pesquisas realizadas em 2012 e 2013 sugeriram que não há consenso entre os especialistas sobre a previsão de quando a IAG chegará, com o desvio padrão (>100 anos) excedendo a mediana (algumas décadas). Em seu livro de 2020, The Precipice: Existential Risk and the Future of Humanity (\"O Precipício: Risco Existencial e o Futuro da Humanidade\"), Toby Ord, pesquisador sênior do Instituto Future of Humanity da Universidade de Oxford, estima que o risco existencial total da IA desalinhada nos próximos cem anos seja de cerca de um em dez. Os céticos que acreditam ser impossível que a IAG chegue tão cedo tendem a argumentar que expressar preocupação com o risco existencial da IA é inútil porque pode distrair as pessoas de preocupações mais imediatas sobre o impacto da IAG, por causa do medo de que isso possa levar à regulamentação governamental"}
{"source": "Risco existencial da inteligência artificial geral", "chunk_id": "Risco existencial da inteligência artificial geral_45", "text": "com o risco existencial da IA é inútil porque pode distrair as pessoas de preocupações mais imediatas sobre o impacto da IAG, por causa do medo de que isso possa levar à regulamentação governamental ou dificultar a obtenção de financiamento para a pesquisa de IA, ou porque pode dar má reputação à pesquisa de IA. Alguns pesquisadores, como Oren Etzioni, procuram agressivamente acabar com a preocupação com o risco existencial da IA, dizendo que \"Elon Musk nos impugnou com uma linguagem muito forte, dizendo que estamos liberando o demônio, e por isso estamos respondendo\". Em 2014, Adam Elkus, da Slate, argumentou que \"nossa IA 'mais inteligente' é tão inteligente quanto uma criança de colo - e somente quando se trata de tarefas instrumentais, como a recuperação de informações. A maioria dos roboticistas ainda está tentando fazer com que a mão de um robô pegue uma bola ou corra sem cair\". Elkus continua argumentando que a analogia de Musk de \"invocar o demônio\" pode ser prejudicial porque"}
{"source": "Risco existencial da inteligência artificial geral", "chunk_id": "Risco existencial da inteligência artificial geral_46", "text": "ainda está tentando fazer com que a mão de um robô pegue uma bola ou corra sem cair\". Elkus continua argumentando que a analogia de Musk de \"invocar o demônio\" pode ser prejudicial porque pode resultar em \"cortes severos\" nos orçamentos de pesquisa de IA. A Fundação de Tecnologia da Informação e Inovação (ITIF), um laboratório de ideias de Washington, D.C., concedeu seu Prêmio Anual Luddite de 2015 a \"alarmistas que apregoam um apocalipse de inteligência artificial\"; seu presidente, Robert D. Atkinson, reclamou que Musk, Hawking e especialistas dizem que a IA é a maior ameaça existencial à humanidade. Atkinson declarou: \"Essa não é uma mensagem muito positiva se você quiser obter financiamento para IA do Congresso da Fundação Nacional de Ciências\". A Nature discordou veementemente da ITIF em um editorial de abril de 2016, ficando do lado de Musk, Hawking e Russell, e concluindo: \"É fundamental que o progresso da tecnologia seja acompanhado por pesquisas sólidas e bem financiadas para"}
{"source": "Risco existencial da inteligência artificial geral", "chunk_id": "Risco existencial da inteligência artificial geral_47", "text": "em um editorial de abril de 2016, ficando do lado de Musk, Hawking e Russell, e concluindo: \"É fundamental que o progresso da tecnologia seja acompanhado por pesquisas sólidas e bem financiadas para prever os cenários que ela pode gerar... Se essa é uma perspectiva ludita, que seja\". Em um editorial do The Washington Post de 2015, o pesquisador Murray Shanahan afirmou que é improvável que a IA de nível humano chegue \"tão cedo\", mas que, mesmo assim, \"o momento de começar a pensar nas consequências é agora\". A tese de que a IA poderia representar um risco existencial provoca uma ampla gama de reações na comunidade científica, bem como no público em geral. Muitos dos pontos de vista opostos, no entanto, têm pontos em comum. Os Princípios de IA de Asilomar, que contêm apenas os princípios acordados por 90% dos participantes da conferência Beneficial AI 2017 do Instituto Future of Life, concordam, em princípio, que \"Não havendo consenso, devemos evitar suposições fortes em relação aos"}
{"source": "Risco existencial da inteligência artificial geral", "chunk_id": "Risco existencial da inteligência artificial geral_48", "text": "acordados por 90% dos participantes da conferência Beneficial AI 2017 do Instituto Future of Life, concordam, em princípio, que \"Não havendo consenso, devemos evitar suposições fortes em relação aos limites superiores das capacidades futuras de IA\" e \"A IA avançada pode representar uma mudança profunda na história da vida na Terra e deve ser planejada e gerenciada com cuidado e recursos proporcionais\". Os defensores da segurança da IA, como Bostrom e Tegmark, criticaram o uso pela mídia convencional \"daquelas imagens insanas do Exterminador do Futuro\" para ilustrar as preocupações com a segurança da IA: \"Não deve ser muito divertido ser alvo de críticas em relação à sua disciplina acadêmica, à sua comunidade profissional, ao trabalho de sua vida... Peço a todas as partes que tenham paciência e moderação e que se envolvam em diálogo direto e colaboração tanto quanto possível\". Por outro lado, muitos céticos concordam que a pesquisa contínua sobre as implicações da inteligência"}
{"source": "Risco existencial da inteligência artificial geral", "chunk_id": "Risco existencial da inteligência artificial geral_49", "text": "paciência e moderação e que se envolvam em diálogo direto e colaboração tanto quanto possível\". Por outro lado, muitos céticos concordam que a pesquisa contínua sobre as implicações da inteligência artificial geral é valiosa. O cético Martin Ford afirma que \"acho sensato aplicar algo como a famosa 'Doutrina do 1%' de Dick Cheney ao espectro da inteligência artificial avançada: as chances de sua ocorrência, pelo menos em um futuro previsível, podem ser muito baixas, mas as implicações são tão dramáticas que devem ser levadas a sério\". Da mesma forma, um economista cético declarou em 2014 que \"as implicações da introdução de uma segunda espécie inteligente na Terra são suficientes impactantes a ponto de merecerem uma reflexão profunda, mesmo que a perspectiva pareça remota\". Uma pesquisa de 2014 mostrou que a opinião de especialistas no campo da inteligência artificial é mista, com frações consideráveis tanto preocupadas quanto despreocupadas com o risco de uma eventual IA com"}
{"source": "Risco existencial da inteligência artificial geral", "chunk_id": "Risco existencial da inteligência artificial geral_50", "text": "de 2014 mostrou que a opinião de especialistas no campo da inteligência artificial é mista, com frações consideráveis tanto preocupadas quanto despreocupadas com o risco de uma eventual IA com capacidade sobre-humana. Uma pesquisa por e-mail de 2017 com pesquisadores com publicações nas conferências de aprendizado de máquina NIPS e ICML de 2015 pediu que eles avaliassem as preocupações de Stuart J. Russell sobre o risco da IA. Dos entrevistados, 5% disseram que esse era \"um dos problemas mais importantes da área\", 34% disseram que era \"um problema importante\" e 31% disseram que era \"moderadamente importante\", enquanto 19% disseram que \"não era importante\" e 11% disseram que \"não era um problema real\". Os resultados preliminares de uma pesquisa com especialistas em 2022, com uma taxa de resposta de 17%, parecem mostrar respostas medianas em torno de cinco ou dez por cento quando solicitados a estimar a probabilidade de extinção humana devido à inteligência artificial. A tese de que a"}
{"source": "Risco existencial da inteligência artificial geral", "chunk_id": "Risco existencial da inteligência artificial geral_51", "text": "de 17%, parecem mostrar respostas medianas em torno de cinco ou dez por cento quando solicitados a estimar a probabilidade de extinção humana devido à inteligência artificial. A tese de que a IA representa um risco existencial e que esse risco precisa de muito mais atenção do que recebe atualmente foi endossada por muitos cientistas da computação e figuras públicas, incluindo Alan Turing, o cientista da computação mais citado, Geoffrey Hinton, Elon Musk, o CEO da OpenAI, Sam Altman, Bill Gates e Stephen Hawking. Os defensores da tese às vezes expressam perplexidade com os céticos: Gates afirma que não \"entende por que algumas pessoas não estão preocupadas\", e Hawking criticou a indiferença generalizada em seu editorial de 2014: A preocupação com o risco da inteligência artificial levou a algumas doações e investimentos de alto nível. Em 2015, Peter Thiel, a Amazon Web Services, Musk e outros, em conjunto, destinaram US$ 1 bilhão para a OpenAI, que consiste em uma corporação com fins"}
{"source": "Risco existencial da inteligência artificial geral", "chunk_id": "Risco existencial da inteligência artificial geral_52", "text": "algumas doações e investimentos de alto nível. Em 2015, Peter Thiel, a Amazon Web Services, Musk e outros, em conjunto, destinaram US$ 1 bilhão para a OpenAI, que consiste em uma corporação com fins lucrativos e uma empresa controladora sem fins lucrativos que afirma ter como objetivo defender o desenvolvimento responsável da IA. O cofundador do Facebook, Dustin Moskovitz, financiou e deu origem a vários laboratórios que trabalham com Alinhamento de IA, notadamente US$ 5,5 milhões em 2016 para lançar o Centro de IA Compatível com Humanos, liderado pelo Professor Stuart Russell. Em janeiro de 2015, Elon Musk doou US$ 10 milhões para o Instituto Futuro da Vida para financiar pesquisas sobre a compreensão da tomada de decisões em IA. O objetivo do instituto é \"aumentar a sabedoria com a qual gerenciamos\" o crescente poder da tecnologia. Musk também financia empresas que desenvolvem inteligência artificial, como a DeepMind e a Vicarious, para \"ficar de olho no que está acontecendo com a"}
{"source": "Risco existencial da inteligência artificial geral", "chunk_id": "Risco existencial da inteligência artificial geral_53", "text": "gerenciamos\" o crescente poder da tecnologia. Musk também financia empresas que desenvolvem inteligência artificial, como a DeepMind e a Vicarious, para \"ficar de olho no que está acontecendo com a inteligência artificial\", dizendo: \"Acho que há um resultado potencialmente perigoso\". A tese de que a IA pode representar um risco existencial tem muitos detratores. Os céticos às vezes acusam a tese de ser cripto-religiosa, com uma crença irracional na possibilidade de superinteligência substituindo uma crença irracional em um Deus onipotente. Jaron Lanier argumentou em 2014 que todo o conceito de que as máquinas atuais eram de alguma forma inteligentes era \"uma ilusão\" e um \"golpe estupendo\" dos ricos. Algumas críticas argumentam que a IAG é improvável no curto prazo. O pesquisador de IA Rodney Brooks escreveu em 2014: \"Acho que é um erro nos preocuparmos com a possibilidade de desenvolvermos uma IA malévola nas próximas centenas de anos. Acho que a preocupação decorre de um erro"}
{"source": "Risco existencial da inteligência artificial geral", "chunk_id": "Risco existencial da inteligência artificial geral_54", "text": "IA Rodney Brooks escreveu em 2014: \"Acho que é um erro nos preocuparmos com a possibilidade de desenvolvermos uma IA malévola nas próximas centenas de anos. Acho que a preocupação decorre de um erro fundamental ao não distinguir a diferença entre os avanços recentes muito reais em um aspecto específico da IA e a enormidade e complexidade da construção de uma inteligência volitiva senciente\". O vice-presidente do Baidu, Andrew Ng, declarou em 2015 que o risco existencial da IA é \"como se preocupar com a superpopulação em Marte quando ainda nem pisamos no planeta\". O cientista da computação Gordon Bell argumentou em 2008 que a raça humana se destruirá antes de atingir a singularidade tecnológica. Gordon Moore, o proponente original da Lei de Moore, declara que \"sou um cético. Não acredito que uma singularidade tecnológica possa acontecer, pelo menos por um longo tempo. E não sei por que me sinto assim\". Para que o perigo da IA avançada sem controle se concretize, a IA hipotética pode"}
{"source": "Risco existencial da inteligência artificial geral", "chunk_id": "Risco existencial da inteligência artificial geral_55", "text": "que uma singularidade tecnológica possa acontecer, pelo menos por um longo tempo. E não sei por que me sinto assim\". Para que o perigo da IA avançada sem controle se concretize, a IA hipotética pode ter que superar ou pensar melhor do que qualquer ser humano, o que alguns especialistas argumentam ser uma possibilidade distante o suficiente no futuro para não valer a pena pesquisá-la. O economista Robin Hanson considera que, para lançar uma explosão de inteligência, a IA teria que se tornar muito melhor em inovação de software do que todo o resto do mundo combinado, o que parece implausível para ele. Outra linha de crítica postula que a inteligência é apenas um componente de uma capacidade muito mais ampla de atingir objetivos. Magnus Vinding argumenta que \"as capacidades avançadas de atingir objetivos, incluindo as capacidades de construir novas ferramentas, exigem muitas ferramentas, e nossas capacidades cognitivas são apenas um subconjunto dessas ferramentas. Hardware, materiais e"}
{"source": "Risco existencial da inteligência artificial geral", "chunk_id": "Risco existencial da inteligência artificial geral_56", "text": "objetivos, incluindo as capacidades de construir novas ferramentas, exigem muitas ferramentas, e nossas capacidades cognitivas são apenas um subconjunto dessas ferramentas. Hardware, materiais e energia avançados devem ser adquiridos para que qualquer meta avançada seja alcançada\". Vinding argumenta ainda que \"o que observamos consistentemente na história é que, à medida que os sistemas de alcance de metas se tornaram mais competentes, eles se tornaram cada vez mais dependentes de um sistema cada vez maior e mais distribuído\". Vinding escreve que não há razão para esperar que a tendência se reverta, especialmente no caso das máquinas, que \"dependem de materiais, ferramentas e know-how distribuídos amplamente pelo mundo para sua construção e manutenção\". Esses argumentos levam Vinding a pensar que não há um \"centro concentrado de capacidade\" e, portanto, nenhum \"grande problema de controle\". O futurista Max More considera que, mesmo que surgisse uma superinteligência, ela seria"}
{"source": "Risco existencial da inteligência artificial geral", "chunk_id": "Risco existencial da inteligência artificial geral_57", "text": "a pensar que não há um \"centro concentrado de capacidade\" e, portanto, nenhum \"grande problema de controle\". O futurista Max More considera que, mesmo que surgisse uma superinteligência, ela seria limitada pela velocidade do resto do mundo e, portanto, impedida de assumir o controle da economia de forma incontrolável: A natureza caótica ou a complexidade temporal de alguns sistemas também pode limitar fundamentalmente a capacidade de uma superinteligência de prever alguns aspectos do futuro, aumentando sua incerteza. Alguns pesquisadores de IA e IAG podem relutar em discutir os riscos, preocupados com o fato de que os formuladores de políticas não têm conhecimento sofisticado do campo e são propensos a serem convencidos por mensagens \"alarmistas\", ou preocupados com o fato de que tais mensagens levarão a cortes no financiamento da IA. A Slate observa que alguns pesquisadores dependem de subsídios de agências governamentais, como a DARPA. Vários céticos argumentam que os possíveis"}
{"source": "Risco existencial da inteligência artificial geral", "chunk_id": "Risco existencial da inteligência artificial geral_58", "text": "mensagens levarão a cortes no financiamento da IA. A Slate observa que alguns pesquisadores dependem de subsídios de agências governamentais, como a DARPA. Vários céticos argumentam que os possíveis benefícios de curto prazo da IA superam os riscos. O CEO do Facebook, Mark Zuckerberg, acredita que a IA \"desbloqueará uma enorme quantidade de coisas positivas\", como a cura de doenças e o aumento da segurança dos carros autônomos. Os pontos de vista intermediários geralmente assumem a posição de que o problema de controle da inteligência artificial geral pode existir, mas que será resolvido por meio do progresso da inteligência artificial, por exemplo, criando um ambiente de aprendizado moral para a IA, tomando cuidado para identificar comportamentos malévolos desajeitados (o \"tropeço sórdido\", \"sordid stumble\" em inglês) e, em seguida, intervindo diretamente no código antes que a IA refine seu comportamento, ou até mesmo a pressão de colegas de IAs amigáveis. Em um painel de discussão"}
{"source": "Risco existencial da inteligência artificial geral", "chunk_id": "Risco existencial da inteligência artificial geral_59", "text": "\"sordid stumble\" em inglês) e, em seguida, intervindo diretamente no código antes que a IA refine seu comportamento, ou até mesmo a pressão de colegas de IAs amigáveis. Em um painel de discussão de 2015 no The Wall Street Journal dedicado aos riscos da IA, o vice-presidente de Computação Cognitiva da IBM, Guruduth S. Banavar, descartou a discussão sobre a IAG com a frase: \"é especulação de qualquer um\". Geoffrey Hinton, o \"padrinho da aprendizagem profunda\", observou que \"não há um bom histórico de coisas menos inteligentes controlando coisas de maior inteligência\", mas afirmou que continua sua pesquisa porque \"a perspectiva de descoberta é muito boa\". Questionado sobre a possibilidade de uma IA tentar eliminar a raça humana, Hinton declarou que tal cenário \"não é inconcebível\", mas que o maior problema com uma \"explosão de inteligência\" seria a concentração de poder resultante. Em 2004, o professor de direito Richard Posner escreveu que os esforços dedicados para lidar com a IA podem"}
{"source": "Risco existencial da inteligência artificial geral", "chunk_id": "Risco existencial da inteligência artificial geral_60", "text": "maior problema com uma \"explosão de inteligência\" seria a concentração de poder resultante. Em 2004, o professor de direito Richard Posner escreveu que os esforços dedicados para lidar com a IA podem esperar, mas que devemos coletar mais informações sobre o problema nesse meio tempo. Em um artigo de 2014 no The Atlantic, James Hamblin observou que a maioria das pessoas não se importa com a IAG e caracterizou sua própria reação instintiva ao tópico como: \"Saia daqui. Tenho cem mil coisas com as quais estou me preocupando neste exato momento. Será que preciso seriamente acrescentar a isso uma singularidade tecnológica?\". Em uma entrevista à Wired em 2016 com o presidente Barack Obama e Joi Ito, do Laboratório de Mídia do MIT, Ito declarou: Obama acrescentou: Hillary Clinton declarou em What Happened: Em uma pesquisa YouGov de 2016 com o público para a Associação Britânica para o Avanço da Ciência, cerca de um terço dos entrevistados disse que a IA representará uma ameaça à sobrevivência"}
{"source": "Risco existencial da inteligência artificial geral", "chunk_id": "Risco existencial da inteligência artificial geral_61", "text": "Happened: Em uma pesquisa YouGov de 2016 com o público para a Associação Britânica para o Avanço da Ciência, cerca de um terço dos entrevistados disse que a IA representará uma ameaça à sobrevivência da humanidade a longo prazo. Jacob Brogan, da Slate, declarou que \"a maioria dos leitores que preencheram nossa pesquisa on-line não estava convencida de que a IA em si representa uma ameaça direta\". Em 2018, uma pesquisa da SurveyMonkey com o público americano, realizada pelo USA Today, revelou que 68% achavam que a verdadeira ameaça atual continua sendo a \"inteligência humana\"; no entanto, a pesquisa também revelou que 43% disseram que a IA superinteligente, se viesse a acontecer, resultaria em \"mais mal do que bem\" e 38% disseram que causaria \"quantidades iguais de mal e bem\". Um ponto de vista tecno-utópico expresso em algumas ficções populares é que a IAG pode tender para a construção da paz. Muitos estudiosos preocupados com o risco existencial da IAG acreditam que a melhor"}
{"source": "Risco existencial da inteligência artificial geral", "chunk_id": "Risco existencial da inteligência artificial geral_62", "text": "de vista tecno-utópico expresso em algumas ficções populares é que a IAG pode tender para a construção da paz. Muitos estudiosos preocupados com o risco existencial da IAG acreditam que a melhor abordagem é realizar pesquisas substanciais para resolver o difícil \"problema de controle\": que tipos de salvaguardas, algoritmos ou arquiteturas os programadores podem implementar para maximizar a probabilidade de que sua IA de melhoria recursiva continue a se comportar de maneira amigável depois de atingir a superinteligência? Medidas sociais podem mitigar o risco existencial da IAG; por exemplo, uma recomendação é um \"Tratado de IAG benevolente\" patrocinado pela ONU que garantiria que apenas IAGs altruístas fossem criadas. Da mesma forma, uma abordagem de controle de armas foi sugerida, assim como um tratado de paz global fundamentado na teoria de relações internacionais do instrumentalismo conforme, com uma IAG potencialmente sendo signatária. Pesquisadores do Google propuseram uma"}
{"source": "Risco existencial da inteligência artificial geral", "chunk_id": "Risco existencial da inteligência artificial geral_63", "text": "assim como um tratado de paz global fundamentado na teoria de relações internacionais do instrumentalismo conforme, com uma IAG potencialmente sendo signatária. Pesquisadores do Google propuseram uma pesquisa sobre questões gerais de \"segurança da IA\" para mitigar simultaneamente os riscos de curto prazo da IA restrita e os riscos de longo prazo da IAG. Uma estimativa de 2020 coloca os gastos globais com o risco existencial da IA entre US$ 10 e US$ 50 milhões, em comparação com os gastos globais com IA em torno de talvez US$ 40 bilhões. Bostrom sugere um princípio geral de \"desenvolvimento tecnológico diferencial\": que os financiadores devem acelerar o desenvolvimento de tecnologias protetoras em relação ao desenvolvimento de tecnologias perigosas. Alguns financiadores, como Elon Musk, propõem que o aprimoramento cognitivo humano radical poderia ser uma tecnologia desse tipo, por exemplo, a ligação neural direta entre o ser humano e a máquina; no entanto, outros argumentam que as"}
{"source": "Risco existencial da inteligência artificial geral", "chunk_id": "Risco existencial da inteligência artificial geral_64", "text": "propõem que o aprimoramento cognitivo humano radical poderia ser uma tecnologia desse tipo, por exemplo, a ligação neural direta entre o ser humano e a máquina; no entanto, outros argumentam que as tecnologias de aprimoramento podem representar um risco existencial. Os pesquisadores, se não forem pegos de surpresa, poderiam monitorar de perto ou tentar encaixotar uma IA inicial que corra o risco de se tornar muito poderosa, como uma tentativa de medida paliativa. Uma IA superinteligente dominante, se estivesse alinhada com os interesses humanos, poderia tomar medidas para mitigar o risco de aquisição por uma IA rival, embora a própria criação da IA dominante pudesse representar um risco existencial. Instituições como o Instituto de Pesquisa de Inteligência de Máquinas (\"Machine Intelligence Research Institute\"), o Instituto do Future of Humanity, o Instituto Future of Life, o Centro para o Estudo do Risco Existencial (Centre for the Study of Existential Risk) e o Centro para IA"}
{"source": "Risco existencial da inteligência artificial geral", "chunk_id": "Risco existencial da inteligência artificial geral_65", "text": "Research Institute\"), o Instituto do Future of Humanity, o Instituto Future of Life, o Centro para o Estudo do Risco Existencial (Centre for the Study of Existential Risk) e o Centro para IA Compatível com Humanos (\"Center for Human-Compatible AI\") estão envolvidos na mitigação do risco existencial da inteligência artificial avançada, por exemplo, por meio de pesquisas sobre inteligência artificial amigável. Proibição A maioria dos acadêmicos acredita que, mesmo que a IAG represente um risco existencial, tentar proibir a pesquisa em inteligência artificial ainda seria insensato e provavelmente fútil. Os céticos argumentam que a regulamentação da IA seria completamente inútil, pois não existe risco existencial. No entanto, os estudiosos que acreditam no risco existencial propuseram que é difícil depender de pessoas do setor de IA para regulamentar ou restringir a pesquisa de IA, pois isso contradiz diretamente seus interesses pessoais. Os estudiosos também concordam com os céticos que"}
{"source": "Risco existencial da inteligência artificial geral", "chunk_id": "Risco existencial da inteligência artificial geral_66", "text": "depender de pessoas do setor de IA para regulamentar ou restringir a pesquisa de IA, pois isso contradiz diretamente seus interesses pessoais. Os estudiosos também concordam com os céticos que proibir a pesquisa seria insensato, pois a pesquisa poderia ser transferida para países com regulamentações mais flexíveis ou conduzida secretamente. A última questão é particularmente relevante, pois a pesquisa em inteligência artificial pode ser feita em pequena escala, sem infraestrutura ou recursos substanciais. Duas dificuldades hipotéticas adicionais com as proibições (ou outra regulamentação) são que os empreendedores de tecnologia tendem estatisticamente ao ceticismo geral sobre a regulamentação governamental e que as empresas poderiam ter um forte incentivo para (e poderiam muito bem ter sucesso) combater a regulamentação e politizar o debate subjacente. Regulamentação Em março de 2023, o Instituto Future ture of Life (FLI), financiado por Elon Musk, redigiu uma carta pedindo aos"}
{"source": "Risco existencial da inteligência artificial geral", "chunk_id": "Risco existencial da inteligência artificial geral_67", "text": "ter sucesso) combater a regulamentação e politizar o debate subjacente. Regulamentação Em março de 2023, o Instituto Future ture of Life (FLI), financiado por Elon Musk, redigiu uma carta pedindo aos principais desenvolvedores de IA que concordassem com uma pausa verificável de seis meses de quaisquer sistemas \"mais poderosos do que o GPT-4\" e que usassem esse tempo para instituir uma estrutura para garantir a segurança; ou, na falta disso, que os governos interviessem com uma moratória. A carta se referia à possibilidade de \"uma mudança profunda na história da vida na Terra\", bem como aos riscos potenciais de propaganda gerada por IA, perda de empregos, obsolescência humana e perda de controle em toda a sociedade. Além de Musk, entre os signatários proeminentes estavam Steve Wozniak, Evan Sharp, Chris Larsen e Gary Marcus; os CEOs de laboratórios de IA Connor Leahy e Emad Mostaque; o político Andrew Yang; e o pioneiro em aprendizagem profunda Yoshua Bengio. Marcus afirmou que \"a"}
{"source": "Risco existencial da inteligência artificial geral", "chunk_id": "Risco existencial da inteligência artificial geral_68", "text": "Evan Sharp, Chris Larsen e Gary Marcus; os CEOs de laboratórios de IA Connor Leahy e Emad Mostaque; o político Andrew Yang; e o pioneiro em aprendizagem profunda Yoshua Bengio. Marcus afirmou que \"a carta não é perfeita, mas o espírito é correto\". Mostaque declarou: \"Não acho que uma pausa de seis meses seja a melhor ideia nem concordo com tudo, mas há algumas coisas interessantes nessa carta\". Em contrapartida, Bengio endossou explicitamente a pausa de seis meses em uma coletiva de imprensa. Musk declarou que \"Os principais desenvolvedores de IAG não darão atenção a esse aviso, mas pelo menos ele foi dito\". Alguns signatários, como Marcus, assinaram por preocupação com riscos mundanos, como propaganda gerada por IA, e não por preocupação com IAG superinteligente. Margaret Mitchell, cujo trabalho é citado na carta, criticou-a, dizendo: \"Ao tratar muitas ideias questionáveis como um dado adquirido, a carta afirma um conjunto de prioridades e uma narrativa sobre IA que beneficia os"}
{"source": "Risco existencial da inteligência artificial geral", "chunk_id": "Risco existencial da inteligência artificial geral_69", "text": "trabalho é citado na carta, criticou-a, dizendo: \"Ao tratar muitas ideias questionáveis como um dado adquirido, a carta afirma um conjunto de prioridades e uma narrativa sobre IA que beneficia os defensores da FLI. Ignorar os danos ativos neste momento é um privilégio que alguns de nós não têm\". Musk pediu algum tipo de regulamentação do desenvolvimento de IA já em 2017. De acordo com a NPR, o CEO da Tesla \"claramente não está entusiasmado\" por estar defendendo o escrutínio do governo que poderia afetar seu próprio setor, mas acredita que os riscos de ficar completamente sem supervisão são muito altos: \"Normalmente, a maneira como as regulamentações são estabelecidas é quando um monte de coisas ruins acontece, há um clamor público e, depois de muitos anos, uma agência reguladora é criada para regulamentar esse setor. Isso leva uma eternidade. Isso, no passado, foi ruim, mas não algo que representasse um risco fundamental para a existência da civilização\". Musk afirma que o primeiro"}
{"source": "Risco existencial da inteligência artificial geral", "chunk_id": "Risco existencial da inteligência artificial geral_70", "text": "para regulamentar esse setor. Isso leva uma eternidade. Isso, no passado, foi ruim, mas não algo que representasse um risco fundamental para a existência da civilização\". Musk afirma que o primeiro passo seria o governo obter uma \"percepção\" do status real da pesquisa atual, alertando que \"quando houver conscientização, as pessoas ficarão extremamente temerosas... como deveriam ficar\". Em resposta, os políticos expressaram ceticismo sobre a sabedoria de regulamentar uma tecnologia que ainda está em desenvolvimento. Em resposta a Musk e às propostas de fevereiro de 2017 dos legisladores da União Europeia para regulamentar a IA e a robótica, o CEO da Intel, Brian Krzanich, argumentou que a IA está em sua infância e que é muito cedo para regulamentar a tecnologia. Em vez de tentar regulamentar a tecnologia em si, alguns estudiosos sugerem normas comuns, incluindo requisitos para o teste e a transparência de algoritmos, possivelmente em combinação com alguma forma de garantia. O"}
{"source": "Risco existencial da inteligência artificial geral", "chunk_id": "Risco existencial da inteligência artificial geral_71", "text": "a tecnologia em si, alguns estudiosos sugerem normas comuns, incluindo requisitos para o teste e a transparência de algoritmos, possivelmente em combinação com alguma forma de garantia. O desenvolvimento de sistemas de armas bem regulamentados está de acordo com o ethos das forças armadas de alguns países. Em 31 de outubro de 2019, o Conselho de Inovação em Defesa do Departamento de Defesa dos Estados Unidos (DoD) publicou o rascunho de um relatório que delineia cinco princípios para IA armada e faz 12 recomendações para o uso ético da inteligência artificial pelo DoD que busca gerenciar o problema de controle em toda a IA armada do DoD. A regulamentação da IAG provavelmente seria influenciada pela regulamentação da IA armada ou militarizada, ou seja, a corrida armamentista da IA, que é uma questão emergente. Embora haja progresso das Nações Unidas na regulamentação da IA, sua capacidade institucional e legal de gerenciar o risco existencial da IAG é muito limitada. Qualquer forma de"}
{"source": "Risco existencial da inteligência artificial geral", "chunk_id": "Risco existencial da inteligência artificial geral_72", "text": "questão emergente. Embora haja progresso das Nações Unidas na regulamentação da IA, sua capacidade institucional e legal de gerenciar o risco existencial da IAG é muito limitada. Qualquer forma de regulamentação internacional provavelmente será influenciada por desenvolvimentos na política interna dos países líderes em relação à IA militarizada, que nos EUA está sob a alçada da Comissão de Segurança Nacional sobre Inteligência Artificial (\"National Security Commission on Artificial Intelligence\"), e movimentos internacionais para regulamentar uma corrida armamentista de IA. A regulamentação da pesquisa em IAGse concentra no papel dos conselhos de revisão, incentivando a pesquisa em IA segura, a possibilidade de progresso tecnológico diferenciado (priorizando estratégias de redução de riscos em detrimento de estratégias de assunção de riscos no desenvolvimento de IA) ou a realização de vigilância internacional em massa para realizar o controle de armas de IAG. A regulamentação de IAGs"}
{"source": "Risco existencial da inteligência artificial geral", "chunk_id": "Risco existencial da inteligência artificial geral_73", "text": "em detrimento de estratégias de assunção de riscos no desenvolvimento de IA) ou a realização de vigilância internacional em massa para realizar o controle de armas de IAG. A regulamentação de IAGs conscientes se concentra em integrá-los à sociedade humana existente e pode ser dividida em considerações sobre sua situação legal e seus direitos morais. O controle de armas de IA provavelmente exigirá a institucionalização de novas normas internacionais incorporadas em especificações técnicas eficazes combinadas com monitoramento ativo e diplomacia informal por comunidades de especialistas, juntamente com um processo de verificação legal e política. Apelo à probabilidade Alinhamento da inteligência artificial Segurança da inteligência artificial Filosofia da inteligência artificial Altruísmo eficaz Grey goo Armas Autônomas Letais"}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_0", "text": "O aprendizado automático (português brasileiro) ou a aprendizagem automática (português europeu) ou também aprendizado de máquina (português brasileiro) ou aprendizagem de máquina (português europeu) (em inglês: machine learning) é um subcampo da Engenharia e da ciência da computação que evoluiu do estudo de reconhecimento de padrões e da teoria do aprendizado computacional em inteligência artificial. Em 1959, Arthur Samuel definiu aprendizado de máquina como o \"campo de estudo que dá aos computadores a habilidade de aprender sem serem explicitamente programados\"(livre tradução). O aprendizado automático explora o estudo e construção de algoritmos que podem aprender de seus erros e fazer previsões sobre dados. Tais algoritmos operam construindo um modelo a partir de inputs amostrais a fim de fazer previsões ou decisões guiadas pelos dados ao invés de simplesmente seguindo inflexíveis e estáticas instruções programadas. Enquanto que na inteligência artificial existem dois tipos de"}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_1", "text": "fim de fazer previsões ou decisões guiadas pelos dados ao invés de simplesmente seguindo inflexíveis e estáticas instruções programadas. Enquanto que na inteligência artificial existem dois tipos de raciocínio (o indutivo, que extrai regras e padrões de grandes conjuntos de dados, e o dedutivo), o aprendizado de máquina só se preocupa com o indutivo. Algumas partes do aprendizado automático estão intimamente ligadas (e muitas vezes sobrepostas) à estatística computacional; uma disciplina que foca em como fazer previsões através do uso de computadores, com pesquisas focando nas propriedades dos métodos estatísticos e sua complexidade computacional. Ela tem fortes laços com a otimização matemática, que produz métodos, teoria e domínios de aplicação para este campo. O aprendizado automático é usado em uma variedade de tarefas computacionais onde criar e programar algoritmos explícitos é impraticável. Exemplos de aplicações incluem filtragem de spam, reconhecimento ótico de caracteres"}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_2", "text": "é usado em uma variedade de tarefas computacionais onde criar e programar algoritmos explícitos é impraticável. Exemplos de aplicações incluem filtragem de spam, reconhecimento ótico de caracteres (OCR), processamento de linguagem natural, motores de busca, diagnósticos médicos, bioinformática, reconhecimento de fala, reconhecimento de escrita, visão computacional e locomoção de robôs. O aprendizado de máquinas é às vezes confundido com mineração de dados, que é um sub-campo que foca mais em análise exploratória de dados e é conhecido como aprendizado não supervisionado. No campo da análise de dados, o aprendizado de máquinas é um método usado para planejar modelos complexos e algoritmos que prestam-se para fazer predições- no uso comercial, isso é conhecido como análise preditiva. Esses modelos analíticos permitem que pesquisadores, cientistas de dados, engenheiros, e analistas possam \"produzir decisões e resultados confiáveis e repetitíveis\" e descobrir os \"insights escondidos\""}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_3", "text": "modelos analíticos permitem que pesquisadores, cientistas de dados, engenheiros, e analistas possam \"produzir decisões e resultados confiáveis e repetitíveis\" e descobrir os \"insights escondidos\" através do aprendizado das relações e tendências históricas nos dados. As contribuições para a fundação da aprendizagem automática (aprendizado de máquina) feitas pelos cientistas John Hopfield e Geoffrey Hinton foram distinguidas em 2024 com o Prémio Nobel de Física. O Comité Nobel destacou os cientistas por \"descobertas fundamentais e invenções que permitem aprendizagem automática com redes neuronais artificiais”. Tom M. Mitchell forneceu uma definição mais formal amplamente citada: \"Diz-se que um programa de computador aprende pela experiência E, com respeito a algum tipo de tarefa T e performance P, se sua performance P nas tarefas em T, na forma medida por P, melhoram com a experiência E.\" Esta definição das tarefas envolvidas no aprendizado de máquina é dada de forma fundamentalmente"}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_4", "text": "P, se sua performance P nas tarefas em T, na forma medida por P, melhoram com a experiência E.\" Esta definição das tarefas envolvidas no aprendizado de máquina é dada de forma fundamentalmente operacional, ao invés de cognitiva, seguindo a proposta de Alan Turing em seu artigo \"Computadores e inteligência\", em que a pergunta \"As máquinas são capazes de pensar?\" seja substituída pela pergunta \"As máquinas são capazes de fazer o que (nós como entidades pensantes) podemos fazer?\" As tarefas de aprendizado de máquina são tipicamente classificadas em três categorias amplas, de acordo com a natureza do \"sinal\" ou \"feedback\" de aprendizado disponível para um sistema de aprendizado. Essas categorias são: Aprendizado supervisionado: São apresentadas ao computador exemplos de entradas e saídas desejadas, fornecidas por um \"professor\". O objetivo é aprender uma regra geral que mapeia as entradas para as saídas. Aprendizado não supervisionado: Nenhum tipo de etiqueta é dado ao algoritmo de"}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_5", "text": "desejadas, fornecidas por um \"professor\". O objetivo é aprender uma regra geral que mapeia as entradas para as saídas. Aprendizado não supervisionado: Nenhum tipo de etiqueta é dado ao algoritmo de aprendizado, deixando-o sozinho para encontrar estrutura nas entradas fornecidas. O aprendizado não supervisionado pode ser um objetivo em si mesmo (descobrir novos padrões nos dados) ou um meio para atingir um fim. Aprendizado por reforço: Um programa de computador interage com um ambiente dinâmico, em que o programa deve desempenhar determinado objetivo (por exemplo, dirigir um veículo). É fornecido, ao programa, feedback quanto a premiações e punições, na medida em que é navegado o espaço do problema. Outro exemplo de aprendizado por reforço é aprender a jogar um determinado jogo apenas jogando contra um oponente. Entre o aprendizado supervisionado e o não supervisionado, está o aprendizado semi-supervisionado, em que o professor fornece um sinal de treinamento incompleto: um conjunto de"}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_6", "text": "contra um oponente. Entre o aprendizado supervisionado e o não supervisionado, está o aprendizado semi-supervisionado, em que o professor fornece um sinal de treinamento incompleto: um conjunto de dados de treinamento com algumas (muitas vezes várias) das saídas desejadas ausentes. A transdução é um caso especial deste princípio, em que o conjunto inteiro das instâncias do problema é conhecido no momento do aprendizado, mas com parte dos objetivos ausente. Entre outras categorias de problemas de aprendizado de máquina, o meta-aprendizado aprende seu próprio viés indutivo com base em experiência prévias. A robótica epigenética, elaborada para o aprendizado de robôs, gera suas próprias sequências de situações de aprendizado (também chamadas de 'currículo'), para adquirir cumulativamente repertórios de novas habilidades, através de uma auto-exploração autônoma e da interação social com professores humanos. Faz uso de técnicas como aprendizado ativo, maturação, sinergias motoras e"}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_7", "text": "repertórios de novas habilidades, através de uma auto-exploração autônoma e da interação social com professores humanos. Faz uso de técnicas como aprendizado ativo, maturação, sinergias motoras e imitação. Outra categorização de tarefas de aprendizado de máquina surge quando se considera a saída desejada em um sistema de aprendizado de máquina: Em classificação, entradas são divididas em duas ou mais classes, e o aprendiz deve produzir um modelo que vincula entradas não vistas a uma ou mais dessas classes (classificação multi-etiquetada). Isso é tipicamente abordado de forma supervisionada. A filtragem de spam é um exemplo de classificação, em que as entradas são as mensagens de emails (ou outros) e as classes são \"spam\" ou \"não spam\". Em regressão, também um problema supervisionado, as saídas são contínuas, em vez de discretas. Em clustering, um conjunto de entradas é dividido em grupos. De maneira diferente da classificação, os grupos não são conhecidos previamente, tornando o"}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_8", "text": "as saídas são contínuas, em vez de discretas. Em clustering, um conjunto de entradas é dividido em grupos. De maneira diferente da classificação, os grupos não são conhecidos previamente, tornando o clustering uma tarefa tipicamente não supervisionada. A estimativa de densidades encontra a distribuição de entradas em algum espaço. A redução dimensional simplifica as entradas ao mapeá-las para um espaço de menor dimensão. A modelagem de tópicos é um problema relacionado, em que é fornecida ao programa uma lista de documentos em linguagem natural, solicitando que encontre documentos tratando de tópicos similares. Como um esforço científico, o aprendizado de máquina cresceu a partir da busca pela inteligência artificial. Ainda nos princípios da IA como disciplina acadêmica, alguns pesquisadores já se interessavam em fazer máquinas aprenderem a partir de dados. Eles tentaram abordar o problema desde vários métodos simbólicos, assim como com o que foi então nomeado de \"rede neural"}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_9", "text": "já se interessavam em fazer máquinas aprenderem a partir de dados. Eles tentaram abordar o problema desde vários métodos simbólicos, assim como com o que foi então nomeado de \"rede neural artificial\"; estes eram majoritariamente perceptrons e outros modelos que mais tardes foram entendidos como reinvenções de modelos linear generalizados de estatística. A lógica probabilística também foi usada, especialmente em diagnósticos médicos automatizados.:488 No entanto, uma crescente ênfase na abordagem lógica, baseada em conhecimento, causou uma brecha entre a IA e o aprendizado de máquina. Sistemas probabilísticos eram atormentados por problemas teoréticos e práticos de aquisição e representação de dados.:488 Em 1980, sistemas especialistas haviam dominado a IA, e a estatística estava fora de uso. Trabalhos em aprendizado baseado em conhecimento/simbólico continuaram com a IA, levando até a programação lógica indutiva, mas agora as pesquisas mais voltadas para a estatística estavam fora do"}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_10", "text": "Trabalhos em aprendizado baseado em conhecimento/simbólico continuaram com a IA, levando até a programação lógica indutiva, mas agora as pesquisas mais voltadas para a estatística estavam fora do campo da IA, em reconhecimento de padrões e recuperação de informação.:708–710; 755 Pesquisas em redes neuronais haviam sido abandonadas pela IA e ciência computacional em torno do mesmo período. Essa linha, também, foi continuada forma dos campos da IA e da ciência da computação, como \"conexionismos\", por pesquisadores de outras disciplinas incluindo Hopfield, Rumelhart e Hinton. Seu sucesso principal veio em meados da década de 1980 com a reinvenção da propagação para trás.:25 O aprendizado de máquina, reorganizado como um campo separado, começou a florescer na década de 1990. O campo mudou seu objetivo de alcançar a inteligência artificial para abordar problemas solucionáveis de natureza prática. Ele abandonou o foco em abordagens simbólicas que havia herdado da IA para métodos e modelos"}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_11", "text": "objetivo de alcançar a inteligência artificial para abordar problemas solucionáveis de natureza prática. Ele abandonou o foco em abordagens simbólicas que havia herdado da IA para métodos e modelos emprestados da estatística e da teoria da probabilidade. Ele também se beneficiou do crescente número de informação digitalizada disponível e a possibilidade de distribuir ela via internet. O aprendizado de máquina e a mineração de dados com freqüência fazem uso dos mesmos métodos e se sobrepõe significativamente, mas enquanto o aprendizado de máquina foca em fazer previsões, baseado em propriedades conhecidas aprendidas pelo dados de treinamento, a mineração de dados foca em descobrir as propriedades (previamente) desconhecidas nos dados (este é o passo dado na análise de extração de conhecimento na base de dados). A mineração de dados usa muitas métodos do aprendizado de máquina, mas com objetivos diferentes; por outro lado, o aprendizado de máquina também faz uso de métodos da mineração"}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_12", "text": "na base de dados). A mineração de dados usa muitas métodos do aprendizado de máquina, mas com objetivos diferentes; por outro lado, o aprendizado de máquina também faz uso de métodos da mineração de dados como \"aprendizado não supervisionado\" ou como um passo de processamento para melhorar a precisão do aprendiz. Muita da confusão entre essas duas comunidades de pesquisa (que com freqüência tem conferências e periódicos separados, ECML PKDD sendo a grande exceção) vem da suposição básica com que eles trabalham: em aprendizado de máquina, a performance é normalmente avaliada com respeito a habilidade de reproduzir conhecimento conhecido, enquanto que com a extração de conhecimento e mineração de dados (KDD) a tarefa chave é o descobrimento de conhecimento previamente desconhecido. Avaliado com respeito ao conhecimento conhecido, um método uniforme (não supervisionado) será facilmente superado por outros métodos supervisionados, enquanto que em uma tarefa KDD típica, métodos"}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_13", "text": "Avaliado com respeito ao conhecimento conhecido, um método uniforme (não supervisionado) será facilmente superado por outros métodos supervisionados, enquanto que em uma tarefa KDD típica, métodos supervisionados não podem ser usados devido a não disponibilidade de dados de treinamento. O aprendizado de máquina também tem laços íntimos com a otimização: muitos dos problemas de aprendizado são formulados como minimização de algumas funções de perda em um conjunto exemplo de treinamentos. Funções de perda expressam a discrepância entre as previsões do modelo sendo treinado e as verdadeiras instâncias do problema (por exemplo, em classificação, o objetivo é designar etiquetas para instâncias, e modelos são treinados para predizer corretamente as etiquetas previamente designadas de um conjunto exemplo). A diferença entre os dois campos surge do objetivo da generalização: enquanto que o algoritmo de otimização pode minimizar a perda em um conjunto de treinamento, o aprendizado de máquina"}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_14", "text": "exemplo). A diferença entre os dois campos surge do objetivo da generalização: enquanto que o algoritmo de otimização pode minimizar a perda em um conjunto de treinamento, o aprendizado de máquina está preocupado com a minimização da perda de amostras não vistas. O aprendizado de máquina e a estatística são campos intimamente relacionados. De acordo com Michael I. Jordan, as ideias do aprendizado de máquina, dos princípios metodológicos às ferramentas teóricas, tem uma longa pré-história na estatística. Ele também sugeriu o termo ciência de dados como um substituto para chamar o campo como um todo. Leo Breiman distinguiu dois paradigmas da modelagem estatística: modelo de dados e modelo algorítmico, onde \"modelo algorítmico\" significa mais ou menos os algoritmos do aprendizado de máquina como a Floresta aleatória. Alguns estatísticos tem adotado métodos do aprendizado de máquinas, levando ao campo combinado que eles chamam de aprendizado estatístico. Um dos objetivos centrais de um"}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_15", "text": "como a Floresta aleatória. Alguns estatísticos tem adotado métodos do aprendizado de máquinas, levando ao campo combinado que eles chamam de aprendizado estatístico. Um dos objetivos centrais de um aprendiz é generalizar a partir de suas experiências. Generalização neste contexto é a habilidade de uma máquina aprendiz de desempenhar com precisão em novos, não vistos, exemplos/tarefas depois de ter experimentado um conjunto de dados de aprendizado. Os exemplos de treinamento vem de algumas, geralmente desconhecidas, distribuições de probabilidade (consideradas representativas do espaço de ocorrência) e o aprendiz tem de construir um modelo geral sobre este espaço que o permita produzir previsões o suficientemente precisas em novos casos. A análise computacional de algoritmos de aprendizado de máquina e sua performance é um ramo da ciência da computação teórica conhecida como teoria do aprendizado computacional. Porque os conjuntos de treinamento são finitos e o futuro é incerto, a"}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_16", "text": "de máquina e sua performance é um ramo da ciência da computação teórica conhecida como teoria do aprendizado computacional. Porque os conjuntos de treinamento são finitos e o futuro é incerto, a teoria de aprendizado normalmente não guarda garantias para a performance dos algoritmos. Em vez disso,previsões probabilísticas para a performance são bastante comuns. O trade-off entre variância e viés é uma forma de qualificar o erro de generalização. Para uma melhor performance no contexto de generalização, a complexidade da hipótese deveria combinar com a complexidade da função subjacente aos dados. Se a hipótese é menos complexa que a função, então o modelo sub-ajustou (underfitting) os dados. Se a complexidade do modelo é aumentada em resposta, então o erro de treinamento diminui. Mas se a hipótese é muito complexa, então o modelo foi sobreajustado (overfitting), e a generalização será mais pobre. Em adição aos limites da performance, teóricos do aprendizado computacional estudam a"}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_17", "text": "a hipótese é muito complexa, então o modelo foi sobreajustado (overfitting), e a generalização será mais pobre. Em adição aos limites da performance, teóricos do aprendizado computacional estudam a complexidade do tempo e a viabilidade do aprendizado. Na teoria do aprendizado computacional, uma computação é considerada viável se puder ser feita em tempo polinomial. Há dois tipos de resultados de complexidade temporal. Resultados positivos mostram que uma certa classe de funções pode ser aprendida em tempo polinomial. Resultados negativos mostram que certas classes não podem ser aprendidas em tempo polinomial. Aprendizado baseado em árvores de decisão usa a árvore de decisão como um modelo de previsão, o qual mapeia as observações sobre um item às conclusões sobre o valor do objetivo desse item. Aprendizado por regras de associação é um método para descobrir relações interessantes entre variáveis em base de dados grandes. Um algoritmo de aprendizado de rede neural artificial"}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_18", "text": "desse item. Aprendizado por regras de associação é um método para descobrir relações interessantes entre variáveis em base de dados grandes. Um algoritmo de aprendizado de rede neural artificial (aprendizagem de rede neuronal artificial), normalmente chamado de \"rede neural\" ou \"rede neuronal\" (RN), é um algoritmo do tipo \"machine learning\" que é inspirado na estrutura e aspectos funcionais das redes neurais biológicas. Computações são estruturadas em termos de um grupo interconectado de neurônios artificiais, processando informação usando uma abordagem de conexionismo na computação. Redes neuronais modernas são ferramentas de modelagem de dados estatísticos não lineares. Normalmente eles são usados para modelar relações complexas entre entradas e saídas, para encontrar padrões nos dados, ou para capturar a estrutura estatística em uma distribuição de probabilidade conjunta desconhecida entre variáveis observáveis. Os preços mais baixos do hardware e o desenvolvimento de GPUs para uso"}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_19", "text": "ou para capturar a estrutura estatística em uma distribuição de probabilidade conjunta desconhecida entre variáveis observáveis. Os preços mais baixos do hardware e o desenvolvimento de GPUs para uso pessoal nos últimos anos contribuiu para o desenvolvimento do conceito de aprendizado profundo, que consiste em múltiplas camadas escondidas em uma rede neural artificial. Esta abordagem tenta modelar a forma com que o cérebro humano processa luz e som na visão e escuta. Alguns aplicações úteis do aprendizado profundo são visão computacional e reconhecimento de fala. Lógica de programação indutiva (LPI) é uma abordagem que regra o aprendizado fazendo uso de programação lógica como uma representação uniforme para exemplos de inputs, conhecimento de pano de fundo, e hipóteses. Dada uma codificação do pano de fundo conhecido do conhecimento e um conjunto de exemplos representados como uma base de dados lógica de fatos, um sistema LPI derivará uma lógica hipotética que envolve todos os"}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_20", "text": "do pano de fundo conhecido do conhecimento e um conjunto de exemplos representados como uma base de dados lógica de fatos, um sistema LPI derivará uma lógica hipotética que envolve todos os exemplos positivos e não negativos. A programação indutiva é um campo relacionado que considera qualquer tipo de linguagem de programação para representar hipóteses (e não apenas programações lógicas), tais como as programações funcionais. Máquinas de vetores de suporte (MVSs) são um conjunto relacionado de métodos de aprendizado supervisionado usados para classificação e regressão. Dado um conjunto de exemplos de treinamento, cada um marcado como pertencente de uma ou duas categorias, um algoritmo de treino SVM constrói um modelo que prediz se um novo exemplo cai dentro de uma categoria ou outra. Análise de clusters é a atribuição de um conjunto de observações à subconjuntos (chamados clusters) de forma que as observações dentro de um mesmo cluster são similares de acordo com algum critério ou"}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_21", "text": "de clusters é a atribuição de um conjunto de observações à subconjuntos (chamados clusters) de forma que as observações dentro de um mesmo cluster são similares de acordo com algum critério ou critérios pré-designados, enquanto que observações feitas em clusters diferentes não são similares. Diferentes técnicas de clustering fazem diferentes suposições sobre a estrutura dos dados, freqüentemente definida por algumas métricas de similaridade e avaliados, por exemplo, por compacidade interna (similaridade entre membros de um mesmo cluster) e separação entre clusters diferentes. Outros métodos são baseado em estimações de densidade e gráficos de conectividade. Clustering é um método de aprendizado não supervisionado e uma técnica comum em análise de dados estatísticos. Uma rede bayesiana, rede de opinião ou um modelo gráfico acíclico dirigido é um modelo gráfico probabilístico que representa um conjunto de variáveis aleatórias e suas independências condicionais via um grafo acíclico"}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_22", "text": "rede de opinião ou um modelo gráfico acíclico dirigido é um modelo gráfico probabilístico que representa um conjunto de variáveis aleatórias e suas independências condicionais via um grafo acíclico dirigido (GAD). Por exemplo, uma rede bayesiana poderia representar as relações probabilísticas entre doenças e sintomas. Dado um sintoma, a rede pode ser usada para computar as probabilidades da presença de várias doenças. Existem algoritmos eficientes que desempenham inferência e aprendizado. O aprendizado por reforço se preocupa com o como um agente deve agir em um ambiente de forma que maximize alguma noção de recompensa a longo tempo. Os algoritmos de aprendizado por reforço tentam encontrar a política que mapeia os estados do mundo às ações que o agente deve ter nesses estados. Aprendizado por reforço se distingue do problema do aprendizado supervisionado no sentindo em que pares de input/output corretos nunca são apresentados, nem as ações sub-ótimas são explicitamente corrigidas."}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_23", "text": "por reforço se distingue do problema do aprendizado supervisionado no sentindo em que pares de input/output corretos nunca são apresentados, nem as ações sub-ótimas são explicitamente corrigidas. Vários algoritmos de aprendizado, a maioria algoritmos de aprendizado não supervisionado, tem como objetivo descobrir melhores representações dos inputs que são dados durante o treinamento. Exemplos clássicos incluem análise de componentes principais e análise de clusters. Os algoritmos de aprendizado por representação com freqüência tentam preservar a informação e seu input mas transformando-a de forma que a torne útil, frequentemente como um passo pré-processamento antes de desempenhar classificações ou previsões, permitindo a reconstrução dos inputs vindos de dados geradores de distribuição desconhecidos, enquanto não sendo necessariamente fiel à configurações que são implausíveis sob essa distribuição. Algoritmos de aprendizado múltiplo tentam fazer isso sob a restrição de que a"}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_24", "text": "desconhecidos, enquanto não sendo necessariamente fiel à configurações que são implausíveis sob essa distribuição. Algoritmos de aprendizado múltiplo tentam fazer isso sob a restrição de que a representação aprendida é de baixa dimensão. Algoritmos de código esparso tentam fazer isso sob a restrição de que a representação aprendida é espersa (tem muitos zeros). O algoritmo de aprendizado em subespaço multilinear tem como objetivo aprender representações de baixa dimensão diretamente das representações de tensores para dados multidimensionais, sem os transformar em vetores de alta dimensão. Algoritmos de aprendizado profundo descobrem múltiplos níveis de representação, ou uma hierarquia de características, com um nível mais alto, características mais abstratas definidas em termos de (ou geradas a partir de) características de nível mais baixo. Tem sido argumentado que uma máquina inteligente é aquela que aprende uma representação que desembaraça os fatores subjacentes de variação que"}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_25", "text": "a partir de) características de nível mais baixo. Tem sido argumentado que uma máquina inteligente é aquela que aprende uma representação que desembaraça os fatores subjacentes de variação que explicam os dados observados. Neste problema, se dá a máquina aprendiz pares de exemplos que são considerados similares e pares de objetos menos similares. Então ela precisa aprender uma função de similaridade (ou uma função de distancia métrica) que possa predizer se novos objetos são similares. Isso é as vezes usado em sistemas de recomendação. Neste método, um dado é representado como uma combinação de ligar funções bases, e os coeficientes são assumidos como esparsos. Deixe x ser uma dado d-dimensional, D ser um d por n matrizes, onde cada coluna de D representa uma função base. r é o coeficiente para representar x usando D. Matematicamente, aprendizado por dicionário esparso significa resolver x ≈ D r {\\displaystyle x\\approx Dr} onde r é esparso. Falando genericamente, se assume que n é"}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_26", "text": "para representar x usando D. Matematicamente, aprendizado por dicionário esparso significa resolver x ≈ D r {\\displaystyle x\\approx Dr} onde r é esparso. Falando genericamente, se assume que n é maior que d para permitir a liberdade para uma representação esparsa. Aprender um dicionário junto com representações esparsas é fortemente NP-completo e também difícil de resolver aproximadamente. Um método heurístico popular para aprendizado por dicionário esparso é o K-SVD. Aprendizado por dicionário esparso tem sido aplicado a vários contextos. Em classificação, o problema é determinar a quais classes um dado previamente não visto pertence. Suponha que um dicionário para cada classe já tenha sido construído. Então um novo dado é associado com a classe de forma que esteja o melhor esparcialmente representado pelo dicionário correspondente. Aprendizado por dicionário esparso também tem sido aplicado a suavização de imagem. A ideia chave é que um pedaço de imagem limpa pode ser representado"}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_27", "text": "representado pelo dicionário correspondente. Aprendizado por dicionário esparso também tem sido aplicado a suavização de imagem. A ideia chave é que um pedaço de imagem limpa pode ser representado esparcialmente por um dicionário de imagem, mas o ruído não. Em mineração de dados, a detecção de anomalias (também detecção de outliers ) é a identificação de itens, eventos ou observações raros que levantam suspeitas por serem significativamente diferentes da maioria dos dados. Normalmente, os itens anômalos se referem a algum tipo de problema, como fraude bancária, defeito estrutural, problemas médicos ou erros em um texto. Anomalias são também referidas como outliers, ruído, desvios e exceções. Um algoritmo genético (AG) é uma busca heurística que imita o processo de seleção natural e usa métodos com mutação e recombinação para gerar novos genotipos na esperança de encontrar boas soluções para um dado problema. Em aprendizado de máquinas, algoritmos genéticos encontraram alguma utilidade"}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_28", "text": "com mutação e recombinação para gerar novos genotipos na esperança de encontrar boas soluções para um dado problema. Em aprendizado de máquinas, algoritmos genéticos encontraram alguma utilidade em 1980 e 1990. Vice versa, técnicas do aprendizado de máquina tem sido usadas para melhorar a performance de algoritmos genéticos e evolutivos. Aplicações para o aprendizado de máquina incluem: Em 2006, a companhia de filmes online Netflix fez a primeira competição \"Netflix Prize\" para encontrar um programa que melhor prediria as performances dos usuários e melhoraria a precisão do algoritmo de recomendação Cinematch existente em ao menos 10%. Um time composto por pesquisadores da AT&T Labs em colaboração com o time Big Chaos e Pragmatic Theory construíram um modelo conjunto para ganhar o grande prêmio em 2009 de 1 milhão de dólares. Logo após os prêmio ser concedido, a Netflix se deu conta que as avaliações dos usuários não eram as melhores indicações de seus padrões de filmes e séries"}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_29", "text": "prêmio em 2009 de 1 milhão de dólares. Logo após os prêmio ser concedido, a Netflix se deu conta que as avaliações dos usuários não eram as melhores indicações de seus padrões de filmes e séries vistos (\"tudo é recomendação\") e mudaram seu motor de recomendação. Em 2010 o Periódico do Wall Street escreveu sobre a firma de gestão de dinheiro Rebellion Research que usava o aprendizado de máquina para predizer os movimentos econômicos. O artigo descrevia a previsão da Rebellion Research sobre a crise financeira e a recuperação econômica. Em 2014 foi relatado que um algoritmo de aprendizado de máquina foi aplicado em Historia da Arte para estudar as pinturas de arte e que ele pode ter revelado influencias entre artistas previamente não reconhecidas. Em 2015, o serviço de streaming de música Spotify criou a playlist chamada Descobertas da Semana, que funciona como uma curadoria digital. O algoritmo responsável por esta playlist utiliza técnicas de Filtragem Colaborativa, Processamento de"}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_30", "text": "Spotify criou a playlist chamada Descobertas da Semana, que funciona como uma curadoria digital. O algoritmo responsável por esta playlist utiliza técnicas de Filtragem Colaborativa, Processamento de Linguagem Natural e Processamento de Sinais de Áudio através de Redes Neurais Convolucionais para compor a playlist semanalmente. Mais informações atualizadas sobre como o Spotify aborda algoritmos de inteligência artificial podem ser acessadas em entrevista recente do CEO Gustav Soderstrom. Modelos de classificação de aprendizado de máquina podem ser validados por técnicas como validação cruzada, onde os dados são divididos em conjuntos de teste e treinamento e medidas apropriadas como precisão são calculadas para ambos os conjuntos de dados e comparadas. Para além da precisão, sensibilidade (Avaliação Positiva Verdadeira) e especificidade (Avaliação Negativa Verdadeira) podem prover modos de modelos de avaliação. De forma similar, Avaliações Positivas Falsas assim como Avaliações"}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_31", "text": "(Avaliação Positiva Verdadeira) e especificidade (Avaliação Negativa Verdadeira) podem prover modos de modelos de avaliação. De forma similar, Avaliações Positivas Falsas assim como Avaliações Negativas Falsas poder ser computadas. Curvas Receptoras de Operação (CRO) em conjunto com a Área em baixo da CRO (AUC) oferecem ferramentas adicionais para a classificação de modelos de avaliação. Graus maiores de AUC estão associados a um modelo de melhor performance. Software suites contendo uma variedade de algoritmos de aprendizado de máquina incluem os seguintes: Veja também esta lista de pacotes em muitas linguagens de programação: Awesome Machine Learning. Journal of Machine Learning Research Machine Learning Neural Computation International Journal of Machine Learning and Cybernetics Conference on Neural Information Processing Systems International Conference on Machine Learning Ablação (inteligência artificial) Aprendizagem profunda Aprendizado por transferência Inteligência artificial"}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_32", "text": "on Neural Information Processing Systems International Conference on Machine Learning Ablação (inteligência artificial) Aprendizagem profunda Aprendizado por transferência Inteligência artificial Lista de projetos de inteligência artificial Redes Neurais Clustering Bioinformática Visão computacional Mineração de dados Reconhecimento de padrões Máquina de Vetores de Suporte Big data Ciência cognitiva Inteligência computacional Neurociência computacional «Conceitos sobre Aprendizado de Maquina» (PDF) Curso online no Coursera, ministrado por Andrew Ng. Utiliza GNU Octave. O curso é uma versão livre do curso da Stanford University ministrado por Ng, cujas aulas também estão disponíveis gratuitamente. Aula sobre Aprendizagem por Reforço, ministrada pelo professor Ronaldo C. Prati, Professor Adjunto da UFABC Brocardo ML, Traore I, Woungang I, Obaidat MS. \"Authorship verification using deep belief network systems\". Int J Commun Syst. 2017. doi:10.1002/dac.3259 Trevor Hasti, Robert Tibshirani"}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_33", "text": "da UFABC Brocardo ML, Traore I, Woungang I, Obaidat MS. \"Authorship verification using deep belief network systems\". Int J Commun Syst. 2017. doi:10.1002/dac.3259 Trevor Hasti, Robert Tibshirani e Jerome H. Friedman (2001). The Elements of Statistical Learning, Springer. ISBN 0-387-95284-5. Pedro Domingos (September 2015), The Master Algorithm, Basic Books, ISBN 978-0-465-06570-7 Mehryar Mohri, Afshin Rostamizadeh, Ameet Talwalkar (2012). Foundations of Machine Learning, The MIT Press. ISBN 978-0-262-01825-8. Ian H. Witten and Eibe Frank (2011). Data Mining: Practical machine learning tools and techniques Morgan Kaufmann, 664pp., ISBN 978-0-12-374856-0. David J. C. MacKay. Information Theory, Inference, and Learning Algorithms Cambridge: Cambridge University Press, 2003. ISBN 0-521-64298-1 Richard O. Duda, Peter E. Hart, David G. Stork (2001) Pattern classification (2nd edition), Wiley, New York, ISBN 0-471-05669-3. Christopher Bishop (1995). Neural Networks for Pattern Recognition,"}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_34", "text": "Richard O. Duda, Peter E. Hart, David G. Stork (2001) Pattern classification (2nd edition), Wiley, New York, ISBN 0-471-05669-3. Christopher Bishop (1995). Neural Networks for Pattern Recognition, Oxford University Press. ISBN 0-19-853864-2. Vladimir Vapnik (1998). Statistical Learning Theory. Wiley-Interscience, ISBN 0-471-03003-1. Ray Solomonoff, An Inductive Inference Machine, IRE Convention Record, Section on Information Theory, Part 2, pp., 56-62, 1957. Ray Solomonoff, \"An Inductive Inference Machine\" Um relato privado que circulou na Dartmouth Summer Research Conference sobre IA em 1956."}
{"source": "Engenharia de inteligência artificial", "chunk_id": "Engenharia de inteligência artificial_0", "text": "A engenharia de inteligência artificial (IA) é uma disciplina tecnológica voltada para o desenvolvimento, implementação e manutenção de sistemas que emulam a inteligência humana por meio de máquinas e softwares. Envolve a aplicação de princípios de engenharia para criar soluções capazes de aprendizado, raciocínio, percepção e tomada de decisão de forma autônoma, utilizando tecnologias como aprendizado de máquina (machine learning), processamento de linguagem natural (NLP) e visão computacional. Com o aumento da automação e a crescente dependência de tecnologias inteligentes em setores como saúde, transporte e segurança, a engenharia de IA tem se tornado essencial para impulsionar inovações tecnológicas e transformar diversos campos da economia global. A engenharia de inteligência artificial tem suas origens nas primeiras pesquisas sobre automação e inteligência mecânica realizadas nas décadas de 1950 e 1960, como o Teste de Turing. Nessa época, os cientistas estavam interessados em"}
{"source": "Engenharia de inteligência artificial", "chunk_id": "Engenharia de inteligência artificial_1", "text": "tem suas origens nas primeiras pesquisas sobre automação e inteligência mecânica realizadas nas décadas de 1950 e 1960, como o Teste de Turing. Nessa época, os cientistas estavam interessados em criar sistemas que pudessem simular o raciocínio humano e resolver problemas de forma autônoma. Esse período marcou o início da exploração de conceitos fundamentais, como a lógica formal, a teoria da informação e as primeiras tentativas de construir sistemas baseados em regras. O termo \"inteligência artificial\" foi cunhado em 1956, durante a Conferência de Dartmouth, evento amplamente reconhecido como o ponto de partida oficial da IA como um campo de estudo. Nos anos seguintes, projetos pioneiros, como o General Problem Solver (GPS), focavam na resolução de problemas através de estratégias algorítmicas. No entanto, as limitações tecnológicas da época, particularmente a falta de poder computacional, restringiam os avanços práticos. Durante as décadas de 1970 e 1980, o campo da IA foi"}
{"source": "Engenharia de inteligência artificial", "chunk_id": "Engenharia de inteligência artificial_2", "text": "algorítmicas. No entanto, as limitações tecnológicas da época, particularmente a falta de poder computacional, restringiam os avanços práticos. Durante as décadas de 1970 e 1980, o campo da IA foi impulsionado por avanços em matemática aplicada, como a teoria dos grafos e o desenvolvimento de algoritmos de busca. Surgiram também os sistemas especialistas, que utilizavam grandes bases de conhecimento para resolver problemas em domínios específicos, como diagnósticos médicos e planejamento industrial. O sistema DENDRAL (1965) e o MYCIN (1972) são exemplos notáveis que demonstraram a eficácia de sistemas especializados em tarefas técnicas e científicas. Porém, durante esse período, o campo sofreu com o que se chamou de \"invernos da IA\" — fases de estagnação causadas por expectativas exageradas e pela falta de resultados práticos, o que resultou em cortes de financiamento e diminuição do interesse no campo. Foi a partir dos anos 1990 que a IA começou a retomar seu crescimento,"}
{"source": "Engenharia de inteligência artificial", "chunk_id": "Engenharia de inteligência artificial_3", "text": "exageradas e pela falta de resultados práticos, o que resultou em cortes de financiamento e diminuição do interesse no campo. Foi a partir dos anos 1990 que a IA começou a retomar seu crescimento, impulsionada pelo aumento exponencial do poder computacional, pelo surgimento da Internet e pelo acesso a grandes volumes de dados, o que possibilitou o desenvolvimento de novos algoritmos de aprendizagem automática. Modelos baseados em redes neurais, anteriormente teóricos, começaram a ser utilizados de forma mais prática. O surgimento de técnicas de aprendizado supervisionado e não supervisionado marcou uma nova era para a IA, permitindo que os sistemas aprendessem diretamente a partir de dados, sem depender exclusivamente de regras predefinidas. No início dos anos 2000, a engenharia de IA deu um salto significativo com o avanço das redes neurais artificiais e o surgimento de algoritmos de aprendizado profundo (deep learning). Pesquisadores como Geoffrey Hinton e Yann LeCun lideraram o"}
{"source": "Engenharia de inteligência artificial", "chunk_id": "Engenharia de inteligência artificial_4", "text": "deu um salto significativo com o avanço das redes neurais artificiais e o surgimento de algoritmos de aprendizado profundo (deep learning). Pesquisadores como Geoffrey Hinton e Yann LeCun lideraram o desenvolvimento de redes neurais profundas, capazes de lidar com grandes quantidades de dados e identificar padrões complexos em imagens, sons e textos. Esses avanços permitiram que a IA fosse aplicada de maneira eficaz em áreas como visão computacional, processamento de linguagem natural e sistemas de recomendação. Um dos principais marcos desse período foi a vitória do sistema AlphaGo, da empresa DeepMind, sobre campeões humanos no jogo de Go em 2016. Esse feito demonstrou o poder das técnicas de aprendizado profundo e reforçou a capacidade da IA em resolver problemas extremamente complexos, que exigem uma combinação de raciocínio estratégico e aprendizado autônomo. Nos últimos anos, a engenharia de IA se consolidou como um campo robusto de engenharia, com aplicações práticas em setores"}
{"source": "Engenharia de inteligência artificial", "chunk_id": "Engenharia de inteligência artificial_5", "text": "que exigem uma combinação de raciocínio estratégico e aprendizado autônomo. Nos últimos anos, a engenharia de IA se consolidou como um campo robusto de engenharia, com aplicações práticas em setores como saúde, finanças, transporte e entretenimento. Tecnologias como veículos autônomos, assistentes virtuais e sistemas de diagnóstico médico automatizados são exemplos de como a IA tem transformado indústrias inteiras, além de impactar o cotidiano das pessoas. Com o avanço das tecnologias de computação em nuvem e o desenvolvimento contínuo de algoritmos mais sofisticados, a engenharia de IA continua a expandir seus horizontes. A disciplina não apenas explora os limites técnicos da inteligência artificial, mas também lida com questões éticas e de governança relacionadas à implementação segura e responsável de sistemas inteligentes em larga escala. Os fundamentos da engenharia de IA podem ser detalhados em diversas subáreas, cada uma com um papel essencial no desenvolvimento de sistemas"}
{"source": "Engenharia de inteligência artificial", "chunk_id": "Engenharia de inteligência artificial_6", "text": "e responsável de sistemas inteligentes em larga escala. Os fundamentos da engenharia de IA podem ser detalhados em diversas subáreas, cada uma com um papel essencial no desenvolvimento de sistemas inteligentes. O aprendizado de máquina é o pilar central da engenharia de IA, baseado na criação de algoritmos que permitem que sistemas evoluam a partir da experiência adquirida com dados. O processo envolve a criação de modelos capazes de identificar padrões em grandes volumes de dados, aprimorando-se continuamente sem a necessidade de intervenção humana direta. Existem três tipos principais de aprendizado de máquina: Supervisionado: onde o modelo é treinado com base em exemplos rotulados, ou seja, onde as respostas corretas já são conhecidas. Não supervisionado: o sistema deve descobrir padrões e estruturas ocultas em dados não rotulados. Aprendizado por reforço: o agente aprende a tomar decisões ao interagir com um ambiente, recebendo recompensas ou punições com base em suas ações. Deep"}
{"source": "Engenharia de inteligência artificial", "chunk_id": "Engenharia de inteligência artificial_7", "text": "e estruturas ocultas em dados não rotulados. Aprendizado por reforço: o agente aprende a tomar decisões ao interagir com um ambiente, recebendo recompensas ou punições com base em suas ações. Deep Learning é uma subárea do aprendizado de máquina que utiliza redes neurais artificiais profundas para processar e aprender com grandes volumes de dados. O termo \"profundo\" refere-se às múltiplas camadas de neurônios artificiais que compõem essas redes, permitindo que elas realizem tarefas altamente complexas, como reconhecimento de padrões visuais e de fala, interpretação de imagens e processamento de texto. Os avanços recentes nessa área foram possíveis devido ao aumento da capacidade computacional e à disponibilidade de grandes conjuntos de dados. Redes neurais convolucionais (CNNs) são amplamente utilizadas em visão computacional (trabalho com imagens e vídeos), enquanto redes neurais recorrentes (RNNs) são aplicadas em tarefas que envolvem sequência, como tradução automática. Explora"}
{"source": "Engenharia de inteligência artificial", "chunk_id": "Engenharia de inteligência artificial_8", "text": "utilizadas em visão computacional (trabalho com imagens e vídeos), enquanto redes neurais recorrentes (RNNs) são aplicadas em tarefas que envolvem sequência, como tradução automática. Explora como os sistemas de IA podem interagir e entender a linguagem humana. Os avanços no NLP estão por trás de assistentes virtuais, sistemas de tradução automática e análise de sentimento. Essa subárea envolve diversas técnicas, desde o uso de modelos baseados em regras até métodos modernos baseados em transformadores, como o BERT e o GPT. Esses modelos permitem que as máquinas compreendam o contexto e as nuances da linguagem, possibilitando uma interação mais natural entre humanos e computadores. Os sistemas de raciocínio envolvem a criação de algoritmos que possibilitam a tomada de decisões com base em dados e regras lógicas. Eles são capazes de realizar inferências, resolver problemas e gerar planos de ação. Em IA, o raciocínio automatizado pode ser aplicado em tarefas como resolução de"}
{"source": "Engenharia de inteligência artificial", "chunk_id": "Engenharia de inteligência artificial_9", "text": "base em dados e regras lógicas. Eles são capazes de realizar inferências, resolver problemas e gerar planos de ação. Em IA, o raciocínio automatizado pode ser aplicado em tarefas como resolução de quebra-cabeças, diagnósticos médicos, planejamento estratégico, ou controle de sistemas complexos, como os sistemas de tráfego. A lógica simbólica e os algoritmos baseados em ontologias são alguns dos métodos utilizados para estruturar essas capacidades. Os frameworks permitem que engenheiros e cientistas de dados implementem e treinem modelos de aprendizado de máquina de forma eficiente, otimizando o uso de recursos computacionais. TensorFlow Desenvolvido pelo Google, o TensorFlow é um dos frameworks mais populares e poderosos para o desenvolvimento de redes neurais e modelos de deep learning. Suporta tanto CPU quanto GPU, sendo amplamente usado em produção e pesquisa. PyTorch Mantido pelo Facebook, PyTorch tem se destacado por sua facilidade de uso e por ser a escolha preferida de muitos"}
{"source": "Engenharia de inteligência artificial", "chunk_id": "Engenharia de inteligência artificial_10", "text": "Suporta tanto CPU quanto GPU, sendo amplamente usado em produção e pesquisa. PyTorch Mantido pelo Facebook, PyTorch tem se destacado por sua facilidade de uso e por ser a escolha preferida de muitos pesquisadores. Ele permite a criação dinâmica de grafos computacionais, o que facilita o desenvolvimento rápido e iterativo de modelos. Scikit-Learn Uma biblioteca poderosa em Python, focada em algoritmos de aprendizado de máquina tradicional, como classificação, regressão e clustering. Scikit-Learn é amplamente utilizada em aplicações mais leves e com conjuntos de dados menores. Keras Inicialmente uma biblioteca de alto nível para o TensorFlow, Keras se destaca por sua simplicidade, permitindo a rápida prototipagem de modelos de deep learning sem necessidade de configurar os detalhes mais complexos. As plataformas de IA em nuvem têm sido um catalisador no desenvolvimento de soluções de IA em larga escala. Elas fornecem infraestrutura de alta performance e uma série de ferramentas que"}
{"source": "Engenharia de inteligência artificial", "chunk_id": "Engenharia de inteligência artificial_11", "text": "complexos. As plataformas de IA em nuvem têm sido um catalisador no desenvolvimento de soluções de IA em larga escala. Elas fornecem infraestrutura de alta performance e uma série de ferramentas que agilizam o processo de desenvolvimento. AWS (Amazon Web Services) O AWS oferece serviços como o SageMaker, que facilita o treinamento, ajuste e implantação de modelos de machine learning. Também fornece recursos computacionais em grande escala, como instâncias baseadas em GPU, ideais para treinamento de redes neurais profundas. Microsoft Azure Oferece uma série de serviços de IA e aprendizado de máquina, como o Azure Machine Learning, além de soluções integradas de inteligência artificial que permitem a criação e a implementação rápida de modelos em diferentes setores. Google Cloud AI Proporciona acesso ao TensorFlow Extended (TFX), uma plataforma para a criação de pipelines de machine learning de ponta a ponta. O Google Cloud oferece ainda APIs de IA pré-treinadas, como o Google Vision e"}
{"source": "Engenharia de inteligência artificial", "chunk_id": "Engenharia de inteligência artificial_12", "text": "acesso ao TensorFlow Extended (TFX), uma plataforma para a criação de pipelines de machine learning de ponta a ponta. O Google Cloud oferece ainda APIs de IA pré-treinadas, como o Google Vision e o Natural Language API, que aceleram a integração de funcionalidades de IA em aplicações. Python É amplamente considerada a principal linguagem de programação no desenvolvimento de IA, graças à sua simplicidade e à vasta gama de bibliotecas e frameworks de machine learning e deep learning. Python facilita o trabalho com dados e modelos complexos, além de ser facilmente integrado com plataformas de IA em nuvem. R Muito utilizada em estatística e análise de dados, R é uma escolha popular em projetos de aprendizado de máquina voltados para modelagem estatística e exploração de dados. Suas bibliotecas, como caret e randomForest, são amplamente usadas em análise preditiva. Java Embora menos comum do que Python em IA, Java continua a ser uma escolha forte em projetos que exigem desempenho e"}
{"source": "Engenharia de inteligência artificial", "chunk_id": "Engenharia de inteligência artificial_13", "text": "como caret e randomForest, são amplamente usadas em análise preditiva. Java Embora menos comum do que Python em IA, Java continua a ser uma escolha forte em projetos que exigem desempenho e escalabilidade, especialmente em sistemas de produção. Frameworks como Deeplearning4j permitem o desenvolvimento de modelos de aprendizado profundo nessa linguagem. Julia Linguagem emergente no campo de IA, Julia combina a simplicidade de Python com a eficiência de linguagens como C++, tornando-se cada vez mais relevante em projetos que exigem grande performance computacional. São cruciais para compreender e comunicar os resultados de modelos de IA. Matplotlib e Seaborn Muito utilizados em Python, Matplotlib e Seaborn permitem a criação de gráficos estáticos e dinâmicos que ajudam a visualizar os padrões descobertos pelos modelos de aprendizado de máquina. Tableau e Power BI Tableau e Power BI são ferramentas de business intelligence que auxiliam na visualização de grandes volumes de dados e nos"}
{"source": "Engenharia de inteligência artificial", "chunk_id": "Engenharia de inteligência artificial_14", "text": "descobertos pelos modelos de aprendizado de máquina. Tableau e Power BI Tableau e Power BI são ferramentas de business intelligence que auxiliam na visualização de grandes volumes de dados e nos insights gerados por sistemas de IA, permitindo que os resultados sejam facilmente interpretados por públicos não técnicos. Gerenciar o ciclo de vida dos modelos de IA é um dos maiores desafios para os profissionais que trabalham com esta tecnologia, uma vez que envolve desde a criação e o desenvolvimento do modelo até sua implantação em sistemas reais e sua contínua manutenção. O gerenciamento eficaz desse ciclo é essencial para garantir que os modelos de IA permaneçam precisos, eficientes e relevantes em um ambiente de produção. O treinamento de modelos de IA é a fase inicial e crítica do ciclo de vida. Nessa etapa, os algoritmos de IA são alimentados com grandes volumes de dados, que são usados para ajustar os parâmetros do modelo. Esses parâmetros determinam como o modelo processa e"}
{"source": "Engenharia de inteligência artificial", "chunk_id": "Engenharia de inteligência artificial_15", "text": "ciclo de vida. Nessa etapa, os algoritmos de IA são alimentados com grandes volumes de dados, que são usados para ajustar os parâmetros do modelo. Esses parâmetros determinam como o modelo processa e interpreta os dados de entrada para gerar previsões ou decisões. Durante o treinamento, o modelo \"aprende\" padrões a partir dos dados, e esse processo é iterativo – quanto mais dados o modelo recebe, melhor ele pode ajustar seus parâmetros. Além disso, técnicas como o aprendizado supervisionado, não supervisionado e o aprendizado por reforço podem ser empregadas, dependendo do tipo de modelo e da aplicação. Um desafio importante nesta fase é garantir que o modelo não sofra de overfitting, ou seja, que ele não se torne excessivamente especializado nos dados de treinamento, o que comprometeria sua capacidade de generalizar para novos dados. Após o treinamento, a etapa de validação e teste é crucial para verificar a eficácia e a precisão do modelo. Os modelos de IA são avaliados com"}
{"source": "Engenharia de inteligência artificial", "chunk_id": "Engenharia de inteligência artificial_16", "text": "sua capacidade de generalizar para novos dados. Após o treinamento, a etapa de validação e teste é crucial para verificar a eficácia e a precisão do modelo. Os modelos de IA são avaliados com conjuntos de dados separados, que não foram usados no treinamento, para garantir que eles façam previsões corretas em novos cenários. Durante essa fase, são aplicadas métricas de desempenho como precisão, recall, F1-score e curvas ROC para medir a qualidade das previsões. O modelo também é testado para identificar e mitigar possíveis vieses nos dados ou na sua lógica, evitando que tome decisões injustas ou incorretas. Outro aspecto crítico é a robustez do modelo: ele precisa ser capaz de lidar com dados ruidosos ou incompletos sem comprometer significativamente o desempenho. Testes de estresse também são comuns, onde o modelo é desafiado com dados extremos ou não convencionais para avaliar sua resiliência. A implantação de um modelo de IA em produção é uma das fases mais complexas e desafiadoras"}
{"source": "Engenharia de inteligência artificial", "chunk_id": "Engenharia de inteligência artificial_17", "text": "são comuns, onde o modelo é desafiado com dados extremos ou não convencionais para avaliar sua resiliência. A implantação de um modelo de IA em produção é uma das fases mais complexas e desafiadoras da engenharia de IA. Após ser treinado e validado, o modelo precisa ser integrado a um sistema de produção, onde ele começará a funcionar em ambientes reais, processando dados e fazendo previsões em tempo real ou quase real. Nesse contexto, é necessário garantir que o modelo funcione de maneira eficiente e segura, seja em uma aplicação móvel, em um sistema de e-commerce, ou em uma plataforma de nuvem. Uma das maiores preocupações nesta etapa é a escalabilidade: à medida que o volume de dados e o número de usuários aumentam, o modelo deve ser capaz de lidar com essa carga adicional sem degradação de desempenho. Ferramentas de orquestração de contêineres, como Kubernetes, são frequentemente utilizadas para garantir que os modelos possam ser escalados e gerenciados com eficiência. Além disso,"}
{"source": "Engenharia de inteligência artificial", "chunk_id": "Engenharia de inteligência artificial_18", "text": "de desempenho. Ferramentas de orquestração de contêineres, como Kubernetes, são frequentemente utilizadas para garantir que os modelos possam ser escalados e gerenciados com eficiência. Além disso, questões relacionadas à segurança precisam ser abordadas, garantindo que os dados processados estejam protegidos contra acessos não autorizados. Após a implantação, o monitoramento contínuo é essencial para garantir que o modelo de IA esteja operando conforme esperado. Isso envolve verificar o desempenho do modelo em tempo real, monitorar a precisão das previsões e identificar possíveis desvios em relação ao comportamento esperado. O desempenho do modelo pode se degradar com o tempo devido a mudanças nos padrões dos dados, uma situação conhecida como drift de dados. Quando isso ocorre, o modelo precisa ser reavaliado e, em muitos casos, treinado com novos dados para restaurar sua precisão. Essa fase também envolve o ajuste e a otimização contínua do modelo, além de atualizações periódicas"}
{"source": "Engenharia de inteligência artificial", "chunk_id": "Engenharia de inteligência artificial_19", "text": "precisa ser reavaliado e, em muitos casos, treinado com novos dados para restaurar sua precisão. Essa fase também envolve o ajuste e a otimização contínua do modelo, além de atualizações periódicas para incorporar novas funcionalidades ou melhorias no desempenho. Um sistema de feedback contínuo é muitas vezes implementado, onde os resultados do modelo são constantemente avaliados e comparados com os resultados reais, permitindo ajustes dinâmicos. Uma parte fundamental da engenharia de inteligência artificial envolve abordar as questões éticas e as implicações sociais associadas ao desenvolvimento e ao uso de sistemas inteligentes. À medida que a IA se torna cada vez mais integrada a diversas áreas da sociedade, como saúde, justiça, finanças e segurança, os engenheiros de IA enfrentam o desafio de garantir que esses sistemas operem de maneira justa, segura e transparente, respeitando os valores humanos e promovendo o bem-estar social. Muitos dos sistemas de IA, especialmente os que"}
{"source": "Engenharia de inteligência artificial", "chunk_id": "Engenharia de inteligência artificial_20", "text": "desafio de garantir que esses sistemas operem de maneira justa, segura e transparente, respeitando os valores humanos e promovendo o bem-estar social. Muitos dos sistemas de IA, especialmente os que utilizam técnicas de aprendizado profundo, funcionam como “caixas-pretas”, nas quais o processo de tomada de decisão é opaco para os usuários e até mesmo para os desenvolvedores. No entanto, em muitas aplicações críticas, como diagnósticos médicos ou decisões judiciais, é essencial que as decisões de IA sejam explicáveis e compreensíveis para os usuários. A explicabilidade da IA, ou IA Explicável (XAI), proporcionam insights sobre como o modelo chegou a determinadas conclusões. Isso é crucial para aumentar a confiança nos sistemas de IA, garantindo que eles não sejam vistos apenas como mecanismos automáticos e inquestionáveis, mas como ferramentas que podem ser auditadas e ajustadas quando necessário. O viés algorítmico ocorre quando os sistemas de IA perpetuam ou ampliam preconceitos"}
{"source": "Engenharia de inteligência artificial", "chunk_id": "Engenharia de inteligência artificial_21", "text": "automáticos e inquestionáveis, mas como ferramentas que podem ser auditadas e ajustadas quando necessário. O viés algorítmico ocorre quando os sistemas de IA perpetuam ou ampliam preconceitos existentes na sociedade. Isso pode acontecer quando os dados utilizados para treinar os algoritmos refletem desigualdades sociais ou discriminações históricas. Por exemplo, um sistema de IA usado em processos de recrutamento pode favorecer determinados grupos sociais ou raciais se for treinado com dados tendenciosos, resultando em discriminação. Para enfrentar esse problema, os engenheiros de IA devem se comprometer a avaliar rigorosamente os dados de treinamento, corrigir vieses e desenvolver algoritmos que sejam equitativos. Além disso, é importante promover a diversidade nas equipes que desenvolvem essas tecnologias, garantindo que diferentes perspectivas sejam consideradas durante o processo de criação e implementação dos modelos. Os sistemas de IA, especialmente quando integrados em setores"}
{"source": "Engenharia de inteligência artificial", "chunk_id": "Engenharia de inteligência artificial_22", "text": "essas tecnologias, garantindo que diferentes perspectivas sejam consideradas durante o processo de criação e implementação dos modelos. Os sistemas de IA, especialmente quando integrados em setores críticos como transporte, finanças e defesa, podem ser alvos de manipulação ou ataques cibernéticos. A segurança envolve proteger a integridade dos dados usados pelos sistemas, bem como garantir que os modelos de IA não sejam corrompidos ou mal utilizados. Isso é particularmente importante em aplicações como carros autônomos, onde falhas ou vulnerabilidades podem resultar em consequências graves para a segurança pública. Os engenheiros de IA devem desenvolver soluções robustas, aplicando técnicas de cibersegurança e adotando práticas de codificação seguras para prevenir possíveis falhas ou violações. A automação impulsionada por IA tem o potencial de transformar diversas indústrias, substituindo tarefas repetitivas e manuais por processos automatizados. Isso, por um lado, pode aumentar a"}
{"source": "Engenharia de inteligência artificial", "chunk_id": "Engenharia de inteligência artificial_23", "text": "A automação impulsionada por IA tem o potencial de transformar diversas indústrias, substituindo tarefas repetitivas e manuais por processos automatizados. Isso, por um lado, pode aumentar a eficiência e a produtividade, mas, por outro lado, pode levar à perda de empregos em certas áreas. Trabalhadores em setores como manufatura, transporte e até mesmo serviços financeiros podem ver suas funções substituídas por sistemas de IA. No entanto, a IA também pode criar novas oportunidades de trabalho, especialmente em áreas como ciência de dados, desenvolvimento de algoritmos e monitoramento de sistemas inteligentes. É responsabilidade dos engenheiros de IA considerar esses efeitos de maneira proativa, garantindo que os benefícios da automação sejam distribuídos de maneira justa."}
{"source": "Meta AI", "chunk_id": "Meta AI_0", "text": "Meta AI é um laboratório de inteligência artificial (IA) que pertence à Meta Platforms, Inc. (anteriormente conhecida como Facebook, Inc.) A Meta AI pretende desenvolver diversas formas de inteligência artificial, aprimorando tecnologias de realidade aumentada e artificial. Meta AI é um laboratório de pesquisa acadêmica focado na geração de conhecimento para a comunidade de IA. Isto contrasta com a equipe de Applied Machine Learning (AML) do Facebook, que se concentra em aplicações práticas de seus produtos. Meta AI começou como Facebook Artificial Intelligence Research (FAIR) com locais em Menlo Park, Califórnia, sede, Londres, Reino Unido, e um novo laboratório em Manhattan. FAIR foi anunciado oficialmente em setembro de 2013. FAIR foi dirigido por Yann LeCun da Universidade de Nova York , professor de aprendizagem profunda e vencedor do Prêmio Turing . Trabalhando com o Centro de Ciência de Dados da NYU, o objetivo inicial da FAIR era pesquisar ciência de dados, aprendizado de"}
{"source": "Meta AI", "chunk_id": "Meta AI_1", "text": "York , professor de aprendizagem profunda e vencedor do Prêmio Turing . Trabalhando com o Centro de Ciência de Dados da NYU, o objetivo inicial da FAIR era pesquisar ciência de dados, aprendizado de máquina e inteligência artificial e \"compreender a inteligência, descobrir seus princípios fundamentais e tornar as máquinas significativamente mais inteligentes\". A pesquisa na FAIR foi pioneira na tecnologia que levou ao reconhecimento facial, marcação em fotografias e recomendação de feed personalizada. Vladimir Vapnik, um pioneiro na aprendizagem estatística, juntou-se à FAIR em 2014, ele é o coinventor da máquina de vetores de suporte e um dos desenvolvedores da teoria Vapnik-Chervonenkis ."}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_0", "text": "Na informática, a Inteligência Artificial (abreviado IA) genericamente é a inteligência, o raciocínio e o aprendizado exibida por máquinas semelhante ao raciocino humano; busca desenvolver máquinas autônomas ou sistemas especialistas capazes de simular o pensamento humano e realizar várias tarefas complexas de forma independente. É o sistema que permite aos computadores executar funções avançadas, como a capacidade de analisar dados em grande escala e fazer previsões/recomendações; É um campo de pesquisa em ciência da computação que desenvolve e estuda métodos e softwares que permitem que as máquinas percebam seu ambiente e usem o aprendizado e a inteligência para tomar ações que maximizem suas chances de atingir objetivos definidos. A IA iniciou na década de 1950 com os pesquisadores Alan Turing e Herbert Simon baseado no conceito do filósofo grego Aristóteles. Em 1950, o matemático inglês Allan Turing escreveu sobre ser possível uma máquina pensar, e imitar o comportamento humano"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_1", "text": "Turing e Herbert Simon baseado no conceito do filósofo grego Aristóteles. Em 1950, o matemático inglês Allan Turing escreveu sobre ser possível uma máquina pensar, e imitar o comportamento humano inteligente. Também esboçou uma proposta de pesquisa para tornar isto possível. Aplicações de IA incluem mecanismos avançados de busca na web (por exemplo, Google Search); sistemas de recomendação (usados pelo YouTube, Amazon e Netflix); assistentes virtuais (por exemplo, Google Assistant, Siri e Alexa ); veículos autônomos (por exemplo, Waymo); ferramentas generativas e criativas (por exemplo, ChatGPT, DeepSeek e AI art); e jogo e análise sobre-humanos em jogos de estratégia (por exemplo, xadrez e Go). No entanto, muitas aplicações de IA não são percebidas como IA porque já se tornaram comuns o suficiente no cotidiano das pessoas. Como por exemplo, o reconhecimento óptico de caracteres (OCR) que extrai o texto de imagens; transforma conteúdo não estruturado em dados estruturados com insights"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_2", "text": "no cotidiano das pessoas. Como por exemplo, o reconhecimento óptico de caracteres (OCR) que extrai o texto de imagens; transforma conteúdo não estruturado em dados estruturados com insights prontos para negócios; tradução de textos em idiomas estrangeiros e tradução de voz. A IA é um campo que abrange muitas disciplinas, como: ciência da computação, estatísticas, engenharia de hardware e de software, linguística, neurociência e, filosofia. Vários subcampos da pesquisa em IA são centrados em objetivos específicos e no uso de ferramentas específicas. Os objetivos tradicionais da pesquisa em IA incluem raciocínio, representação de conhecimento, planejamento, aprendizagem, processamento de linguagem natural, percepção e suporte à robótica. A inteligência geral — a capacidade de completar qualquer tarefa realizada por um humano em um nível pelo menos igual — está entre os objetivos de longo prazo do campo. Para atingir esses objetivos, os pesquisadores de IA adaptaram e integraram uma"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_3", "text": "qualquer tarefa realizada por um humano em um nível pelo menos igual — está entre os objetivos de longo prazo do campo. Para atingir esses objetivos, os pesquisadores de IA adaptaram e integraram uma ampla gama de técnicas, incluindo otimização matemática e de busca, lógica formal, redes neurais artificiais e métodos baseados em estatística, pesquisa operacional e economia. A IA também se baseia na psicologia, linguística, filosofia, neurociência e em outros campos. A inteligência artificial foi fundada como disciplina acadêmica em 1956 e o campo passou por múltiplos ciclos de otimismo ao longo de sua história, seguidos por períodos de decepção e perda de financiamento. Os recursos e o interesse aumentaram enormemente após 2012, quando a aprendizagem profunda superou as técnicas de IA anteriores. Este crescimento acelerou ainda mais depois de 2017 e no início da década de 2020 muitos milhares de milhões de dólares estavam a ser investidos em IA e o campo experimentou um rápido"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_4", "text": "IA anteriores. Este crescimento acelerou ainda mais depois de 2017 e no início da década de 2020 muitos milhares de milhões de dólares estavam a ser investidos em IA e o campo experimentou um rápido progresso contínuo no que ficou conhecido como o boom da IA. O surgimento da IA generativa avançada e sua capacidade de criar e modificar conteúdo expôs diversas consequências e danos não intencionais no presente e levantou preocupações sobre os riscos da IA e seus efeitos de longo prazo no futuro, gerando discussões sobre políticas regulatórias para garantir a segurança e os benefícios da tecnologia. O interesse no desenvolvimento de máquinas autônomas capazes de simular o pensamento humano e de realizar varias tarefas cresceu vertiginosamente nas últimas décadas, da segunda metade do século XX, realizando assim os primeiros estudos sobre inteligência artificial (IA) a um propósito comum, a partir de iniciativas de cientistas de diversas áreas, como: psicologia, ciência cognitiva, ciência"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_5", "text": "realizando assim os primeiros estudos sobre inteligência artificial (IA) a um propósito comum, a partir de iniciativas de cientistas de diversas áreas, como: psicologia, ciência cognitiva, ciência da computação e, robótica. Ferramentas eficientes em analisar problemas e oferecer soluções e planejamentos (tomada de decisão), automatização de tarefas no cotidiano das pessoas. Mas apesar dos estudos serem modernos, o conceito de inteligência artificial não é contemporâneo; Aristóteles (professor de Alexandre, o Grande) sonhava em substituir a mão-de-obra escrava por ferramentas autônomas, sendo esta possivelmente a primeira ideia de Inteligência Artificial relatada, que a ciência da computação exploraria muito tempo depois. O desenvolvimento dessa ideia ocorreu plenamente no século XX, principalmente na década de 1950, com pensadores como Allan Turing, Herbert Simon e, John McCarthy. Turing escreveu o artigo \"Computing Machinery and InteIligence\" sobre a possibilidade de uma máquina"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_6", "text": "na década de 1950, com pensadores como Allan Turing, Herbert Simon e, John McCarthy. Turing escreveu o artigo \"Computing Machinery and InteIligence\" sobre a possibilidade de uma máquina pensar e imitar o comportamento humano inteligente com tal perfeição, de forma que pudesse confundir ate um juiz humano. Turing também esboçou uma proposta de pesquisa para tornar possível. Inicialmente os teste em IA foram repletos de sucessos – porém limitados devido o desempenho reduzido dos primeiros computadores - oque causava surpresa, foi o fato de um computador realizar atividade remotamente inteligente. O sucesso inicial prosseguiu em 1957 com o General Problem Solver (GPS, Solucionador de problemas gerais) desenvolvido por Herbert Simon e Allen Newell, um programa foi projetado para imitar protocolos humanos de resolução de problemas. Dentro da classe limitada de quebra-cabeças com a qual podia lidar, verificou-se que a ordem em que os seres humanos abordavam os mesmos problemas. Desse modo,"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_7", "text": "humanos de resolução de problemas. Dentro da classe limitada de quebra-cabeças com a qual podia lidar, verificou-se que a ordem em que os seres humanos abordavam os mesmos problemas. Desse modo, o GPS talvez tenha sido o primeiro programa a incorporar a abordagem de “pensar de forma humana”. Em 1961, a proposta de Turing voltou no artigo de Herbert Simon e Allen Newell no artigo \"The Simulation of Human Thought\" sobre o teste de uma teoria de resolução humana de problemas. Esta teoria tenta explicar alguns aspectos dos processos mentais responsáveis pela inteligencia humana, um projeto de estudos conhecido pelo nome de Projeto de Simulação Cognitiva. Desde o início os fundamentos da inteligência artificial tiveram o suporte de várias disciplinas que contribuíram com ideias, pontos de vista e técnicas para a IA. Os filósofos (desde 400 a.C.) tornaram a IA concebível, considerando as ideias de que a mente é, em alguns aspectos, semelhante a uma máquina, de que ela opera sobre o"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_8", "text": "de vista e técnicas para a IA. Os filósofos (desde 400 a.C.) tornaram a IA concebível, considerando as ideias de que a mente é, em alguns aspectos, semelhante a uma máquina, de que ela opera sobre o conhecimento codificado em alguma linguagem interna e que o pensamento pode ser usado para escolher as ações que deverão ser executadas. Por sua vez, os matemáticos forneceram as ferramentas para manipular declarações de certeza lógica, bem como declarações incertas e probabilísticas. Eles também definiram a base para a compreensão da computação e do raciocínio sobre algoritmos. Os economistas formalizaram o problema de tomar decisões que maximizam o resultado esperado para o tomador de decisões. Os psicólogos adotaram a ideia de que os seres humanos e os animais podem ser considerados máquinas de processamento de informações. Os linguistas mostraram que o uso da linguagem se ajusta a esse modelo. Os engenheiros de computação fornecem os artefatos que tornam possíveis as aplicações de IA."}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_9", "text": "de processamento de informações. Os linguistas mostraram que o uso da linguagem se ajusta a esse modelo. Os engenheiros de computação fornecem os artefatos que tornam possíveis as aplicações de IA. Os programas de IA tendem a ser extensos e não poderiam funcionar sem os grandes avanços em velocidade e memória que a indústria de informática tem proporcionado. Atualmente, a IA abrange uma enorme variedade de subcampos. Dentre esses subcampos está o estudo de modelos conexionistas ou redes neurais. Uma rede neural pode ser vista como um modelo matemático simplificado do funcionamento do cérebro humano. Este consiste de um número muito grande de unidades elementares de processamento, ou neurônios, que recebem e enviam estímulos elétricos uns aos outros, formando uma rede altamente interconectada. No processamento, são compostos os estímulos recebidos conforme a intensidade de cada ligação, produzindo um único estímulo de saída. É o arranjo das interconexões entre os neurônios e as"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_10", "text": "No processamento, são compostos os estímulos recebidos conforme a intensidade de cada ligação, produzindo um único estímulo de saída. É o arranjo das interconexões entre os neurônios e as respectivas intensidades que define as principais propriedades e o funcionamento de uma RN. O estudo das redes neurais ou o conexionismo se relaciona com a capacidade dos computadores aprenderem e reconhecerem padrões. Podemos destacar também o estudo da biologia molecular na tentativa de construir vida artificial e a área da robótica, ligada à biologia e procurando construir máquinas que alojem vida artificial. Outro subcampo de estudo é a ligação da IA com a Psicologia, na tentativa de representar na máquina os mecanismos de raciocínio e de procura. Nos últimos anos, houve uma revolução no trabalho em inteligência artificial, tanto no conteúdo quanto na metodologia. Agora, é mais comum usar as teorias existentes como bases, em vez de propor teorias inteiramente novas, fundamentar as informações em"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_11", "text": "inteligência artificial, tanto no conteúdo quanto na metodologia. Agora, é mais comum usar as teorias existentes como bases, em vez de propor teorias inteiramente novas, fundamentar as informações em teoremas rigorosos ou na evidência experimental rígida, em vez de utilizar como base a intuição e destacar a relevância de aplicações reais em vez de exemplos hipotéticos. A utilização da IA permite obter não somente ganhos significativos de performance, mas também possibilita o desenvolvimento de aplicações inovadoras, capazes de expandir de forma extraordinária nossos sentidos e habilidades intelectuais. Cada vez mais presente, a inteligência artificial simula o pensamento humano e se alastra por nosso cotidiano. Em maio de 2017 no Brasil, foi criada a ABRIA (Associação Brasileira de Inteligência Artificial) com o objetivo de mapear iniciativas brasileiras no setor de inteligência artificial, englobando os esforços entre as empresas nacionais e formação de mão de obra especializada."}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_12", "text": "Artificial) com o objetivo de mapear iniciativas brasileiras no setor de inteligência artificial, englobando os esforços entre as empresas nacionais e formação de mão de obra especializada. Esse passo reforça que, atualmente, a inteligência artificial é impactante no setor econômico. A inteligência artificial começou como um campo experimental na década de 1950 com pioneiros como Allen Newell e Herbert Simon, que fundaram o primeiro laboratório de inteligência artificial na Universidade Carnegie Mellon, e McCarty que juntamente com Marvin Minsky, que fundaram o MIT AI Lab em 1959. Foram eles alguns dos participantes na famosa conferência de verão de 1956 em Darthmouth College. Historicamente, existem dois grandes estilos de investigação em IA: IA \"neats\" e IA \"scruffies\". A IA \"neats\", limpa, clássica ou simbólica. Envolve a manipulação de símbolos e de conceitos abstractos, e é a metodologia utilizada na maior parte dos sistemas periciais. Paralelamente a esta abordagem existe a"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_13", "text": "limpa, clássica ou simbólica. Envolve a manipulação de símbolos e de conceitos abstractos, e é a metodologia utilizada na maior parte dos sistemas periciais. Paralelamente a esta abordagem existe a abordagem IA \"scruffies\", ou \"coneccionista\", da qual as redes neuronais são o melhor exemplo. Esta abordagem cria sistemas que tentam gerar inteligência pela aprendizagem e adaptação em vez da criação de sistemas desenhados com o objectivo especifico de resolver um problema. Ambas as abordagems apareceram num estágio inicial da história de IA. Nas décadas de 1960/70 os coneccionistas foram retirados do primeiro plano da investigação em IA, mas o interesse por esta vertente da IA foi retomada na década de 1980, quando as limitações da IA \"limpa\" começaram a ser percebidas. Pesquisas sobre inteligência artificial foram intensamente custeadas na década de 1980 pela Agência de Projetos de Pesquisas Avançadas sobre Defesa (“Defense Advanced Research Projects Agency”), nos Estados Unidos, e pelo"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_14", "text": "artificial foram intensamente custeadas na década de 1980 pela Agência de Projetos de Pesquisas Avançadas sobre Defesa (“Defense Advanced Research Projects Agency”), nos Estados Unidos, e pelo Projeto da Quinta Geração (“Fifth Generation Project”), no Japão. O trabalho subsidiado fracassou no sentido de produzir resultados imediatos, a despeito das promessas grandiosas de alguns praticantes de IA, o que levou proporcionalmente a grandes cortes de verbas de agências governamentais no final dos anos 80, e em consequência a um arrefecimento da atividade no setor, fase conhecida como O inverno da IA. No decorrer da década seguinte, muitos pesquisadores de IA mudaram para áreas relacionadas com metas mais modestas, tais como aprendizado de máquinas, robótica e visão computacional, muito embora pesquisas sobre IA pura continuaram em níveis reduzidos. Existem duas abordagens principais para a criação de Sistemas de Inteligência Artificial: O Simbolismo e o Conexionismo. O Simbolismo ou IA"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_15", "text": "pesquisas sobre IA pura continuaram em níveis reduzidos. Existem duas abordagens principais para a criação de Sistemas de Inteligência Artificial: O Simbolismo e o Conexionismo. O Simbolismo ou IA Simbólica, propõe a representação de conhecimento por meio da manipulação de símbolos, isto é, na forma de estruturas construídas por seres humanos, normalmente baseadas em noções de Lógica. Ela teve grande impulso durante uma fase onde foram criados muitos Sistemas Especialistas, muitos deles baseados em Lógica de Primeira Ordem, implementados em Prolog, ou em linguagens de programação derivadas desta ou especializadas, como CLIPS. Normalmente programas desse tipo têm o conhecimento programado diretamente por seres humanos, o que levou a trabalhos de elicitação de conhecimento. Apesar do sucesso inicial dos Sistemas Especialistas, a grande dificuldade de levantar e registrar conhecimento a partir de humanos e o sucesso dos processos de aprendizado de máquina a partir de dados levou a"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_16", "text": "sucesso inicial dos Sistemas Especialistas, a grande dificuldade de levantar e registrar conhecimento a partir de humanos e o sucesso dos processos de aprendizado de máquina a partir de dados levou a dimimuição da importância dessa vertente. O Conexionismo ou IA Conexionista, se baseia em um modelo matemático inspirado no funcionamento dos neurônios, e depende do aprendizado de máquina baseado em grandes massas de dados para calibrar esse modelo, que normalmente começa com parâmetros aleatórios. Essa abordagem, apesar de proposta muito cedo, não encontrou computadores capazes de modelar problemas complexos, apesar de ter sucesso com problemas restritos de reconhecimento de padrão, o que só acontece a partir da década de 2010, com resultados extramemente fortes no final dessa década e no início da década de 2020, a partir de modelos contendo bilhões de parametros, como o GPT-3 e conceitos como Redes Neurais Profundas, Transformers, e Atenção. Em torno de 2022, a maior parte da pesquisa"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_17", "text": "da década de 2020, a partir de modelos contendo bilhões de parametros, como o GPT-3 e conceitos como Redes Neurais Profundas, Transformers, e Atenção. Em torno de 2022, a maior parte da pesquisa em IA gira em torno dos conceitos de Aprendizado de Máquina e Conexionismo, havendo também propostas para sistemas híbridos. A questão sobre o que é \"inteligência artificial\", mesmo como definida anteriormente, pode ser separada em duas partes: \"qual a natureza do artificial\" e \"o que é inteligência\". A primeira questão é de resolução relativamente fácil, apontando no entanto para a questão de o que poderá o homem construir. A segunda questão seria consideravelmente mais difícil, levantando a questão da consciência, identidade e mente (incluindo a mente inconsciente) juntamente com a questão de que componentes estão envolvidos no único tipo de inteligência que universalmente se aceita como estando ao alcance do nosso estudo: a inteligência do ser humano. O estudo de animais e de sistemas"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_18", "text": "de que componentes estão envolvidos no único tipo de inteligência que universalmente se aceita como estando ao alcance do nosso estudo: a inteligência do ser humano. O estudo de animais e de sistemas artificiais que não são modelos triviais começa a ser considerado como pauta de estudo na área da inteligência. Ao conceituar inteligência artificial, presume-se a interação com o ambiente, diante de necessidades reais como relações entre indivíduos semelhantes, a disputa entre indivíduos diferentes, perseguição e fuga; além da comunicação simbólica específica de causa e efeito em diversos níveis de compreensão intuitiva, consciente ou não. Suponhamos uma competição de cara ou coroa, cujos resultados sejam observados ou não. Se na segunda tentativa der o mesmo resultado que a primeira, então não existiam as mesmas chances para ambas opções iniciais. Claro que a coleta de informação em apenas duas amostragens é confiável apenas porque a quantidade de tentativas é divisível pelo número de"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_19", "text": "não existiam as mesmas chances para ambas opções iniciais. Claro que a coleta de informação em apenas duas amostragens é confiável apenas porque a quantidade de tentativas é divisível pelo número de opções de resultados prováveis. A verdade é que o conceito de cara ou coroa está associado a artigos de valor, como moedas e medalhas que podem evitar que as pessoas abandonem o jogo e induza os participantes a acompanhar os resultados até o final. Para manter a disposição do adversário em desafiar a máquina seria necessário aparentar fragilidade e garantir a continuidade da partida. Isso é muito utilizado em máquinas de cassino, sendo que vários apostadores podem ser induzidos a dispensar consideráveis quantias em apostas. A utilização de uma máquina de resultados pode compensar a ausência de um adversário, mas numa partida de xadrez, por exemplo, para que a máquina não precise armazenar todas as informações que excedem a capacidade de próprio universo imaginável são necessárias fórmulas"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_20", "text": "um adversário, mas numa partida de xadrez, por exemplo, para que a máquina não precise armazenar todas as informações que excedem a capacidade de próprio universo imaginável são necessárias fórmulas que possam ser armazenadas para que então sejam calculadas por princípios físicos, lógicos, geométricos, e estatísticos para refletir o sistema completo em cada uma das suas partes; como a integração do Google com Wikipédia, por exemplo. Uma popular e inicial definição de inteligência artificial, introduzida por John McCarthy na famosa conferência de Dartmouth em 1956 é \"fazer a máquina comportar-se de tal forma que seja chamada inteligente caso fosse este o comportamento de um ser humano.\" No entanto, esta definição parece ignorar a possibilidade de existir a IA forte (ver abaixo). Outra definição de Inteligência Artificial é a inteligência que surge de um \"dispositivo artificial\". A maior parte das definições podem ser categorizadas em sistemas que: \"pensam como um humano; agem como um"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_21", "text": "de Inteligência Artificial é a inteligência que surge de um \"dispositivo artificial\". A maior parte das definições podem ser categorizadas em sistemas que: \"pensam como um humano; agem como um humano; pensam racionalmente ou agem racionalmente\". Os principais pesquisadores e livros didáticos definem o campo como \"o estudo e projeto de agentes inteligentes\", onde um agente inteligente é um sistema que percebe seu ambiente e toma atitudes que maximizam suas chances de sucesso. Andreas Kaplan e Michael Haenlein definem a inteligência artificial como “uma capacidade do sistema para interpretar corretamente dados externos, aprender a partir desses dados e utilizar essas aprendizagens para atingir objetivos e tarefas específicas através de adaptação flexível”. John McCarthy, quem cunhou o termo em 1956 (\"numa conferência de especialistas celebrada em Darmouth Colege\" Gubern, Román: O Eros Eletrónico), a define como \"a ciência e engenharia de produzir sistemas inteligentes\". É uma área de"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_22", "text": "em 1956 (\"numa conferência de especialistas celebrada em Darmouth Colege\" Gubern, Román: O Eros Eletrónico), a define como \"a ciência e engenharia de produzir sistemas inteligentes\". É uma área de pesquisa da computação dedicada a buscar métodos ou dispositivos computacionais que possuam ou multipliquem a capacidade racional do ser humano de resolver problemas, pensar ou, de forma ampla, ser inteligente. Nas últimas décadas, o campo exoandiu-se para incluir subáreas como aprendizado de máquina, redes neurais artificiais, processamento de linguagem natural e visão computacional, com ênfase crescente em técnicas estatísticas, métodos conexionistas e abordagens híbridas que combinam modelos simbólicos e aprendizagem profunda.. Também pode ser definida como o ramo da ciência da computação que se ocupa do comportamento inteligente ou ainda, o estudo de como fazer os computadores realizarem coisas que, atualmente, os humanos fazem melhor. Não existe uma teoria ou paradigma unificador que"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_23", "text": "se ocupa do comportamento inteligente ou ainda, o estudo de como fazer os computadores realizarem coisas que, atualmente, os humanos fazem melhor. Não existe uma teoria ou paradigma unificador que orienta a pesquisa de IA. Pesquisadores discordam sobre várias questões. Algumas das perguntas constantes mais longas que ficaram sem resposta são as seguintes: a inteligência artificial deve simular inteligência natural, estudando psicologia ou neurociência? Ou será que a biologia humana é tão irrelevante para a pesquisa de IA como a biologia das aves é para a engenharia aeronáutica? O comportamento inteligente pode ser descrito usando princípios simples e elegantes (como lógica ou otimização)? Ou ela necessariamente requer que se resolva um grande número de problemas completamente não relacionados? A inteligência pode ser reproduzida usando símbolos de alto nível, similares às palavras e ideias? Ou ela requer processamento \"sub-simbólico\"? John Haugeland, que cunhou o termo GOFAI (Good"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_24", "text": "A inteligência pode ser reproduzida usando símbolos de alto nível, similares às palavras e ideias? Ou ela requer processamento \"sub-simbólico\"? John Haugeland, que cunhou o termo GOFAI (Good Old-Fashioned Artificial Intelligence - Boa Inteligência Artificial à Moda Antiga), também propôs que a IA deve ser mais apropriadamente chamada de inteligência sintética, um termo que já foi adotado por alguns pesquisadores não-GOFAI. Nos anos de 1940 e 1950, um número de pesquisadores exploraram a conexão entre neurologia, teoria da informação e cibernética. Alguns deles construíram máquinas que usaram redes eletrônicas para exibir inteligência rudimentar, como as tartarugas de W. Grey Walter e a Besta de Johns Hopkins. Muitos desses pesquisadores se reuniram para encontros da Sociedade teleológica da Universidade de Princeton e o Ratio Club na Inglaterra. Em 1960, esta abordagem foi abandonada, apesar de seus elementos serem revividos na década de 1980. Inteligência computacional Interesse em"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_25", "text": "da Universidade de Princeton e o Ratio Club na Inglaterra. Em 1960, esta abordagem foi abandonada, apesar de seus elementos serem revividos na década de 1980. Inteligência computacional Interesse em redes neurais e \"conexionismo\" foi revivida por David Rumelhart e outros em meados de 1980. Estas e outras abordagens sub-simbólicas, como sistemas de fuzzy e computação evolucionária, são agora estudados coletivamente pela disciplina emergente inteligência computacional. A IA tipo fraca, limitada, ou estreita (em inglês Narrow AI) são máquinas ou sistemas inteligentes que não fazem raciocínio; é limitada porque foi projetada para fazer uma tarefa específica, após ser treinado por um humano. Ou seja, não aprende de forma autônoma. Como por exemplo reconhecer comandos de voz e encontrar a rota mais rápida. A AGI possui a habilidade de compreender e adaptar-se a vários contextos (e desafios) de forma autônoma sem a necessidade treinamento. Máquinas com inteligência versátil semelhante à"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_26", "text": "mais rápida. A AGI possui a habilidade de compreender e adaptar-se a vários contextos (e desafios) de forma autônoma sem a necessidade treinamento. Máquinas com inteligência versátil semelhante à humana, aprende de forma autônoma. Considerada o futuro da IA (especulação), com a criação de máquinas com capacidade de tomar decisões e analisar dados de forma extremamente rápida, superando a IA forte. Conseguem responder rapidamente as tarefas imediatas, mas não conseguem armazenar memória, não melhoraram sua funcionalidade com a experiência (não aprendem). Como por exemplo o mecanismo de recomendação da Netflix, que analisa o histórico do usuário para sugerir um filme/série. É um subcampo da inteligência artificial, na qual uma máquina aprende, ou seja, é ensinada a partir de algoritmos a realizar uma tarefa determinada, entendendo um padrão. Uma estrutura computacional inspirado na estrutura neural do ser humano para simular o cérebro humano, como por exemplo o algoritmo usado no"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_27", "text": "a realizar uma tarefa determinada, entendendo um padrão. Uma estrutura computacional inspirado na estrutura neural do ser humano para simular o cérebro humano, como por exemplo o algoritmo usado no buscador do Google; esta reconhece os termos pesquisados, busca os sinônimos e, assuntos relacionados para assim gerar melhores resultados. É um sistema inteligente com habilidade de interpretar as emoções de pessoas e animais. Um termo emprestado da psicologia, que é a habilidade dos humanos de ler as emoções dos outros e prever ações. Autoconsciente ou ponto de singularidade da IA ou, como defende a academia, senciência da IA, é um estágio hipotético da inteligência artificial em que as máquinas possuem autoconsciência. Um estágio além da teoria da mente e é um dos objetivos finais no desenvolvimento da IA. A investigação recente destaca também os impactos económicos e sociais associados a sistemas de IA avançados, incluindo a automatização de empregos, a concentração de poder tecnológico"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_28", "text": "da IA. A investigação recente destaca também os impactos económicos e sociais associados a sistemas de IA avançados, incluindo a automatização de empregos, a concentração de poder tecnológico e riscos éticos ligados a uma eventual senciência. Estes fatores têm motivado debates académicos sobre regulação, governança e segurança no desenvolvimento da inteligência artificial. Permite que as máquinas/sistemas conversem com os humanos usando a linguagem humana, como por exemplo o uso da Alexa e da Siri. Os assistentes pessoais fazem parte da Inteligência Artificial Estreita (ANI), limitação da IA de executar um conjunto de tarefas específicas. Os sistemas de navegação fazem tarefas bem definidas, como encontrar a rota mais rápida de um ponto a outro. Faz analise e descreve imagens e vídeos, podendo reconhecer objetos e detectar movimentos, mapear um ambiente físico. São máquinas ou sistemas inteligentes usados na indústria , que possuem a capacidade de tomar decisões/fazer ações"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_29", "text": "vídeos, podendo reconhecer objetos e detectar movimentos, mapear um ambiente físico. São máquinas ou sistemas inteligentes usados na indústria , que possuem a capacidade de tomar decisões/fazer ações programadas a partir da coleta de informações do ambiente (como por exemplo a umidade e a temperatura). Capacidade de identificar objetos e capacidade de navegar em diferentes ambientes de forma autônoma, como por exemplo a Figure AI que está construindo robôs humanoides bípedes para trabalharem com os humanos. IA que é cria voz humana realista, transformando texto em voz, modificação do timbre, entonação da fala e, velocidade da voz. São sistemas inteligentes que conseguem criar roteiros, poesias, imagens e vídeos, não limitado apenas em analisar dados. Entre os teóricos que estudam o que é possível fazer com a IA existe uma discussão onde se consideram duas propostas básicas: uma conhecida como \"forte\" e outra conhecida como \"fraca\". Basicamente, a hipótese da IA forte considera ser"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_30", "text": "é possível fazer com a IA existe uma discussão onde se consideram duas propostas básicas: uma conhecida como \"forte\" e outra conhecida como \"fraca\". Basicamente, a hipótese da IA forte considera ser possível criar uma máquina consciente, ou seja, afirma que os sistemas artificiais devem replicar a mentalidade humana. A investigação em Inteligência Artificial Forte aborda a criação da forma de inteligência baseada em computador que consiga raciocinar e resolver problemas; uma forma de IA forte é classificada como auto-consciente. A IA forte é tema bastante controverso, pois envolve temas como consciência e fortes problemas éticos ligados ao que fazer com uma entidade que seja cognitivamente indistinguível de seres humanos. A ficção científica tratou de muitos problemas desse tipo. Isaac Asimov, por exemplo, escreveu O Homem Bicentenário, onde um robô consciente e inteligente luta para possuir um status semelhante ao de um humano na sociedade. E Steven Spielberg dirigiu \"A.I."}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_31", "text": "Isaac Asimov, por exemplo, escreveu O Homem Bicentenário, onde um robô consciente e inteligente luta para possuir um status semelhante ao de um humano na sociedade. E Steven Spielberg dirigiu \"A.I. Inteligência Artificial\" onde um garoto-robô procura conquistar o amor de sua \"mãe\", procurando uma maneira de se tornar real. Por outro lado, o mesmo Asimov reduz os robôs a servos dos seres humanos ao propor as três leis da robótica. Stephen Hawking alertou sobre os perigos da inteligência artificial e considerou uma ameaça à sobrevivência da humanidade (ver: Rebelião das máquinas). Trata-se da noção de como lidar com problemas não determinísticos. Uma contribuição prática de Alan Turing foi o que se chamou depois de Teste de Turing (TT), de 1950: em lugar de responder à pergunta \"podem-se ter computadores inteligentes?\" ele formulou seu teste, que se tornou praticamente o ponto de partida da pesquisa em \"Inteligência Artificial\". O teste consiste em se fazer perguntas a uma pessoa e um"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_32", "text": "computadores inteligentes?\" ele formulou seu teste, que se tornou praticamente o ponto de partida da pesquisa em \"Inteligência Artificial\". O teste consiste em se fazer perguntas a uma pessoa e um computador escondidos. Um computador e seus programas passam no TT se, pelas respostas, for impossível a alguém distinguir qual interlocutor é a máquina e qual é a pessoa. No seu artigo original ele fez a previsão de que até 2000 os computadores passariam seu teste. Pois bem, há um concurso anual de programas para o TT, e o resultado dos sistemas ganhadores é tão fraco (o último tem o nome \"Ella\") que com poucas perguntas logo percebe-se as limitações das respostas da máquina. É interessante notar que tanto a Máquina de Turing quanto o Teste de Turing talvez derivem da visão que Turing tinha de que o ser humano é uma máquina. Há quem diga que essa visão está absolutamente errada, do ponto de vista linguístico, já que associamos à \"máquina\" um artefato inventado e eventualmente construído."}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_33", "text": "que o ser humano é uma máquina. Há quem diga que essa visão está absolutamente errada, do ponto de vista linguístico, já que associamos à \"máquina\" um artefato inventado e eventualmente construído. Dizem eles: \"Nenhum ser humano foi inventado ou construído\". Afirma-se ainda que a comparação, feita por Turing, entre o homem e a máquina é sinônimo de sua \"ingenuidade social\", pois as máquinas são infinitamente mais simples do que o homem, apesar de, paradoxalmente, se afirmar que a vida é complexa. No entanto, esta linha de raciocínio é questionável, afinal de contas, os computadores modernos podem ser considerados \"complexos\" quando comparados ao COLOSSUS (computador cujo desenvolvimento foi liderado por Tommy Flowers, em 1943), ou a qualquer máquina do início do século XX. A inteligência artificial fraca centra a sua investigação na criação de inteligência artificial que não é capaz de verdadeiramente raciocinar e resolver problemas. Uma tal máquina com esta característica de"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_34", "text": "artificial fraca centra a sua investigação na criação de inteligência artificial que não é capaz de verdadeiramente raciocinar e resolver problemas. Uma tal máquina com esta característica de inteligência agiria como se fosse inteligente, mas não tem autoconsciência ou noção de si. O teste clássico para aferição da inteligência em máquinas é o Teste de Turing. Há diversos campos dentro da IA fraca, e um deles é o Processamento de linguagem natural, que trata de estudar e tentar reproduzir os processos de desenvolvimento que resultaram no funcionamento normal da língua. Muitos destes campos utilizam softwares específicos e linguagens de programação criadas para suas finalidades. Um exemplo é o chatbot Eliza, desenvolvido por Joseph Weizenbaum no laboratório de Inteligência Artificial do MIT entre os anos de 1964 e 1966. Outro exemplo bastante conhecido é o programa A.L.I.C.E. (Artificial Linguistic Internet Computer Entity, ou Entidade Computadorizada de Linguagem Artificial para"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_35", "text": "do MIT entre os anos de 1964 e 1966. Outro exemplo bastante conhecido é o programa A.L.I.C.E. (Artificial Linguistic Internet Computer Entity, ou Entidade Computadorizada de Linguagem Artificial para Internet), um software que simula uma conversa humana. Programado em Java e desenvolvido com regras heurísticas para os caracteres de conversação, seu desenvolvimento resultou na AIML (Artificial Intelligence Markup Language), uma linguagem específica para tais programas e seus vários clones, chamados de Alicebots. Muito do trabalho neste campo tem sido feito com simulações em computador de inteligência baseado num conjunto predefinido de regras. Poucos têm sido os progressos na IA forte. Mas dependendo da definição de IA utilizada, pode-se dizer que avanços consideráveis na IA fraca já foram alcançados. Muitos filósofos, sobretudo John Searle e Hubert Dreyfus, inseriram no debate questões de ordem filosófica e epistemológica, questionando qualquer possibilidade efetiva da IA forte."}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_36", "text": "foram alcançados. Muitos filósofos, sobretudo John Searle e Hubert Dreyfus, inseriram no debate questões de ordem filosófica e epistemológica, questionando qualquer possibilidade efetiva da IA forte. Seriam falsos, assim, os próprios pressupostos da construção de uma inteligência ou consciência semelhante à humana em uma máquina. Searle é bastante conhecido por seu contra-argumento sobre o Quarto Chinês (ou Sala Chinesa), que inverte a questão colocada por Minsky a respeito do Teste de Turing. Seu argumento diz que ainda que uma máquina possa parecer falar chinês por meio de recursos de exame comparativo com mostras e tabelas de referência, binárias, isso não implica que tal máquina fale e entenda efetivamente a língua. Ou seja, demonstrar que uma máquina possa passar no Teste de Turing não necessariamente implica um ser consciente, tal como entendido em seu sentido humano. Dreyfus, em seu livro O que os computadores ainda não conseguem fazer: Uma crítica ao raciocínio artificial,"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_37", "text": "não necessariamente implica um ser consciente, tal como entendido em seu sentido humano. Dreyfus, em seu livro O que os computadores ainda não conseguem fazer: Uma crítica ao raciocínio artificial, argumenta que a consciência não pode ser adquirida por sistemas baseados em regras ou lógica; tampouco por sistemas que não façam parte de um corpo físico. No entanto, este último autor deixa aberta a possibilidade de um sistema robótico baseado em Redes Neuronais, ou em mecanismos semelhantes, alcançar a inteligência artificial. Mas já não seria a referida IA forte, mas sim um correlato bem mais próximo do que se entende por IA fraca. Os revezes que a acepção primeira de Inteligência Artificial vem levando nos últimos tempos contribuíram para a imediata relativização de todo seu legado. O papel de Marvin Minsky, figura proeminente do MIT e autor de Sociedade da Mente, fora central para a acepção de uma IA linear que imitaria com perfeição a mente humana, mas seu principal feito foi"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_38", "text": "O papel de Marvin Minsky, figura proeminente do MIT e autor de Sociedade da Mente, fora central para a acepção de uma IA linear que imitaria com perfeição a mente humana, mas seu principal feito foi construir o primeiro computador baseado em redes neurais, conhecido como Snark, tendo simplesmente fracassado pois nunca executou qualquer função interessante, apenas consumiu recursos de outras pesquisas mais promissoras. O primeiro neuro computador a obter sucesso (Mark I Perceptron) surgiu em 1957 e 1958, criado por Frank Rosenblatt, Charles Wightman e outros. Atualmente, no entanto, as vertentes que trabalham com os pressupostos da emergência e com elementos da IA fraca parecem ter ganhado proeminência do campo. As críticas sobre a impossibilidade de criar uma inteligência em um composto artificial podem ser encontradas em Jean-François Lyotard (O Pós-humano) e Lucien Sfez (Crítica da Comunicação); uma contextualização didática do debate encontra-se em Sherry Turkle (O segundo Eu: os"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_39", "text": "artificial podem ser encontradas em Jean-François Lyotard (O Pós-humano) e Lucien Sfez (Crítica da Comunicação); uma contextualização didática do debate encontra-se em Sherry Turkle (O segundo Eu: os computadores e o espírito humano). Pode-se resumir o argumento central no fato de que a própria concepção de inteligência é humana e, nesse sentido, animal e biológica. A possibilidade de transportá-la para uma base plástica, artificial, encontra um limite claro e preciso: se uma inteligência puder ser gerada a partir destes elementos, deverá ser necessariamente diferente da humana, na medida em que o seu resultado provém da emergência de elementos totalmente diferentes dos encontrados nos humanos. A inteligência, tal como a entendemos, é essencialmente o fruto do cruzamento da uma base biológica com um complexo simbólico e cultural, impossível de ser reproduzido artificialmente. Outros filósofos sustentam visões diferentes. Ainda que não vejam problemas com a IA fraca, entendem que há"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_40", "text": "com um complexo simbólico e cultural, impossível de ser reproduzido artificialmente. Outros filósofos sustentam visões diferentes. Ainda que não vejam problemas com a IA fraca, entendem que há elementos suficientes para se crer na IA forte também. Daniel Dennett argumenta em Consciência Explicada que se não há uma centelha mágica ou alma nos seres humanos, então o Homem é apenas uma outra máquina. Dennett questiona por que razão o Homem-máquina deve ter uma posição privilegiada sobre todas as outras possíveis máquinas quando provido de inteligência. Alguns autores sustentam que se a IA fraca é possível, então também o é a forte. O argumento da IA fraca, de uma inteligência imitada mas não real, desvelaria assim uma suposta validação da IA forte. Isso se daria porque, tal como entende Simon Blackburn em seu livro Think, dentre outros, não existe a possibilidade de verificar se uma inteligência é verdadeira ou não. Estes autores argumentam que toda inteligência apenas parece"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_41", "text": "Simon Blackburn em seu livro Think, dentre outros, não existe a possibilidade de verificar se uma inteligência é verdadeira ou não. Estes autores argumentam que toda inteligência apenas parece inteligência, sem necessariamente o ser. Parte-se do princípio que é impossível separar o que é inteligência de fato do que é apenas simulação: apenas acredita-se ser. Estes autores rebatem os argumentos contra a IA forte dizendo que seus críticos reduzem-se a arrogantes que não podem entender a origem da vida sem uma centelha mágica, um Deus ou uma posição superior qualquer. Eles entenderiam, em última instância, máquina como algo essencialmente incapaz e sequer conseguem supô-la como capaz de inteligência. Nos termos de Minsky, a crítica contra a IA forte erra ao supor que toda inteligência derive de um sujeito - tal como indicado por Searle - e assim desconsidera a possibilidade de uma maquinaria complexa que pudesse pensar. Mas Minsky desconsidera o simples fato de que os maiores avanços na"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_42", "text": "de um sujeito - tal como indicado por Searle - e assim desconsidera a possibilidade de uma maquinaria complexa que pudesse pensar. Mas Minsky desconsidera o simples fato de que os maiores avanços na área foram conseguidos com \"maquinaria complexa\", também chamada por pesquisadores mais importantes de Inteligência Artificial Conexista. Se a crítica de Minsky fosse válida a maquina criada por Rosenblatt e Bernard Widrow não estaria em uso ainda hoje, e o Mark I Perceptron não seria o fundador da neuro-computação. Alguns pesquisadores importantes afirmam que um dos motivos das críticas de Minsky foi o fato de ter falhado com Snark. A partir daí começou a criticar essa área por não compreende-la completamente, prejudicando desde então pesquisas importantes sobre o assunto. O debate sobre a IA reflete, em última instância, a própria dificuldade da ciência contemporânea em lidar efetivamente com a ausência de um primado superior. Os argumentos pró-IA forte são esclarecedores dessa questão,"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_43", "text": "reflete, em última instância, a própria dificuldade da ciência contemporânea em lidar efetivamente com a ausência de um primado superior. Os argumentos pró-IA forte são esclarecedores dessa questão, pois são os próprios cientistas, que durante décadas tentaram e falharam ao criar uma IA forte, que ainda procuram a existência de uma ordem superior. Ainda que a IA forte busque uma ordem dentro da própria conjugação dos elementos internos, trata-se ainda da suposição de que existe na inteligência humana uma qualidade superior que deve ser buscada, emulada e recriada. Reflete, assim, a difícil digestão do legado radical da Teoria da Evolução, onde não existe positividade alguma em ser humano e ser inteligente; trata-se apenas de um complexo de relações que propiciaram um estado particular, produto de um cruzamento temporal entre o extrato biológico e uma complexidade simbólica. É argumentado também que a inteligência artificial ainda não é desenvolvida ao ponto de atuar como o cérebro"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_44", "text": "produto de um cruzamento temporal entre o extrato biológico e uma complexidade simbólica. É argumentado também que a inteligência artificial ainda não é desenvolvida ao ponto de atuar como o cérebro humano, de forma criativa. Ademais, o cérebro humano ainda não é suficientemente compreendido. Portanto, a ideia de replicar funções do cérebro humano é atualmente intangível. A IA pode ser uma arma quando usada por pessoas mal-intencionadas, como por exemplo o uso da ferramenta deepfake para golpe. A criação destes sistemas podem gerar vazamento de dados ou acidentes com veículos autônomos. Foi provado que um simulador qualitativo, completo e robusto não pode existir, ou seja, desde que o vocabulário entrada-saída seja usado (como num algoritmo QSIM), haverá sempre modelos de entrada que causam predições erradas na sua saída. Por exemplo, a noção de infinito é impossível ser tida por uma máquina finita (computador ou neurónios se produzirem apenas um número finito de resultados num número"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_45", "text": "predições erradas na sua saída. Por exemplo, a noção de infinito é impossível ser tida por uma máquina finita (computador ou neurónios se produzirem apenas um número finito de resultados num número finito de tempo). Neste caso é um simples paradoxo matemático, porque são em número finito as combinações saídas de qualquer conjunto finito. Se a noção de infinito pudesse ser obtida por uma certa combinação finita, isso significaria que o infinito seria equivalente a essa sequência finita, o que é obviamente uma contradição. Por isso, o infinito e outras noções abstratas têm que ser pré-adquiridas numa máquina finita, não são aí programáveis. A inteligência artificial, em um contexto amplo, possui aplicações diversas, sendo empregada na resolução de problemas práticos por entidades civis, governamentais, e militares. Possui aplicações na área da saúde, mídia e comércio eletrônico, entre outros. Há uma discussão sobre como a IA tem sido integrada em sistemas de planejamento automatizado,"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_46", "text": "e militares. Possui aplicações na área da saúde, mídia e comércio eletrônico, entre outros. Há uma discussão sobre como a IA tem sido integrada em sistemas de planejamento automatizado, diagnóstico médico, utilização por advogados (IA para advogados), reconhecimento de linguagem e muito mais, mostrando a ampla gama de aplicações e o impacto profundo da IA em múltiplas áreas. A adoção ggeberalizada da inteligência artificial levanta preocupações quanto ao seu impacto no emprego e na distribuição de riqueza. Vários estudos recentes indicam que a automação de tarefas cognitivas e rotineiras pode levar ao deslocamento de trabalhadores em setores como transporte, serviços financeiros, atendimento ao cliente entre outros. Entre as funções com maior probabilidade de extinção, a literatura destaca tarefas como produção de conteúdo padronizado, atendimento e vendas roteirizadas, backoffice administrativo, contabilidade simples, análise repetitiva de risco, programação elementar, design"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_47", "text": "destaca tarefas como produção de conteúdo padronizado, atendimento e vendas roteirizadas, backoffice administrativo, contabilidade simples, análise repetitiva de risco, programação elementar, design baseadado em modelos, mediação transacional, formação padronizada, suporte técnico básico, revisão e formatação textual, pesquisa documental simples, edição de imagem para comércio eletrónico e até memdo o comércio electrónico na parte da fixação de preços, descrições automáticas de produtos, relatórios de gestão recorrentes, prospeção de leads genéricos, curadoria de catálogos e auditorias baseadas em listas de verificação. A concentração de capacidades tecnológicas em poucas empresas e países também é alvo de debate, dado o risco de aprofundar desigualdades económicas e sociais. Estas questões têm impulsionado propostas para políticas de requalificação profissional, regulação de algoritmos e desenvolvimento ético da IA, de modo a equilibrar eficiência tecnológica e justiça social."}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_48", "text": "questões têm impulsionado propostas para políticas de requalificação profissional, regulação de algoritmos e desenvolvimento ético da IA, de modo a equilibrar eficiência tecnológica e justiça social. Atualmente existem diversos pesquisadores de IA ao redor do mundo em várias instituições e companhias de pesquisa. Entre os muitos que fizeram contribuições significativas estão: O matemático britânico Alan Turing foi um dos pioneiros na área que mais tarde daria origem à Inteligência artificial. Além de ter criado o “Teste de Turing”, usado para avaliar a capacidade de uma máquina imitar respostas humanas, os seus trabalhos em lógica matemática e computação teórica estabeleceram as bases para a ciência da computação moderna. Matemático, cientista, o criador do termo “inteligência artificial” e também o pai da linguagem de programação LISP. McCarthy foi considerado um dos primeiros homens a trabalhar no desenvolvimento da inteligência artificial e sempre disse que ela deveria interagir"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_49", "text": "e também o pai da linguagem de programação LISP. McCarthy foi considerado um dos primeiros homens a trabalhar no desenvolvimento da inteligência artificial e sempre disse que ela deveria interagir com o homem. Nascido na cidade de Boston, trabalhou na Universidade de Stanford e no Massachusetts Institute of Technology (MIT), além de ter vencido o prêmio Turing em 1972 e a Medalha Nacional de Ciência em 1991. Já a programação LISP, uma das maiores conquistas de McCarthy, surgiu em 1958 e serviu para facilitar o desenvolvimento da inteligência artificial. A linguagem é das mais antigas ainda em uso e foi usada pela primeira vez ao colocar um computador para jogar xadrez contra um adversário humano. Natural de Nova Iorque, onde nasceu, o cientista recebeu diversos prémios internacionais pelo seu trabalho pioneiro no campo da inteligência artificial, incluindo em 1969, o Prêmio Turing, o maior prêmio em ciência informática. O cientista explorou a forma de dotar as máquinas de percepção e"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_50", "text": "seu trabalho pioneiro no campo da inteligência artificial, incluindo em 1969, o Prêmio Turing, o maior prêmio em ciência informática. O cientista explorou a forma de dotar as máquinas de percepção e inteligência semelhantes à humana, criou mãos robóticas com capacidade para manipular objetos, desenvolveu novos marcos de programação e escreveu sobre assuntos filosóficos relacionados com a inteligência artificial. Minsky estava convencido de que o homem, um dia, desenvolveria máquinas que competiriam com a sua inteligência e via o cérebro como uma máquina cujo funcionamento pode ser estudado e reproduzido num computador, o que poderia ajudar a compreender melhor o cérebro humano e as funções mentais superiores. Informático indiano naturalizado estadunidense, foi o primeiro asiático a vencer o Prêmio Turing. Entre suas contribuições para a IA estão a criação do Instituto de Robótica da CMU e demonstrações de diversos sistemas que usam alguma forma de IA. Entre esses sistemas, estão"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_51", "text": "o Prêmio Turing. Entre suas contribuições para a IA estão a criação do Instituto de Robótica da CMU e demonstrações de diversos sistemas que usam alguma forma de IA. Entre esses sistemas, estão sistemas de: fala, controlados por voz, reconhecimento de voz, reconhecimento de voz independente do interlocutor, etc. Para Reddy, ao invés de substituir a humanidade, a tecnologia irá criar um novo tipo de humano que irá coexistir com seus antecessores enquanto se aproveita das vantagens de uma nova classe de ferramentas viabilizada pela tecnologia. Winograd é um cientista da computação estadunidense, professor da Universidade Stanford, e codiretor do grupo de interação humano-computador de Stanford. É conhecido nas áreas de filosofia da mente e inteligência artificial por seu trabalho sobre língua natural usando o programa SHRDLU. Para Terry, não restam dúvidas de que a tecnologia da informática, mais precisamente a área de inteligência artificial, transformará as sociedades, introduzindo"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_52", "text": "natural usando o programa SHRDLU. Para Terry, não restam dúvidas de que a tecnologia da informática, mais precisamente a área de inteligência artificial, transformará as sociedades, introduzindo modificações socioeconômicas irreversíveis. Esse especialista procura saber se os seres humanos seriam capazes de construir máquinas que poderiam compreende-los, resolver seus problemas e dirigir suas vidas, além de buscar respostas sobre o que aconteceria se, algum dia, essas máquinas se tornassem mais inteligentes do que os próprios humanos que as criaram. Nascido na Filadélfia, Pensilvânia, se formou na Universidade da Pensilvânia. Douglas Bruce Lenat é o Diretor Executivo do Cycorp e foi também um pesquisador proeminente em inteligência artificial, recebendo o prêmio bianual IJCAI Computers and Thought em 1976 pela criação do programa de aprendizado de máquinas. Ele também trabalhou em simulações militares e em numerosos projetos para organizações governamentais, militares, científicas e"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_53", "text": "Thought em 1976 pela criação do programa de aprendizado de máquinas. Ele também trabalhou em simulações militares e em numerosos projetos para organizações governamentais, militares, científicas e de inteligência dos EUA. A missão de Lenat, no longo ciclo do projeto Cyc, iniciado em 1984, era de construir a base de uma inteligência artificial geral ao representar manualmente o conhecimento como axiomas lógicos contextualizados na linguagem formal com base em extensões ao cálculo de predicados de primeira ordem e em seguida, usar esse enorme motor de inferência de ontologia e a base de conhecimento contextualizada como um viés indutivo para automatizar e acelerar cada vez mais a educação contínua do próprio Cyc, via aprendizagem em máquina e compreensão da linguagem natural. Ablação (inteligência artificial) Alinhamento da inteligência artificial Lista de projetos de inteligência artificial Segurança da inteligência artificial OpenAI OpenAI Codex Realidade simulada Robocode"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_54", "text": "(inteligência artificial) Alinhamento da inteligência artificial Lista de projetos de inteligência artificial Segurança da inteligência artificial OpenAI OpenAI Codex Realidade simulada Robocode Transferência de energia sem fio «Programa do governo para defender suas questões». (em português) «American Association for Artificial Intelligence» (em inglês) História da IA no YouTube"}
{"source": "George Hotz", "chunk_id": "George Hotz_0", "text": "George Francis Hotz, apelidado geohot, million75 ou simplesmente mil, é um hacker, engenheiro de software e empresário estadunidense conhecido por ter trabalhado com outras pessoas para desbloquear o iPhone, permitindo que o aparelho fosse usado com outras operadoras, diferente da intenção da Apple em disponibilizar para seus clientes apenas o uso com a AT&T. Hotz também criou um método de Jailbreak e desenvolveu um método de crackear o PlayStation 3. Hotz disponibilizou ferramentas capazes de assinar digitalmente softwares (homebrews) para rodar no Playstation 3 e também um software capaz de desbloquear PS3s com o firmware 3.55, no qual podem rodar os softwares assinados com suas ferramentas. A presença da assinatura faz o console pensar que o programa foi autorizado pela Sony, da mesma forma que uma assinatura manuscrita autentica um cheque ou contrato. Atualmente Hotz vem trabalhando em sua empresa de machine learning para automação de veículos, chamada comma.ai e em um projeto de"}
{"source": "George Hotz", "chunk_id": "George Hotz_1", "text": "forma que uma assinatura manuscrita autentica um cheque ou contrato. Atualmente Hotz vem trabalhando em sua empresa de machine learning para automação de veículos, chamada comma.ai e em um projeto de uma framework de deep learning, chamado tinygrad. Hotz e outros membros do grupo hacker conhecido como \"fail0verflow\" enfrentaram um processo da empresa Sony por terem distribuído publicamente uma ferramenta que permite alterar a chave de criptografia do Playstation 3, possibilitando a execução de homebrews, que são softwares com assinatura não-original. Dentre as aplicações desta ferramenta que desbloqueia o PlayStation 3. Para impossibilitar esta vulnerabilidade, a empresa decidiu remover a funcionabilidade \"OtherOS\", que era a porta de entrada para o desbloqueio. Sítio oficial Sítio da comma.ai"}
{"source": "Rede neural artificial", "chunk_id": "Rede neural artificial_0", "text": "Em ciência da computação e campos relacionados, redes neurais artificiais (português brasileiro) ou redes neuronais artificiais (português europeu) (RNAs) são modelos computacionais inspirados pelo sistema nervoso central de um animal (em particular o cérebro) que são capazes de realizar o aprendizado de máquina bem como o reconhecimento de padrões. Redes neurais artificiais geralmente são apresentadas como sistemas de \"neurônios interconectados, que podem computar valores de entradas\", simulando o comportamento de redes neurais biológicas. Por exemplo, uma rede neural para o reconhecimento de escrita manual é definida por um conjunto de neurônios de entrada que podem ser ativados pelos pixels de uma imagem de entrada. Os dados adquiridos por essa ativação dos neurônios são então repassados​​, ponderados e transformados por uma função determinada pelo designer da rede, a outros neurônios. Este processo é repetido até que, finalmente, um neurônio de saída é ativado. Isso determina que"}
{"source": "Rede neural artificial", "chunk_id": "Rede neural artificial_1", "text": "ponderados e transformados por uma função determinada pelo designer da rede, a outros neurônios. Este processo é repetido até que, finalmente, um neurônio de saída é ativado. Isso determina que caractere foi lido. Assim como outros métodos de aprendizado de máquina, sistemas que aprendem a partir dos dados, redes neurais têm sido usadas para resolver uma grande variedade de tarefas que são difíceis de resolver utilizando programação baseada em regras comuns, incluindo visão computacional e reconhecimento de voz. A inspiração original para essa técnica advém do exame das estruturas do cérebro, em particular do exame de neurônios. A propriedade mais importante das redes neurais é a habilidade de interagir com seu ambiente em busca de reconhecer padrões que podem solucionar problemas dos mais fáceis aos mais complexos consequentemente melhorando seu desempenho. Isso é feito através de um processo iterativo de ajustes aplicado aos seus pesos, o treino. A aprendizagem ocorre quando a rede"}
{"source": "Rede neural artificial", "chunk_id": "Rede neural artificial_2", "text": "fáceis aos mais complexos consequentemente melhorando seu desempenho. Isso é feito através de um processo iterativo de ajustes aplicado aos seus pesos, o treino. A aprendizagem ocorre quando a rede neural atinge uma solução generalizada para uma classe de problemas. Denomina-se algoritmo de aprendizagem a um conjunto de regras bem definidas para a solução de um problema de aprendizagem. Outro fator importante é a maneira pela qual uma rede neural se relaciona com o ambiente. Nesse contexto existem os seguintes paradigmas de aprendizagem: Aprendizagem Supervisionada, quando é utilizado um agente externo que indica à rede a resposta desejada para o padrão de entrada, Aprendizagem Não Supervisionada (auto-organização), quando não existe uma agente externo indicando a resposta desejada para os padrões de entrada, e Aprendizagem por Reforço, quando um crítico externo avalia a resposta fornecida pela rede. Reconhecimento Automático de Alvos; Reconhecimento de Caracteres; Robótica;"}
{"source": "Rede neural artificial", "chunk_id": "Rede neural artificial_3", "text": "para os padrões de entrada, e Aprendizagem por Reforço, quando um crítico externo avalia a resposta fornecida pela rede. Reconhecimento Automático de Alvos; Reconhecimento de Caracteres; Robótica; Diagnóstico Médico; Sensoriamento Remoto; Processamento de Voz; Biometria; Análise de dados (Data Mining), incluindo para análise de imagem de sistemas quânticos. Cientistas russos substituíram especialistas em caminhada quântica por inteligência artificial, treinando a máquina para reconhecer redes e dizer se um determinado sistema trará vantagens quânticas. Isso indica as redes que são boas candidatas para a construção de um computador quântico. Aplicações em reconhecimento de padrões; Análise de disfluência da fala - Junto ao Departamento de Fisioterapia, Fonoaudiologia e Terapia Ocupacional da Faculdade de Medicina da USP; Tratamento corretivo do aparelho buco-maxilar - Junto ao Departamento de Informática Médica, Faculdade de Medicina da USP; Predição da Doença de Alzheimer - Junto ao"}
{"source": "Rede neural artificial", "chunk_id": "Rede neural artificial_4", "text": "da Faculdade de Medicina da USP; Tratamento corretivo do aparelho buco-maxilar - Junto ao Departamento de Informática Médica, Faculdade de Medicina da USP; Predição da Doença de Alzheimer - Junto ao Departamento de Informática Médica, Faculdade de Medicina da USP; Reconhecimento de câncer – Câncer de mamas PPEP e Disciplina e Informática Médica, Faculdade de Medicina da USP; Análise do Planejamento Urbano da Cidade de São Paulo; Aplicações em Tomada de Decisão em Engenharia de Produção; Mercado Financeiro. As primeiras informações sobre neurocomputação surgiram em 1943, em artigos do neuroanatomista e psiquiatra Warren McCulloch, do Instituto Tecnológico de Massachusetts, e do matemático Walter Pitts, da Universidade de Illinois. Os autores fizeram uma analogia entre células nervosas vivas e o processo eletrônico, em um trabalho publicado sobre \"neurônios formais\"; simulando o comportamento do neurônio natural, no qual o neurônio possuía apenas uma saída, que era uma função da soma de"}
{"source": "Rede neural artificial", "chunk_id": "Rede neural artificial_5", "text": "e o processo eletrônico, em um trabalho publicado sobre \"neurônios formais\"; simulando o comportamento do neurônio natural, no qual o neurônio possuía apenas uma saída, que era uma função da soma de valor de suas diversas entradas. O trabalho consistia num modelo de resistores variáveis e amplificadores, representando conexões sinápticas de um neurônio biológico. Possivelmente uma das publicações mais significativas, formulada por von Neumann, foi The General and Logical Theory of Automata, no final da década de 1940. Talvez a mais remota influência (no início do século XIX), foi a do \"Pato de Vaucanson\", um autômato em forma de pato com centenas de peças e que além de grasnar, comia, bebia, digeria e nadava. Não esquecendo de mencionar também a máquina de Turing (1936). O resultado do autômato de Turing influenciou von Neumann, e o levou a perceber que os seres vivos estavam de fato entre as máquinas que a máquina de Turing poderia emular. Na sua obra, arquitetura de von Neumann, ele"}
{"source": "Rede neural artificial", "chunk_id": "Rede neural artificial_6", "text": "de Turing influenciou von Neumann, e o levou a perceber que os seres vivos estavam de fato entre as máquinas que a máquina de Turing poderia emular. Na sua obra, arquitetura de von Neumann, ele fez uma analogia entre os órgãos e as partes de um computador, entre portas lógicas, circuitos e neurônios. O livro Cybernetics de Wiener publicado em 1948 descreve alguns conceitos sobre controle, comunicação e processamento estatístico de sinais. Em 1961 foi adicionado na segunda edição do livro material sobre aprendizagem e auto-organização. Em ambas as edições desse livro o Capítulo 2 traz o compreendimento do significado físico da mecânica estatística no contexto desse assunto segundo Wiener, mas quem conseguiu terminar a ligação entre a mecânica estatística e os sistemas de aprendizagem foi Hopfield mais de 30 anos depois. Em meados de 1948, o polonês Stanilaw Jaśkowskipor, discípulo de Łukasiewicz, publicou estudos sobre cálculo proposicional paraconsistente. Em meados da década de 1950,"}
{"source": "Rede neural artificial", "chunk_id": "Rede neural artificial_7", "text": "mais de 30 anos depois. Em meados de 1948, o polonês Stanilaw Jaśkowskipor, discípulo de Łukasiewicz, publicou estudos sobre cálculo proposicional paraconsistente. Em meados da década de 1950, Jaśkowski e o brasileiro matemático lógico Newton Carneiro Affonso da Costa propuseram a contradição na estrutura lógica e ficaram conhecidos como os fundadores da Paraconsistent Logic. Newton Carneiro Affonso da Costa propôs, em 1954, predicados, lógicas de ordem superior (teoria de conjuntos). A Lógica Paraconsistente faz parte das chamadas lógicas não clássicas (ABE, 2011), pois contém disposições contrárias a alguns dos princípios básicos da Lógica Aristotélica, como o princípio da contradição. Essa nova lógica surgiu com o reconhecimento pela comunidade científica (ABE, 2011) do lógico polonês Jan Łukasiewicz Lvov, nascido em 1878, e do filósofo russo Nicolai Alexandrovich Vasilév, nascido em 1910, considerados predecessores da Lógica Paraconsistente, batizada inclusive como Lógica"}
{"source": "Rede neural artificial", "chunk_id": "Rede neural artificial_8", "text": "polonês Jan Łukasiewicz Lvov, nascido em 1878, e do filósofo russo Nicolai Alexandrovich Vasilév, nascido em 1910, considerados predecessores da Lógica Paraconsistente, batizada inclusive como Lógica Imaginária. Em 1949 Hebb introduziu a capacidade de aprender através de seu livro \"The Organization of Behavior\". Hebb descreveu um sistema de aprendizado por correlação dos neurônios que acabou dando origem à Regra de Aprendizagem de Hebb e essa teoria é comumente evocada para explicar alguns tipos de aprendizagem associativos no qual a ativação simultânea de células leva a um crescimento pronunciado na força sináptica. Tal aprendizado é conhecido como aprendizagem hebbiana. Em 1951, foi construído o primeiro neuro computador denominado Snark, por Mavin Minsky. O Snark operava com sucesso a partir de um ponto de partida técnico, ajustando seus pesos automaticamente, entretanto, ele nunca executou qualquer função de processamento de informação interessante, mas serviu de inspiração para"}
{"source": "Rede neural artificial", "chunk_id": "Rede neural artificial_9", "text": "partir de um ponto de partida técnico, ajustando seus pesos automaticamente, entretanto, ele nunca executou qualquer função de processamento de informação interessante, mas serviu de inspiração para as ideias de estruturas que o sucederam. O livro de Ashby (Design for a Brain: The Origin of Adaptive Behavior) que foi publicado em 1952 trata do conhecimento básico de que o comportamento adaptativo não nasce com o indivíduo, mas sim é aprendido, e que através da aprendizagem o animal (sistema) normalmente muda seu comportamento para melhor. São enfatizados neste livro os aspectos dinâmicos do organismo vivo como uma máquina e o conceito correlacionado de estabilidade. Gabor, um dos pioneiros da teoria da comunicação e o inventor da holografia, propôs em 1954 a ideia de um filtro adaptativo não linear. Com a ajuda de colaboradores, Gabor construiu uma máquina que alimentada com amostras de um processo estocástico, mais a função-alvo que a máquina deveria produzir, realizava a"}
{"source": "Rede neural artificial", "chunk_id": "Rede neural artificial_10", "text": "adaptativo não linear. Com a ajuda de colaboradores, Gabor construiu uma máquina que alimentada com amostras de um processo estocástico, mais a função-alvo que a máquina deveria produzir, realizava a aprendizagem. Em 1954-1955, Cragg e Tamperley observaram que os átomos em uma rede têm seus spins apontando \"para cima\" ou \"para baixo\", assim como os neurônios podem ser \"disparados\" (ativados) ou \"não disparados\" (quiescentes). Em 1956 no Darthmouth College nasceram os dois paradigmas da Inteligência Artificial, a simbólica e o conexionista. A Inteligência Artificial Simbólica tenta simular o comportamento inteligente humano desconsiderando os mecanismos responsáveis por tal. Já a Inteligência Artificial Conexionista acredita que construíndo-se um sistema que simule a estrutura do cérebro, este sistema apresentará inteligência, ou seja, será capaz de aprender, assimilar, errar e aprender com seus erros. O livro de Hebb tem sido uma fonte de inspiração para o desenvolvimento de modelos"}
{"source": "Rede neural artificial", "chunk_id": "Rede neural artificial_11", "text": "este sistema apresentará inteligência, ou seja, será capaz de aprender, assimilar, errar e aprender com seus erros. O livro de Hebb tem sido uma fonte de inspiração para o desenvolvimento de modelos computacionais de sistema adaptativos e de aprendizagem. O artigo de Rochester, Holland, Haibt e Duda (1956) talvez seja a primeira tentativa de usar simulação computacional para testar uma teoria neural bem-formulada com base no postulado de aprendizagem de Hebb (que a eficiência de uma sinapse variável entre dois neurônios é aumentada pela ativação repetida de um neurônio causada pelo outro neurônio). Naquele mesmo ano Uttley (1956) demonstrou que uma rede neural com sinapses modificáveis pode aprender a classificar conjuntos simples de padrões binários em classes correspondentes. Em 1957 Rosenblatt inicia testes simulados em um computador IBM 704 no Laboratório da Aeronáutica de Cornell. Pelo estudo de redes neurais, como a Perceptron, Rosenblatt esperava que as leis fundamentais da"}
{"source": "Rede neural artificial", "chunk_id": "Rede neural artificial_12", "text": "Rosenblatt inicia testes simulados em um computador IBM 704 no Laboratório da Aeronáutica de Cornell. Pelo estudo de redes neurais, como a Perceptron, Rosenblatt esperava que as leis fundamentais da organização que são comuns a todos os sistemas de informação de movimentação, máquinas e homens incluídos, pudesse eventualmente ser compreendida. Em 1958, Frank Rosenblatt criou o Perceptron, um modelo cognitivo que consistia de unidades sensoriais conectadas a uma única camada de neurônios de Warren McCulloch e Pitts, capaz de aprender tudo o que pudesse representar. Rosenblatt demonstrou que, se fossem acrescidas sinapses ajustáveis, as redes neurais de Warren McCulloch e Pitts poderiam ser treinadas para classificar padrões em classes linearmente separáveis, convergindo em um número limitado de passos. Eficiência de transmissão (peso) ajustável; esta envia a resposta (saídas) para a terceira camada. O intuito de Rosenblatt era projetar RNAs que fossem capazes de fazer descobertas"}
{"source": "Rede neural artificial", "chunk_id": "Rede neural artificial_13", "text": "de passos. Eficiência de transmissão (peso) ajustável; esta envia a resposta (saídas) para a terceira camada. O intuito de Rosenblatt era projetar RNAs que fossem capazes de fazer descobertas interessantes sem a necessidade de regras, o que, aliás, continua sendo alvo dos pesquisadores. No início da década de 1960, Widrow e Hoff publicam um artigo no qual especificam um neurônio artificial baseado no modelo de McCulloch e Pitts, denominado ADALINE. Conforme, a importância desse modelo está associada à regra de aprendizagem proposta, a regra Delta. A combinação de uma série de ADELINEs é chamada de MADALINE (Multiple Adaline) é uma de duas camadas de rede neural com um conjunto de ADALINEs. Widrow também fundou a primeira companhia de hardware de neurocomputadores e componentes. Em 1967, Cowan caracterizou o disparo \"sigmóide\" e a condição de disparo suave para um neurônio baseando-se na função logística. Em 1967-1968, Grossberg envolvendo equações não-lineares de"}
{"source": "Rede neural artificial", "chunk_id": "Rede neural artificial_14", "text": "Em 1967, Cowan caracterizou o disparo \"sigmóide\" e a condição de disparo suave para um neurônio baseando-se na função logística. Em 1967-1968, Grossberg envolvendo equações não-lineares de diferenças/diferenciais introduziu o modelo aditivo de um neurônio e como base para a memória de curto prazo explorou o uso do modelo. A publicação de Perceptrons de Minsky e Papert, em 1969, expôs as limitações do modelo de Rosenblatt, provando que tais redes não são capazes de resolver uma ampla classe de problemas devido às restrições de representação. O impacto desta publicação foi devastador, praticamente desaparecendo o interesse em redes neurais artificiais nos anos seguintes, somente poucos pesquisadores como Malsburg, Grossberg, Kohonen e Anderson permaneceram concentrando suas atividades na abordagem conexionista. Nos anos 70, não ocorreram grandes progressos nos estudos de redes neurais devido um entusiasmo exagerado de muitos pesquisadores, que passaram a publicar mais e mais artigos e"}
{"source": "Rede neural artificial", "chunk_id": "Rede neural artificial_15", "text": "conexionista. Nos anos 70, não ocorreram grandes progressos nos estudos de redes neurais devido um entusiasmo exagerado de muitos pesquisadores, que passaram a publicar mais e mais artigos e livros que faziam uma previsão pouco confiável para a época, sobre máquinas tão poderosas quanto o cérebro humano que surgiriam em um curto espaço de tempo. Isto tirou quase toda a credibilidade dos estudos desta área e causou grandes aborrecimentos aos técnicos de outras áreas. Dentre os poucos pesquisadores que continuaram trabalhando na área, destacam-se: Igor Aleksander, Inglaterra: redes sem pesos; Kunihiko Fukushima, Japão: cognitron e neocognitron; Steven Grossberg, Estados Unidos: sistemas auto-adaptativos; Teuvo Kohonen, Finlândia: memórias associativas e auto-organizadas. No ano de 1970 a Universidade de Michigan foi palco para as pesquisas de vida artificial, J. Holland foi o primeiro pesquisador a conseguir o título de PhD em Ciência da Computação. Ele e T. Toffoli foram atraidos pela"}
{"source": "Rede neural artificial", "chunk_id": "Rede neural artificial_16", "text": "de Michigan foi palco para as pesquisas de vida artificial, J. Holland foi o primeiro pesquisador a conseguir o título de PhD em Ciência da Computação. Ele e T. Toffoli foram atraidos pela ideia de comportamento adaptativo onde envolvia biologia, computadores e informação, se tornaram associados em algoritmos genéricos e autômatos celulares, respectivamente. Toffoli sempre se preocupou em criar a conexão do mundo físico com o autômato. Em 1972 foi introduzido de forma independente por Amari o modelo aditivo de um neurônio para estudar o comportamento dinâmico de elementos semelhantes a neurônios conectados aleatoriamente. Ainda em 1972, Wilson e Cowan derivaram equações diferenciais não-lineares acopladas correspondentes à dinâmica de populações localizadas no espaço, contendo neurônios tanto excitadores como inibitórios. - 1974: WERBOS lançou bases para o algoritmo de retropropagação (backpropagation). Em 1975, Little e Shaw descreveram e usaram o modelo probabilístico de um"}
{"source": "Rede neural artificial", "chunk_id": "Rede neural artificial_17", "text": "tanto excitadores como inibitórios. - 1974: WERBOS lançou bases para o algoritmo de retropropagação (backpropagation). Em 1975, Little e Shaw descreveram e usaram o modelo probabilístico de um neurônio, disparando ou não um potencial de ação, para desenvolver uma teoria da memória de curto prazo. Em 1977, Andereson, Silverstein, Ritz e Jones, sugeriram o modelo do estado cerebral em uma caixa (BSB, brain-state-in-a-box), compondo-se de uma rede associativa simples acoplada a uma dinâmica não-linear. A partir dos anos 80, com o avanço da tecnologia e o fracasso da escola simbolista na solução de determinados tipos de problemas, as redes neurais artificiais passaram a atrair substancial atenção novamente, as pesquisas na área foram retomadas com força. A nova explosão de interesse pelas redes neurais artificiais na comunidade científica foi impulsionada, principalmente, pelo avanço da tecnologia (especialmente da microeletrônica) e também pelo impacto causado pelo artigo publicado por"}
{"source": "Rede neural artificial", "chunk_id": "Rede neural artificial_18", "text": "neurais artificiais na comunidade científica foi impulsionada, principalmente, pelo avanço da tecnologia (especialmente da microeletrônica) e também pelo impacto causado pelo artigo publicado por John Hopfield em 1982, no qual chamou a atenção para as propriedades associativas das RNAs. Hopfield mostrou a relação entre redes recorrentes autoassossiativas e sistemas físicos, abrindo espaço para a utilização de teorias correntes da Física para estudar tais modelos. Em 1982, a introdução do modelo conexionista conhecido pelo nome de seu idealizador, John Hopfield, permitiu esclarecer, pelas suas características computacionais e estabilidade, boa parte das dúvidas até então existentes em relação ao processo dinâmico executado por certas redes neurais. No mesmo ano, Teuvo Kohonen publicou um artigo descrevendo uma rede neural artificial baseada em auto-organização e nas características de aprendizado adaptativo do cérebro humano. Hinton e Seynowsky, em 1983, estenderam o modelo de Hopfield"}
{"source": "Rede neural artificial", "chunk_id": "Rede neural artificial_19", "text": "descrevendo uma rede neural artificial baseada em auto-organização e nas características de aprendizado adaptativo do cérebro humano. Hinton e Seynowsky, em 1983, estenderam o modelo de Hopfield com a incorporação de dinâmica estocástica. Este modelo de rede neural passou a ser conhecido como Máquina de Boltzmann. Porém talvez o fato mais importante deste período tenha ocorrido quando Ira Skurnick, um administrador de programas da DARPA (Defense Advanced Research Projects Agency) decidiu ouvir os argumentos da neuro computação e seus projetistas, e divergindo dos caminhos tradicionais dos conhecimentos convencionais, fundou em 1983 pesquisas em neuro computação. Este ato não só abriu as portas para a neuro computação, como também deu à DARPA o status de uma das líderes mundiais em se tratando de \"moda\" tecnológica. Em meados da década de 1980 surgiu a descrição do algoritmo de treinamento backpropagation (Rumelhart, Hinton, & Williams 1986).O termo backpropagation surge do fato que o"}
{"source": "Rede neural artificial", "chunk_id": "Rede neural artificial_20", "text": "de \"moda\" tecnológica. Em meados da década de 1980 surgiu a descrição do algoritmo de treinamento backpropagation (Rumelhart, Hinton, & Williams 1986).O termo backpropagation surge do fato que o algoritmo se baseia na retropropagação dos erros para realizar os ajustes de pesos das camadas intermediárias. A maneira de calcular as derivadas parciais do erro de saída em relação a cada um dos pesos da rede é o que caracteriza o backpropagation. Com isso o algoritmo backpropagation foi aplicado em vários problemas, como na identificação da estrutura de proteínas, hifenização de palavras em inglês, reconhecimento da fala, compressão de imagens e previsão de séries temporais. O sucesso deste algoritmo estimulou o desenvolvimento de muitas pesquisas em redes neurais artificiais e de uma variedade de modelos cognitivos. Após a publicação em 1986 do hoje clássico Parallel Distributed Processing, editado por Rumerlhart e McClelland do PDP Research Group da Universidade da Califórnia em San"}
{"source": "Rede neural artificial", "chunk_id": "Rede neural artificial_21", "text": "de modelos cognitivos. Após a publicação em 1986 do hoje clássico Parallel Distributed Processing, editado por Rumerlhart e McClelland do PDP Research Group da Universidade da Califórnia em San Diego, a área de redes neurais teve um desenvolvimento explosivo com a multiplicação exponencial de Journal's, associação locais e internacionais, sem falar da torrente de teses e paper's científicos. No começo desta década surgiram várias empresas para a exploração comercial de produtos de redes neurais, invariavelmente produtos de software para o desenvolvimento de aplicações ou simulação acadêmicas Em 1987 ocorreu em São Francisco a primeira conferência de redes neurais em tempos modernos, a IEEE International Conference on Neural Networks, e também foi formada a International Neural Networks Society (INNS). A partir destes acontecimentos decorreram a fundação do INNS journal em 1989, seguido do Neural Computation e do IEEE Transactions on Neural Networks em 1990. As redes neurais"}
{"source": "Rede neural artificial", "chunk_id": "Rede neural artificial_22", "text": "Society (INNS). A partir destes acontecimentos decorreram a fundação do INNS journal em 1989, seguido do Neural Computation e do IEEE Transactions on Neural Networks em 1990. As redes neurais artificiais (RNA) têm muitas vantagens, porque se baseiam na estrutura do sistema nervoso humano, principalmente o cérebro. Sua Aprendizagem: as RNAs têm a capacidade de aprender através de uma fase chamada fase de aprendizagem. Trata-se de fornecer dados como entrada RNA, por sua vez, informando qual é a saída (resposta) que é esperada. Auto-organização: uma RNA cria sua própria representação de informação no seu interior, descarregando ao usuário isto. Tolerância a falhas: Como uma RNA armazena informações de forma redundante, pode continuar a responder de uma forma aceitável, mesmo que esteja parcialmente danificada. Flexibilidade: Uma rede neural pode lidar com grandes mudanças na informação de entrada, tais como sinais ruidosos ou outras alterações na entrada (por exemplo, se a informação de"}
{"source": "Rede neural artificial", "chunk_id": "Rede neural artificial_23", "text": "danificada. Flexibilidade: Uma rede neural pode lidar com grandes mudanças na informação de entrada, tais como sinais ruidosos ou outras alterações na entrada (por exemplo, se a informação de entrada é a imagem de um objeto, a correspondente resposta mantém-se inalterada, mesmo se a imagem muda um pouco de brilho ou o objeto muda um pouco de formato). Real Time: A estrutura de uma RNA é paralela, de modo que se for implementado com computadores ou dispositivos eletrônicos especiais, podem obter respostas em tempo real. Os neurônios de uma RNAs devem estar conectados entre si, são dispostos em camadas, e os neurônios de uma mesma camada normalmente se comportam da mesma maneira. A disposição dos neurônios nas camadas e o padrão de conexão entre estas definem a arquitetura da RNA. As redes sem realimentação (feedforward) têm neurônios agrupados em camadas. O sinal percorre a rede em uma única direção, da entrada para a saída. Os neurônios da mesma camada não são conectados. Nas redes"}
{"source": "Rede neural artificial", "chunk_id": "Rede neural artificial_24", "text": "sem realimentação (feedforward) têm neurônios agrupados em camadas. O sinal percorre a rede em uma única direção, da entrada para a saída. Os neurônios da mesma camada não são conectados. Nas redes com realimentação ou recorrentes (recurrent), a saída de alguns neurônios alimentam neurônios da mesma camada (inclusive o próprio) ou de camadas anteriores. O sinal percorre a rede em duas direções, tem memória dinâmica e capacidade de representar estados em sistemas dinâmicos. Um exemplo é a rede de Hopfield. Uma típica rede neural feedforward é um conjunto de nós. Alguns desses estão na camada de entrada, alguns nós na camada de saída, e os outros estão nas camadas intermediárias/escondidos. Cada conexão entre os neurônios tem um peso numérico. Quando a rede estiver em operação, o valor será aplicado a cada nó de entrada - os valores que estão sendo alimentados por um operador humano, a partir de sensores ambientais, ou de algum programa externo. Cada nó passa então o valor dado às"}
{"source": "Rede neural artificial", "chunk_id": "Rede neural artificial_25", "text": "será aplicado a cada nó de entrada - os valores que estão sendo alimentados por um operador humano, a partir de sensores ambientais, ou de algum programa externo. Cada nó passa então o valor dado às conexões que levam para fora dela, e em cada conexão o valor é multiplicado pelo peso associado a esse respeito. Cada nó na camada seguinte então recebe um valor que é a soma dos valores produzidos pelas conexões que levam até ele, e em cada nó um simples cálculo é realizado sobre o valor - uma função sigmóide é típica. Este processo é repetido então com os resultados sendo passados através de camadas subsequentes de nós até que os nós de saída são alcançados. Os primeiros modelos tiveram um número fixo de camadas. Mais recentemente, os algoritmos genéticos são usados para desenvolver a estrutura neural. A curva sigmóide é frequentemente utilizada como uma função de transferência, porque introduz a não-linearidade em rede cálculos da por \"esmagamento\" de ativação do neurônio de nível para"}
{"source": "Rede neural artificial", "chunk_id": "Rede neural artificial_26", "text": "neural. A curva sigmóide é frequentemente utilizada como uma função de transferência, porque introduz a não-linearidade em rede cálculos da por \"esmagamento\" de ativação do neurônio de nível para o intervalo [0,1]. A função sigmóide tem a vantagem adicional de ter uma função extremamente simples derivado, tal como exigido para a parte traseira de propagação de erros através de uma rede neural feed-forward. Outras funções com características semelhantes podem ser utilizados, mais comumente tanh que comprime as ativações para o intervalo de [-1,1] em vez disso, ou, ocasionalmente, uma função linear por partes que pode ser encaixada a ativação, em vez de o esmagar. Se nenhuma não-linearidade é introduzida por esmagamento ou corte, a rede perde muito do seu poder computacional, tornando-se uma operação de multiplicação matriz simples de álgebra linear . modelos alternativos de cálculo nas redes neurais incluem modelos com alças, onde algum tipo de processo demora tempo deve ser usado, e"}
{"source": "Rede neural artificial", "chunk_id": "Rede neural artificial_27", "text": "operação de multiplicação matriz simples de álgebra linear . modelos alternativos de cálculo nas redes neurais incluem modelos com alças, onde algum tipo de processo demora tempo deve ser usado, e \"o vencedor leva todos os modelos\", onde o neurônio com o maior valor desde o cálculo incêndios e assume um valor 1, e todos os outros neurônios tomam o valor 0. Normalmente, os pesos em uma rede neural são ajustados inicialmente para pequenos valores aleatórios. Isto representa a rede sem saber nada, sua saída é essencialmente uma função de reprodução aleatória de sua entrada. Como o produto processo de treinamento, os pesos de conexão são gradualmente modificados de acordo com as regras computacionais específicos para o algoritmo de aprendizagem a ser utilizado. Idealmente, os pesos eventualmente convergir para os valores que lhes permitam executar uma computação útil. Assim, pode-se dizer que a rede neural começa sabendo nada e move-se para ganhar algum conhecimento real, embora o"}
{"source": "Rede neural artificial", "chunk_id": "Rede neural artificial_28", "text": "convergir para os valores que lhes permitam executar uma computação útil. Assim, pode-se dizer que a rede neural começa sabendo nada e move-se para ganhar algum conhecimento real, embora o conhecimento é sub-simbólico. As redes neurais são particularmente úteis para lidar com delimitadas de valor real de dados , onde uma saída de valor real é desejado; desta maneira as redes neurais irão realizar a classificação por graus, e são capazes de expressar valores equivalentes a \"não sabe\". Se a rede neural é treinada usando a função de erro de entropia cruzada e se a saída da rede neural é sigmoidal, então as saídas serão estimativas da probabilidade posterior real de uma classe. O aprendizado consiste na modificação dos pesos das conexões entre os neurônios, os pesos iniciais (sinapses) são modificados de forma iterativa, por um algoritmo que segue um dos seguintes paradigmas de aprendizado: Aprendizado Supervisionado: é apresentado um conjunto de treino, consistindo de entradas e"}
{"source": "Rede neural artificial", "chunk_id": "Rede neural artificial_29", "text": "são modificados de forma iterativa, por um algoritmo que segue um dos seguintes paradigmas de aprendizado: Aprendizado Supervisionado: é apresentado um conjunto de treino, consistindo de entradas e correspondentes saídas desejadas. Aprendizado por Reforço: para cada entrada apresentada, é produzida uma indicação (reforço) sobre a adequação das saídas correspondentes produzidas pela rede. Aprendizado Não-supervisionado: A rede atualiza seus pesos sem o uso de pares entrada-saídas desejadas e sem indicações sobre a adequação das saídas produzidas. As redes neurais artificiais são um método para solucionar problemas através da simulação do cérebro humano, inclusive em seu comportamento, ou seja, aprendendo, errando e fazendo descobertas. São técnicas computacionais que apresentam um modelo inspirado na estrutura neural de organismos inteligentes e que adquirem conhecimento através da experiência. As redes neurais possuem nós ou unidades de processamento. Cada unidade possui ligações para"}
{"source": "Rede neural artificial", "chunk_id": "Rede neural artificial_30", "text": "na estrutura neural de organismos inteligentes e que adquirem conhecimento através da experiência. As redes neurais possuem nós ou unidades de processamento. Cada unidade possui ligações para outras unidades, nas quais recebem e enviam sinais. Cada unidade pode possuir memória local. Essas unidades são a simulação dos neurônios, recebendo e retransmitindo informações. Somam-se as entradas e se retorna uma saída, caso esta seja maior que o valor da soma. Uma rede neural pode possuir uma ou múltiplas camadas. Exemplificando com três camadas, poderíamos ter a camada de entrada, em que as unidades recebem os padrões; a camada intermediária, onde é feito processamento e a extração de características; e a camada de saída, que conclui e apresenta o resultado final. Quanto maior o número de camadas, melhor a capacidade de aprendizado. A camada de entrada deve possuir uma unidade especial conhecida como bias, usada para aumentar os graus de liberdade, permitindo uma melhor adaptação, por parte"}
{"source": "Rede neural artificial", "chunk_id": "Rede neural artificial_31", "text": "melhor a capacidade de aprendizado. A camada de entrada deve possuir uma unidade especial conhecida como bias, usada para aumentar os graus de liberdade, permitindo uma melhor adaptação, por parte da rede neural, ao conhecimento a ela fornecido. Em termos mais técnicos, o número de camadas define a capacidade de representação das relações entre o espaço de entrada e o de saída. A inexistência da camada intermediária, característica do modelo perceptron, condiciona-o a representar bem somente relações linearmente independentes. A existência de camadas intermediárias, característica do modelo perceptron de múltipla camada (PMC), retira tal limitação. Se houver apenas uma camada intermediária, o PMC pode representar (com qualquer grau de aproximação, por menor que seja) qualquer função contínua. Duas ou mais camadas ampliam o universo de representação a qualquer função, contínua ou não. As redes neurais artificiais, seguindo a tradição estadunidense, estão muito associadas à adaptação de"}
{"source": "Rede neural artificial", "chunk_id": "Rede neural artificial_32", "text": "Duas ou mais camadas ampliam o universo de representação a qualquer função, contínua ou não. As redes neurais artificiais, seguindo a tradição estadunidense, estão muito associadas à adaptação de conexões (sinapses) entre neurônios, o conexionismo. Cabe registrar, entretanto, a existência de modelos nos quais as conexões não são adaptadas, mas apenas transmitem estimulação entre neurônios. Tais modelos são chamados redes neurais sem pesos (do inglês, weightless neural networks). Para completar, há modelos em que as sinapses não são adaptadas, mas calculadas previamente, servindo a tarefas de otimização, geralmente. Podemos classificar as RNAs segundo suas capacidades de processar diferentes tipos de informações como: Redes analógicas: processam dados de entrada com valores contínuos e, geralmente limitados. Exemplo deste tipo de rede são: Hopfield, Kohonen e as redes de aprendizagem competitivo. Redes discretas: processam dados de entrada de natureza discreta, geralmente valores"}
{"source": "Rede neural artificial", "chunk_id": "Rede neural artificial_33", "text": "e, geralmente limitados. Exemplo deste tipo de rede são: Hopfield, Kohonen e as redes de aprendizagem competitivo. Redes discretas: processam dados de entrada de natureza discreta, geralmente valores lógicos booleanos. Exemplo deste segundo tipo de rede são as máquinas de Boltzmann e Cauchy, e a rede discreta de Hopfield. A maior parte dos investigadores concorda em que as redes neurais são muito diferentes do cérebro em termos de estrutura. No entanto, como o cérebro, uma rede neural é uma coleção massivamente paralela de unidades de processamento pequenas e simples, onde as interligações formam a maior parte da inteligência da rede. Entretanto, em termos de escala, o cérebro é muito maior que qualquer rede neural. Além disso, as unidades usadas na rede neural são tipicamente muito mais simples que os neurônios e o processo de aprendizado do cérebro (embora ainda desconhecido) é, certamente, muito diferente do das redes neurais. Uma rede neural pró-alimentada (em contraposição à"}
{"source": "Rede neural artificial", "chunk_id": "Rede neural artificial_34", "text": "simples que os neurônios e o processo de aprendizado do cérebro (embora ainda desconhecido) é, certamente, muito diferente do das redes neurais. Uma rede neural pró-alimentada (em contraposição à retroalimentada) típica consiste de um conjunto de nós em que alguns desses nós são designados nós de entrada, outros nós de saída e aqueles que estão entre esses dois tipos de nós são chamados de nós escondidos. Existem também conexões entre os neurônios, com um número referido como um ponderador associado a cada conexão. Quando a rede está em operação, um valor de entrada será aplicado a cada nó de entrada - esses valores são colocados por um operador humano ou por sensores ambientais, ou talvez por outros programas. Cada nó então passa seu dado valor para as conexões que saem dele e em cada conexão o valor é multiplicado por um ponderador associado a essa conexão. Cada nó na camada seguinte recebe um valor, que é a soma dos valores produzidos pelas conexões que chegam até ele, e em cada nó"}
{"source": "Rede neural artificial", "chunk_id": "Rede neural artificial_35", "text": "o valor é multiplicado por um ponderador associado a essa conexão. Cada nó na camada seguinte recebe um valor, que é a soma dos valores produzidos pelas conexões que chegam até ele, e em cada nó é realizada uma computação simples sobre esse valor - uma função sigmóide é típica nesse caso. O processo então é repetido com os resultados sendo passados através de camadas subseqüentes de nós, até que os nós de resultados sejam atingidos. Isso é baseado em um modelo de neurônio da década de 1970. Os modelos alternativos de cálculo nas redes neurais incluem aqueles dotados de laços (nos quais algum tipo de processo de retardamento de tempo precisa ser usado) e os modelos o \"vencedor leva tudo\", nos quais o neurônio com os valores mais altos dispara e toma o valor 1 e todos os outros neurônios tomam o valor 0. Tipicamente, os ponderadores em uma rede neural são colocados inicialmente em valores aleatórios pequenos; isso significa que a rede não sabe nada. À medida que o processo de"}
{"source": "Rede neural artificial", "chunk_id": "Rede neural artificial_36", "text": "tomam o valor 0. Tipicamente, os ponderadores em uma rede neural são colocados inicialmente em valores aleatórios pequenos; isso significa que a rede não sabe nada. À medida que o processo de treinamento acontece, esses ponderadores irão convergir para valores que permitem que eles realizem uma computação útil. Assim, pode ser dito que uma rede neural começa sabendo nada e move-se no sentido de ganhar algum conhecimento real. As redes neurais são particularmente úteis para lidar com dados ligados a valores reais em que se deseja obter uma saída dotada de valor real. Dessa maneira, as redes neurais irão realizar uma classificação por graus e serão capazes de expressar valores equivalentes a \"não conhecido com certeza\". Se uma rede neural é treinada usando a função de erro de entropia cruzada e se a saída dessa rede neural tem uma forma sigmoidal não-linear, então as saídas serão estimativas de uma probabilidade posterior real de uma classe. Em aplicações reais, as redes neurais se saem"}
{"source": "Rede neural artificial", "chunk_id": "Rede neural artificial_37", "text": "e se a saída dessa rede neural tem uma forma sigmoidal não-linear, então as saídas serão estimativas de uma probabilidade posterior real de uma classe. Em aplicações reais, as redes neurais se saem particularmente bem nas seguintes tarefas: aproximação de funções; previsão de séries temporais; classificações; reconhecimento de padrões. Outros tipos de redes neurais, em particular redes neurais recorrentes de tempo contínuo (CTRNN), são usadas em conjunto com algoritmos genéticos para produzir controladores robóticos. O genoma é então constituído dos parâmetros de rede e a aptidão de uma rede é a adequação do comportamento exibido pelo robô controlado (ou freqüentemente por uma simulação desse comportamento). O exemplo mais antigo de redes neurais são as redes perceptron, com uma camada de nós de saída, conectados às entradas por conjuntos de pesos. Essa topologia pode ser considerada a forma mais simples de rede em avanço. A soma do produtos dos pesos pelas entradas é calculada por"}
{"source": "Rede neural artificial", "chunk_id": "Rede neural artificial_38", "text": "de nós de saída, conectados às entradas por conjuntos de pesos. Essa topologia pode ser considerada a forma mais simples de rede em avanço. A soma do produtos dos pesos pelas entradas é calculada por cada nó de saída e, se o valor calculado ultrapassar um certo limiar (geralmente 0), o neurônio dispara e ajusta a saída para o valor 1; se o valor calculado é menor que o limiar, a saída é ajustada para o valor -1. Neurônios com esse comportamento são chamados de neurônios de McCulloch-Pitts ou neurônios com limiar. Ao mesmo tempo, um algoritmo de aprendizado calcula a diferença entre a saída calculada e os dados de entrada e usa o valor da diferença para ajustar os pesos da rede. Um exemplo mais contemporâneo de redes neurais são a família de Células Neurais Artificiais Paraconsistentes - CNAP’s: CNAPba, CNAPcls, CNAPclse, CNAPp, CNAPco, CNAPd, CNAPap, CNAPa, CNAPm. Célula Neural Artificial Paraconsistente Básica - CNAPba : temos três saídas (outputs) possíveis: F-Falso V-Verdadeiro"}
{"source": "Rede neural artificial", "chunk_id": "Rede neural artificial_39", "text": "- CNAP’s: CNAPba, CNAPcls, CNAPclse, CNAPp, CNAPco, CNAPd, CNAPap, CNAPa, CNAPm. Célula Neural Artificial Paraconsistente Básica - CNAPba : temos três saídas (outputs) possíveis: F-Falso V-Verdadeiro I-Indefinido. Célula Neural Artificial Paraconsistente de Conexão Lógica Simples - CNAPcls : esta Célula tem a função de fazer a análise lógica dos sinais através da maximização e da minimização. Célula Neural Artificial Paraconsistente de Conexão Lógica Seletiva - CNAPclse: esta célula tem duas entradas e duas saídas distintas. A função desta Célula é fazer a análise lógica dos sinais utilizando conectivos lógicos como o de maximização e o de minimização e, simultaneamente, ir selecionando quais das duas saída deve ficar ativa. Célula Neural Artificial Paraconsistente de Passagem – CNAPp : esta célula tem a função de direcionar o fluxo de informações para determinada região da rede. Célula Neural Artificial Paraconsistente de Complementação – CNAPco : esta célula tem a função de fazer a"}
{"source": "Rede neural artificial", "chunk_id": "Rede neural artificial_40", "text": "célula tem a função de direcionar o fluxo de informações para determinada região da rede. Célula Neural Artificial Paraconsistente de Complementação – CNAPco : esta célula tem a função de fazer a complementação do valor em relação à unidade a qualquer sinal aplicado na sua entrada. Célula Neural Artificial Paraconsistente de decisão – CNAPd : esta célula tem a função de fazer a análise paraconsistente e determinar uma decisão baseada nos resultados da análise. A decisão vem na forma de três estados lógicos: Verdadeiro, Falso ou Indefinido. Célula Neural Artificial Paraconsistente de aprendizagem – CNAPap : Uma CNAPap constrói-se a partir de uma Célula Neural Artificial Paraconsistente Básica – CNAPba. Sua função é dupla: ela serve como partes de unidades de memórias ou como sensores de padrões em camadas primárias. Uma CNAPap é uma Célula Neural Artificial Paraconsistente de conexão analítica CNAPca com sua saída interligada à entrada do grau de evidência contrária. Em um processo de"}
{"source": "Rede neural artificial", "chunk_id": "Rede neural artificial_41", "text": "em camadas primárias. Uma CNAPap é uma Célula Neural Artificial Paraconsistente de conexão analítica CNAPca com sua saída interligada à entrada do grau de evidência contrária. Em um processo de treinamento, inicialmente, considera-se uma CNAPca sem os fatores de tolerância e que não sofreu nenhum processo de aprendizagem. Célula Neural Artificial Paraconsistente de aprendizagem – CNAPa: esta Célula tem a função de aprender e desaprender padrões que sejam aplicados repetitivamente na sua entrada. Célula Neural Artificial Paraconsistente de memorização – CNAPm : esta Célula tem a função de guardar os padrões (verdade e falsidade) aprendidos pela célula de aprendizagem num processo de funcionamento de aprendizagem/memorização. Perceptrons podem ser treinados por um algoritmo de aprendizagem simples, chamado geralmente de regra-delta. Esse algoritmo calcula os erros entre a saída dos dados calculados e a saída desejada e utiliza isso para ajustar os pesos, assim executando um formulário"}
{"source": "Rede neural artificial", "chunk_id": "Rede neural artificial_42", "text": "simples, chamado geralmente de regra-delta. Esse algoritmo calcula os erros entre a saída dos dados calculados e a saída desejada e utiliza isso para ajustar os pesos, assim executando um formulário da descida do gradiente. Os perceptrons de uma camada são capazes de aprender somente sobre problemas linearmente separáveis (que podem ser separados por uma reta em um hiperplano). Em 1969, na famosa monografia Perceptrons por Marvin Minsky e por Seymour Papert, mostrou-se que era impossível para uma única rede do perceptron da camada aprender uma função de XOR. Conjecturou-se (incorretamente) que um resultado similar penderia para uma rede multicamadas do perceptron. Embora uma única unidade do ponto inicial fosse completamente limitada em seu poder computacional, mostrou-se que as redes de unidades paralelas do ponto inicial podem aproximar toda a função contínua de um intervalo compacto dos números reais no intervalo [- 1, 1 ]. Esta classe de rede consiste de múltiplas camadas de"}
{"source": "Rede neural artificial", "chunk_id": "Rede neural artificial_43", "text": "de unidades paralelas do ponto inicial podem aproximar toda a função contínua de um intervalo compacto dos números reais no intervalo [- 1, 1 ]. Esta classe de rede consiste de múltiplas camadas de unidades computacionais, geralmente interconectadas em uma forma de alimentação avante. Isso quer dizer que cada neurônio em uma camada tem conexões diretas a neurônios da próxima camada. Em muitas aplicações, as unidades dessas redes utilizam uma função sigmóide (em forma de S) como a função de ativação. O teorema de aproximação universal dita que toda função contínua que mapeia intervalos de números reais de entrada a algum intervalo de números reais de saída pode ser arbitrariamente aproximada com precisão por um perceptron multicamadas com somente uma camada oculta. Esse resultado só é válido para classes restritas de funções de ativação, por exemplo, funções sigmóides. As redes multicamadas podem usar um grande número de técnicas de aprendizado, sendo que a mais popular é a propagação"}
{"source": "Rede neural artificial", "chunk_id": "Rede neural artificial_44", "text": "para classes restritas de funções de ativação, por exemplo, funções sigmóides. As redes multicamadas podem usar um grande número de técnicas de aprendizado, sendo que a mais popular é a propagação reversa. Nesse caso, os valores de saída são comparados com a resposta correta para computar o valor de alguma função de erro pré-definida. Por alguma técnica, o erro é então alimentado de volta na rede. Usando essa informação, o algoritmo ajusta os pesos de cada conexão para reduzir o valor da função de erro. Cada uma das camadas de uma rede neural Função de base radial (Radial Basis Function) executa um papel específico. A camada inicial de processamento, cujos neurônios utilizam funções RBF, agrupa os dados em grupos (clusters) por meio de hiperelipsóides no espaço de entrada dos padrões da rede, diferentemente das redes neurais multicamadas que particionam o espaço de entrada através de hiperplanos. Esta camada radial transforma um conjunto de padrões de entrada não-linearmente"}
{"source": "Rede neural artificial", "chunk_id": "Rede neural artificial_45", "text": "da rede, diferentemente das redes neurais multicamadas que particionam o espaço de entrada através de hiperplanos. Esta camada radial transforma um conjunto de padrões de entrada não-linearmente separáveis em um conjunto de saídas linearmente separáveis. A camada seguinte da rede RBF, que utiliza funções lineares, classifica os padrões recebidos da camada anterior. ART são as siglas em inglês de Teoria da Ressonância Adaptativa (Adaptive Resonance Theory), desenvolvida inicialmente por Stephen Grossberg, em 1976, e em publicações posteriores em parceria com Gail Carpenter (1986/87). As redes neurais artificiais ART são redes que não precisam da exposição prévia de qualquer número de elementos do conjunto de dados para o seu treinamento. A principal característica dessa família de arquiteturas é a sua capacidade para formar agrupamentos (clusters), que nos permite identificar padrões desconhecidos. Existem três modelos de redes ARTs: ART1: é capaz de aprender a categorizar padrões de"}
{"source": "Rede neural artificial", "chunk_id": "Rede neural artificial_46", "text": "é a sua capacidade para formar agrupamentos (clusters), que nos permite identificar padrões desconhecidos. Existem três modelos de redes ARTs: ART1: é capaz de aprender a categorizar padrões de entrada binários apresentados em ordem arbitrária. ART2: pode aprender a categorizar padrões de entrada analógicos ou binários. ART3 (ARTMAP): pode realizar uma busca paralela, ou teste de hipóteses, em códigos com reconhecimento distribuído. Aplicação Reconhecimento Automático de Alvos; Reconhecimento de Caracteres; Robótica; Diagnóstico Médico; Sensoriamento Remoto; Processamento de Voz; Aprendizado O algoritmo de aprendizado da rede ART 1 não é supervisionado e pode ser ativa a qualquer momento, permitindo que a rede aprenda novos padrões continuamente. Existem 2 tipos de aprendizado na rede ART 1, o aprendizado rápido e o lento. O processo de aprendizado da rede envolve 3 fases como: reconhecimento, comparação e busca. Em 1982 houve uma nova evolução nos trabalhos das redes neurais iniciado"}
{"source": "Rede neural artificial", "chunk_id": "Rede neural artificial_47", "text": "1, o aprendizado rápido e o lento. O processo de aprendizado da rede envolve 3 fases como: reconhecimento, comparação e busca. Em 1982 houve uma nova evolução nos trabalhos das redes neurais iniciado por John Hopfield, nascido em 15 de julho de 1933 é um americano Cientista mais conhecido pela invenção de uma rede neural associativa, conhecida como a Rede de Hopfield. John Hopfield publicou dois artigos que influenciaram vários pesquisadores, chamando a atenção para as propriedades associativas de uma classe de Redes Neurais. A análise é baseada na definição de “energia” da rede. É uma prova de que a rede opera minimizando esta energia quando evolui para padrões estáveis de operação. É uma memória auto-associativa. Suas entradas são valores binários. Possui uma natureza de operação assíncrona, isto é a cada instante de tempo, cada neurônio tem seu estado de ativação “avaliado” de maneira independente dos outros neurônios. É um conceito intuitivo, onde parece ser uma das funções"}
{"source": "Rede neural artificial", "chunk_id": "Rede neural artificial_48", "text": "assíncrona, isto é a cada instante de tempo, cada neurônio tem seu estado de ativação “avaliado” de maneira independente dos outros neurônios. É um conceito intuitivo, onde parece ser uma das funções primárias do cérebro, e facilmente associamos objetos, imagens e sensações a eventos com a rede Hopfield, serve para reconstituir padrões corrompidos ou incompletos, um exemplo é uma pessoa que normalmente não usa óculos escuros, com eles, mesmo assim é reconhecido, assim recuperando informações pelo conteúdo. A rede de Hopfield pode ser vista como uma memória associativa, ou uma memória endereçável por conteúdo, cuja principal função é restaurar um padrão (item de memória ) armazenado em resposta à apresentação de uma versão incompleta ou ruidosa deste padrão. A rede Hopfield foi aplicada em várias áreas, tendo um campo de utilização muito grande, umas delas foi a Identificação de alvos militares B-52, Boeing 747 e Space Shuttle, Autentição de usuários, exploração de petróleo e"}
{"source": "Rede neural artificial", "chunk_id": "Rede neural artificial_49", "text": "em várias áreas, tendo um campo de utilização muito grande, umas delas foi a Identificação de alvos militares B-52, Boeing 747 e Space Shuttle, Autentição de usuários, exploração de petróleo e determinação e litologia, Predição no Mercado Financeiro, Reconhecimentos de Faces e Controle de Navegação Autônoma de Veículos ALVINN at CMU. As Redes Neurais vem sendo usadas com sucesso para determinar o rating de crédito de empresas. Como nos mostra a pesquisa de Zekic-Susac et al. 2004 que compara a eficácia de diferentes formas de determinação do crédito as Redes Neurais com Backpropagation apresentam os melhores resultados, inclusive mostrando dados e relações a respeito das empresas estudadas que não apareceram de outras formas. Um bom exemplo de uso de Redes Neurais para a determinação de rating de crédito para empresas é visto no artigo de Carling Et al. 2002 em que é feito um estudo do rating de debentures no mercado asiático. Eles usam o modelo de backpropagation e constroem a"}
{"source": "Rede neural artificial", "chunk_id": "Rede neural artificial_50", "text": "de rating de crédito para empresas é visto no artigo de Carling Et al. 2002 em que é feito um estudo do rating de debentures no mercado asiático. Eles usam o modelo de backpropagation e constroem a análise usando uma série de indicadores usados pelos especialistas em análise de crédito. As unidades em redes de Hopfield são unidades binárias do ponto inicial, isto é, as unidades fazem exame somente em dois valores diferentes para seus estados e o valor é determinado perto se ou não a entrada das unidades excede seu ponto inicial. As redes de Hopfield podem um ou outro ter as unidades que fazem exame em valores de 1 ou de -1, ou as unidades que fazem exame em valores de 1 ou de 0. Treinar uma rede de Hopfield envolve abaixar a energia dos estados que a rede se “recorde”. Isto permite que a rede sirva como um sistema da memória endereçável satisfeita, aquele é dizer, a rede convergirá a um estado “recordado” se for dado somente a parte do estado. A rede pode ser usada recuperar de uma"}
{"source": "Rede neural artificial", "chunk_id": "Rede neural artificial_51", "text": "a rede sirva como um sistema da memória endereçável satisfeita, aquele é dizer, a rede convergirá a um estado “recordado” se for dado somente a parte do estado. A rede pode ser usada recuperar de uma entrada distorcida o estado treinado que é o mais similar a essa entrada. Isto é chamado memória associativa porque recupera memórias na base da similaridade. Por exemplo, se nós treinarmos uma rede de Hopfield com cinco unidades de modo que o estado (1, 0, 1, 0, 1) seja um mínimo da energia, e nós damos à rede o estado (1, 0, 0, 0, 1) que convergirá (1, 0, 1, 0, 1). Assim, a rede está treinada corretamente quando a energia dos estados que a rede deve recordar é mínimos locais. O treinamento é de suma importância para o desempenho eficaz do mesmo Memória associativa é um meio de armazenamento e recuperação da informação por associação com outras informações. Um dispositivo de armazenamento é chamado memória associativa, se você pode recuperar informações a partir do conhecimento parcial"}
{"source": "Rede neural artificial", "chunk_id": "Rede neural artificial_52", "text": "e recuperação da informação por associação com outras informações. Um dispositivo de armazenamento é chamado memória associativa, se você pode recuperar informações a partir do conhecimento parcial do seu conteúdo, sem saber seu local de armazenamento. Às vezes também chamado de memória de conteúdo não endereçável. Os Computadores tradicionais não usam este direcionamento, se baseiam no conhecimento exato da direção (endereço) da memória em que se encontra a informacão. No entanto, o cérebro humano não funciona assim. Se nos lembrarmos do nome de uma pessoa, não seria útil determinar qual foi o nome de número 3.274 que aprendemos. Seria mais útil saber que seu nome começa e termina com 'N' e é um famoso cientista Inglês. Com essa informação, quase certamente se lembraria com sucesso de \"Newton\". Memórias associativas são uma das mais importantes redes neurais com uma vasta gama de aplicações em áreas como o acesso ao conteúdo de memória, reconhecimento de padrões e controle"}
{"source": "Rede neural artificial", "chunk_id": "Rede neural artificial_53", "text": "de \"Newton\". Memórias associativas são uma das mais importantes redes neurais com uma vasta gama de aplicações em áreas como o acesso ao conteúdo de memória, reconhecimento de padrões e controle inteligente. Uma memória associativa pode armazenar e recuperar informações quando necessário, ou seja, uma rede realimenta a saída que é usada repetidamente como uma nova entrada até que o processo termine. Você pode obter essas informações com base no conhecimento da parte dela (chave). O padrão de chave pode ser uma versão ruidosa de um padrão de memorização, ou seja, que difere em alguns componentes. A memória humana é uma reminiscência de uma pessoa, mesmo se você se veste diferente ou usa óculos. Os primeiros modelos de memórias associativas baseadas na Morfologia Matemática, referidos como Memórias Associativas Morfológicas (MAMs), foram introduzidas por Ritter e Sussner em meados dos anos 1990. Especificamente, os neurônios das MAMs efetuam generalizações das operações da abordagem"}
{"source": "Rede neural artificial", "chunk_id": "Rede neural artificial_54", "text": "Memórias Associativas Morfológicas (MAMs), foram introduzidas por Ritter e Sussner em meados dos anos 1990. Especificamente, os neurônios das MAMs efetuam generalizações das operações da abordagem umbra da morfologia matemática em tons de cinza. Em termos gerais, a principal diferença entre os modelos clássicos de memórias associativas e os modelos morfológicos está em utilizar as operações baseadas em reticulados no lugar das operações usuais de multiplicação de matrizes. O Perceptron multicamadas é um aproximador universal de funções, como provado pelo teorema de Cybenko. No entanto, a prova não é construtiva sobre o número de neurônios requeridos ou as configurações dos valores dos pesos necessárias. O trabalho de Hava Siegelmann e Eduardo D. Sontag forneceu uma prova que uma arquitetura recorrente específica com valores lógicos dos pesos tem o todo o poder de uma Máquina de Turing usando um número finito de neurônios e conexões lineares padrões. Eles mostram também que o uso de"}
{"source": "Rede neural artificial", "chunk_id": "Rede neural artificial_55", "text": "recorrente específica com valores lógicos dos pesos tem o todo o poder de uma Máquina de Turing usando um número finito de neurônios e conexões lineares padrões. Eles mostram também que o uso de valores ilógicos para os pesos resulta em uma máquina com capacidade de uma \"super\" Máquina de Turing. Modelos de RNAs tem uma propriedade chamada capacidade, a qual grosseiramente corresponde a sua habilidade de modelar qualquer função determinada. Isso está relacionado com a quantidade de informação que pode ser armazenada na rede e a noção de complexidade. No geral nada pode ser dito sobre convergência vendo que ela depende de alguns de fatores. Primeiramente, podem existir mínimos locais e isto depende da função de custo e do modelo. Em segundo lugar, o método de otimização usado pode não garantir a convergência quando estiver muito longe do mínimo local. Em terceiro lugar, para uma quantidade de dados ou parâmetros muito grande, alguns métodos se tornam impraticáveis. No geral, foi"}
{"source": "Rede neural artificial", "chunk_id": "Rede neural artificial_56", "text": "garantir a convergência quando estiver muito longe do mínimo local. Em terceiro lugar, para uma quantidade de dados ou parâmetros muito grande, alguns métodos se tornam impraticáveis. No geral, foi descoberto que garantias teóricas sobre a convergência são guias pouco confiáveis para aplicação prática. Em aplicações nas quais o objetivo é criar um sistema que generalize bem em exemplos cegos, surge o problema de excesso de treinamento. Isso acontece em sistemas complicados ou excessivamente específicos, quando a capacidade da rede excede significantemente a necessidade dos parâmetros. Há duas escolas de pensamento para evitar este problema: A primeira é o uso da validação cruzada e técnicas similares para checar a presença de excesso de treinamento e selecionar otimamente hiperparâmetros a fim de minimizar o erro de generalização. A segunda é usar alguma forma de regularização. Este conceito surge naturalmente em um quadro probabilístico (Baysiano), no qual a regularização pode ser"}
{"source": "Rede neural artificial", "chunk_id": "Rede neural artificial_57", "text": "a fim de minimizar o erro de generalização. A segunda é usar alguma forma de regularização. Este conceito surge naturalmente em um quadro probabilístico (Baysiano), no qual a regularização pode ser feita selecionando uma maior probabilidade anterior em relação a modelos mais simples; mas também no aprendizado estatístico teórico, no qual o objetivo é minimizar até duas quantidades: o 'risco empírico' e o 'risco estrutural', o qual corresponde ao erro sobre o conjunto de treinamento e o erro previsto em dados cegos. Redes neurais supervisionadas que usam uma função de custo de erro médio quadrático podem usar métodos estatísticos formais para determinar a confiança do modelo treinado. O erro médio quadrático em um conjunto de validação pode ser usado como uma estimativa para variação. Este valor pode então ser usado para calcular o intervalo de confiança de uma saída na rede neural, assumindo a distribuição normal. A análise da confiança feita desta maneira é estatisticamente válida"}
{"source": "Rede neural artificial", "chunk_id": "Rede neural artificial_58", "text": "valor pode então ser usado para calcular o intervalo de confiança de uma saída na rede neural, assumindo a distribuição normal. A análise da confiança feita desta maneira é estatisticamente válida enquanto a distribuição probabilística da saída se mantiver a mesma e a rede neural não modificada. Assumindo a função de ativação softmax na camada de saída da rede neural para variáveis categóricas alvos, a saída pode ser interpretada como probabilidades posteriores. Isso é muito útil na classificação, pois dá uma medida de certeza sobre as classificações. função de ativação softmax: y i = e x i ∑ j = 1 c e x j {\\displaystyle y_{i}={\\frac {e^{x_{i}}}{\\sum _{j=1}^{c}e^{x_{j}}}}} Neurociência computacional é o campo preocupado com a análise teórica e a modelagem computacional do sistema nervoso biológico. Como sistemas neurais estão intimamente relacionados com processos cognitivos e comportamentais, eles também estão fortemente ligados a modelagem cognitiva e comportamental. O objetivo do"}
{"source": "Rede neural artificial", "chunk_id": "Rede neural artificial_59", "text": "biológico. Como sistemas neurais estão intimamente relacionados com processos cognitivos e comportamentais, eles também estão fortemente ligados a modelagem cognitiva e comportamental. O objetivo do campo é criar modelos de sistemas neurais biológicos para entender o funcionamento de sistemas biológicos reais. Para chegar a esse entendimento, neurocientistas tentam fazer uma ligação entre processos biológicos observados (dados), mecanismos biologicamente plausíveis de processamento e aprendizado neural (modelos de redes neurais biológicas) e teoria (aprendizado estatístico e teoria da informação). Muitos modelos são usados neste campo, cada um definido em um nível diferente de abstração e tentando modelar diferentes aspectos de sistemas neurais. Eles vão de modelos de comportamento de curto prazo de neurônios individuais, passando por modelos de como as dinâmicas de circuitos neurais surgem de interações entre neurônios individuais, até modelos de como comportamentos podem surgir de"}
{"source": "Rede neural artificial", "chunk_id": "Rede neural artificial_60", "text": "prazo de neurônios individuais, passando por modelos de como as dinâmicas de circuitos neurais surgem de interações entre neurônios individuais, até modelos de como comportamentos podem surgir de módulos neurais abstratos que representam subsistemas completos. Estes incluem modelos de plasticidade de curto e longo prazo de sistemas neurais e sua relação com o aprendizado e a memória, de um neurônio individual até o nível de um sistema. Redes neurais biológicas Inteligência artificial FAN (rede neural) Neurociência computacional Computação bioinspirada Aprendizado por transferência"}
{"source": "Rede Neural", "chunk_id": "Rede Neural_0", "text": "A rede neural é uma rede ou circuito de neurônios biológicos, ou em um sentido mais moderno, uma rede neural artificial, composta de neurônios artificiais ou nodos. Portanto, uma rede neural pode ser uma rede neural biológica, composta por neurônios biológicos, ou uma rede neural artificial, usada em inteligência artificial (IA). As conexões de neurônios biológicos são representadas nas redes neurais artificiais como pesos entre nodos. Um peso positivo representa uma conexão estimulante enquanto valores negativos representam conexões inibitórias. Finalmente, a função de ativação controla a amplitude de saída. Por exemplo, um intervalo de saída aceitável é normalmente entre 0 e 1, ou poderia ser também entre -1 e 1. Essas redes neurais artificiais podem ser treinadas por um conjunto de dados e usadas para modelagem preditiva, controle adaptativo e aplicações onde as redes podem ser treinadas através de um conjunto de dados. A autoaprendizagem pela experiência pode acontecer entre as"}
{"source": "Rede Neural", "chunk_id": "Rede Neural_1", "text": "e usadas para modelagem preditiva, controle adaptativo e aplicações onde as redes podem ser treinadas através de um conjunto de dados. A autoaprendizagem pela experiência pode acontecer entre as redes, gerando conclusões de um grupo de informações complexo e aparentemente não relacionado ao problema. A rede neural biológica é composta por grupos quimicamente conectados ou associados funcionalmente a neurônios. Um neurônio pode estar conectado a muitos outros neurônios e o número total de neurônios e conexões em uma rede pode ser extenso. Conexões, chamadas de sinapses, formam-se normalmente por axônios e dendritos, porém sinapse dendro dendrítica e outras conexões são possíveis. outras formas de sinalização também ocorrem por causa da difusão de neurotransmissores . Inteligência artificial, modelagem cognitiva e redes neurais são paradigmas de processamento de informações, inspirados pelo processo no qual sistemas neurais biológicos processam dados. Inteligência artificial e modelagem"}
{"source": "Rede Neural", "chunk_id": "Rede Neural_2", "text": "modelagem cognitiva e redes neurais são paradigmas de processamento de informações, inspirados pelo processo no qual sistemas neurais biológicos processam dados. Inteligência artificial e modelagem cognitiva tentam simular algumas propriedades das redes neurais biológicas. Na área de inteligência artificial, redes neurais artificiais obtiveram sucesso em reconhecimento de fala, análises de imagens e controle adaptativo com o objetivo de construir agentes de software (em computadores e jogos eletrônicos) ou robôs autônomos. Historicamente, computadores digitais evoluíram da arquitetura de von Neumann e operam pela execução de instruções explícitas, com o acesso da memória por um número de processadores. Por outro lado, a origem das redes neurais são baseadas no esforço de modelagem de processamento de informação de sistemas biológicos. Diferentemente da arquitetura de von Neumann, a computação das redes neurais não separa a memória e o processamento. A teoria da rede neural tem servido"}
{"source": "Rede Neural", "chunk_id": "Rede Neural_3", "text": "de informação de sistemas biológicos. Diferentemente da arquitetura de von Neumann, a computação das redes neurais não separa a memória e o processamento. A teoria da rede neural tem servido para melhorar o conhecimento de como os neurônios cerebrais funcionam e, também, providenciar uma base no empenho da criação da inteligência artificial. A base teórica preliminar de redes neurais contemporâneas foi proposta independentemente por Alexander Bain (1873) e William James (1890). Em seus trabalhos, tanto os pensamentos quanto as atividades corporais ocorrem pela interação doe neurônios com o cérebro. De acordo Bain, toda atividade levava ao disparo de um determinado conjunto de neurônios. Quando as atividades forem repetidas, as conexões entre esses neurônios se fortalecem. De acordo com a sua teoria, essa repetição foi o que levou à formação da memória. A comunidade científica do período era, em geral, cética em relação à teoria de Bain porque esta requer um número excessivo de"}
{"source": "Rede Neural", "chunk_id": "Rede Neural_4", "text": "com a sua teoria, essa repetição foi o que levou à formação da memória. A comunidade científica do período era, em geral, cética em relação à teoria de Bain porque esta requer um número excessivo de conexões neurais no cérebro. Hoje em dia, é aparente que o cérebro é extremamente complexo e que a mesma “fiação” pode lidar com muitos problemas e informações. A teoria de James era similar à de Bain, porém, ele sugeriu que as memórias e ações eram resultados de correntes elétricas fluindo entre os neurônios e o cérebro. O seu modelo foca no fluir de correntes elétricas e não requer conexões individuais para cada memória ou ação. CS Sherrington (1898) conduziu experimentos para testar a teoria de James. Ele conduziu correntes elétricas pela medula espinhal de ratos. Porém, ao invés de demonstrar um aumento de corrente elétrica, como James havia projetado, Sherrington descobriu que a força das correntes elétricas diminuíram conforme os experimentos continuavam. Importantemente, esse"}
{"source": "Rede Neural", "chunk_id": "Rede Neural_5", "text": "um aumento de corrente elétrica, como James havia projetado, Sherrington descobriu que a força das correntes elétricas diminuíram conforme os experimentos continuavam. Importantemente, esse trabalho levou à descoberta do conceito de habituação . McCulloch e Pitts (1943) criaram um modelo computacional para redes neurais baseado em matemática e algoritmos chamado de lógica de limiar. Esse modelo abriu caminho para que as pesquisas de redes neurais se dividissem em duas áreas distintas, processos biológicos no cérebro e aplicações de redes neurais em inteligência artificial. No final de 1940, o psicólogo Donald Hebb criou a hipótese de aprendizagem baseado no mecanismo de plasticidade neural, agora conhecida como aprendizagem Hebbiana . Esta é considerada uma regra típica de aprendizado não supervisionado e suas variações são modelos iniciais da potencialização de longa duração . Essas idéias começaram a ser utilizadas em modelos computacionais em 1948 com o tipo-B de máquinas"}
{"source": "Rede Neural", "chunk_id": "Rede Neural_6", "text": "não supervisionado e suas variações são modelos iniciais da potencialização de longa duração . Essas idéias começaram a ser utilizadas em modelos computacionais em 1948 com o tipo-B de máquinas desorganizadas de Alan Turing . Farley e Clark (1954) usaram pela primeira vez máquinas computacionais, na época chamadas de calculadoras, pela primeira vez na MIT (Massachussets Institute of Technology - Instituto de Tecnologia de Massachusetts) para simular a rede Hebbian. Outras máquinas computacionais de redes neurais foram criadas por Rochester, Holland, Habit e Duda (1956). Rosenblatt (1958) criou o perceptron, um algoritmo baseado na aprendizagem de duas camadas de rede de computadores. Este algoritmo reconhece padrões utilizando adição e subtração básica. Rosenblatt também utilizou notações matemáticas para descrever circuitos que não faziam parte do perceptron básico, como o circuito ou exclusivo, um circuito no qual sua computação matemática não pode ser processada até a criação do"}
{"source": "Rede Neural", "chunk_id": "Rede Neural_7", "text": "matemáticas para descrever circuitos que não faziam parte do perceptron básico, como o circuito ou exclusivo, um circuito no qual sua computação matemática não pode ser processada até a criação do algoritmo de retropropagação fosse criado por Werbos (1975). As pesquisas em redes neurais estagnaram depois da publicação de Marvin Minsky e Seymour Papert sobre aprendizado de máquina (1969). Eles descobriram dois problemas Eles descobriram dois problemas chaves com a máquinas computacionais de redes neurais. O primeiro problema estava relacionado com a incapacidade de processamento do circuito ou exclusivo por redes neurais de uma camada. O segundo problema significante foi que os computadores não eram sofisticados o suficiente para, efetivamente, processarem tempo de execução longos, o que era necessário para redes neurais grandes. As pesquisas em redes neurais começaram a aumentar depois que os computadores conseguiram aumentar as suas capacidades de processamento. Vale também mencionar"}
{"source": "Rede Neural", "chunk_id": "Rede Neural_8", "text": "necessário para redes neurais grandes. As pesquisas em redes neurais começaram a aumentar depois que os computadores conseguiram aumentar as suas capacidades de processamento. Vale também mencionar que os avanços nas pesquisas em redes neurais se devem à criação do algoritmo de retropropagação que efetivamente resolveu o problema ou exclusivo (Werbos 1975). O processamento paralelo da metade de 1980 se tornou popular como conexionismo . O texto de Rumelhart e McClelland (1986) fez uma exposição completa sobre o uso do conexionismo em computadores para simular processos neurais. As redes neurais usadas em inteligência artificial são tradicionalmente vistas como modelos simples do processo neural no cérebro, apesar de que a relação entre este modelo e a arquitetura biológica cerebral ainda são debatidas. Ainda não está claro até que ponto as redes neurais artificiais espelham a função cerebral. A rede neural (RN), no caso de neurônios artificiais chamada de rede neural artificial (RNA)"}
{"source": "Rede Neural", "chunk_id": "Rede Neural_9", "text": "são debatidas. Ainda não está claro até que ponto as redes neurais artificiais espelham a função cerebral. A rede neural (RN), no caso de neurônios artificiais chamada de rede neural artificial (RNA) ou rede neural simulada (SNN), é um grupo natural ou artificial de neurônios interconectados que usam modelos matemáticos ou computacionais para processamento de informação baseado no conexionismo para abordar a computação. Na maioria dos casos, a rede neural artificial é um sistema adaptativo que muda sua estrutura baseando-se em informações internas ou externas que fluem por suas redes Em termos mais práticos, as redes neurais são modelagem de dados estatísticos não lineares ou ferramentas de decisões .Elas podem ser usadas para modelar relações complexas entre entradas e saídas ou para encontrar padrões em dados. Uma rede neural artificial envolve uma rede de elementos de processamento simples ( neurônios artificiais ) que podem exibir um comportamento global complexo, determinado"}
{"source": "Rede Neural", "chunk_id": "Rede Neural_10", "text": "encontrar padrões em dados. Uma rede neural artificial envolve uma rede de elementos de processamento simples ( neurônios artificiais ) que podem exibir um comportamento global complexo, determinado pelas conexões entre os elementos de processamento e os parâmetros dos elementos. Neurônios artificiais foram propostos pela primeira vez em 1943 por Warren McCulloch, um neurofisiologista, e Walter Pitts, um lógico, que colaboraram pela primeira vez na Universidade de Chicago . Um tipo clássico de rede neural artificial é a rede neural recorrente de Hopfield. O conceito de rede neural foi aparentemente proposto por Alan Turing em seu artigo de 1948 Intelligent Machinery (Máquina Inteligentes) de 1948 no qual ele se referiu a eles como, \"máquinas não organizadas do tipo-B\". A utilidade da modelagem de redes neurais artificiais reside no fato de que elas podem deduzir uma função a partir de observações e também podem usá-la. Redes neurais não supervisionadas também podem ser usadas para"}
{"source": "Rede Neural", "chunk_id": "Rede Neural_11", "text": "de redes neurais artificiais reside no fato de que elas podem deduzir uma função a partir de observações e também podem usá-la. Redes neurais não supervisionadas também podem ser usadas para aprenderem as representações das entradas que capturam as características salientes da distribuição de entrada. Para exemplos, leia sobre máquina de Boltzmann (1983) e, mais recentemente, o algoritmo de aprendizado estruturado profundo, o qual pode aprender implicitamente a função de distribuição dos dados observados. O aprendizado em redes neurais é particularmente útil em aplicações onde a complexidade dos dados ou trabalho faz com que a criação manual dessas funções não seja algo prático. As redes neurais podem ser utilizadas em áreas diferentes. Os trabalhos nos quais as redes neurais artificiais são aplicadas tendem a cair entre as seguintes categorias amplas: Aproximação de funções ouregressão, incluindo série temporal e modelagem. Classificação, incluindo padrão e reconhecimento de"}
{"source": "Rede Neural", "chunk_id": "Rede Neural_12", "text": "são aplicadas tendem a cair entre as seguintes categorias amplas: Aproximação de funções ouregressão, incluindo série temporal e modelagem. Classificação, incluindo padrão e reconhecimento de sequências, detecção de novidades e decisões sequenciais. Processamento de dados, incluindo filtragem de dados, agrupamento, separação cega de sinais e compressão. As áreas de aplicação das RNAs incluem sistema de identificação não linear e controle (controle de veículos e processos), jogos e decisões (gamão, xadrez, jogo de corrida), reconhecimento de padrões (sistemas de radar, identificação facial, reconhecimento de objeto), reconhecimento de sequências. (gestos, fala, reconhecimento de texto escrito ), diagnóstico médico, aplicações financeiras, mineração de dados (ou descoberta de conhecimento em bancos de dados, \"KDD\"), visualização e filtragem de spam de e-mail . Por exemplo, é possível criar um perfil semântico dos interesses do usuário, emergindo-o de imagens treinadas para"}
{"source": "Rede Neural", "chunk_id": "Rede Neural_13", "text": "em bancos de dados, \"KDD\"), visualização e filtragem de spam de e-mail . Por exemplo, é possível criar um perfil semântico dos interesses do usuário, emergindo-o de imagens treinadas para reconhecimento de objetos. A neurociência teórica e computacional é a área preocupada com a análise e modelagem computacional do sistema neural biológico. Como os sistemas neurais estão intimamente relacionados aos processos cognitivos e comportamentais, O objetivo da área é criação de modelos de sistemas neurais biológicos para entender como os sistemas biológicos funcionam. Para ganhar esse entendimento, neurocientistas se esforçam em criar uma ligação entre os processos biológicos observados (dados), mecanismos biologicamente e aprendizagem neural (modelagem de rede neurais biológicas ) e teoria (teoria de aprendizagem estatística e teoria da informação ). Usam-se vários, que são definidos em níveis diferentes de abstração e modelam aspectos diferentes do sistema neural. Eles variam entre modelos"}
{"source": "Rede Neural", "chunk_id": "Rede Neural_14", "text": "de aprendizagem estatística e teoria da informação ). Usam-se vários, que são definidos em níveis diferentes de abstração e modelam aspectos diferentes do sistema neural. Eles variam entre modelos de neurônios individuais com comportamento de curto prazo, modelos da dinâmica do circuito neural que ocorrem pela interação de neurônios individuais e modelos de comportamento que ocorrem por causa dos modelos neurais abstratos, os quais representam subsistemas completos. Entre eles também estão inclusos modelos de plasticidade dos sistemas neurais de longo e curto prazo e suas relações com o aprendizado e memória, começando por um neurônio individual até o nível de sistema. Em agosto de 2020, cientistas relataram que conexões bidirecionais ou o adicionamento apropriado de conexões de retorno, podem acelerar e promover a comunicação entre redes neurais modulares do córtex cerebral e diminuir o limiar para que tenham uma comunicação bem sucedida. Eles mostraram que adicionar conexões de"}
{"source": "Rede Neural", "chunk_id": "Rede Neural_15", "text": "podem acelerar e promover a comunicação entre redes neurais modulares do córtex cerebral e diminuir o limiar para que tenham uma comunicação bem sucedida. Eles mostraram que adicionar conexões de retorno entre os pares de ressonância pode auxiliar uma propagação bem sucedida de um pacote de pulso singular em toda a rede. Uma crítica comum de redes neurais, particularmente em robótica, é que estas requerem uma grande diversidade de exemplos de treinamento para sua operação no mundo real. Isto não é uma surpresa, qualquer máquina de aprendizado precisa de exemplos representativos suficientes para capturar a estrutura subjacente e assim generalizar novos casos. Dean Pomerleau, em sua pesquisa publicada no artigo Knowledge-based Training of Artificial Neural Networks for Autonomous Robot Driving (Treinamento Baseado no Conhecimento de Redes Neurais Artificiais para Condução Autônoma de Robôs), usou uma rede neural para treinar um veículo robótico a dirigir vários tipos de estradas (via"}
{"source": "Rede Neural", "chunk_id": "Rede Neural_16", "text": "(Treinamento Baseado no Conhecimento de Redes Neurais Artificiais para Condução Autônoma de Robôs), usou uma rede neural para treinar um veículo robótico a dirigir vários tipos de estradas (via única, várias vias, estrada, etc). Uma parte grande de sua pesquisa está voltada para (1) extrapolar múltiplos cenários de uma única experiência, (2) e para a preservação de treinamentos do passado, para que o sistema não fique super treinado (se, por exemplo, este for apresentado com uma série de curvas à direita - este não deverá aprender a dobrar sempre à direita). Esses problemas são comuns em redes neurais onde o modelo tem que tomar uma decisão dentre uma variedade enorme de respostas, porém isto pode ser resolvido de muitas maneiras diferentes. Entre elas, por exemplo, o embaralhamento aleatório de exemplos de treinamento, a utilização de um algoritmo numérico de otimização que não precise de muitos passos enquanto faz a troca das conexões das redes, seguindo um exemplo ou pelo"}
{"source": "Rede Neural", "chunk_id": "Rede Neural_17", "text": "aleatório de exemplos de treinamento, a utilização de um algoritmo numérico de otimização que não precise de muitos passos enquanto faz a troca das conexões das redes, seguindo um exemplo ou pelo agrupamento de exemplos, também chamados de mini-lotes. AK Dewdney, ex-colunista da Scientific American (revista científica Americana), escreveu em 1997: \"Apesar de que redes neurais solucionam alguns problemas em brinquedos, o seu poder computacional é tão limitado que me surpreende qualquer pessoa acreditar que elas podem ser utilizadas como ferramentas para resolver problemas generalizados\" (Dewdney, pág. 82). Os argumentos para a posição de Dewdney incluem a necessidade de dedicar bastante recursos de armazenamento e processamento para que um software de redes neurais grandes seja implementado com eficiência. Enquanto o cérebro já possui hardware adaptado para o trabalho de processar sinais por meio do de um gráfico de neurônios, a simulação na tecnologia de Von Neumann, até mesmo a forma"}
{"source": "Rede Neural", "chunk_id": "Rede Neural_18", "text": "com eficiência. Enquanto o cérebro já possui hardware adaptado para o trabalho de processar sinais por meio do de um gráfico de neurônios, a simulação na tecnologia de Von Neumann, até mesmo a forma mais simples, poderá fazer com que um desenvolvedor de rede neural encha muitos milhões de linhas de banco de dados para suas conexões – isso pode consumir grandes quantidades de memória e da capacidade de armazenamento de dados em computadores. Além disso, o desenvolvedor de sistemas de redes neurais precisará, com frequência, simular a transmissão de sinais através de muitas destas conexões e os neurônios associados às mesmas - o que geralmente deverá ser combinado com um tamanho incrível de tempo e poder de processamento pela CPU. Ainda que redes neurais produzam programas eficazes com frequência, elas geralmente o fazem com o custo da eficiência (eles tendem a consumir tamanhos consideráveis de tempo e dinheiro). Argumentos contra a posição de Dewdney incluem o uso com sucesso de redes"}
{"source": "Rede Neural", "chunk_id": "Rede Neural_19", "text": "elas geralmente o fazem com o custo da eficiência (eles tendem a consumir tamanhos consideráveis de tempo e dinheiro). Argumentos contra a posição de Dewdney incluem o uso com sucesso de redes neurais para solucionar muitos problemas complexos e trabalhos diversos, como aeronaves que voam autonomamente. O escritor tecnológico Roger Bridgman fez o seguinte comentário sobre as declarações de Dewdney sobre redes neurais:Redes neurais, por exemplo, estão no banco dos réus não só porque elas foram intensamente promovidas (O que não foi?), mas também porque você pode criar uma rede com sucesso sem entender como ela funciona: os inúmeros números que capturam o seu comportamento provavelmente seriam \"opacos, uma tabela que não se pode ler… sem valor como um recurso científico\". Apesar de sua declaração enfática de que ciência não é tecnologia, Dewdney parece rotular redes neurais como uma ciência ruim, enquanto a maioria das pessoas que as desenvolvem só estão tentando ser bons engenheiros."}
{"source": "Rede Neural", "chunk_id": "Rede Neural_20", "text": "enfática de que ciência não é tecnologia, Dewdney parece rotular redes neurais como uma ciência ruim, enquanto a maioria das pessoas que as desenvolvem só estão tentando ser bons engenheiros. Ainda vale muito a pena ter uma tabela que não pode ser lida por pessoas mas que pode ser lida por uma máquina.Embora analisar o que foi aprendido por uma rede neural seja difícil, a análise do aprendido por uma rede neural biológica acaba sendo mais fácil. Além disso, ênfases recentes na explicabilidade da inteligência artificial têm contribuído ao desenvolvimento de métodos, notavelmente os métodos baseados nos mecanismos de atenção, visualização e explicação de redes neurais que foram aprendidas. Os pesquisadores envolvidos em algoritmos de aprendizado exploratório em redes neurais estão gradualmente descobrindo princípios genéricos que permitem uma máquina de aprendizado a ser bem sucedida. Por exemplo, Bengio e LeCun (2007) escreveram um artigo a respeito de aprendizado local versus não"}
{"source": "Rede Neural", "chunk_id": "Rede Neural_21", "text": "descobrindo princípios genéricos que permitem uma máquina de aprendizado a ser bem sucedida. Por exemplo, Bengio e LeCun (2007) escreveram um artigo a respeito de aprendizado local versus não local e também sobre arquitetura superficial versus profunda. Outras críticas vieram de de pessoas que acreditam em modelos híbridos (combinando redes neurais e abordagens simbólicas ). Elas defendem a mistura dessas duas abordagens e acreditam que modelos híbridos podem capturar melhor os mecanismos da mente humana (Sun e Bookman, 1990). Embora pesquisas iniciais tenham se preocupado principalmente com as características elétricas dos neurônios, uma parte particularmente importante das investigações dos últimos anos tem sido a exploração do papel de neuromoduladores como dopamina, acetilcolina e serotonina no comportamento e no aprendizado. Modelos biofísicos, como a teoria BCM, têm sido importantes na compreensão dos mecanismos da plasticidade sináptica e têm tido aplicações tanto na ciência da"}
{"source": "Rede Neural", "chunk_id": "Rede Neural_22", "text": "no comportamento e no aprendizado. Modelos biofísicos, como a teoria BCM, têm sido importantes na compreensão dos mecanismos da plasticidade sináptica e têm tido aplicações tanto na ciência da computação quanto na neurociência. A pesquisa sobre a compreensão de algoritmos computacionais usados no cérebro está em andamento, recentemente, houve evidências biológicas sobre de redes de base radial e retropropagação neural como mecanismos de processamento de dados. Dispositivos computacionais foram criados em CMOS (Semicondutor de óxido de metal complementar) tanto para simulação biofísica e computação neuromórfica . Esforços recentes são promissores para a criação de nanodispositivos para análises e convolução de componentes principais em grande escala. Se bem sucedidos, esses esforços podem gerar uma nova era de computação neural que seria um passo à frente da computação digital, porque dependeria do aprendizado ao invés da programação e também porque seria fundamentalmente analógico em"}
{"source": "Rede Neural", "chunk_id": "Rede Neural_23", "text": "gerar uma nova era de computação neural que seria um passo à frente da computação digital, porque dependeria do aprendizado ao invés da programação e também porque seria fundamentalmente analógico em vez de digital, apesar de que suas primeiras serem de fato feitas por dispositivos digitais CMOS. Entre 2009 e 2012, as redes neurais recorrentes e redes neurais de feedforward densa, desenvolvidas na pesquisa de grupo de Jürgen Schmidhuber no laboratório suíço de inteligência artificial IDSIA (Swiss AI Lab IDSIA) ganharam oito competições internacionais em reconhecimento de padrões e máquina de aprendizado . Por exemplo, curta e longa memória multidimensional (LSTM) ganhou três competições em reconhecimento de escrita manual conectada em 2009 na Conferência Internacional em Reconhecimento e Análises de Documentos (ICDAR - International Conference on Document Analysis and Recognition), sem ter nenhum conhecimento sobre os três idiomas que seriam aprendidos. Variantes do algoritmo de"}
{"source": "Rede Neural", "chunk_id": "Rede Neural_24", "text": "e Análises de Documentos (ICDAR - International Conference on Document Analysis and Recognition), sem ter nenhum conhecimento sobre os três idiomas que seriam aprendidos. Variantes do algoritmo de retropropagação, assim como métodos não supervisionados por Geoff Hinton e colegas da Universidade de Toronto, podem ser usadas para o treinamento profundo de arquiteturas altamente não lineares. Semelhantes ao Neocognitron de 1980 por Kunihiko Fukushima, e a \"arquitetura padrão de visão\", inspirada pelas células simples e complexas identificadas por David H. Hubel e Torsten Wiesel no córtex visual primário . A função de base radial e as redes wavelet também foram introduzidas. Estas apresentam melhores propriedades de aproximação e têm sido aplicadas em sistemas de identificação não linear como também em aplicações de classificações . As redes feedforward de aprendizado profundo alternam camadas convolucionais e camadas de pooling máximo, encimadas por várias camadas de classificação pura."}
{"source": "Rede Neural", "chunk_id": "Rede Neural_25", "text": "também em aplicações de classificações . As redes feedforward de aprendizado profundo alternam camadas convolucionais e camadas de pooling máximo, encimadas por várias camadas de classificação pura. Implementações rápidas baseadas em GPU (Graphics processing unit - Unidade de processamento gráfico) desta abordagem ganharam várias competições de reconhecimento de padrãos, incluindo o IJCNN 2011 Traffic Sign Recognition Competition (Competição de Reconhecimento de Sinais de Trânsito) e o ISBI 2012 Segmentation of Neuronal Structures in Electron Microscopy Stacks challenge (Desafio de Estruturas Neuronais em Pilhas de Microscopia Eletrônica). Essas redes neurais também foram as primeiras a reconhecer padrões artificiais que alcançaram uma performance que pode competir com humanos e até superá-los em benchmarks como reconhecimento de sinais de trânsito (IJCNN 2012), ou o problema de dígitos manuais MNIST por Yann LeCun e colegas da NYU (Universidade de Nova York)."}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_0", "text": "Na informática, a Inteligência Artificial (abreviado IA) genericamente é a inteligência, o raciocínio e o aprendizado exibida por máquinas semelhante ao raciocino humano; busca desenvolver máquinas autônomas ou sistemas especialistas capazes de simular o pensamento humano e realizar várias tarefas complexas de forma independente. É o sistema que permite aos computadores executar funções avançadas, como a capacidade de analisar dados em grande escala e fazer previsões/recomendações; É um campo de pesquisa em ciência da computação que desenvolve e estuda métodos e softwares que permitem que as máquinas percebam seu ambiente e usem o aprendizado e a inteligência para tomar ações que maximizem suas chances de atingir objetivos definidos. A IA iniciou na década de 1950 com os pesquisadores Alan Turing e Herbert Simon baseado no conceito do filósofo grego Aristóteles. Em 1950, o matemático inglês Allan Turing escreveu sobre ser possível uma máquina pensar, e imitar o comportamento humano"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_1", "text": "Turing e Herbert Simon baseado no conceito do filósofo grego Aristóteles. Em 1950, o matemático inglês Allan Turing escreveu sobre ser possível uma máquina pensar, e imitar o comportamento humano inteligente. Também esboçou uma proposta de pesquisa para tornar isto possível. Aplicações de IA incluem mecanismos avançados de busca na web (por exemplo, Google Search); sistemas de recomendação (usados pelo YouTube, Amazon e Netflix); assistentes virtuais (por exemplo, Google Assistant, Siri e Alexa ); veículos autônomos (por exemplo, Waymo); ferramentas generativas e criativas (por exemplo, ChatGPT, DeepSeek e AI art); e jogo e análise sobre-humanos em jogos de estratégia (por exemplo, xadrez e Go). No entanto, muitas aplicações de IA não são percebidas como IA porque já se tornaram comuns o suficiente no cotidiano das pessoas. Como por exemplo, o reconhecimento óptico de caracteres (OCR) que extrai o texto de imagens; transforma conteúdo não estruturado em dados estruturados com insights"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_2", "text": "no cotidiano das pessoas. Como por exemplo, o reconhecimento óptico de caracteres (OCR) que extrai o texto de imagens; transforma conteúdo não estruturado em dados estruturados com insights prontos para negócios; tradução de textos em idiomas estrangeiros e tradução de voz. A IA é um campo que abrange muitas disciplinas, como: ciência da computação, estatísticas, engenharia de hardware e de software, linguística, neurociência e, filosofia. Vários subcampos da pesquisa em IA são centrados em objetivos específicos e no uso de ferramentas específicas. Os objetivos tradicionais da pesquisa em IA incluem raciocínio, representação de conhecimento, planejamento, aprendizagem, processamento de linguagem natural, percepção e suporte à robótica. A inteligência geral — a capacidade de completar qualquer tarefa realizada por um humano em um nível pelo menos igual — está entre os objetivos de longo prazo do campo. Para atingir esses objetivos, os pesquisadores de IA adaptaram e integraram uma"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_3", "text": "qualquer tarefa realizada por um humano em um nível pelo menos igual — está entre os objetivos de longo prazo do campo. Para atingir esses objetivos, os pesquisadores de IA adaptaram e integraram uma ampla gama de técnicas, incluindo otimização matemática e de busca, lógica formal, redes neurais artificiais e métodos baseados em estatística, pesquisa operacional e economia. A IA também se baseia na psicologia, linguística, filosofia, neurociência e em outros campos. A inteligência artificial foi fundada como disciplina acadêmica em 1956 e o campo passou por múltiplos ciclos de otimismo ao longo de sua história, seguidos por períodos de decepção e perda de financiamento. Os recursos e o interesse aumentaram enormemente após 2012, quando a aprendizagem profunda superou as técnicas de IA anteriores. Este crescimento acelerou ainda mais depois de 2017 e no início da década de 2020 muitos milhares de milhões de dólares estavam a ser investidos em IA e o campo experimentou um rápido"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_4", "text": "IA anteriores. Este crescimento acelerou ainda mais depois de 2017 e no início da década de 2020 muitos milhares de milhões de dólares estavam a ser investidos em IA e o campo experimentou um rápido progresso contínuo no que ficou conhecido como o boom da IA. O surgimento da IA generativa avançada e sua capacidade de criar e modificar conteúdo expôs diversas consequências e danos não intencionais no presente e levantou preocupações sobre os riscos da IA e seus efeitos de longo prazo no futuro, gerando discussões sobre políticas regulatórias para garantir a segurança e os benefícios da tecnologia. O interesse no desenvolvimento de máquinas autônomas capazes de simular o pensamento humano e de realizar varias tarefas cresceu vertiginosamente nas últimas décadas, da segunda metade do século XX, realizando assim os primeiros estudos sobre inteligência artificial (IA) a um propósito comum, a partir de iniciativas de cientistas de diversas áreas, como: psicologia, ciência cognitiva, ciência"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_5", "text": "realizando assim os primeiros estudos sobre inteligência artificial (IA) a um propósito comum, a partir de iniciativas de cientistas de diversas áreas, como: psicologia, ciência cognitiva, ciência da computação e, robótica. Ferramentas eficientes em analisar problemas e oferecer soluções e planejamentos (tomada de decisão), automatização de tarefas no cotidiano das pessoas. Mas apesar dos estudos serem modernos, o conceito de inteligência artificial não é contemporâneo; Aristóteles (professor de Alexandre, o Grande) sonhava em substituir a mão-de-obra escrava por ferramentas autônomas, sendo esta possivelmente a primeira ideia de Inteligência Artificial relatada, que a ciência da computação exploraria muito tempo depois. O desenvolvimento dessa ideia ocorreu plenamente no século XX, principalmente na década de 1950, com pensadores como Allan Turing, Herbert Simon e, John McCarthy. Turing escreveu o artigo \"Computing Machinery and InteIligence\" sobre a possibilidade de uma máquina"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_6", "text": "na década de 1950, com pensadores como Allan Turing, Herbert Simon e, John McCarthy. Turing escreveu o artigo \"Computing Machinery and InteIligence\" sobre a possibilidade de uma máquina pensar e imitar o comportamento humano inteligente com tal perfeição, de forma que pudesse confundir ate um juiz humano. Turing também esboçou uma proposta de pesquisa para tornar possível. Inicialmente os teste em IA foram repletos de sucessos – porém limitados devido o desempenho reduzido dos primeiros computadores - oque causava surpresa, foi o fato de um computador realizar atividade remotamente inteligente. O sucesso inicial prosseguiu em 1957 com o General Problem Solver (GPS, Solucionador de problemas gerais) desenvolvido por Herbert Simon e Allen Newell, um programa foi projetado para imitar protocolos humanos de resolução de problemas. Dentro da classe limitada de quebra-cabeças com a qual podia lidar, verificou-se que a ordem em que os seres humanos abordavam os mesmos problemas. Desse modo,"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_7", "text": "humanos de resolução de problemas. Dentro da classe limitada de quebra-cabeças com a qual podia lidar, verificou-se que a ordem em que os seres humanos abordavam os mesmos problemas. Desse modo, o GPS talvez tenha sido o primeiro programa a incorporar a abordagem de “pensar de forma humana”. Em 1961, a proposta de Turing voltou no artigo de Herbert Simon e Allen Newell no artigo \"The Simulation of Human Thought\" sobre o teste de uma teoria de resolução humana de problemas. Esta teoria tenta explicar alguns aspectos dos processos mentais responsáveis pela inteligencia humana, um projeto de estudos conhecido pelo nome de Projeto de Simulação Cognitiva. Desde o início os fundamentos da inteligência artificial tiveram o suporte de várias disciplinas que contribuíram com ideias, pontos de vista e técnicas para a IA. Os filósofos (desde 400 a.C.) tornaram a IA concebível, considerando as ideias de que a mente é, em alguns aspectos, semelhante a uma máquina, de que ela opera sobre o"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_8", "text": "de vista e técnicas para a IA. Os filósofos (desde 400 a.C.) tornaram a IA concebível, considerando as ideias de que a mente é, em alguns aspectos, semelhante a uma máquina, de que ela opera sobre o conhecimento codificado em alguma linguagem interna e que o pensamento pode ser usado para escolher as ações que deverão ser executadas. Por sua vez, os matemáticos forneceram as ferramentas para manipular declarações de certeza lógica, bem como declarações incertas e probabilísticas. Eles também definiram a base para a compreensão da computação e do raciocínio sobre algoritmos. Os economistas formalizaram o problema de tomar decisões que maximizam o resultado esperado para o tomador de decisões. Os psicólogos adotaram a ideia de que os seres humanos e os animais podem ser considerados máquinas de processamento de informações. Os linguistas mostraram que o uso da linguagem se ajusta a esse modelo. Os engenheiros de computação fornecem os artefatos que tornam possíveis as aplicações de IA."}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_9", "text": "de processamento de informações. Os linguistas mostraram que o uso da linguagem se ajusta a esse modelo. Os engenheiros de computação fornecem os artefatos que tornam possíveis as aplicações de IA. Os programas de IA tendem a ser extensos e não poderiam funcionar sem os grandes avanços em velocidade e memória que a indústria de informática tem proporcionado. Atualmente, a IA abrange uma enorme variedade de subcampos. Dentre esses subcampos está o estudo de modelos conexionistas ou redes neurais. Uma rede neural pode ser vista como um modelo matemático simplificado do funcionamento do cérebro humano. Este consiste de um número muito grande de unidades elementares de processamento, ou neurônios, que recebem e enviam estímulos elétricos uns aos outros, formando uma rede altamente interconectada. No processamento, são compostos os estímulos recebidos conforme a intensidade de cada ligação, produzindo um único estímulo de saída. É o arranjo das interconexões entre os neurônios e as"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_10", "text": "No processamento, são compostos os estímulos recebidos conforme a intensidade de cada ligação, produzindo um único estímulo de saída. É o arranjo das interconexões entre os neurônios e as respectivas intensidades que define as principais propriedades e o funcionamento de uma RN. O estudo das redes neurais ou o conexionismo se relaciona com a capacidade dos computadores aprenderem e reconhecerem padrões. Podemos destacar também o estudo da biologia molecular na tentativa de construir vida artificial e a área da robótica, ligada à biologia e procurando construir máquinas que alojem vida artificial. Outro subcampo de estudo é a ligação da IA com a Psicologia, na tentativa de representar na máquina os mecanismos de raciocínio e de procura. Nos últimos anos, houve uma revolução no trabalho em inteligência artificial, tanto no conteúdo quanto na metodologia. Agora, é mais comum usar as teorias existentes como bases, em vez de propor teorias inteiramente novas, fundamentar as informações em"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_11", "text": "inteligência artificial, tanto no conteúdo quanto na metodologia. Agora, é mais comum usar as teorias existentes como bases, em vez de propor teorias inteiramente novas, fundamentar as informações em teoremas rigorosos ou na evidência experimental rígida, em vez de utilizar como base a intuição e destacar a relevância de aplicações reais em vez de exemplos hipotéticos. A utilização da IA permite obter não somente ganhos significativos de performance, mas também possibilita o desenvolvimento de aplicações inovadoras, capazes de expandir de forma extraordinária nossos sentidos e habilidades intelectuais. Cada vez mais presente, a inteligência artificial simula o pensamento humano e se alastra por nosso cotidiano. Em maio de 2017 no Brasil, foi criada a ABRIA (Associação Brasileira de Inteligência Artificial) com o objetivo de mapear iniciativas brasileiras no setor de inteligência artificial, englobando os esforços entre as empresas nacionais e formação de mão de obra especializada."}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_12", "text": "Artificial) com o objetivo de mapear iniciativas brasileiras no setor de inteligência artificial, englobando os esforços entre as empresas nacionais e formação de mão de obra especializada. Esse passo reforça que, atualmente, a inteligência artificial é impactante no setor econômico. A inteligência artificial começou como um campo experimental na década de 1950 com pioneiros como Allen Newell e Herbert Simon, que fundaram o primeiro laboratório de inteligência artificial na Universidade Carnegie Mellon, e McCarty que juntamente com Marvin Minsky, que fundaram o MIT AI Lab em 1959. Foram eles alguns dos participantes na famosa conferência de verão de 1956 em Darthmouth College. Historicamente, existem dois grandes estilos de investigação em IA: IA \"neats\" e IA \"scruffies\". A IA \"neats\", limpa, clássica ou simbólica. Envolve a manipulação de símbolos e de conceitos abstractos, e é a metodologia utilizada na maior parte dos sistemas periciais. Paralelamente a esta abordagem existe a"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_13", "text": "limpa, clássica ou simbólica. Envolve a manipulação de símbolos e de conceitos abstractos, e é a metodologia utilizada na maior parte dos sistemas periciais. Paralelamente a esta abordagem existe a abordagem IA \"scruffies\", ou \"coneccionista\", da qual as redes neuronais são o melhor exemplo. Esta abordagem cria sistemas que tentam gerar inteligência pela aprendizagem e adaptação em vez da criação de sistemas desenhados com o objectivo especifico de resolver um problema. Ambas as abordagems apareceram num estágio inicial da história de IA. Nas décadas de 1960/70 os coneccionistas foram retirados do primeiro plano da investigação em IA, mas o interesse por esta vertente da IA foi retomada na década de 1980, quando as limitações da IA \"limpa\" começaram a ser percebidas. Pesquisas sobre inteligência artificial foram intensamente custeadas na década de 1980 pela Agência de Projetos de Pesquisas Avançadas sobre Defesa (“Defense Advanced Research Projects Agency”), nos Estados Unidos, e pelo"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_14", "text": "artificial foram intensamente custeadas na década de 1980 pela Agência de Projetos de Pesquisas Avançadas sobre Defesa (“Defense Advanced Research Projects Agency”), nos Estados Unidos, e pelo Projeto da Quinta Geração (“Fifth Generation Project”), no Japão. O trabalho subsidiado fracassou no sentido de produzir resultados imediatos, a despeito das promessas grandiosas de alguns praticantes de IA, o que levou proporcionalmente a grandes cortes de verbas de agências governamentais no final dos anos 80, e em consequência a um arrefecimento da atividade no setor, fase conhecida como O inverno da IA. No decorrer da década seguinte, muitos pesquisadores de IA mudaram para áreas relacionadas com metas mais modestas, tais como aprendizado de máquinas, robótica e visão computacional, muito embora pesquisas sobre IA pura continuaram em níveis reduzidos. Existem duas abordagens principais para a criação de Sistemas de Inteligência Artificial: O Simbolismo e o Conexionismo. O Simbolismo ou IA"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_15", "text": "pesquisas sobre IA pura continuaram em níveis reduzidos. Existem duas abordagens principais para a criação de Sistemas de Inteligência Artificial: O Simbolismo e o Conexionismo. O Simbolismo ou IA Simbólica, propõe a representação de conhecimento por meio da manipulação de símbolos, isto é, na forma de estruturas construídas por seres humanos, normalmente baseadas em noções de Lógica. Ela teve grande impulso durante uma fase onde foram criados muitos Sistemas Especialistas, muitos deles baseados em Lógica de Primeira Ordem, implementados em Prolog, ou em linguagens de programação derivadas desta ou especializadas, como CLIPS. Normalmente programas desse tipo têm o conhecimento programado diretamente por seres humanos, o que levou a trabalhos de elicitação de conhecimento. Apesar do sucesso inicial dos Sistemas Especialistas, a grande dificuldade de levantar e registrar conhecimento a partir de humanos e o sucesso dos processos de aprendizado de máquina a partir de dados levou a"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_16", "text": "sucesso inicial dos Sistemas Especialistas, a grande dificuldade de levantar e registrar conhecimento a partir de humanos e o sucesso dos processos de aprendizado de máquina a partir de dados levou a dimimuição da importância dessa vertente. O Conexionismo ou IA Conexionista, se baseia em um modelo matemático inspirado no funcionamento dos neurônios, e depende do aprendizado de máquina baseado em grandes massas de dados para calibrar esse modelo, que normalmente começa com parâmetros aleatórios. Essa abordagem, apesar de proposta muito cedo, não encontrou computadores capazes de modelar problemas complexos, apesar de ter sucesso com problemas restritos de reconhecimento de padrão, o que só acontece a partir da década de 2010, com resultados extramemente fortes no final dessa década e no início da década de 2020, a partir de modelos contendo bilhões de parametros, como o GPT-3 e conceitos como Redes Neurais Profundas, Transformers, e Atenção. Em torno de 2022, a maior parte da pesquisa"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_17", "text": "da década de 2020, a partir de modelos contendo bilhões de parametros, como o GPT-3 e conceitos como Redes Neurais Profundas, Transformers, e Atenção. Em torno de 2022, a maior parte da pesquisa em IA gira em torno dos conceitos de Aprendizado de Máquina e Conexionismo, havendo também propostas para sistemas híbridos. A questão sobre o que é \"inteligência artificial\", mesmo como definida anteriormente, pode ser separada em duas partes: \"qual a natureza do artificial\" e \"o que é inteligência\". A primeira questão é de resolução relativamente fácil, apontando no entanto para a questão de o que poderá o homem construir. A segunda questão seria consideravelmente mais difícil, levantando a questão da consciência, identidade e mente (incluindo a mente inconsciente) juntamente com a questão de que componentes estão envolvidos no único tipo de inteligência que universalmente se aceita como estando ao alcance do nosso estudo: a inteligência do ser humano. O estudo de animais e de sistemas"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_18", "text": "de que componentes estão envolvidos no único tipo de inteligência que universalmente se aceita como estando ao alcance do nosso estudo: a inteligência do ser humano. O estudo de animais e de sistemas artificiais que não são modelos triviais começa a ser considerado como pauta de estudo na área da inteligência. Ao conceituar inteligência artificial, presume-se a interação com o ambiente, diante de necessidades reais como relações entre indivíduos semelhantes, a disputa entre indivíduos diferentes, perseguição e fuga; além da comunicação simbólica específica de causa e efeito em diversos níveis de compreensão intuitiva, consciente ou não. Suponhamos uma competição de cara ou coroa, cujos resultados sejam observados ou não. Se na segunda tentativa der o mesmo resultado que a primeira, então não existiam as mesmas chances para ambas opções iniciais. Claro que a coleta de informação em apenas duas amostragens é confiável apenas porque a quantidade de tentativas é divisível pelo número de"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_19", "text": "não existiam as mesmas chances para ambas opções iniciais. Claro que a coleta de informação em apenas duas amostragens é confiável apenas porque a quantidade de tentativas é divisível pelo número de opções de resultados prováveis. A verdade é que o conceito de cara ou coroa está associado a artigos de valor, como moedas e medalhas que podem evitar que as pessoas abandonem o jogo e induza os participantes a acompanhar os resultados até o final. Para manter a disposição do adversário em desafiar a máquina seria necessário aparentar fragilidade e garantir a continuidade da partida. Isso é muito utilizado em máquinas de cassino, sendo que vários apostadores podem ser induzidos a dispensar consideráveis quantias em apostas. A utilização de uma máquina de resultados pode compensar a ausência de um adversário, mas numa partida de xadrez, por exemplo, para que a máquina não precise armazenar todas as informações que excedem a capacidade de próprio universo imaginável são necessárias fórmulas"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_20", "text": "um adversário, mas numa partida de xadrez, por exemplo, para que a máquina não precise armazenar todas as informações que excedem a capacidade de próprio universo imaginável são necessárias fórmulas que possam ser armazenadas para que então sejam calculadas por princípios físicos, lógicos, geométricos, e estatísticos para refletir o sistema completo em cada uma das suas partes; como a integração do Google com Wikipédia, por exemplo. Uma popular e inicial definição de inteligência artificial, introduzida por John McCarthy na famosa conferência de Dartmouth em 1956 é \"fazer a máquina comportar-se de tal forma que seja chamada inteligente caso fosse este o comportamento de um ser humano.\" No entanto, esta definição parece ignorar a possibilidade de existir a IA forte (ver abaixo). Outra definição de Inteligência Artificial é a inteligência que surge de um \"dispositivo artificial\". A maior parte das definições podem ser categorizadas em sistemas que: \"pensam como um humano; agem como um"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_21", "text": "de Inteligência Artificial é a inteligência que surge de um \"dispositivo artificial\". A maior parte das definições podem ser categorizadas em sistemas que: \"pensam como um humano; agem como um humano; pensam racionalmente ou agem racionalmente\". Os principais pesquisadores e livros didáticos definem o campo como \"o estudo e projeto de agentes inteligentes\", onde um agente inteligente é um sistema que percebe seu ambiente e toma atitudes que maximizam suas chances de sucesso. Andreas Kaplan e Michael Haenlein definem a inteligência artificial como “uma capacidade do sistema para interpretar corretamente dados externos, aprender a partir desses dados e utilizar essas aprendizagens para atingir objetivos e tarefas específicas através de adaptação flexível”. John McCarthy, quem cunhou o termo em 1956 (\"numa conferência de especialistas celebrada em Darmouth Colege\" Gubern, Román: O Eros Eletrónico), a define como \"a ciência e engenharia de produzir sistemas inteligentes\". É uma área de"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_22", "text": "em 1956 (\"numa conferência de especialistas celebrada em Darmouth Colege\" Gubern, Román: O Eros Eletrónico), a define como \"a ciência e engenharia de produzir sistemas inteligentes\". É uma área de pesquisa da computação dedicada a buscar métodos ou dispositivos computacionais que possuam ou multipliquem a capacidade racional do ser humano de resolver problemas, pensar ou, de forma ampla, ser inteligente. Nas últimas décadas, o campo exoandiu-se para incluir subáreas como aprendizado de máquina, redes neurais artificiais, processamento de linguagem natural e visão computacional, com ênfase crescente em técnicas estatísticas, métodos conexionistas e abordagens híbridas que combinam modelos simbólicos e aprendizagem profunda.. Também pode ser definida como o ramo da ciência da computação que se ocupa do comportamento inteligente ou ainda, o estudo de como fazer os computadores realizarem coisas que, atualmente, os humanos fazem melhor. Não existe uma teoria ou paradigma unificador que"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_23", "text": "se ocupa do comportamento inteligente ou ainda, o estudo de como fazer os computadores realizarem coisas que, atualmente, os humanos fazem melhor. Não existe uma teoria ou paradigma unificador que orienta a pesquisa de IA. Pesquisadores discordam sobre várias questões. Algumas das perguntas constantes mais longas que ficaram sem resposta são as seguintes: a inteligência artificial deve simular inteligência natural, estudando psicologia ou neurociência? Ou será que a biologia humana é tão irrelevante para a pesquisa de IA como a biologia das aves é para a engenharia aeronáutica? O comportamento inteligente pode ser descrito usando princípios simples e elegantes (como lógica ou otimização)? Ou ela necessariamente requer que se resolva um grande número de problemas completamente não relacionados? A inteligência pode ser reproduzida usando símbolos de alto nível, similares às palavras e ideias? Ou ela requer processamento \"sub-simbólico\"? John Haugeland, que cunhou o termo GOFAI (Good"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_24", "text": "A inteligência pode ser reproduzida usando símbolos de alto nível, similares às palavras e ideias? Ou ela requer processamento \"sub-simbólico\"? John Haugeland, que cunhou o termo GOFAI (Good Old-Fashioned Artificial Intelligence - Boa Inteligência Artificial à Moda Antiga), também propôs que a IA deve ser mais apropriadamente chamada de inteligência sintética, um termo que já foi adotado por alguns pesquisadores não-GOFAI. Nos anos de 1940 e 1950, um número de pesquisadores exploraram a conexão entre neurologia, teoria da informação e cibernética. Alguns deles construíram máquinas que usaram redes eletrônicas para exibir inteligência rudimentar, como as tartarugas de W. Grey Walter e a Besta de Johns Hopkins. Muitos desses pesquisadores se reuniram para encontros da Sociedade teleológica da Universidade de Princeton e o Ratio Club na Inglaterra. Em 1960, esta abordagem foi abandonada, apesar de seus elementos serem revividos na década de 1980. Inteligência computacional Interesse em"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_25", "text": "da Universidade de Princeton e o Ratio Club na Inglaterra. Em 1960, esta abordagem foi abandonada, apesar de seus elementos serem revividos na década de 1980. Inteligência computacional Interesse em redes neurais e \"conexionismo\" foi revivida por David Rumelhart e outros em meados de 1980. Estas e outras abordagens sub-simbólicas, como sistemas de fuzzy e computação evolucionária, são agora estudados coletivamente pela disciplina emergente inteligência computacional. A IA tipo fraca, limitada, ou estreita (em inglês Narrow AI) são máquinas ou sistemas inteligentes que não fazem raciocínio; é limitada porque foi projetada para fazer uma tarefa específica, após ser treinado por um humano. Ou seja, não aprende de forma autônoma. Como por exemplo reconhecer comandos de voz e encontrar a rota mais rápida. A AGI possui a habilidade de compreender e adaptar-se a vários contextos (e desafios) de forma autônoma sem a necessidade treinamento. Máquinas com inteligência versátil semelhante à"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_26", "text": "mais rápida. A AGI possui a habilidade de compreender e adaptar-se a vários contextos (e desafios) de forma autônoma sem a necessidade treinamento. Máquinas com inteligência versátil semelhante à humana, aprende de forma autônoma. Considerada o futuro da IA (especulação), com a criação de máquinas com capacidade de tomar decisões e analisar dados de forma extremamente rápida, superando a IA forte. Conseguem responder rapidamente as tarefas imediatas, mas não conseguem armazenar memória, não melhoraram sua funcionalidade com a experiência (não aprendem). Como por exemplo o mecanismo de recomendação da Netflix, que analisa o histórico do usuário para sugerir um filme/série. É um subcampo da inteligência artificial, na qual uma máquina aprende, ou seja, é ensinada a partir de algoritmos a realizar uma tarefa determinada, entendendo um padrão. Uma estrutura computacional inspirado na estrutura neural do ser humano para simular o cérebro humano, como por exemplo o algoritmo usado no"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_27", "text": "a realizar uma tarefa determinada, entendendo um padrão. Uma estrutura computacional inspirado na estrutura neural do ser humano para simular o cérebro humano, como por exemplo o algoritmo usado no buscador do Google; esta reconhece os termos pesquisados, busca os sinônimos e, assuntos relacionados para assim gerar melhores resultados. É um sistema inteligente com habilidade de interpretar as emoções de pessoas e animais. Um termo emprestado da psicologia, que é a habilidade dos humanos de ler as emoções dos outros e prever ações. Autoconsciente ou ponto de singularidade da IA ou, como defende a academia, senciência da IA, é um estágio hipotético da inteligência artificial em que as máquinas possuem autoconsciência. Um estágio além da teoria da mente e é um dos objetivos finais no desenvolvimento da IA. A investigação recente destaca também os impactos económicos e sociais associados a sistemas de IA avançados, incluindo a automatização de empregos, a concentração de poder tecnológico"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_28", "text": "da IA. A investigação recente destaca também os impactos económicos e sociais associados a sistemas de IA avançados, incluindo a automatização de empregos, a concentração de poder tecnológico e riscos éticos ligados a uma eventual senciência. Estes fatores têm motivado debates académicos sobre regulação, governança e segurança no desenvolvimento da inteligência artificial. Permite que as máquinas/sistemas conversem com os humanos usando a linguagem humana, como por exemplo o uso da Alexa e da Siri. Os assistentes pessoais fazem parte da Inteligência Artificial Estreita (ANI), limitação da IA de executar um conjunto de tarefas específicas. Os sistemas de navegação fazem tarefas bem definidas, como encontrar a rota mais rápida de um ponto a outro. Faz analise e descreve imagens e vídeos, podendo reconhecer objetos e detectar movimentos, mapear um ambiente físico. São máquinas ou sistemas inteligentes usados na indústria , que possuem a capacidade de tomar decisões/fazer ações"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_29", "text": "vídeos, podendo reconhecer objetos e detectar movimentos, mapear um ambiente físico. São máquinas ou sistemas inteligentes usados na indústria , que possuem a capacidade de tomar decisões/fazer ações programadas a partir da coleta de informações do ambiente (como por exemplo a umidade e a temperatura). Capacidade de identificar objetos e capacidade de navegar em diferentes ambientes de forma autônoma, como por exemplo a Figure AI que está construindo robôs humanoides bípedes para trabalharem com os humanos. IA que é cria voz humana realista, transformando texto em voz, modificação do timbre, entonação da fala e, velocidade da voz. São sistemas inteligentes que conseguem criar roteiros, poesias, imagens e vídeos, não limitado apenas em analisar dados. Entre os teóricos que estudam o que é possível fazer com a IA existe uma discussão onde se consideram duas propostas básicas: uma conhecida como \"forte\" e outra conhecida como \"fraca\". Basicamente, a hipótese da IA forte considera ser"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_30", "text": "é possível fazer com a IA existe uma discussão onde se consideram duas propostas básicas: uma conhecida como \"forte\" e outra conhecida como \"fraca\". Basicamente, a hipótese da IA forte considera ser possível criar uma máquina consciente, ou seja, afirma que os sistemas artificiais devem replicar a mentalidade humana. A investigação em Inteligência Artificial Forte aborda a criação da forma de inteligência baseada em computador que consiga raciocinar e resolver problemas; uma forma de IA forte é classificada como auto-consciente. A IA forte é tema bastante controverso, pois envolve temas como consciência e fortes problemas éticos ligados ao que fazer com uma entidade que seja cognitivamente indistinguível de seres humanos. A ficção científica tratou de muitos problemas desse tipo. Isaac Asimov, por exemplo, escreveu O Homem Bicentenário, onde um robô consciente e inteligente luta para possuir um status semelhante ao de um humano na sociedade. E Steven Spielberg dirigiu \"A.I."}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_31", "text": "Isaac Asimov, por exemplo, escreveu O Homem Bicentenário, onde um robô consciente e inteligente luta para possuir um status semelhante ao de um humano na sociedade. E Steven Spielberg dirigiu \"A.I. Inteligência Artificial\" onde um garoto-robô procura conquistar o amor de sua \"mãe\", procurando uma maneira de se tornar real. Por outro lado, o mesmo Asimov reduz os robôs a servos dos seres humanos ao propor as três leis da robótica. Stephen Hawking alertou sobre os perigos da inteligência artificial e considerou uma ameaça à sobrevivência da humanidade (ver: Rebelião das máquinas). Trata-se da noção de como lidar com problemas não determinísticos. Uma contribuição prática de Alan Turing foi o que se chamou depois de Teste de Turing (TT), de 1950: em lugar de responder à pergunta \"podem-se ter computadores inteligentes?\" ele formulou seu teste, que se tornou praticamente o ponto de partida da pesquisa em \"Inteligência Artificial\". O teste consiste em se fazer perguntas a uma pessoa e um"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_32", "text": "computadores inteligentes?\" ele formulou seu teste, que se tornou praticamente o ponto de partida da pesquisa em \"Inteligência Artificial\". O teste consiste em se fazer perguntas a uma pessoa e um computador escondidos. Um computador e seus programas passam no TT se, pelas respostas, for impossível a alguém distinguir qual interlocutor é a máquina e qual é a pessoa. No seu artigo original ele fez a previsão de que até 2000 os computadores passariam seu teste. Pois bem, há um concurso anual de programas para o TT, e o resultado dos sistemas ganhadores é tão fraco (o último tem o nome \"Ella\") que com poucas perguntas logo percebe-se as limitações das respostas da máquina. É interessante notar que tanto a Máquina de Turing quanto o Teste de Turing talvez derivem da visão que Turing tinha de que o ser humano é uma máquina. Há quem diga que essa visão está absolutamente errada, do ponto de vista linguístico, já que associamos à \"máquina\" um artefato inventado e eventualmente construído."}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_33", "text": "que o ser humano é uma máquina. Há quem diga que essa visão está absolutamente errada, do ponto de vista linguístico, já que associamos à \"máquina\" um artefato inventado e eventualmente construído. Dizem eles: \"Nenhum ser humano foi inventado ou construído\". Afirma-se ainda que a comparação, feita por Turing, entre o homem e a máquina é sinônimo de sua \"ingenuidade social\", pois as máquinas são infinitamente mais simples do que o homem, apesar de, paradoxalmente, se afirmar que a vida é complexa. No entanto, esta linha de raciocínio é questionável, afinal de contas, os computadores modernos podem ser considerados \"complexos\" quando comparados ao COLOSSUS (computador cujo desenvolvimento foi liderado por Tommy Flowers, em 1943), ou a qualquer máquina do início do século XX. A inteligência artificial fraca centra a sua investigação na criação de inteligência artificial que não é capaz de verdadeiramente raciocinar e resolver problemas. Uma tal máquina com esta característica de"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_34", "text": "artificial fraca centra a sua investigação na criação de inteligência artificial que não é capaz de verdadeiramente raciocinar e resolver problemas. Uma tal máquina com esta característica de inteligência agiria como se fosse inteligente, mas não tem autoconsciência ou noção de si. O teste clássico para aferição da inteligência em máquinas é o Teste de Turing. Há diversos campos dentro da IA fraca, e um deles é o Processamento de linguagem natural, que trata de estudar e tentar reproduzir os processos de desenvolvimento que resultaram no funcionamento normal da língua. Muitos destes campos utilizam softwares específicos e linguagens de programação criadas para suas finalidades. Um exemplo é o chatbot Eliza, desenvolvido por Joseph Weizenbaum no laboratório de Inteligência Artificial do MIT entre os anos de 1964 e 1966. Outro exemplo bastante conhecido é o programa A.L.I.C.E. (Artificial Linguistic Internet Computer Entity, ou Entidade Computadorizada de Linguagem Artificial para"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_35", "text": "do MIT entre os anos de 1964 e 1966. Outro exemplo bastante conhecido é o programa A.L.I.C.E. (Artificial Linguistic Internet Computer Entity, ou Entidade Computadorizada de Linguagem Artificial para Internet), um software que simula uma conversa humana. Programado em Java e desenvolvido com regras heurísticas para os caracteres de conversação, seu desenvolvimento resultou na AIML (Artificial Intelligence Markup Language), uma linguagem específica para tais programas e seus vários clones, chamados de Alicebots. Muito do trabalho neste campo tem sido feito com simulações em computador de inteligência baseado num conjunto predefinido de regras. Poucos têm sido os progressos na IA forte. Mas dependendo da definição de IA utilizada, pode-se dizer que avanços consideráveis na IA fraca já foram alcançados. Muitos filósofos, sobretudo John Searle e Hubert Dreyfus, inseriram no debate questões de ordem filosófica e epistemológica, questionando qualquer possibilidade efetiva da IA forte."}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_36", "text": "foram alcançados. Muitos filósofos, sobretudo John Searle e Hubert Dreyfus, inseriram no debate questões de ordem filosófica e epistemológica, questionando qualquer possibilidade efetiva da IA forte. Seriam falsos, assim, os próprios pressupostos da construção de uma inteligência ou consciência semelhante à humana em uma máquina. Searle é bastante conhecido por seu contra-argumento sobre o Quarto Chinês (ou Sala Chinesa), que inverte a questão colocada por Minsky a respeito do Teste de Turing. Seu argumento diz que ainda que uma máquina possa parecer falar chinês por meio de recursos de exame comparativo com mostras e tabelas de referência, binárias, isso não implica que tal máquina fale e entenda efetivamente a língua. Ou seja, demonstrar que uma máquina possa passar no Teste de Turing não necessariamente implica um ser consciente, tal como entendido em seu sentido humano. Dreyfus, em seu livro O que os computadores ainda não conseguem fazer: Uma crítica ao raciocínio artificial,"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_37", "text": "não necessariamente implica um ser consciente, tal como entendido em seu sentido humano. Dreyfus, em seu livro O que os computadores ainda não conseguem fazer: Uma crítica ao raciocínio artificial, argumenta que a consciência não pode ser adquirida por sistemas baseados em regras ou lógica; tampouco por sistemas que não façam parte de um corpo físico. No entanto, este último autor deixa aberta a possibilidade de um sistema robótico baseado em Redes Neuronais, ou em mecanismos semelhantes, alcançar a inteligência artificial. Mas já não seria a referida IA forte, mas sim um correlato bem mais próximo do que se entende por IA fraca. Os revezes que a acepção primeira de Inteligência Artificial vem levando nos últimos tempos contribuíram para a imediata relativização de todo seu legado. O papel de Marvin Minsky, figura proeminente do MIT e autor de Sociedade da Mente, fora central para a acepção de uma IA linear que imitaria com perfeição a mente humana, mas seu principal feito foi"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_38", "text": "O papel de Marvin Minsky, figura proeminente do MIT e autor de Sociedade da Mente, fora central para a acepção de uma IA linear que imitaria com perfeição a mente humana, mas seu principal feito foi construir o primeiro computador baseado em redes neurais, conhecido como Snark, tendo simplesmente fracassado pois nunca executou qualquer função interessante, apenas consumiu recursos de outras pesquisas mais promissoras. O primeiro neuro computador a obter sucesso (Mark I Perceptron) surgiu em 1957 e 1958, criado por Frank Rosenblatt, Charles Wightman e outros. Atualmente, no entanto, as vertentes que trabalham com os pressupostos da emergência e com elementos da IA fraca parecem ter ganhado proeminência do campo. As críticas sobre a impossibilidade de criar uma inteligência em um composto artificial podem ser encontradas em Jean-François Lyotard (O Pós-humano) e Lucien Sfez (Crítica da Comunicação); uma contextualização didática do debate encontra-se em Sherry Turkle (O segundo Eu: os"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_39", "text": "artificial podem ser encontradas em Jean-François Lyotard (O Pós-humano) e Lucien Sfez (Crítica da Comunicação); uma contextualização didática do debate encontra-se em Sherry Turkle (O segundo Eu: os computadores e o espírito humano). Pode-se resumir o argumento central no fato de que a própria concepção de inteligência é humana e, nesse sentido, animal e biológica. A possibilidade de transportá-la para uma base plástica, artificial, encontra um limite claro e preciso: se uma inteligência puder ser gerada a partir destes elementos, deverá ser necessariamente diferente da humana, na medida em que o seu resultado provém da emergência de elementos totalmente diferentes dos encontrados nos humanos. A inteligência, tal como a entendemos, é essencialmente o fruto do cruzamento da uma base biológica com um complexo simbólico e cultural, impossível de ser reproduzido artificialmente. Outros filósofos sustentam visões diferentes. Ainda que não vejam problemas com a IA fraca, entendem que há"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_40", "text": "com um complexo simbólico e cultural, impossível de ser reproduzido artificialmente. Outros filósofos sustentam visões diferentes. Ainda que não vejam problemas com a IA fraca, entendem que há elementos suficientes para se crer na IA forte também. Daniel Dennett argumenta em Consciência Explicada que se não há uma centelha mágica ou alma nos seres humanos, então o Homem é apenas uma outra máquina. Dennett questiona por que razão o Homem-máquina deve ter uma posição privilegiada sobre todas as outras possíveis máquinas quando provido de inteligência. Alguns autores sustentam que se a IA fraca é possível, então também o é a forte. O argumento da IA fraca, de uma inteligência imitada mas não real, desvelaria assim uma suposta validação da IA forte. Isso se daria porque, tal como entende Simon Blackburn em seu livro Think, dentre outros, não existe a possibilidade de verificar se uma inteligência é verdadeira ou não. Estes autores argumentam que toda inteligência apenas parece"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_41", "text": "Simon Blackburn em seu livro Think, dentre outros, não existe a possibilidade de verificar se uma inteligência é verdadeira ou não. Estes autores argumentam que toda inteligência apenas parece inteligência, sem necessariamente o ser. Parte-se do princípio que é impossível separar o que é inteligência de fato do que é apenas simulação: apenas acredita-se ser. Estes autores rebatem os argumentos contra a IA forte dizendo que seus críticos reduzem-se a arrogantes que não podem entender a origem da vida sem uma centelha mágica, um Deus ou uma posição superior qualquer. Eles entenderiam, em última instância, máquina como algo essencialmente incapaz e sequer conseguem supô-la como capaz de inteligência. Nos termos de Minsky, a crítica contra a IA forte erra ao supor que toda inteligência derive de um sujeito - tal como indicado por Searle - e assim desconsidera a possibilidade de uma maquinaria complexa que pudesse pensar. Mas Minsky desconsidera o simples fato de que os maiores avanços na"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_42", "text": "de um sujeito - tal como indicado por Searle - e assim desconsidera a possibilidade de uma maquinaria complexa que pudesse pensar. Mas Minsky desconsidera o simples fato de que os maiores avanços na área foram conseguidos com \"maquinaria complexa\", também chamada por pesquisadores mais importantes de Inteligência Artificial Conexista. Se a crítica de Minsky fosse válida a maquina criada por Rosenblatt e Bernard Widrow não estaria em uso ainda hoje, e o Mark I Perceptron não seria o fundador da neuro-computação. Alguns pesquisadores importantes afirmam que um dos motivos das críticas de Minsky foi o fato de ter falhado com Snark. A partir daí começou a criticar essa área por não compreende-la completamente, prejudicando desde então pesquisas importantes sobre o assunto. O debate sobre a IA reflete, em última instância, a própria dificuldade da ciência contemporânea em lidar efetivamente com a ausência de um primado superior. Os argumentos pró-IA forte são esclarecedores dessa questão,"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_43", "text": "reflete, em última instância, a própria dificuldade da ciência contemporânea em lidar efetivamente com a ausência de um primado superior. Os argumentos pró-IA forte são esclarecedores dessa questão, pois são os próprios cientistas, que durante décadas tentaram e falharam ao criar uma IA forte, que ainda procuram a existência de uma ordem superior. Ainda que a IA forte busque uma ordem dentro da própria conjugação dos elementos internos, trata-se ainda da suposição de que existe na inteligência humana uma qualidade superior que deve ser buscada, emulada e recriada. Reflete, assim, a difícil digestão do legado radical da Teoria da Evolução, onde não existe positividade alguma em ser humano e ser inteligente; trata-se apenas de um complexo de relações que propiciaram um estado particular, produto de um cruzamento temporal entre o extrato biológico e uma complexidade simbólica. É argumentado também que a inteligência artificial ainda não é desenvolvida ao ponto de atuar como o cérebro"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_44", "text": "produto de um cruzamento temporal entre o extrato biológico e uma complexidade simbólica. É argumentado também que a inteligência artificial ainda não é desenvolvida ao ponto de atuar como o cérebro humano, de forma criativa. Ademais, o cérebro humano ainda não é suficientemente compreendido. Portanto, a ideia de replicar funções do cérebro humano é atualmente intangível. A IA pode ser uma arma quando usada por pessoas mal-intencionadas, como por exemplo o uso da ferramenta deepfake para golpe. A criação destes sistemas podem gerar vazamento de dados ou acidentes com veículos autônomos. Foi provado que um simulador qualitativo, completo e robusto não pode existir, ou seja, desde que o vocabulário entrada-saída seja usado (como num algoritmo QSIM), haverá sempre modelos de entrada que causam predições erradas na sua saída. Por exemplo, a noção de infinito é impossível ser tida por uma máquina finita (computador ou neurónios se produzirem apenas um número finito de resultados num número"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_45", "text": "predições erradas na sua saída. Por exemplo, a noção de infinito é impossível ser tida por uma máquina finita (computador ou neurónios se produzirem apenas um número finito de resultados num número finito de tempo). Neste caso é um simples paradoxo matemático, porque são em número finito as combinações saídas de qualquer conjunto finito. Se a noção de infinito pudesse ser obtida por uma certa combinação finita, isso significaria que o infinito seria equivalente a essa sequência finita, o que é obviamente uma contradição. Por isso, o infinito e outras noções abstratas têm que ser pré-adquiridas numa máquina finita, não são aí programáveis. A inteligência artificial, em um contexto amplo, possui aplicações diversas, sendo empregada na resolução de problemas práticos por entidades civis, governamentais, e militares. Possui aplicações na área da saúde, mídia e comércio eletrônico, entre outros. Há uma discussão sobre como a IA tem sido integrada em sistemas de planejamento automatizado,"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_46", "text": "e militares. Possui aplicações na área da saúde, mídia e comércio eletrônico, entre outros. Há uma discussão sobre como a IA tem sido integrada em sistemas de planejamento automatizado, diagnóstico médico, utilização por advogados (IA para advogados), reconhecimento de linguagem e muito mais, mostrando a ampla gama de aplicações e o impacto profundo da IA em múltiplas áreas. A adoção ggeberalizada da inteligência artificial levanta preocupações quanto ao seu impacto no emprego e na distribuição de riqueza. Vários estudos recentes indicam que a automação de tarefas cognitivas e rotineiras pode levar ao deslocamento de trabalhadores em setores como transporte, serviços financeiros, atendimento ao cliente entre outros. Entre as funções com maior probabilidade de extinção, a literatura destaca tarefas como produção de conteúdo padronizado, atendimento e vendas roteirizadas, backoffice administrativo, contabilidade simples, análise repetitiva de risco, programação elementar, design"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_47", "text": "destaca tarefas como produção de conteúdo padronizado, atendimento e vendas roteirizadas, backoffice administrativo, contabilidade simples, análise repetitiva de risco, programação elementar, design baseadado em modelos, mediação transacional, formação padronizada, suporte técnico básico, revisão e formatação textual, pesquisa documental simples, edição de imagem para comércio eletrónico e até memdo o comércio electrónico na parte da fixação de preços, descrições automáticas de produtos, relatórios de gestão recorrentes, prospeção de leads genéricos, curadoria de catálogos e auditorias baseadas em listas de verificação. A concentração de capacidades tecnológicas em poucas empresas e países também é alvo de debate, dado o risco de aprofundar desigualdades económicas e sociais. Estas questões têm impulsionado propostas para políticas de requalificação profissional, regulação de algoritmos e desenvolvimento ético da IA, de modo a equilibrar eficiência tecnológica e justiça social."}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_48", "text": "questões têm impulsionado propostas para políticas de requalificação profissional, regulação de algoritmos e desenvolvimento ético da IA, de modo a equilibrar eficiência tecnológica e justiça social. Atualmente existem diversos pesquisadores de IA ao redor do mundo em várias instituições e companhias de pesquisa. Entre os muitos que fizeram contribuições significativas estão: O matemático britânico Alan Turing foi um dos pioneiros na área que mais tarde daria origem à Inteligência artificial. Além de ter criado o “Teste de Turing”, usado para avaliar a capacidade de uma máquina imitar respostas humanas, os seus trabalhos em lógica matemática e computação teórica estabeleceram as bases para a ciência da computação moderna. Matemático, cientista, o criador do termo “inteligência artificial” e também o pai da linguagem de programação LISP. McCarthy foi considerado um dos primeiros homens a trabalhar no desenvolvimento da inteligência artificial e sempre disse que ela deveria interagir"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_49", "text": "e também o pai da linguagem de programação LISP. McCarthy foi considerado um dos primeiros homens a trabalhar no desenvolvimento da inteligência artificial e sempre disse que ela deveria interagir com o homem. Nascido na cidade de Boston, trabalhou na Universidade de Stanford e no Massachusetts Institute of Technology (MIT), além de ter vencido o prêmio Turing em 1972 e a Medalha Nacional de Ciência em 1991. Já a programação LISP, uma das maiores conquistas de McCarthy, surgiu em 1958 e serviu para facilitar o desenvolvimento da inteligência artificial. A linguagem é das mais antigas ainda em uso e foi usada pela primeira vez ao colocar um computador para jogar xadrez contra um adversário humano. Natural de Nova Iorque, onde nasceu, o cientista recebeu diversos prémios internacionais pelo seu trabalho pioneiro no campo da inteligência artificial, incluindo em 1969, o Prêmio Turing, o maior prêmio em ciência informática. O cientista explorou a forma de dotar as máquinas de percepção e"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_50", "text": "seu trabalho pioneiro no campo da inteligência artificial, incluindo em 1969, o Prêmio Turing, o maior prêmio em ciência informática. O cientista explorou a forma de dotar as máquinas de percepção e inteligência semelhantes à humana, criou mãos robóticas com capacidade para manipular objetos, desenvolveu novos marcos de programação e escreveu sobre assuntos filosóficos relacionados com a inteligência artificial. Minsky estava convencido de que o homem, um dia, desenvolveria máquinas que competiriam com a sua inteligência e via o cérebro como uma máquina cujo funcionamento pode ser estudado e reproduzido num computador, o que poderia ajudar a compreender melhor o cérebro humano e as funções mentais superiores. Informático indiano naturalizado estadunidense, foi o primeiro asiático a vencer o Prêmio Turing. Entre suas contribuições para a IA estão a criação do Instituto de Robótica da CMU e demonstrações de diversos sistemas que usam alguma forma de IA. Entre esses sistemas, estão"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_51", "text": "o Prêmio Turing. Entre suas contribuições para a IA estão a criação do Instituto de Robótica da CMU e demonstrações de diversos sistemas que usam alguma forma de IA. Entre esses sistemas, estão sistemas de: fala, controlados por voz, reconhecimento de voz, reconhecimento de voz independente do interlocutor, etc. Para Reddy, ao invés de substituir a humanidade, a tecnologia irá criar um novo tipo de humano que irá coexistir com seus antecessores enquanto se aproveita das vantagens de uma nova classe de ferramentas viabilizada pela tecnologia. Winograd é um cientista da computação estadunidense, professor da Universidade Stanford, e codiretor do grupo de interação humano-computador de Stanford. É conhecido nas áreas de filosofia da mente e inteligência artificial por seu trabalho sobre língua natural usando o programa SHRDLU. Para Terry, não restam dúvidas de que a tecnologia da informática, mais precisamente a área de inteligência artificial, transformará as sociedades, introduzindo"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_52", "text": "natural usando o programa SHRDLU. Para Terry, não restam dúvidas de que a tecnologia da informática, mais precisamente a área de inteligência artificial, transformará as sociedades, introduzindo modificações socioeconômicas irreversíveis. Esse especialista procura saber se os seres humanos seriam capazes de construir máquinas que poderiam compreende-los, resolver seus problemas e dirigir suas vidas, além de buscar respostas sobre o que aconteceria se, algum dia, essas máquinas se tornassem mais inteligentes do que os próprios humanos que as criaram. Nascido na Filadélfia, Pensilvânia, se formou na Universidade da Pensilvânia. Douglas Bruce Lenat é o Diretor Executivo do Cycorp e foi também um pesquisador proeminente em inteligência artificial, recebendo o prêmio bianual IJCAI Computers and Thought em 1976 pela criação do programa de aprendizado de máquinas. Ele também trabalhou em simulações militares e em numerosos projetos para organizações governamentais, militares, científicas e"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_53", "text": "Thought em 1976 pela criação do programa de aprendizado de máquinas. Ele também trabalhou em simulações militares e em numerosos projetos para organizações governamentais, militares, científicas e de inteligência dos EUA. A missão de Lenat, no longo ciclo do projeto Cyc, iniciado em 1984, era de construir a base de uma inteligência artificial geral ao representar manualmente o conhecimento como axiomas lógicos contextualizados na linguagem formal com base em extensões ao cálculo de predicados de primeira ordem e em seguida, usar esse enorme motor de inferência de ontologia e a base de conhecimento contextualizada como um viés indutivo para automatizar e acelerar cada vez mais a educação contínua do próprio Cyc, via aprendizagem em máquina e compreensão da linguagem natural. Ablação (inteligência artificial) Alinhamento da inteligência artificial Lista de projetos de inteligência artificial Segurança da inteligência artificial OpenAI OpenAI Codex Realidade simulada Robocode"}
{"source": "Inteligência artificial", "chunk_id": "Inteligência artificial_54", "text": "(inteligência artificial) Alinhamento da inteligência artificial Lista de projetos de inteligência artificial Segurança da inteligência artificial OpenAI OpenAI Codex Realidade simulada Robocode Transferência de energia sem fio «Programa do governo para defender suas questões». (em português) «American Association for Artificial Intelligence» (em inglês) História da IA no YouTube"}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_0", "text": "O aprendizado automático (português brasileiro) ou a aprendizagem automática (português europeu) ou também aprendizado de máquina (português brasileiro) ou aprendizagem de máquina (português europeu) (em inglês: machine learning) é um subcampo da Engenharia e da ciência da computação que evoluiu do estudo de reconhecimento de padrões e da teoria do aprendizado computacional em inteligência artificial. Em 1959, Arthur Samuel definiu aprendizado de máquina como o \"campo de estudo que dá aos computadores a habilidade de aprender sem serem explicitamente programados\"(livre tradução). O aprendizado automático explora o estudo e construção de algoritmos que podem aprender de seus erros e fazer previsões sobre dados. Tais algoritmos operam construindo um modelo a partir de inputs amostrais a fim de fazer previsões ou decisões guiadas pelos dados ao invés de simplesmente seguindo inflexíveis e estáticas instruções programadas. Enquanto que na inteligência artificial existem dois tipos de"}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_1", "text": "fim de fazer previsões ou decisões guiadas pelos dados ao invés de simplesmente seguindo inflexíveis e estáticas instruções programadas. Enquanto que na inteligência artificial existem dois tipos de raciocínio (o indutivo, que extrai regras e padrões de grandes conjuntos de dados, e o dedutivo), o aprendizado de máquina só se preocupa com o indutivo. Algumas partes do aprendizado automático estão intimamente ligadas (e muitas vezes sobrepostas) à estatística computacional; uma disciplina que foca em como fazer previsões através do uso de computadores, com pesquisas focando nas propriedades dos métodos estatísticos e sua complexidade computacional. Ela tem fortes laços com a otimização matemática, que produz métodos, teoria e domínios de aplicação para este campo. O aprendizado automático é usado em uma variedade de tarefas computacionais onde criar e programar algoritmos explícitos é impraticável. Exemplos de aplicações incluem filtragem de spam, reconhecimento ótico de caracteres"}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_2", "text": "é usado em uma variedade de tarefas computacionais onde criar e programar algoritmos explícitos é impraticável. Exemplos de aplicações incluem filtragem de spam, reconhecimento ótico de caracteres (OCR), processamento de linguagem natural, motores de busca, diagnósticos médicos, bioinformática, reconhecimento de fala, reconhecimento de escrita, visão computacional e locomoção de robôs. O aprendizado de máquinas é às vezes confundido com mineração de dados, que é um sub-campo que foca mais em análise exploratória de dados e é conhecido como aprendizado não supervisionado. No campo da análise de dados, o aprendizado de máquinas é um método usado para planejar modelos complexos e algoritmos que prestam-se para fazer predições- no uso comercial, isso é conhecido como análise preditiva. Esses modelos analíticos permitem que pesquisadores, cientistas de dados, engenheiros, e analistas possam \"produzir decisões e resultados confiáveis e repetitíveis\" e descobrir os \"insights escondidos\""}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_3", "text": "modelos analíticos permitem que pesquisadores, cientistas de dados, engenheiros, e analistas possam \"produzir decisões e resultados confiáveis e repetitíveis\" e descobrir os \"insights escondidos\" através do aprendizado das relações e tendências históricas nos dados. As contribuições para a fundação da aprendizagem automática (aprendizado de máquina) feitas pelos cientistas John Hopfield e Geoffrey Hinton foram distinguidas em 2024 com o Prémio Nobel de Física. O Comité Nobel destacou os cientistas por \"descobertas fundamentais e invenções que permitem aprendizagem automática com redes neuronais artificiais”. Tom M. Mitchell forneceu uma definição mais formal amplamente citada: \"Diz-se que um programa de computador aprende pela experiência E, com respeito a algum tipo de tarefa T e performance P, se sua performance P nas tarefas em T, na forma medida por P, melhoram com a experiência E.\" Esta definição das tarefas envolvidas no aprendizado de máquina é dada de forma fundamentalmente"}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_4", "text": "P, se sua performance P nas tarefas em T, na forma medida por P, melhoram com a experiência E.\" Esta definição das tarefas envolvidas no aprendizado de máquina é dada de forma fundamentalmente operacional, ao invés de cognitiva, seguindo a proposta de Alan Turing em seu artigo \"Computadores e inteligência\", em que a pergunta \"As máquinas são capazes de pensar?\" seja substituída pela pergunta \"As máquinas são capazes de fazer o que (nós como entidades pensantes) podemos fazer?\" As tarefas de aprendizado de máquina são tipicamente classificadas em três categorias amplas, de acordo com a natureza do \"sinal\" ou \"feedback\" de aprendizado disponível para um sistema de aprendizado. Essas categorias são: Aprendizado supervisionado: São apresentadas ao computador exemplos de entradas e saídas desejadas, fornecidas por um \"professor\". O objetivo é aprender uma regra geral que mapeia as entradas para as saídas. Aprendizado não supervisionado: Nenhum tipo de etiqueta é dado ao algoritmo de"}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_5", "text": "desejadas, fornecidas por um \"professor\". O objetivo é aprender uma regra geral que mapeia as entradas para as saídas. Aprendizado não supervisionado: Nenhum tipo de etiqueta é dado ao algoritmo de aprendizado, deixando-o sozinho para encontrar estrutura nas entradas fornecidas. O aprendizado não supervisionado pode ser um objetivo em si mesmo (descobrir novos padrões nos dados) ou um meio para atingir um fim. Aprendizado por reforço: Um programa de computador interage com um ambiente dinâmico, em que o programa deve desempenhar determinado objetivo (por exemplo, dirigir um veículo). É fornecido, ao programa, feedback quanto a premiações e punições, na medida em que é navegado o espaço do problema. Outro exemplo de aprendizado por reforço é aprender a jogar um determinado jogo apenas jogando contra um oponente. Entre o aprendizado supervisionado e o não supervisionado, está o aprendizado semi-supervisionado, em que o professor fornece um sinal de treinamento incompleto: um conjunto de"}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_6", "text": "contra um oponente. Entre o aprendizado supervisionado e o não supervisionado, está o aprendizado semi-supervisionado, em que o professor fornece um sinal de treinamento incompleto: um conjunto de dados de treinamento com algumas (muitas vezes várias) das saídas desejadas ausentes. A transdução é um caso especial deste princípio, em que o conjunto inteiro das instâncias do problema é conhecido no momento do aprendizado, mas com parte dos objetivos ausente. Entre outras categorias de problemas de aprendizado de máquina, o meta-aprendizado aprende seu próprio viés indutivo com base em experiência prévias. A robótica epigenética, elaborada para o aprendizado de robôs, gera suas próprias sequências de situações de aprendizado (também chamadas de 'currículo'), para adquirir cumulativamente repertórios de novas habilidades, através de uma auto-exploração autônoma e da interação social com professores humanos. Faz uso de técnicas como aprendizado ativo, maturação, sinergias motoras e"}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_7", "text": "repertórios de novas habilidades, através de uma auto-exploração autônoma e da interação social com professores humanos. Faz uso de técnicas como aprendizado ativo, maturação, sinergias motoras e imitação. Outra categorização de tarefas de aprendizado de máquina surge quando se considera a saída desejada em um sistema de aprendizado de máquina: Em classificação, entradas são divididas em duas ou mais classes, e o aprendiz deve produzir um modelo que vincula entradas não vistas a uma ou mais dessas classes (classificação multi-etiquetada). Isso é tipicamente abordado de forma supervisionada. A filtragem de spam é um exemplo de classificação, em que as entradas são as mensagens de emails (ou outros) e as classes são \"spam\" ou \"não spam\". Em regressão, também um problema supervisionado, as saídas são contínuas, em vez de discretas. Em clustering, um conjunto de entradas é dividido em grupos. De maneira diferente da classificação, os grupos não são conhecidos previamente, tornando o"}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_8", "text": "as saídas são contínuas, em vez de discretas. Em clustering, um conjunto de entradas é dividido em grupos. De maneira diferente da classificação, os grupos não são conhecidos previamente, tornando o clustering uma tarefa tipicamente não supervisionada. A estimativa de densidades encontra a distribuição de entradas em algum espaço. A redução dimensional simplifica as entradas ao mapeá-las para um espaço de menor dimensão. A modelagem de tópicos é um problema relacionado, em que é fornecida ao programa uma lista de documentos em linguagem natural, solicitando que encontre documentos tratando de tópicos similares. Como um esforço científico, o aprendizado de máquina cresceu a partir da busca pela inteligência artificial. Ainda nos princípios da IA como disciplina acadêmica, alguns pesquisadores já se interessavam em fazer máquinas aprenderem a partir de dados. Eles tentaram abordar o problema desde vários métodos simbólicos, assim como com o que foi então nomeado de \"rede neural"}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_9", "text": "já se interessavam em fazer máquinas aprenderem a partir de dados. Eles tentaram abordar o problema desde vários métodos simbólicos, assim como com o que foi então nomeado de \"rede neural artificial\"; estes eram majoritariamente perceptrons e outros modelos que mais tardes foram entendidos como reinvenções de modelos linear generalizados de estatística. A lógica probabilística também foi usada, especialmente em diagnósticos médicos automatizados.:488 No entanto, uma crescente ênfase na abordagem lógica, baseada em conhecimento, causou uma brecha entre a IA e o aprendizado de máquina. Sistemas probabilísticos eram atormentados por problemas teoréticos e práticos de aquisição e representação de dados.:488 Em 1980, sistemas especialistas haviam dominado a IA, e a estatística estava fora de uso. Trabalhos em aprendizado baseado em conhecimento/simbólico continuaram com a IA, levando até a programação lógica indutiva, mas agora as pesquisas mais voltadas para a estatística estavam fora do"}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_10", "text": "Trabalhos em aprendizado baseado em conhecimento/simbólico continuaram com a IA, levando até a programação lógica indutiva, mas agora as pesquisas mais voltadas para a estatística estavam fora do campo da IA, em reconhecimento de padrões e recuperação de informação.:708–710; 755 Pesquisas em redes neuronais haviam sido abandonadas pela IA e ciência computacional em torno do mesmo período. Essa linha, também, foi continuada forma dos campos da IA e da ciência da computação, como \"conexionismos\", por pesquisadores de outras disciplinas incluindo Hopfield, Rumelhart e Hinton. Seu sucesso principal veio em meados da década de 1980 com a reinvenção da propagação para trás.:25 O aprendizado de máquina, reorganizado como um campo separado, começou a florescer na década de 1990. O campo mudou seu objetivo de alcançar a inteligência artificial para abordar problemas solucionáveis de natureza prática. Ele abandonou o foco em abordagens simbólicas que havia herdado da IA para métodos e modelos"}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_11", "text": "objetivo de alcançar a inteligência artificial para abordar problemas solucionáveis de natureza prática. Ele abandonou o foco em abordagens simbólicas que havia herdado da IA para métodos e modelos emprestados da estatística e da teoria da probabilidade. Ele também se beneficiou do crescente número de informação digitalizada disponível e a possibilidade de distribuir ela via internet. O aprendizado de máquina e a mineração de dados com freqüência fazem uso dos mesmos métodos e se sobrepõe significativamente, mas enquanto o aprendizado de máquina foca em fazer previsões, baseado em propriedades conhecidas aprendidas pelo dados de treinamento, a mineração de dados foca em descobrir as propriedades (previamente) desconhecidas nos dados (este é o passo dado na análise de extração de conhecimento na base de dados). A mineração de dados usa muitas métodos do aprendizado de máquina, mas com objetivos diferentes; por outro lado, o aprendizado de máquina também faz uso de métodos da mineração"}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_12", "text": "na base de dados). A mineração de dados usa muitas métodos do aprendizado de máquina, mas com objetivos diferentes; por outro lado, o aprendizado de máquina também faz uso de métodos da mineração de dados como \"aprendizado não supervisionado\" ou como um passo de processamento para melhorar a precisão do aprendiz. Muita da confusão entre essas duas comunidades de pesquisa (que com freqüência tem conferências e periódicos separados, ECML PKDD sendo a grande exceção) vem da suposição básica com que eles trabalham: em aprendizado de máquina, a performance é normalmente avaliada com respeito a habilidade de reproduzir conhecimento conhecido, enquanto que com a extração de conhecimento e mineração de dados (KDD) a tarefa chave é o descobrimento de conhecimento previamente desconhecido. Avaliado com respeito ao conhecimento conhecido, um método uniforme (não supervisionado) será facilmente superado por outros métodos supervisionados, enquanto que em uma tarefa KDD típica, métodos"}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_13", "text": "Avaliado com respeito ao conhecimento conhecido, um método uniforme (não supervisionado) será facilmente superado por outros métodos supervisionados, enquanto que em uma tarefa KDD típica, métodos supervisionados não podem ser usados devido a não disponibilidade de dados de treinamento. O aprendizado de máquina também tem laços íntimos com a otimização: muitos dos problemas de aprendizado são formulados como minimização de algumas funções de perda em um conjunto exemplo de treinamentos. Funções de perda expressam a discrepância entre as previsões do modelo sendo treinado e as verdadeiras instâncias do problema (por exemplo, em classificação, o objetivo é designar etiquetas para instâncias, e modelos são treinados para predizer corretamente as etiquetas previamente designadas de um conjunto exemplo). A diferença entre os dois campos surge do objetivo da generalização: enquanto que o algoritmo de otimização pode minimizar a perda em um conjunto de treinamento, o aprendizado de máquina"}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_14", "text": "exemplo). A diferença entre os dois campos surge do objetivo da generalização: enquanto que o algoritmo de otimização pode minimizar a perda em um conjunto de treinamento, o aprendizado de máquina está preocupado com a minimização da perda de amostras não vistas. O aprendizado de máquina e a estatística são campos intimamente relacionados. De acordo com Michael I. Jordan, as ideias do aprendizado de máquina, dos princípios metodológicos às ferramentas teóricas, tem uma longa pré-história na estatística. Ele também sugeriu o termo ciência de dados como um substituto para chamar o campo como um todo. Leo Breiman distinguiu dois paradigmas da modelagem estatística: modelo de dados e modelo algorítmico, onde \"modelo algorítmico\" significa mais ou menos os algoritmos do aprendizado de máquina como a Floresta aleatória. Alguns estatísticos tem adotado métodos do aprendizado de máquinas, levando ao campo combinado que eles chamam de aprendizado estatístico. Um dos objetivos centrais de um"}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_15", "text": "como a Floresta aleatória. Alguns estatísticos tem adotado métodos do aprendizado de máquinas, levando ao campo combinado que eles chamam de aprendizado estatístico. Um dos objetivos centrais de um aprendiz é generalizar a partir de suas experiências. Generalização neste contexto é a habilidade de uma máquina aprendiz de desempenhar com precisão em novos, não vistos, exemplos/tarefas depois de ter experimentado um conjunto de dados de aprendizado. Os exemplos de treinamento vem de algumas, geralmente desconhecidas, distribuições de probabilidade (consideradas representativas do espaço de ocorrência) e o aprendiz tem de construir um modelo geral sobre este espaço que o permita produzir previsões o suficientemente precisas em novos casos. A análise computacional de algoritmos de aprendizado de máquina e sua performance é um ramo da ciência da computação teórica conhecida como teoria do aprendizado computacional. Porque os conjuntos de treinamento são finitos e o futuro é incerto, a"}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_16", "text": "de máquina e sua performance é um ramo da ciência da computação teórica conhecida como teoria do aprendizado computacional. Porque os conjuntos de treinamento são finitos e o futuro é incerto, a teoria de aprendizado normalmente não guarda garantias para a performance dos algoritmos. Em vez disso,previsões probabilísticas para a performance são bastante comuns. O trade-off entre variância e viés é uma forma de qualificar o erro de generalização. Para uma melhor performance no contexto de generalização, a complexidade da hipótese deveria combinar com a complexidade da função subjacente aos dados. Se a hipótese é menos complexa que a função, então o modelo sub-ajustou (underfitting) os dados. Se a complexidade do modelo é aumentada em resposta, então o erro de treinamento diminui. Mas se a hipótese é muito complexa, então o modelo foi sobreajustado (overfitting), e a generalização será mais pobre. Em adição aos limites da performance, teóricos do aprendizado computacional estudam a"}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_17", "text": "a hipótese é muito complexa, então o modelo foi sobreajustado (overfitting), e a generalização será mais pobre. Em adição aos limites da performance, teóricos do aprendizado computacional estudam a complexidade do tempo e a viabilidade do aprendizado. Na teoria do aprendizado computacional, uma computação é considerada viável se puder ser feita em tempo polinomial. Há dois tipos de resultados de complexidade temporal. Resultados positivos mostram que uma certa classe de funções pode ser aprendida em tempo polinomial. Resultados negativos mostram que certas classes não podem ser aprendidas em tempo polinomial. Aprendizado baseado em árvores de decisão usa a árvore de decisão como um modelo de previsão, o qual mapeia as observações sobre um item às conclusões sobre o valor do objetivo desse item. Aprendizado por regras de associação é um método para descobrir relações interessantes entre variáveis em base de dados grandes. Um algoritmo de aprendizado de rede neural artificial"}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_18", "text": "desse item. Aprendizado por regras de associação é um método para descobrir relações interessantes entre variáveis em base de dados grandes. Um algoritmo de aprendizado de rede neural artificial (aprendizagem de rede neuronal artificial), normalmente chamado de \"rede neural\" ou \"rede neuronal\" (RN), é um algoritmo do tipo \"machine learning\" que é inspirado na estrutura e aspectos funcionais das redes neurais biológicas. Computações são estruturadas em termos de um grupo interconectado de neurônios artificiais, processando informação usando uma abordagem de conexionismo na computação. Redes neuronais modernas são ferramentas de modelagem de dados estatísticos não lineares. Normalmente eles são usados para modelar relações complexas entre entradas e saídas, para encontrar padrões nos dados, ou para capturar a estrutura estatística em uma distribuição de probabilidade conjunta desconhecida entre variáveis observáveis. Os preços mais baixos do hardware e o desenvolvimento de GPUs para uso"}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_19", "text": "ou para capturar a estrutura estatística em uma distribuição de probabilidade conjunta desconhecida entre variáveis observáveis. Os preços mais baixos do hardware e o desenvolvimento de GPUs para uso pessoal nos últimos anos contribuiu para o desenvolvimento do conceito de aprendizado profundo, que consiste em múltiplas camadas escondidas em uma rede neural artificial. Esta abordagem tenta modelar a forma com que o cérebro humano processa luz e som na visão e escuta. Alguns aplicações úteis do aprendizado profundo são visão computacional e reconhecimento de fala. Lógica de programação indutiva (LPI) é uma abordagem que regra o aprendizado fazendo uso de programação lógica como uma representação uniforme para exemplos de inputs, conhecimento de pano de fundo, e hipóteses. Dada uma codificação do pano de fundo conhecido do conhecimento e um conjunto de exemplos representados como uma base de dados lógica de fatos, um sistema LPI derivará uma lógica hipotética que envolve todos os"}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_20", "text": "do pano de fundo conhecido do conhecimento e um conjunto de exemplos representados como uma base de dados lógica de fatos, um sistema LPI derivará uma lógica hipotética que envolve todos os exemplos positivos e não negativos. A programação indutiva é um campo relacionado que considera qualquer tipo de linguagem de programação para representar hipóteses (e não apenas programações lógicas), tais como as programações funcionais. Máquinas de vetores de suporte (MVSs) são um conjunto relacionado de métodos de aprendizado supervisionado usados para classificação e regressão. Dado um conjunto de exemplos de treinamento, cada um marcado como pertencente de uma ou duas categorias, um algoritmo de treino SVM constrói um modelo que prediz se um novo exemplo cai dentro de uma categoria ou outra. Análise de clusters é a atribuição de um conjunto de observações à subconjuntos (chamados clusters) de forma que as observações dentro de um mesmo cluster são similares de acordo com algum critério ou"}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_21", "text": "de clusters é a atribuição de um conjunto de observações à subconjuntos (chamados clusters) de forma que as observações dentro de um mesmo cluster são similares de acordo com algum critério ou critérios pré-designados, enquanto que observações feitas em clusters diferentes não são similares. Diferentes técnicas de clustering fazem diferentes suposições sobre a estrutura dos dados, freqüentemente definida por algumas métricas de similaridade e avaliados, por exemplo, por compacidade interna (similaridade entre membros de um mesmo cluster) e separação entre clusters diferentes. Outros métodos são baseado em estimações de densidade e gráficos de conectividade. Clustering é um método de aprendizado não supervisionado e uma técnica comum em análise de dados estatísticos. Uma rede bayesiana, rede de opinião ou um modelo gráfico acíclico dirigido é um modelo gráfico probabilístico que representa um conjunto de variáveis aleatórias e suas independências condicionais via um grafo acíclico"}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_22", "text": "rede de opinião ou um modelo gráfico acíclico dirigido é um modelo gráfico probabilístico que representa um conjunto de variáveis aleatórias e suas independências condicionais via um grafo acíclico dirigido (GAD). Por exemplo, uma rede bayesiana poderia representar as relações probabilísticas entre doenças e sintomas. Dado um sintoma, a rede pode ser usada para computar as probabilidades da presença de várias doenças. Existem algoritmos eficientes que desempenham inferência e aprendizado. O aprendizado por reforço se preocupa com o como um agente deve agir em um ambiente de forma que maximize alguma noção de recompensa a longo tempo. Os algoritmos de aprendizado por reforço tentam encontrar a política que mapeia os estados do mundo às ações que o agente deve ter nesses estados. Aprendizado por reforço se distingue do problema do aprendizado supervisionado no sentindo em que pares de input/output corretos nunca são apresentados, nem as ações sub-ótimas são explicitamente corrigidas."}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_23", "text": "por reforço se distingue do problema do aprendizado supervisionado no sentindo em que pares de input/output corretos nunca são apresentados, nem as ações sub-ótimas são explicitamente corrigidas. Vários algoritmos de aprendizado, a maioria algoritmos de aprendizado não supervisionado, tem como objetivo descobrir melhores representações dos inputs que são dados durante o treinamento. Exemplos clássicos incluem análise de componentes principais e análise de clusters. Os algoritmos de aprendizado por representação com freqüência tentam preservar a informação e seu input mas transformando-a de forma que a torne útil, frequentemente como um passo pré-processamento antes de desempenhar classificações ou previsões, permitindo a reconstrução dos inputs vindos de dados geradores de distribuição desconhecidos, enquanto não sendo necessariamente fiel à configurações que são implausíveis sob essa distribuição. Algoritmos de aprendizado múltiplo tentam fazer isso sob a restrição de que a"}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_24", "text": "desconhecidos, enquanto não sendo necessariamente fiel à configurações que são implausíveis sob essa distribuição. Algoritmos de aprendizado múltiplo tentam fazer isso sob a restrição de que a representação aprendida é de baixa dimensão. Algoritmos de código esparso tentam fazer isso sob a restrição de que a representação aprendida é espersa (tem muitos zeros). O algoritmo de aprendizado em subespaço multilinear tem como objetivo aprender representações de baixa dimensão diretamente das representações de tensores para dados multidimensionais, sem os transformar em vetores de alta dimensão. Algoritmos de aprendizado profundo descobrem múltiplos níveis de representação, ou uma hierarquia de características, com um nível mais alto, características mais abstratas definidas em termos de (ou geradas a partir de) características de nível mais baixo. Tem sido argumentado que uma máquina inteligente é aquela que aprende uma representação que desembaraça os fatores subjacentes de variação que"}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_25", "text": "a partir de) características de nível mais baixo. Tem sido argumentado que uma máquina inteligente é aquela que aprende uma representação que desembaraça os fatores subjacentes de variação que explicam os dados observados. Neste problema, se dá a máquina aprendiz pares de exemplos que são considerados similares e pares de objetos menos similares. Então ela precisa aprender uma função de similaridade (ou uma função de distancia métrica) que possa predizer se novos objetos são similares. Isso é as vezes usado em sistemas de recomendação. Neste método, um dado é representado como uma combinação de ligar funções bases, e os coeficientes são assumidos como esparsos. Deixe x ser uma dado d-dimensional, D ser um d por n matrizes, onde cada coluna de D representa uma função base. r é o coeficiente para representar x usando D. Matematicamente, aprendizado por dicionário esparso significa resolver x ≈ D r {\\displaystyle x\\approx Dr} onde r é esparso. Falando genericamente, se assume que n é"}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_26", "text": "para representar x usando D. Matematicamente, aprendizado por dicionário esparso significa resolver x ≈ D r {\\displaystyle x\\approx Dr} onde r é esparso. Falando genericamente, se assume que n é maior que d para permitir a liberdade para uma representação esparsa. Aprender um dicionário junto com representações esparsas é fortemente NP-completo e também difícil de resolver aproximadamente. Um método heurístico popular para aprendizado por dicionário esparso é o K-SVD. Aprendizado por dicionário esparso tem sido aplicado a vários contextos. Em classificação, o problema é determinar a quais classes um dado previamente não visto pertence. Suponha que um dicionário para cada classe já tenha sido construído. Então um novo dado é associado com a classe de forma que esteja o melhor esparcialmente representado pelo dicionário correspondente. Aprendizado por dicionário esparso também tem sido aplicado a suavização de imagem. A ideia chave é que um pedaço de imagem limpa pode ser representado"}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_27", "text": "representado pelo dicionário correspondente. Aprendizado por dicionário esparso também tem sido aplicado a suavização de imagem. A ideia chave é que um pedaço de imagem limpa pode ser representado esparcialmente por um dicionário de imagem, mas o ruído não. Em mineração de dados, a detecção de anomalias (também detecção de outliers ) é a identificação de itens, eventos ou observações raros que levantam suspeitas por serem significativamente diferentes da maioria dos dados. Normalmente, os itens anômalos se referem a algum tipo de problema, como fraude bancária, defeito estrutural, problemas médicos ou erros em um texto. Anomalias são também referidas como outliers, ruído, desvios e exceções. Um algoritmo genético (AG) é uma busca heurística que imita o processo de seleção natural e usa métodos com mutação e recombinação para gerar novos genotipos na esperança de encontrar boas soluções para um dado problema. Em aprendizado de máquinas, algoritmos genéticos encontraram alguma utilidade"}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_28", "text": "com mutação e recombinação para gerar novos genotipos na esperança de encontrar boas soluções para um dado problema. Em aprendizado de máquinas, algoritmos genéticos encontraram alguma utilidade em 1980 e 1990. Vice versa, técnicas do aprendizado de máquina tem sido usadas para melhorar a performance de algoritmos genéticos e evolutivos. Aplicações para o aprendizado de máquina incluem: Em 2006, a companhia de filmes online Netflix fez a primeira competição \"Netflix Prize\" para encontrar um programa que melhor prediria as performances dos usuários e melhoraria a precisão do algoritmo de recomendação Cinematch existente em ao menos 10%. Um time composto por pesquisadores da AT&T Labs em colaboração com o time Big Chaos e Pragmatic Theory construíram um modelo conjunto para ganhar o grande prêmio em 2009 de 1 milhão de dólares. Logo após os prêmio ser concedido, a Netflix se deu conta que as avaliações dos usuários não eram as melhores indicações de seus padrões de filmes e séries"}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_29", "text": "prêmio em 2009 de 1 milhão de dólares. Logo após os prêmio ser concedido, a Netflix se deu conta que as avaliações dos usuários não eram as melhores indicações de seus padrões de filmes e séries vistos (\"tudo é recomendação\") e mudaram seu motor de recomendação. Em 2010 o Periódico do Wall Street escreveu sobre a firma de gestão de dinheiro Rebellion Research que usava o aprendizado de máquina para predizer os movimentos econômicos. O artigo descrevia a previsão da Rebellion Research sobre a crise financeira e a recuperação econômica. Em 2014 foi relatado que um algoritmo de aprendizado de máquina foi aplicado em Historia da Arte para estudar as pinturas de arte e que ele pode ter revelado influencias entre artistas previamente não reconhecidas. Em 2015, o serviço de streaming de música Spotify criou a playlist chamada Descobertas da Semana, que funciona como uma curadoria digital. O algoritmo responsável por esta playlist utiliza técnicas de Filtragem Colaborativa, Processamento de"}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_30", "text": "Spotify criou a playlist chamada Descobertas da Semana, que funciona como uma curadoria digital. O algoritmo responsável por esta playlist utiliza técnicas de Filtragem Colaborativa, Processamento de Linguagem Natural e Processamento de Sinais de Áudio através de Redes Neurais Convolucionais para compor a playlist semanalmente. Mais informações atualizadas sobre como o Spotify aborda algoritmos de inteligência artificial podem ser acessadas em entrevista recente do CEO Gustav Soderstrom. Modelos de classificação de aprendizado de máquina podem ser validados por técnicas como validação cruzada, onde os dados são divididos em conjuntos de teste e treinamento e medidas apropriadas como precisão são calculadas para ambos os conjuntos de dados e comparadas. Para além da precisão, sensibilidade (Avaliação Positiva Verdadeira) e especificidade (Avaliação Negativa Verdadeira) podem prover modos de modelos de avaliação. De forma similar, Avaliações Positivas Falsas assim como Avaliações"}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_31", "text": "(Avaliação Positiva Verdadeira) e especificidade (Avaliação Negativa Verdadeira) podem prover modos de modelos de avaliação. De forma similar, Avaliações Positivas Falsas assim como Avaliações Negativas Falsas poder ser computadas. Curvas Receptoras de Operação (CRO) em conjunto com a Área em baixo da CRO (AUC) oferecem ferramentas adicionais para a classificação de modelos de avaliação. Graus maiores de AUC estão associados a um modelo de melhor performance. Software suites contendo uma variedade de algoritmos de aprendizado de máquina incluem os seguintes: Veja também esta lista de pacotes em muitas linguagens de programação: Awesome Machine Learning. Journal of Machine Learning Research Machine Learning Neural Computation International Journal of Machine Learning and Cybernetics Conference on Neural Information Processing Systems International Conference on Machine Learning Ablação (inteligência artificial) Aprendizagem profunda Aprendizado por transferência Inteligência artificial"}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_32", "text": "on Neural Information Processing Systems International Conference on Machine Learning Ablação (inteligência artificial) Aprendizagem profunda Aprendizado por transferência Inteligência artificial Lista de projetos de inteligência artificial Redes Neurais Clustering Bioinformática Visão computacional Mineração de dados Reconhecimento de padrões Máquina de Vetores de Suporte Big data Ciência cognitiva Inteligência computacional Neurociência computacional «Conceitos sobre Aprendizado de Maquina» (PDF) Curso online no Coursera, ministrado por Andrew Ng. Utiliza GNU Octave. O curso é uma versão livre do curso da Stanford University ministrado por Ng, cujas aulas também estão disponíveis gratuitamente. Aula sobre Aprendizagem por Reforço, ministrada pelo professor Ronaldo C. Prati, Professor Adjunto da UFABC Brocardo ML, Traore I, Woungang I, Obaidat MS. \"Authorship verification using deep belief network systems\". Int J Commun Syst. 2017. doi:10.1002/dac.3259 Trevor Hasti, Robert Tibshirani"}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_33", "text": "da UFABC Brocardo ML, Traore I, Woungang I, Obaidat MS. \"Authorship verification using deep belief network systems\". Int J Commun Syst. 2017. doi:10.1002/dac.3259 Trevor Hasti, Robert Tibshirani e Jerome H. Friedman (2001). The Elements of Statistical Learning, Springer. ISBN 0-387-95284-5. Pedro Domingos (September 2015), The Master Algorithm, Basic Books, ISBN 978-0-465-06570-7 Mehryar Mohri, Afshin Rostamizadeh, Ameet Talwalkar (2012). Foundations of Machine Learning, The MIT Press. ISBN 978-0-262-01825-8. Ian H. Witten and Eibe Frank (2011). Data Mining: Practical machine learning tools and techniques Morgan Kaufmann, 664pp., ISBN 978-0-12-374856-0. David J. C. MacKay. Information Theory, Inference, and Learning Algorithms Cambridge: Cambridge University Press, 2003. ISBN 0-521-64298-1 Richard O. Duda, Peter E. Hart, David G. Stork (2001) Pattern classification (2nd edition), Wiley, New York, ISBN 0-471-05669-3. Christopher Bishop (1995). Neural Networks for Pattern Recognition,"}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_34", "text": "Richard O. Duda, Peter E. Hart, David G. Stork (2001) Pattern classification (2nd edition), Wiley, New York, ISBN 0-471-05669-3. Christopher Bishop (1995). Neural Networks for Pattern Recognition, Oxford University Press. ISBN 0-19-853864-2. Vladimir Vapnik (1998). Statistical Learning Theory. Wiley-Interscience, ISBN 0-471-03003-1. Ray Solomonoff, An Inductive Inference Machine, IRE Convention Record, Section on Information Theory, Part 2, pp., 56-62, 1957. Ray Solomonoff, \"An Inductive Inference Machine\" Um relato privado que circulou na Dartmouth Summer Research Conference sobre IA em 1956."}
{"source": "Rede neural convolucional", "chunk_id": "Rede neural convolucional_0", "text": "No contexto de inteligência artificial e aprendizagem de máquina, uma rede neural convolucional (CNN do inglês Convolutional Neural network ou ConvNet) é uma classe de rede neural artificial do tipo feed-forward, que vem sendo aplicada com sucesso no processamento e análise de imagens digitais. Uma CNN usa uma variação de perceptrons multicamada desenvolvidos de modo a demandar o mínimo pré-processamento possível. Essas redes também são conhecidas como redes neurais artificiais invariantes a deslocamento (shift invariant) ou invariantes a espaço (space invariant), em ambos os casos representadas pela sigla em inglês SIANN. As redes convolucionais são inspiradas nos processos biológicos. Nelas o padrão de conectividade entre os neurônios é inspirado na organização do córtex visual dos animais. Neurônios corticais individuais respondem a estímulos apenas em regiões restritas do campo de visão conhecidas como campos receptivos. Os campos receptivos de diferentes neurônios se sobrepõem"}
{"source": "Rede neural convolucional", "chunk_id": "Rede neural convolucional_1", "text": "Neurônios corticais individuais respondem a estímulos apenas em regiões restritas do campo de visão conhecidas como campos receptivos. Os campos receptivos de diferentes neurônios se sobrepõem parcialmente de forma a cobrir todo o campo de visão. Uma CNN tende a demandar um nivel minimo de pre-processamento quando comparada a outros algoritmos de classificação de imagens. Isso significa que a rede \"aprende\" os filtros que em um algoritmo tradicional precisariam ser implementados manualmente. Essa independencia de um conhecimento a priori e do esforço humano no desenvolvimento de suas funcionalidades basicas pode ser considerada a maior vantagem de sua aplicação. Esse tipo de rede é usada principalmente em reconhecimento de imagens e processamento de vídeo, embora já tenha sido aplicada com sucesso em experimentos envolvendo processamento de voz e linguagem natural. Na saúde usa-se esta metodologia com algoritmos específicos, recorrendo a um grande número de fotografias clínicas, para"}
{"source": "Rede neural convolucional", "chunk_id": "Rede neural convolucional_2", "text": "sucesso em experimentos envolvendo processamento de voz e linguagem natural. Na saúde usa-se esta metodologia com algoritmos específicos, recorrendo a um grande número de fotografias clínicas, para o diagnóstico da retinopatia diabética e do cancro da pele, com resultados muito precisos e comparáveis aos clínicos especializados."}
{"source": "Aprendizagem profunda", "chunk_id": "Aprendizagem profunda_0", "text": "No aprendizado de máquina, a aprendizagem profunda se concentra na utilização de redes neurais multicamadas para executar tarefas como classificação, regressão e aprendizagem de representação. O campo se inspira na neurociência biológica e é centrado em empilhar neurônios artificiais em camadas e \"treiná-los\" para processar dados. O adjetivo \"profunda\" se refere ao uso de múltiplas camadas (variando de três a várias centenas ou milhares) na rede. Os métodos usados podem ser supervisionados, semissupervisionados ou não serem supervisionados. Algumas arquiteturas comuns de redes de aprendizagem profunds incluem redes totalmente conectadas, redes de crenças profundas, redes neurais recorrentes, redes neurais convolucionais, redes adversárias generativas, transformadoras e campos de radiância neural. Essas arquiteturas foram aplicadas a campos como visão computacional, reconhecimento de fala, processamento de linguagem natural, tradução automática, bioinformática, design de medicamentos,"}
{"source": "Aprendizagem profunda", "chunk_id": "Aprendizagem profunda_1", "text": "neural. Essas arquiteturas foram aplicadas a campos como visão computacional, reconhecimento de fala, processamento de linguagem natural, tradução automática, bioinformática, design de medicamentos, análise de imagens médicas, ciência do clima, inspeção de materiais e programas de jogos de tabuleiro, onde produziram resultados comparáveis e, em alguns casos, superando o desempenho de especialistas humanos. As primeiras formas de redes neurais foram inspiradas pelo processamento de informações e nós de comunicação distribuídos em sistemas biológicos, particularmente o cérebro humano. No entanto, as redes neurais atuais não pretendem modelar a função cerebral dos organismos e são geralmente vistas como modelos de baixa qualidade para esse propósito. A maioria dos modelos modernos de aprendizagem profunda são baseados em redes neurais multicamadas, como redes neurais convolucionais e transformadoras, embora também possam incluir fórmulas proposicionais ou variáveis latentes organizadas"}
{"source": "Aprendizagem profunda", "chunk_id": "Aprendizagem profunda_2", "text": "profunda são baseados em redes neurais multicamadas, como redes neurais convolucionais e transformadoras, embora também possam incluir fórmulas proposicionais ou variáveis latentes organizadas em camadas em modelos generativos profundos, como os nós em redes de crenças profundas e máquinas de Boltzmann profundas. Fundamentalmente, a aprendizagem profunda se refere a uma classe de algoritmos de aprendizado de máquina em que uma hierarquia de camadas é usada para transformar dados de entrada em uma representação progressivamente mais abstrata e composta. Por exemplo, em um modelo de reconhecimento de imagem, a entrada bruta pode ser uma imagem (representada como um tensor de pixels). A primeira camada representacional pode tentar identificar formas básicas, como linhas e círculos, a segunda camada pode compor e codificar arranjos de bordas, a terceira camada pode codificar um nariz e olhos, e a quarta camada pode reconhecer que a imagem contém um rosto. É importante ressaltar que um"}
{"source": "Aprendizagem profunda", "chunk_id": "Aprendizagem profunda_3", "text": "camada pode compor e codificar arranjos de bordas, a terceira camada pode codificar um nariz e olhos, e a quarta camada pode reconhecer que a imagem contém um rosto. É importante ressaltar que um processo de aprendizagem profunda pode aprender quais recursos posicionar de forma ideal em qual nível por conta própria. Antes da aprendizagem profunda, as técnicas de aprendizado de máquina frequentemente envolviam engenharia de recursos feita à mão para transformar os dados em uma representação mais adequada para um algoritmo de classificação operar. Na abordagem de aprendizagem profunda, os recursos não são feitos à mão e o modelo descobre representações úteis de recursos a partir dos dados automaticamente. Isso não elimina a necessidade de ajuste manual; por exemplo, números variados de camadas e tamanhos de camadas podem fornecer diferentes graus de abstração. A palavra \"profunda\" em \"aprendizagem profunda\" se refere ao número de camadas através das quais os dados são transformados."}
{"source": "Aprendizagem profunda", "chunk_id": "Aprendizagem profunda_4", "text": "e tamanhos de camadas podem fornecer diferentes graus de abstração. A palavra \"profunda\" em \"aprendizagem profunda\" se refere ao número de camadas através das quais os dados são transformados. Mais precisamente, os sistemas de aprendizagem profunda têm uma profundidade substancial de caminho de atribuição de crédito (CAP). O caminho de atribuição de crédito é a sequência de transformações de entrada para saída. Os caminhos de atribuição de crédito descrevem conexões potencialmente causais entre entrada e saída. Para uma rede neural feedforward, a profundidade dos caminhos de atribuição de crédito é a da rede e é o número de camadas ocultas mais uma (já que a camada de saída também é parametrizada). Para redes neurais recorrentes, nas quais um sinal pode se propagar através de uma camada mais de uma vez, a profundidade do caminho de atribuição de crédito é potencialmente ilimitada. Nenhum limite universalmente acordado de profundidade divide a aprendizagem superficial da aprendizagem"}
{"source": "Aprendizagem profunda", "chunk_id": "Aprendizagem profunda_5", "text": "mais de uma vez, a profundidade do caminho de atribuição de crédito é potencialmente ilimitada. Nenhum limite universalmente acordado de profundidade divide a aprendizagem superficial da aprendizagem profunda, mas a maioria dos pesquisadores concorda que a aprendizagem profunda envolve profundidade de caminho de atribuição de crédito maior que dois. O caminho de atribuição de crédito de profundidade dois demonstrou ser um aproximador universal no sentido de que pode emular qualquer função. Além disso, mais camadas não aumentam a capacidade de aproximação de função da rede. Modelos profundos (caminho de atribuição de crédito maior que dois) conseguem extrair melhores características do que modelos superficiais e, portanto, camadas extras ajudam a aprender as características de forma eficaz. Arquiteturas de aprendizagem profunda podem ser construídas com um método ganancioso camada por camada. A aprendizagem profunda ajuda a desembaraçar essas abstrações e escolher quais recursos"}
{"source": "Aprendizagem profunda", "chunk_id": "Aprendizagem profunda_6", "text": "eficaz. Arquiteturas de aprendizagem profunda podem ser construídas com um método ganancioso camada por camada. A aprendizagem profunda ajuda a desembaraçar essas abstrações e escolher quais recursos melhoram o desempenho. Algoritmos de aprendizagem profunda podem ser aplicados a tarefas de aprendizado que não são supervisionadas. Este é um benefício importante porque dados que não são rotulados são mais abundantes do que os dados rotulados. Exemplos de estruturas profundas que podem ser treinadas de maneira que não é supervisionada são redes de crenças profundas. O termo aprendizagem profunda foi introduzido na comunidade de aprendizado de máquina por Rina Dechter em 1986, e nas redes neurais artificiais por Igor Aizenberg e colegas em 2000, no contexto de neurônios de limiar booleano. Embora a história de seu surgimento seja aparentemente mais complicada. Redes neurais profundas são geralmente interpretadas em termos do teorema da aproximação universal ou da inferência"}
{"source": "Aprendizagem profunda", "chunk_id": "Aprendizagem profunda_7", "text": "booleano. Embora a história de seu surgimento seja aparentemente mais complicada. Redes neurais profundas são geralmente interpretadas em termos do teorema da aproximação universal ou da inferência probabilística. O teorema clássico da aproximação universal diz respeito à capacidade das redes neurais feedforward com uma única camada oculta de tamanho finito para aproximar funções contínuas. Em 1989, a primeira prova foi publicada por George Cybenko para funções de ativação sigmoides e foi generalizada para arquiteturas multicamadas feed-forward em 1991 por Kurt Hornik. Trabalhos recentes também mostraram que a aproximação universal também é válida para funções de ativação que não são limitadas, como a unidade linear retificada (ReLU) de Kunihiko Fukushima. O teorema da aproximação universal para redes neurais profundas diz respeito à capacidade de redes com largura limitada, mas a profundidade pode crescer. Lu et al. provaram que se a largura de uma rede neural profunda com ativação"}
{"source": "Aprendizagem profunda", "chunk_id": "Aprendizagem profunda_8", "text": "para redes neurais profundas diz respeito à capacidade de redes com largura limitada, mas a profundidade pode crescer. Lu et al. provaram que se a largura de uma rede neural profunda com ativação de unidade linear retificada (ReLU) for estritamente maior do que a dimensão de entrada, então a rede pode aproximar qualquer função integrável de Lebesgue; se a largura for menor ou igual à dimensão de entrada, então uma rede neural profunda não é um aproximador universal. A interpretação probabilística deriva do campo do aprendizado de máquina. Ela apresenta inferência, bem como os conceitos de otimização de treinamento e teste, relacionados ao ajuste e generalização, respectivamente. Mais especificamente, a interpretação probabilística considera a não linearidade de ativação como uma função de distribuição cumulativa. A interpretação probabilística levou à introdução do abandono (dropout) ou da diluição como regularizador em redes neurais. A interpretação probabilística foi introduzida por"}
{"source": "Aprendizagem profunda", "chunk_id": "Aprendizagem profunda_9", "text": "distribuição cumulativa. A interpretação probabilística levou à introdução do abandono (dropout) ou da diluição como regularizador em redes neurais. A interpretação probabilística foi introduzida por pesquisadores como Hopfield, Widrow, e Narendra e popularizada em pesquisas como a de Bishop. Existem dois tipos de redes neurais artificiais (ANNs): redes neurais feedforward (FNNs) ou perceptrons multicamadas (MLPs) e redes neurais recorrentes (RNNs). As redes neurais recorrentes têm ciclos em suas estruturas de conectividade, as redes neurais feedforward não. Na década de 1920, Wilhelm Lenz e Ernst Ising criaram o modelo de Ising que é essencialmente uma arquitetura de rede neural recorrente que não é de aprendizagem consistindo de elementos de limiar semelhantes a neurônios. Em 1972, Shun'ichi Amari tornou essa arquitetura adaptável. Sua rede neural recorrente de aprendizagem foi republicada por John Hopfield em 1982. Outras redes neurais recorrentes anteriores foram publicadas por"}
{"source": "Aprendizagem profunda", "chunk_id": "Aprendizagem profunda_10", "text": "Amari tornou essa arquitetura adaptável. Sua rede neural recorrente de aprendizagem foi republicada por John Hopfield em 1982. Outras redes neurais recorrentes anteriores foram publicadas por Kaoru Nakano em 1971. Já em 1948, Alan Turing produziu um trabalho sobre \"Maquinário Inteligente\" que não foi publicado em sua vida, contendo \"ideias relacionadas a redes neurais recorrentes de aprendizagem e evolução artificiais\". Frank Rosenblatt (1958) propôs a perceptron, uma perceptron multicamadas com 3 camadas: uma camada de entrada, uma camada oculta com pesos aleatórios que não aprendiam e uma camada de saída. Mais tarde, ele publicou um livro em 1962 que também introduziu experimentos de computador e variantes, incluindo uma versão com perceptrons de quatro camadas \"com redes pré-terminais adaptativas\" onde as duas últimas camadas aprenderam pesos (aqui ele dá créditos a H. D. Block e B. W. Knight). O livro cita uma rede anterior de R. D. Joseph (1960) \"funcionalmente equivalente a uma"}
{"source": "Aprendizagem profunda", "chunk_id": "Aprendizagem profunda_11", "text": "adaptativas\" onde as duas últimas camadas aprenderam pesos (aqui ele dá créditos a H. D. Block e B. W. Knight). O livro cita uma rede anterior de R. D. Joseph (1960) \"funcionalmente equivalente a uma variação\" deste sistema de quatro camadas (o livro menciona Joseph mais de 30 vezes). Joseph deve, portanto, ser considerado o criador das perceptrons multicamadas adaptativas com unidades ocultas de aprendizagem próprias? Infelizmente, o algoritmo de aprendizagem não era funcional e caiu no esquecimento. O primeiro algoritmo de aprendizagem profunda funcional foi o método de manipulação de dados de grupo, um método para treinar redes neurais profundas arbitrariamente, publicado por Alexey Ivakhnenko e Lapa em 1965. Eles o consideraram uma forma de regressão polinomial, ou uma generalização da perceptron de Rosenblatt para lidar com relacionamentos mais complexos, que não são lineares, e hierárquicos. Um artigo de 1971 descreveu uma rede profunda com oito camadas treinada por este método,"}
{"source": "Aprendizagem profunda", "chunk_id": "Aprendizagem profunda_12", "text": "perceptron de Rosenblatt para lidar com relacionamentos mais complexos, que não são lineares, e hierárquicos. Um artigo de 1971 descreveu uma rede profunda com oito camadas treinada por este método, que é baseado no treinamento de camada por camada por meio de análise de regressão. Unidades ocultas supérfluas são podadas usando um conjunto de validação separado. Como as funções de ativação dos nós são polinômios de Kolmogorov e Gabor, essas também foram as primeiras redes profundas com \"portas\" ou unidades multiplicativas. A primeira perceptron multicamadas de aprendizagem profunda treinada por descida de gradiente estocástica foi publicada em 1967 por Shun'ichi Amari. Em experimentos de computador conduzidos pelo aluno de Amari, Saito, uma perceptron multicamadas de cinco camadas com duas camadas modificáveis aprendeu representações internas para classificar classes de padrões que não são separáveis linearmente. Desenvolvimentos subsequentes em ajustes de hiperparâmetros e hardware"}
{"source": "Aprendizagem profunda", "chunk_id": "Aprendizagem profunda_13", "text": "camadas modificáveis aprendeu representações internas para classificar classes de padrões que não são separáveis linearmente. Desenvolvimentos subsequentes em ajustes de hiperparâmetros e hardware fizeram da descida de gradiente estocástica de ponta a ponta a técnica de treinamento dominante atualmente. Em 1969, Kunihiko Fukushima introduziu a função de ativação de ReLU (unidade linear retificada). A retificadora se tornou a função de ativação mais popular para aprendizagem profunda. As arquiteturas de aprendizagem profunda para redes neurais convolucionais (CNNs) com camadas convolucionais e camadas de redução de amostragem começaram com a Neocognitron introduzida por Kunihiko Fukushima em 1979, embora não ter sido treinada por retropropagação. A retropropagação é uma aplicação eficiente da regra sequencial derivada por Gottfried Wilhelm Leibniz em 1673 para redes de nós diferenciáveis. A terminologia \"erros de retropropagação\" foi realmente introduzida em 1962 por Rosenblatt, mas"}
{"source": "Aprendizagem profunda", "chunk_id": "Aprendizagem profunda_14", "text": "da regra sequencial derivada por Gottfried Wilhelm Leibniz em 1673 para redes de nós diferenciáveis. A terminologia \"erros de retropropagação\" foi realmente introduzida em 1962 por Rosenblatt, mas ele não sabia como implementar isso, embora Henry J. Kelley tivesse um precursor contínuo da retropropagação em 1960 no contexto da teoria de controle. A forma moderna de retropropagação foi publicada pela primeira vez na tese de mestrado de Seppo Linnainmaa (1970). G.M. Ostrovski et al. republicaram em 1971. Paul Werbos aplicou a retropropagação às redes neurais em 1982 (sua tese de doutorado de 1974, reimpressa em um livro de 1994, ainda não descreveu o algoritmo). Em 1986, David E. Rumelhart et al. popularizaram a retropropagação, mas não citaram o trabalho original. A rede neural de atraso de tempo (TDNN) foi introduzida em 1987 por Alex Waibel para aplicar rede neural convolucional ao reconhecimento de fonemas. Ela usava convoluções, compartilhamento de peso e retropropagação. Em 1988,"}
{"source": "Aprendizagem profunda", "chunk_id": "Aprendizagem profunda_15", "text": "tempo (TDNN) foi introduzida em 1987 por Alex Waibel para aplicar rede neural convolucional ao reconhecimento de fonemas. Ela usava convoluções, compartilhamento de peso e retropropagação. Em 1988, Wei Zhang aplicou uma rede neural convolucional treinada em retropropagação ao reconhecimento de alfabeto. Em 1989, Yann LeCun et al. criaram uma rede neural convolucional chamada LeNet para reconhecer códigos postais manuscritos em correspondências. O treinamento levou 3 dias. Em 1990, Wei Zhang implementou uma rede neural convolucional em hardware de computação óptica. Em 1991, uma rede neural convolucional foi aplicada à segmentação de objetos de imagens médicas e à detecção de câncer de mama em mamografias. A LeNet-5 (1998), uma rede neural convolucional de 7 níveis de Yann LeCun et al., que classifica dígitos, foi aplicada por vários bancos para reconhecer números manuscritos em cheques digitalizados em imagens de 32x32 pixels. As redes neurais recorrentes (RNNs) foram desenvolvidas"}
{"source": "Aprendizagem profunda", "chunk_id": "Aprendizagem profunda_16", "text": "que classifica dígitos, foi aplicada por vários bancos para reconhecer números manuscritos em cheques digitalizados em imagens de 32x32 pixels. As redes neurais recorrentes (RNNs) foram desenvolvidas ainda mais na década de 1980. A recorrência é usada para processamento de sequências e, quando uma rede recorrente é desenrolada, ela se assemelha matematicamente a uma camada de feedforward profunda. Consequentemente, elas têm propriedades e problemas semelhantes, e seus desenvolvimentos tiveram influências mútuas. Em redes neurais recorrentes, dois primeiros trabalhos influentes foram a rede de Jordan (1986) e a rede de Elman (1990), que aplicaram redes neurais recorrentes para estudar problemas em psicologia cognitiva. Na década de 1980, a retropropagação não funcionou bem para aprendizagem profunda com longos caminhos de atribuição de crédito. Para superar esse problema, em 1991, Jürgen Schmidhuber propôs uma hierarquia de redes neurais recorrentes pré-treinadas um nível de cada vez"}
{"source": "Aprendizagem profunda", "chunk_id": "Aprendizagem profunda_17", "text": "profunda com longos caminhos de atribuição de crédito. Para superar esse problema, em 1991, Jürgen Schmidhuber propôs uma hierarquia de redes neurais recorrentes pré-treinadas um nível de cada vez por aprendizado autossupervisionado, onde cada rede neural recorrente tenta prever sua própria próxima entrada, que é a próxima entrada inesperada da rede neural recorrente abaixo. Este \"compressor de histórico neural\" usa codificação preditiva para aprender representações internas em múltiplas escalas de tempo auto-organizadas. Isso pode facilitar substancialmente a aprendizagem profunda a jusante. A hierarquia da rede neural recorrente pode ser colapsada em uma única rede neural recorrente, destilando uma rede fragmentadora de nível superior em uma rede automatizadora de nível inferior. Em 1993, um compressor de histórico neural resolveu uma tarefa de \"aprendizagem muito profunda\" que exigia mais de 1000 camadas subsequentes em uma rede neural recorrente desdobrada no tempo. O \"P\" em"}
{"source": "Aprendizagem profunda", "chunk_id": "Aprendizagem profunda_18", "text": "1993, um compressor de histórico neural resolveu uma tarefa de \"aprendizagem muito profunda\" que exigia mais de 1000 camadas subsequentes em uma rede neural recorrente desdobrada no tempo. O \"P\" em ChatGPT se refere a esse pré-treinamento. A tese de diploma de Sepp Hochreiter (1991) implementou o compressor de história neural, e identificou e analisou o problema do gradiente de desaparecimento. Hochreiter propôs conexões residuais recorrentes para resolver o problema do gradiente de desaparecimento. Isso levou à memória de curto prazo longa (LSTM), publicada em 1995. A memória de curto prazo longa pode aprender tarefas de \"aprendizagem muito profunda\" com longos caminhos de atribuição de crédito que exigem memórias de eventos que aconteceram milhares de passos de tempo discretos antes. Essa memória de curto prazo longa ainda não era a arquitetura moderna, que exigia uma \"portão de esquecimento\", introduzido em 1999, que se tornou a arquitetura de rede neural recorrente padrão. Em"}
{"source": "Aprendizagem profunda", "chunk_id": "Aprendizagem profunda_19", "text": "Essa memória de curto prazo longa ainda não era a arquitetura moderna, que exigia uma \"portão de esquecimento\", introduzido em 1999, que se tornou a arquitetura de rede neural recorrente padrão. Em 1991, Jürgen Schmidhuber também publicou redes neurais adversárias que competem entre si na forma de um jogo de soma zero, onde o ganho de uma rede é a perda da outra rede. A primeira rede é um modelo generativo que modela uma distribuição de probabilidade sobre padrões de saída. A segunda rede aprende por descida do gradiente para prever as reações do ambiente a esses padrões. Isso foi chamado de \"curiosidade artificial\". Em 2014, esse princípio foi usado em redes adversárias generativas (GANs). Durante 1985–1995, inspirados pela mecânica estatística, várias arquiteturas e métodos foram desenvolvidos por Terry Sejnowski, Peter Dayan, Geoffrey Hinton, etc., incluindo a máquina de Boltzmann, a máquina de Boltzmann restrita, a máquina de Helmholtz, e o algoritmo de vigília e sono. Eles foram"}
{"source": "Aprendizagem profunda", "chunk_id": "Aprendizagem profunda_20", "text": "por Terry Sejnowski, Peter Dayan, Geoffrey Hinton, etc., incluindo a máquina de Boltzmann, a máquina de Boltzmann restrita, a máquina de Helmholtz, e o algoritmo de vigília e sono. Eles foram projetados para aprendizado que não é supervisionado de modelos generativos profundos. No entanto, esses eram mais caros computacionalmente em comparação com a retropropagação. O algoritmo de aprendizado de máquina de Boltzmann, publicado em 1985, foi brevemente popular antes de ser eclipsado pelo algoritmo de retropropagação em 1986. (p. 112 ). Uma rede de 1988 se tornou o estado da arte na predição das estruturas de proteínas, uma aplicação inicial da aprendizagem profunda à bioinformática. Tanto a aprendizagem superficial quanto a profunda (por exemplo, redes recorrentes) de redes neurais artificiais para reconhecimento de fala têm sido explorados por muitos anos. Esses métodos nunca superaram a tecnologia do modelo de mistura gaussiana/modelo de Markov oculto (GMM-HMM) manual interno que não"}
{"source": "Aprendizagem profunda", "chunk_id": "Aprendizagem profunda_21", "text": "para reconhecimento de fala têm sido explorados por muitos anos. Esses métodos nunca superaram a tecnologia do modelo de mistura gaussiana/modelo de Markov oculto (GMM-HMM) manual interno que não é uniforme baseada em modelos generativos de fala treinados discriminativamente. As principais dificuldades foram analisadas, incluindo a diminuição de gradiente e a estrutura de correlação temporal fraca em modelos preditivos neurais. Dificuldades adicionais foram a falta de dados de treinamento e poder de computação limitado. A maioria dos pesquisadores de reconhecimento de fala se afastou das redes neurais para buscar modelagem generativa. Uma exceção foi no SRI International no final da década de 1990. Financiado pela NSA e pela DARPA do governo dos EUA, o SRI pesquisou em reconhecimentos de fala e falante. A equipe de reconhecimento de falante liderada por Larry Heck relatou sucesso significativo com redes neurais profundas no processamento de fala no benchmark de reconhecimento de"}
{"source": "Aprendizagem profunda", "chunk_id": "Aprendizagem profunda_22", "text": "de fala e falante. A equipe de reconhecimento de falante liderada por Larry Heck relatou sucesso significativo com redes neurais profundas no processamento de fala no benchmark de reconhecimento de falante do NIST de 1998. Foi implantado no Nuance Verifier, representando a primeira grande aplicação industrial da aprendizagem profunda. O princípio de elevar características \"brutas\" sobre otimização manual foi explorado pela primeira vez com sucesso na arquitetura do autocodificador profundo nas características de bancos de filtros lineares ou espectrogramas \"brutos\" no final da década de 1990, mostrando sua superioridade sobre as características Mel-Cepstrais que contêm estágios de transformações fixas a partir de espectrogramas. As características brutas da fala, as formas das ondas, mais tarde produziram excelentes resultados em larga escala. As redes neurais entraram em um período de calmaria, e modelos mais simples que usam recursos artesanais específicos para tarefas, como filtros"}
{"source": "Aprendizagem profunda", "chunk_id": "Aprendizagem profunda_23", "text": "tarde produziram excelentes resultados em larga escala. As redes neurais entraram em um período de calmaria, e modelos mais simples que usam recursos artesanais específicos para tarefas, como filtros de Gabor e máquinas de vetores de suporte (SVMs), tornaram-se as escolhas preferidas nas décadas de 1990 e 2000, devido ao custo computacional das redes neurais artificiais e à falta de compreensão de como o cérebro conecta suas redes biológicas. Em 2003, a memória de curto prazo longa tornou-se competitiva com os reconhecedores de fala tradicionais em certas tarefas. Em 2006, Alex Graves, Santiago Fernández, Faustino Gomez e Schmidhuber combinaram-na com a classificação temporal conexionista (CTC) em pilhas de memórias de curto prazo longas. Em 2009, tornou-se a primeira rede neural recorrente a vencer um concurso de reconhecimento de padrões, em reconhecimento de escrita manual conectada. Em 2006, publicações de Geoff Hinton, Ruslan Salakhutdinov, Osindero e Teh redes de crenças"}
{"source": "Aprendizagem profunda", "chunk_id": "Aprendizagem profunda_24", "text": "a vencer um concurso de reconhecimento de padrões, em reconhecimento de escrita manual conectada. Em 2006, publicações de Geoff Hinton, Ruslan Salakhutdinov, Osindero e Teh redes de crenças profundas foram desenvolvidas para modelagem generativa. Elas são treinadas treinando uma máquina de Boltzmann restrita, então congelando-a e treinando outra em cima da primeira, e assim por diante, então opcionalmente ajustadas usando retropropagação supervisionada. Elas poderiam modelar distribuições de probabilidade de alta dimensão, como a distribuição de imagens do Banco de dados do Instituto Nacional de Padrões e Tecnologia modificado (MNIST), mas a convergência era lenta. O impacto da aprendizagem profunda na indústria começou no início dos anos 2000, quando as redes neurais convolucionais já processavam cerca de 10% a 20% de todos os cheques emitidos nos EUA, de acordo com Yann LeCun. As aplicações industriais da aprendizagem profunda para reconhecimento de fala em larga escala começaram"}
{"source": "Aprendizagem profunda", "chunk_id": "Aprendizagem profunda_25", "text": "processavam cerca de 10% a 20% de todos os cheques emitidos nos EUA, de acordo com Yann LeCun. As aplicações industriais da aprendizagem profunda para reconhecimento de fala em larga escala começaram por volta de 2010. A Oficina sobre Sistemas de Processamento de Informações Neurais (NIPS) de 2009 sobre Aprendizagem Profunds para Reconhecimento de Fala foi motivada pelas limitações de modelos generativos profundos de fala e pela possibilidade de que, dado hardware mais capaz e conjuntos de dados em larga escala, as redes neurais profundas pudessem se tornar práticas. Acreditava-se que o pré-treinamento de redes neurais profundas usando modelos generativos de redes de crenças profundas superaria as principais dificuldades das redes neurais. No entanto, descobriu-se que a substituição do pré-treinamento por grandes quantidades de dados de treinamento para retropropagação direta ao usar redes neurais profundas com grandes camadas de saída dependentes do contexto produzia taxas de erros"}
{"source": "Aprendizagem profunda", "chunk_id": "Aprendizagem profunda_26", "text": "por grandes quantidades de dados de treinamento para retropropagação direta ao usar redes neurais profundas com grandes camadas de saída dependentes do contexto produzia taxas de erros dramaticamente menores do que o modelo de mistura gaussiana/modelo de Markov oculto de então última geração e também do que sistemas baseados em modelos generativos mais avançados. A natureza dos erros de reconhecimento produzidos pelos dois tipos de sistemas era caracteristicamente diferente, oferecendo percepções técnicas sobre como integrar a aprendizagem profunda no sistema de decodificação de fala altamente eficiente e em tempo de execução existente, implantado por todos os principais sistemas de reconhecimento de fala. A análise por volta de 2009 e 2010, contrastando o modelo de mistura gaussiana (e outros modelos de fala generativa) versus modelos de redes neurais profundas, estimulou o investimento industrial inicial em aprendizagem profunda para reconhecimento de fala. Essa análise foi feita"}
{"source": "Aprendizagem profunda", "chunk_id": "Aprendizagem profunda_27", "text": "outros modelos de fala generativa) versus modelos de redes neurais profundas, estimulou o investimento industrial inicial em aprendizagem profunda para reconhecimento de fala. Essa análise foi feita com desempenho comparável (menos de 1,5% na taxa de erros) entre modelos generativos e redes neurais profundas discriminativos. Em 2010, os pesquisadores estenderam a aprendizagem profunda a partir do TIMIT para o reconhecimento de fala de vocabulário grande, adotando grandes camadas de saída da rede neural profunda com base em estados do modelo de Markov oculto dependentes do contexto construídos por árvores de decisões. A revolução da aprendizagem profunda começou em torno da visão computacional baseada em redes neurais convolucionais e em GPUs. Embora as redes neurais convolucionais treinadas por retropropagação já existissem há décadas e implementações de redes neurais em GPUs há anos, incluindo redes neurais convolucionais, implementações mais rápidas de redes neurais convolucionais"}
{"source": "Aprendizagem profunda", "chunk_id": "Aprendizagem profunda_28", "text": "por retropropagação já existissem há décadas e implementações de redes neurais em GPUs há anos, incluindo redes neurais convolucionais, implementações mais rápidas de redes neurais convolucionais em GPUs eram necessárias para progredir na visão computacional. Mais tarde, conforme a aprendizagem profunda se tornou difundido, otimizações de algoritmo e hardware especializados foram desenvolvidos especificamente para aprendizagem profunda. Um avanço fundamental para a revolução da aprendizagem profunda foram os avanços de hardware, especialmente GPUs. Alguns trabalhos iniciais datam de 2004. Em 2009, Raina, Madhavan e Andrew Ng relataram uma rede de crenças profundas de 100M treinada em 30 GPUs GeForce GTX 280 da Nvidia, uma demonstração inicial de aprendizagem profunda baseada em GPUs. Eles relataram um treinamento até 70 vezes mais rápido. Em 2011, uma rede neural convolucional chamada DanNet por Dan Ciresan, Ueli Meier, Jonathan Masci, Luca Maria Gambardella e Jürgen Schmidhuber"}
{"source": "Aprendizagem profunda", "chunk_id": "Aprendizagem profunda_29", "text": "Eles relataram um treinamento até 70 vezes mais rápido. Em 2011, uma rede neural convolucional chamada DanNet por Dan Ciresan, Ueli Meier, Jonathan Masci, Luca Maria Gambardella e Jürgen Schmidhuber alcançou pela primeira vez um desempenho sobre-humano em um concurso de reconhecimento de padrões visuais, superando os métodos tradicionais por um fator de 3. Em seguida, ganhou mais concursos. Eles também mostraram como o pool máximo de redes neurais convolucionais em GPUs melhorou significativamente o desempenho. Em 2012, Andrew Ng e Jeff Dean criaram uma rede neural feedforward que aprendeu a reconhecer conceitos de nível superior, como gatos, apenas assistindo a imagens que não são rotuladas tiradas de vídeos do YouTube. Em outubro de 2012, AlexNet por Alex Krizhevsky, Ilya Sutskever e Geoffrey Hinton venceu a competição ImageNet em larga escala por uma margem significativa sobre métodos de aprendizado de máquina rasos. Outras melhorias incrementais incluíram a rede VGG-16 por Karen"}
{"source": "Aprendizagem profunda", "chunk_id": "Aprendizagem profunda_30", "text": "Hinton venceu a competição ImageNet em larga escala por uma margem significativa sobre métodos de aprendizado de máquina rasos. Outras melhorias incrementais incluíram a rede VGG-16 por Karen Simonyan e Andrew Zisserman e a Inceptionv3 do Google. O sucesso na classificação de imagens foi então estendido para a tarefa mais desafiadora de gerar descrições (legendas) para imagens, geralmente como uma combinação de redes neurais convolucionais e memórias de curto prazo longas. Em 2014, o estado da arte era treinar \"rede neural muito profunda\" com 20 a 30 camadas. Empilhar muitas camadas levou a uma redução acentuada na precisão do treinamento, conhecida como problema de \"degradação\". Em 2015, duas técnicas foram desenvolvidas para treinar redes muito profundas: a Highway Network foi publicada em maio de 2015, e a rede neural residual (ResNet) em dezembro de 2015. A ResNet se comporta como uma Highway Net de portas abertas. Na mesma época, a aprendizagem profunda começou a impactar o campo"}
{"source": "Aprendizagem profunda", "chunk_id": "Aprendizagem profunda_31", "text": "em maio de 2015, e a rede neural residual (ResNet) em dezembro de 2015. A ResNet se comporta como uma Highway Net de portas abertas. Na mesma época, a aprendizagem profunda começou a impactar o campo da arte. Os primeiros exemplos incluíram o DeepDream do Google (2015) e a transferência de estilo neural (2015), ambos baseados em redes neurais de classificação de imagens pré-treinadas, como a VGG-19. A rede adversária generativa (GAN) (de Ian Goodfellow et al., 2014) (com base no princípio da curiosidade artificial de Jürgen Schmidhuber) tornou-se o estado da arte na modelagem generativa durante o período de 2014 a 2018. Excelente qualidade de imagem é alcançada pela StyleGAN da Nvidia (2018) com base na rede adversária generativa progressiva de Tero Karras et al. Aqui, o gerador da rede adversária generativa é desenvolvido de pequena para grande escala de forma piramidal. A geração de imagens por rede adversária generativa alcançou sucesso popular e provocou discussões sobre"}
{"source": "Aprendizagem profunda", "chunk_id": "Aprendizagem profunda_32", "text": "da rede adversária generativa é desenvolvido de pequena para grande escala de forma piramidal. A geração de imagens por rede adversária generativa alcançou sucesso popular e provocou discussões sobre deepfakes. Os modelos de difusão (2015) eclipsaram as redes adversárias generativas na modelagem generativa desde então, com sistemas como DALL·E 2 (2022) e Stable Diffusion (2022). Em 2015, o reconhecimento de fala do Google melhorou em 49% por um modelo baseado em memória de curto prazo longa, que eles disponibilizaram por meio do Google Voice Search em smartphones. A aprendizagem profunda faz parte de sistemas de última geração em várias disciplinas, particularmente visão computacional e reconhecimento de fala automático (ASR). Os resultados em conjuntos de avaliação comumente usados, como o TIMIT (ASR) e o MNIST (classificação de imagens), bem como uma variedade de tarefas de reconhecimento de fala de vocabulário amplo, melhoraram constantemente. As redes neurais convolucionais foram"}
{"source": "Aprendizagem profunda", "chunk_id": "Aprendizagem profunda_33", "text": "o TIMIT (ASR) e o MNIST (classificação de imagens), bem como uma variedade de tarefas de reconhecimento de fala de vocabulário amplo, melhoraram constantemente. As redes neurais convolucionais foram substituídas para reconhecimento automático de fala por memórias de curto prazo longas, mas são mais bem-sucedidas em visão computacional. Yoshua Bengio, Geoffrey Hinton e Yann LeCun receberam o Prêmio Turing de 2018 por \"avanços conceituais e de engenharia que tornaram as redes neurais profundas um componente crítico da computação\". Redes neurais artificiais (ANNs) ou sistemas conexionistas são sistemas de computação inspirados nas redes neurais biológicas que constituem os cérebros dos animais. Tais sistemas aprendem (melhoram progressivamente sua capacidade de) fazer tarefas considerando exemplos, geralmente sem programação específica para a tarefa. Por exemplo, no reconhecimento de imagens, eles podem aprender a identificar imagens que contêm gatos analisando imagens de exemplo que"}
{"source": "Aprendizagem profunda", "chunk_id": "Aprendizagem profunda_34", "text": "exemplos, geralmente sem programação específica para a tarefa. Por exemplo, no reconhecimento de imagens, eles podem aprender a identificar imagens que contêm gatos analisando imagens de exemplo que foram rotuladas manualmente como \"gato\" ou \"sem gato\" e usando os resultados analíticos para identificar gatos em outras imagens. Eles encontraram mais uso em aplicações difíceis de expressar com um algoritmo de computador tradicional usando programação baseada em regras. Uma rede neural artificial (RNA) é baseada em uma coleção de unidades conectadas chamadas neurônios artificiais (análogos aos neurônios biológicos em um cérebro biológico). Cada conexão (sinapse) entre neurônios pode transmitir um sinal para outro neurônio. O neurônio receptor (pós-sináptico) pode processar o(s) sinal(ais) e então sinalizar os neurônios a jusante conectados a ele. Os neurônios podem ter estado, geralmente representados por números reais, tipicamente entre 0 e 1. Neurônios e sinapses também podem ter um"}
{"source": "Aprendizagem profunda", "chunk_id": "Aprendizagem profunda_35", "text": "e então sinalizar os neurônios a jusante conectados a ele. Os neurônios podem ter estado, geralmente representados por números reais, tipicamente entre 0 e 1. Neurônios e sinapses também podem ter um peso que varia conforme o aprendizado prossegue, o que pode aumentar ou diminuir a força do sinal que ele envia a jusante. Normalmente, os neurônios são organizados em camadas. Camadas diferentes podem executar diferentes tipos de transformações em suas entradas. Os sinais viajam da primeira (entrada) para a última camada (saída), possivelmente após atravessar as camadas várias vezes. O objetivo original da abordagem da rede neural era resolver problemas da mesma forma que um cérebro humano faria. Com o tempo, a atenção se concentrou em combinar habilidades mentais específicas, levando a desvios da biologia, como retropropagação ou passagem de informações na direção reversa e ajuste da rede para refletir essas informações. As redes neurais têm sido usadas em uma variedade de tarefas,"}
{"source": "Aprendizagem profunda", "chunk_id": "Aprendizagem profunda_36", "text": "desvios da biologia, como retropropagação ou passagem de informações na direção reversa e ajuste da rede para refletir essas informações. As redes neurais têm sido usadas em uma variedade de tarefas, incluindo visão computacional, reconhecimento de fala, tradução automática, filtragem de redes sociais, jogos de tabuleiro e vídeo, e diagnóstico médico. Em 2017, as redes neurais normalmente tinham alguns milhares a alguns milhões de unidades e milhões de conexões. Apesar desse número ser várias ordens de magnitude menor do que o número de neurônios em um cérebro humano, essas redes podem executar muitas tarefas em um nível além do dos humanos (por exemplo, reconhecer rostos ou jogar \"Go\"). Uma rede neural profunda (DNN) é uma rede neural artificial com múltiplas camadas entre as camadas de entrada e saída. Existem diferentes tipos de redes neurais, mas elas sempre consistem nos mesmos componentes: neurônios, sinapses, pesos, vieses e funções. Esses componentes como um todo funcionam de"}
{"source": "Aprendizagem profunda", "chunk_id": "Aprendizagem profunda_37", "text": "entrada e saída. Existem diferentes tipos de redes neurais, mas elas sempre consistem nos mesmos componentes: neurônios, sinapses, pesos, vieses e funções. Esses componentes como um todo funcionam de uma forma que imita funções do cérebro humano e podem ser treinados como qualquer outro algoritmo de aprendizado de máquina. Por exemplo, uma rede neural profunda treinada para reconhecer raças de cães examinará a imagem fornecida e calculará a probabilidade de que o cão na imagem seja de uma determinada raça. O usuário pode revisar os resultados e selecionar quais probabilidades a rede deve exibir (acima de um certo limite, etc.) e retornar o rótulo proposto. Cada manipulação matemática como tal é considerada uma camada, e redes neurais profundas complexas têm muitas camadas, daí o nome redes \"profundas\". As redes neurais profundas podem modelar relacionamentos que não são lineares complexos. As arquiteturas dad redes neurais profundas geram modelos composicionais onde o objeto é"}
{"source": "Aprendizagem profunda", "chunk_id": "Aprendizagem profunda_38", "text": "redes \"profundas\". As redes neurais profundas podem modelar relacionamentos que não são lineares complexos. As arquiteturas dad redes neurais profundas geram modelos composicionais onde o objeto é expresso como uma composição em camadas de primitivos. As camadas extras permitem a composição de recursos de camadas inferiores, potencialmente modelando dados complexos com menos unidades do que uma rede rasa de desempenho semelhante. Por exemplo, foi provado que polinômios multivariados esparsos são exponencialmente mais fáceis de aproximar com redes neurais profundas do que com redes rasas. As arquiteturas profundas incluem muitas variantes de algumas abordagens básicas. Cada arquitetura obteve sucesso em domínios específicos. Nem sempre é possível comparar o desempenho de múltiplas arquiteturas, a menos que tenham sido avaliadas nos mesmos conjuntos de dados. As redes neurais profundas são tipicamente redes feedforward nas quais os dados fluem da camada de entrada para a camada de saída"}
{"source": "Aprendizagem profunda", "chunk_id": "Aprendizagem profunda_39", "text": "a menos que tenham sido avaliadas nos mesmos conjuntos de dados. As redes neurais profundas são tipicamente redes feedforward nas quais os dados fluem da camada de entrada para a camada de saída sem fazer loopback. Primeiramente, a rede neural profunda cria um mapa de neurônios virtuais e atribui valores numéricos aleatórios, ou \"pesos\", às conexões entre eles. Os pesos e entradas são multiplicados e retornam uma saída entre 0 e 1. Se a rede não reconhecesse com precisão um padrão específico, um algoritmo ajustaria os pesos. Dessa forma, o algoritmo pode tornar certos parâmetros mais influentes, até determinar a manipulação matemática correta para processar completamente os dados. As redes neurais recorrentes, nas quais os dados podem fluir em qualquer direção, são usadas para aplicações como modelagem de linguagem. A memória de curto prazo longa é particularmente eficaz para esse uso. As redes neurais convolucionais (CNNs) são usadas em visão computacional. As redes neurais"}
{"source": "Aprendizagem profunda", "chunk_id": "Aprendizagem profunda_40", "text": "como modelagem de linguagem. A memória de curto prazo longa é particularmente eficaz para esse uso. As redes neurais convolucionais (CNNs) são usadas em visão computacional. As redes neurais convolucionais também foram aplicadas à modelagem acústica para reconhecimento automático de fala (ASR). Desafios Assim como com redes neurais artificiais, muitos problemas podem surgir com redes neurais profundas treinadas ingenuamente. Dois problemas comuns são o ajuste excessivo e o tempo de computação. As redes neurais profundas são propensas a ajuste excessivo por causa das camadas de abstração adicionadas, que permitem que elas modelem dependências raras nos dados de treinamento. Métodos de regularização como a poda de unidade de Ivakhnenko ou o decaimento de peso (regularização de ℓ 2 {\\displaystyle \\ell _{2}} ) ou esparsidade (regularização de ℓ 1 {\\displaystyle \\ell _{1}} ) podem ser aplicados durante o treinamento para combater ajuste excessivo. Alternativamente, a regularização de"}
{"source": "Aprendizagem profunda", "chunk_id": "Aprendizagem profunda_41", "text": "\\ell _{2}} ) ou esparsidade (regularização de ℓ 1 {\\displaystyle \\ell _{1}} ) podem ser aplicados durante o treinamento para combater ajuste excessivo. Alternativamente, a regularização de abandono omite aleatoriamente unidades das camadas ocultas durante o treinamento. Isso ajuda a excluir dependências raras. Outro desenvolvimento recente interessante é a pesquisa em modelos de complexidade suficiente por meio de uma estimativa da complexidade intrínseca da tarefa que está sendo modelada. Essa abordagem foi aplicada com sucesso para tarefas de previsão de séries temporais multivariadas, como previsão de tráfego. Finalmente, os dados podem ser aumentados por meio de métodos como corte e rotação, de modo que conjuntos de treinamento menores possam ser aumentados em tamanho para reduzir as chances de ajuste excessivo. As redes neurais profundas devem considerar muitos parâmetros de treinamento, como o tamanho (número de camadas e número de unidades por camada), a taxa de aprendizado e"}
{"source": "Aprendizagem profunda", "chunk_id": "Aprendizagem profunda_42", "text": "chances de ajuste excessivo. As redes neurais profundas devem considerar muitos parâmetros de treinamento, como o tamanho (número de camadas e número de unidades por camada), a taxa de aprendizado e pesos iniciais. Varrer o espaço de parâmetros para parâmetros ideais pode não ser viável devido ao custo em tempo e recursos computacionais. Vários truques, como loteamento (computação do gradiente em vários exemplos de treinamento de uma vez em vez de exemplos individuais) aceleram a computação. Grandes capacidades de processamento de arquiteturas de muitos núcleos (como GPUs ou o Intel Xeon Phi) produziram acelerações significativas no treinamento, devido à adequação de tais arquiteturas de processamento para as computações de matriz e vetor. Alternativamente, os engenheiros podem procurar outros tipos de redes neurais com algoritmos de treinamento mais diretos e convergentes. A controladora de articulação de modelo cerebelar (CMAC) é uma desses tipos de rede neural. Ela não requer taxas"}
{"source": "Aprendizagem profunda", "chunk_id": "Aprendizagem profunda_43", "text": "tipos de redes neurais com algoritmos de treinamento mais diretos e convergentes. A controladora de articulação de modelo cerebelar (CMAC) é uma desses tipos de rede neural. Ela não requer taxas de aprendizado ou pesos iniciais randomizados. O processo de treinamento pode ser garantido para convergir em uma etapa com um novo lote de dados, e a complexidade computacional do algoritmo de treinamento é linear em relação ao número de neurônios envolvidos. Desde a década de 2010, os avanços em algoritmos de aprendizado de máquina e hardware de computador levaram a métodos mais eficientes para treinar redes neurais profundas que contêm muitas camadas de unidades ocultas que não são lineares e uma camada de saída muito grande. Em 2019, unidades de processamento gráfico (GPUs), geralmente com aprimoramentos específicos de IA, substituíram as CPUs como o método dominante para treinar IA de nuvem comercial em larga escala. A OpenAI estimou a computação de hardware usada nos maiores projetos de"}
{"source": "Aprendizagem profunda", "chunk_id": "Aprendizagem profunda_44", "text": "específicos de IA, substituíram as CPUs como o método dominante para treinar IA de nuvem comercial em larga escala. A OpenAI estimou a computação de hardware usada nos maiores projetos de aprendizagem profunda de AlexNet (2012) a AlphaZero (2017) e encontrou um aumento de 300.000 vezes na quantidade de computação necessária, com uma linha de tendência de tempo de duplicação de 3,4 meses. Circuitos eletrônicos especiais chamados processadores de aprendizagem profunda foram projetados para acelerar algoritmos de aprendizagem profunda. Os processadores de aprendizagem profunda incluem unidades de processamento neural (NPUs) em celulares Huawei e servidores de computação em nuvem, como unidades de processamento tensorial (TPU) na Google Cloud Platform. A Cerebras Systems também construiu um sistema dedicado para lidar com grandes modelos de aprendizagem profunda, o CS-2, baseado no maior processador do setor, o Wafer Scale Engine de segunda geração (WSE-2). Semicondutores atomicamente"}
{"source": "Aprendizagem profunda", "chunk_id": "Aprendizagem profunda_45", "text": "sistema dedicado para lidar com grandes modelos de aprendizagem profunda, o CS-2, baseado no maior processador do setor, o Wafer Scale Engine de segunda geração (WSE-2). Semicondutores atomicamente finos são considerados promissores para hardware de aprendizagem profunda com eficiência energética, onde a mesma estrutura básica do dispositivo é usada para operações lógicas e armazenamento de dados. Em 2020, Marega et al. publicaram experimentos com um material de canal ativo de grande área para desenvolver dispositivos e circuitos lógicos na memória baseados em transistores de efeito de campo de porta flutuante (FGFETs). Em 2021, J. Feldmann et al. propuseram um acelerador de hardware fotônico integrado para processamento convolucional paralelo. Os autores identificam duas vantagens principais da fotônica integrada sobre suas contrapartes eletrônicas: (1) transferência de dados massivamente paralela por meio de multiplexação por divisão de comprimento de onda em conjunto com pentes de"}
{"source": "Aprendizagem profunda", "chunk_id": "Aprendizagem profunda_46", "text": "da fotônica integrada sobre suas contrapartes eletrônicas: (1) transferência de dados massivamente paralela por meio de multiplexação por divisão de comprimento de onda em conjunto com pentes de frequência e (2) velocidades de modulação de dados extremamente altas. Seu sistema pode executar trilhões de operações de multiplicação e acumulação por segundo, indicando o potencial da fotônica integrada em aplicações de IA com muitos dados. O reconhecimento automático de fala em larga escala é o primeiro e mais convincente caso bem-sucedido de aprendizado profundo. Redes neurais recorrentes de memórias de curto prazo longas podem aprender tarefas de \"Aprendizado Muito Profundo\" que envolvem intervalos de vários segundos contendo eventos de fala separados por milhares de passos de tempo discretos, onde um passo de tempo corresponde a cerca de 10 milissegundos. Memórias de curto prazo longas com portas de esquecimento são competitivas com reconhecedores de fala tradicionais em certas tarefas."}
{"source": "Aprendizagem profunda", "chunk_id": "Aprendizagem profunda_47", "text": "onde um passo de tempo corresponde a cerca de 10 milissegundos. Memórias de curto prazo longas com portas de esquecimento são competitivas com reconhecedores de fala tradicionais em certas tarefas. O sucesso inicial no reconhecimento de fala foi baseado em tarefas de reconhecimento em pequena escala baseadas no TIMIT. O conjunto de dados contém 630 falantes de oito dialetos principais do inglês americano, onde cada falante lê 10 frases. Seu pequeno tamanho permite que muitas configurações sejam tentadas. Mais importante, a tarefa TIMIT diz respeito ao reconhecimento de sequência de fonemas, que, diferentemente do reconhecimento de sequência de palavras, permite modelos de linguagem de bigramas de fonemas fracos. Isso permite que a força dos aspectos de modelagem acústica do reconhecimento de fala seja mais facilmente analisada. As taxas de erro listadas abaixo, incluindo esses resultados iniciais e medidas como taxas de erro de fonemas percentuais (PER), foram resumidas desde 1991. A"}
{"source": "Aprendizagem profunda", "chunk_id": "Aprendizagem profunda_48", "text": "de fala seja mais facilmente analisada. As taxas de erro listadas abaixo, incluindo esses resultados iniciais e medidas como taxas de erro de fonemas percentuais (PER), foram resumidas desde 1991. A estreia das redes neurais profundas para reconhecimento de falantes no final da década de 1990 e do reconhecimento de fala por volta de 2009 a 2011 e da memória de curto prazo longa por volta de 2003 a 2007, acelerou o progresso em oito áreas principais: Treinamento e decodificação de rede neural profunda de aceleração e expansão vertical/horizontal Treinamento discriminativo de sequência Processamento de recursos por modelos profundos com sólida compreensão dos mecanismos subjacentes Adaptação de redes neurais profundas e modelos profundos relacionados Aprendizado multitarefa e de transferência por redes neurais profundas e modelos profundos relacionados Redes neurais convolucionais e como projetá-las para melhor explorar o conhecimento de domínio da fala Rede neural recorrente e suas"}
{"source": "Aprendizagem profunda", "chunk_id": "Aprendizagem profunda_49", "text": "por redes neurais profundas e modelos profundos relacionados Redes neurais convolucionais e como projetá-las para melhor explorar o conhecimento de domínio da fala Rede neural recorrente e suas ricas variantes de memória de curto prazo longa Modelos mais recentes de reconhecimento de fala usam transformadoras ou redes convolucionais temporais (TCN) com aplicações generalizadas e sucesso significativos. Outros tipos de modelos profundos, incluindo modelos baseados em tensores e modelos discriminativos/generativos profundos integrados. Todos os principais sistemas comerciais de reconhecimento de fala (por exemplo, Microsoft Cortana, Xbox, Skype Translator, Amazon Alexa, Google Now, Apple Siri, Baidu e pesquisa por voz da iFlyTek e uma variedade de produtos de fala da Nuance, etc.) são baseados em aprendizado profundo. Um conjunto de avaliação comum para classificação de imagens é o conjunto de dados do banco de dados do MNIST. O MNIST é composto de dígitos manuscritos e inclui 60.000"}
{"source": "Aprendizagem profunda", "chunk_id": "Aprendizagem profunda_50", "text": "em aprendizado profundo. Um conjunto de avaliação comum para classificação de imagens é o conjunto de dados do banco de dados do MNIST. O MNIST é composto de dígitos manuscritos e inclui 60.000 exemplos de treinamento e 10.000 exemplos de teste. Assim como o TIMIT, seu tamanho pequeno permite que os usuários testem várias configurações. Uma lista abrangente de resultados neste conjunto está disponível. O reconhecimento de imagens baseado em aprendizagem profunda se tornou \"super-humano\", produzindo resultados mais precisos do que concorrentes humanos. Isso ocorreu pela primeira vez em 2011 no reconhecimento de sinais de trânsito e, em 2014, com o reconhecimento de rostos humanos. Veículos treinados em aprendizado profundo agora interpretam visualizações de câmera de 360°. Outro exemplo é a Análise de Novas Dismorfologias Faciais (FDNA), usada para analisar casos de malformações humanas conectados a um grande banco de dados de síndromes genéticas. Estreitamente relacionada ao progresso"}
{"source": "Aprendizagem profunda", "chunk_id": "Aprendizagem profunda_51", "text": "Análise de Novas Dismorfologias Faciais (FDNA), usada para analisar casos de malformações humanas conectados a um grande banco de dados de síndromes genéticas. Estreitamente relacionada ao progresso que foi feito no reconhecimento de imagens está a aplicação crescente de técnicas de aprendizado profundo a várias tarefas de artes visuais. As redes neurais profundas provaram ser capazes, por exemplo, de identificar o período de estilo de uma determinada pintura Transferência de estilo neural – capturar o estilo de uma determinada obra de arte e aplicá-lo de uma maneira visualmente agradável a uma fotografia ou vídeo arbitrário gerar imagens impressionantes com base em campos de entrada visual aleatórios. As redes neurais têm sido usadas para implementar modelos de linguagem desde o início dos anos 2000. A memória de curto prazo longa ajudou a melhorar a tradução automática e a modelagem de linguagem. Outras técnicas-chave neste campo são a amostragem negativa e a incorporação de"}
{"source": "Aprendizagem profunda", "chunk_id": "Aprendizagem profunda_52", "text": "dos anos 2000. A memória de curto prazo longa ajudou a melhorar a tradução automática e a modelagem de linguagem. Outras técnicas-chave neste campo são a amostragem negativa e a incorporação de palavras. A incorporação de palavras, como word2vec, pode ser considerada uma camada representacional em uma arquitetura de aprendizagem profunda que transforma uma palavra atômica em uma representação posicional da palavra em relação a outras palavras no conjunto de dados; a posição é representada como um ponto em um espaço vetorial. Usar a incorporação de palavras como uma camada de entrada da rede neural recorrente permite que a rede analise sentenças e frases usando uma gramática vetorial composicional eficaz. Uma gramática vetorial composicional pode ser considerada uma gramática livre de contexto probabilística (PCFG) implementada por uma rede neural recorrente. Os autocodificadores recursivos construídos sobre incorporações de palavras podem avaliar a similaridade de sentenças e detectar"}
{"source": "Aprendizagem profunda", "chunk_id": "Aprendizagem profunda_53", "text": "probabilística (PCFG) implementada por uma rede neural recorrente. Os autocodificadores recursivos construídos sobre incorporações de palavras podem avaliar a similaridade de sentenças e detectar paráfrases. Arquiteturas neurais profundas fornecem os melhores resultados para análise de constituintes, análise de sentimentos, recuperação de informações, compreensão de linguagem falada, tradução automática, vinculação de entidades contextuais, reconhecimento de estilo de escrita, reconhecimento de entidades nomeadas (classificação de tokens), classificação de texto e outros. Desenvolvimentos recentes generalizam a incorporação de palavras para a incorporação de frases. O Google Translate (GT) usa uma grande rede de memória de curto prazo longa (LSTM) de ponta a ponta. A Google Neural Machine Translation (GNMT) usa um método de tradução automática baseada em exemplos no qual o sistema \"aprende com milhões de exemplos\". Ela traduz \"frases inteiras de uma vez, em vez de partes\". O Google"}
{"source": "Aprendizagem profunda", "chunk_id": "Aprendizagem profunda_54", "text": "Translation (GNMT) usa um método de tradução automática baseada em exemplos no qual o sistema \"aprende com milhões de exemplos\". Ela traduz \"frases inteiras de uma vez, em vez de partes\". O Google Translate oferece suporte a mais de cem idiomas. A rede codifica a \"semântica da frase em vez de simplesmente memorizar traduções frase a frase\". O Google Translate usa o inglês como intermediário entre a maioria dos pares de idiomas. Uma grande porcentagem de medicamentos candidatos não consegue obter aprovação regulatória. Essas falhas são causadas por eficácia insuficiente (efeito no alvo), interações indesejadas (efeitos fora do alvo) ou efeitos tóxicos imprevistos. A pesquisa explorou o uso de aprendizagem profunda para prever os alvos biomoleculares, alvos fora do alvo e efeitos tóxicos de produtos químicos ambientais em nutrientes, produtos domésticos e medicamentos. A AtomNet é um sistema de aprendizagem profunda para design de medicamentos racional baseado em estrutura. A AtomNet"}
{"source": "Aprendizagem profunda", "chunk_id": "Aprendizagem profunda_55", "text": "de produtos químicos ambientais em nutrientes, produtos domésticos e medicamentos. A AtomNet é um sistema de aprendizagem profunda para design de medicamentos racional baseado em estrutura. A AtomNet foi usada para prever novas biomoléculas candidatas para alvos de doenças como o vírus Ebola e esclerose múltipla. Em 2017, redes neurais de grafos foram usadas pela primeira vez para prever várias propriedades de moléculas em um grande conjunto de dados de toxicologia. Em 2019, redes neurais generativas foram usadas para produzir moléculas que foram validadas experimentalmente em camundongos. Os sistemas de recomendações têm usado o aprendizagem profunda para extrair recursos significativos para um modelo de fator latente para recomendações de músicas e periódicos baseadas em conteúdo. A aprendizagem profunda multivisualização foi aplicada para aprender as preferências dos usuários de vários domínios. O modelo usa uma abordagem híbrida colaborativa e baseada em conteúdo e aprimora as"}
{"source": "Aprendizagem profunda", "chunk_id": "Aprendizagem profunda_56", "text": "aprendizagem profunda multivisualização foi aplicada para aprender as preferências dos usuários de vários domínios. O modelo usa uma abordagem híbrida colaborativa e baseada em conteúdo e aprimora as recomendações em várias tarefas. Uma rede neural artificial autocodificadora foi usada em bioinformática para prever relações entre funções genéticas e anotações de ontologia genética. Na informática médica, a aprendizagem profunda foi usada para prever a qualidade do sono com base em dados de wearables e previsões de complicações de saúde a partir de dados de registros de saúde eletrônicos. Redes neurais profundas têm mostrado desempenho incomparável na previsão de estruturas de proteínas, de acordo com a sequência dos aminoácidos que as compõem. Em 2020, a AlphaFold, um sistema baseado em aprendizagem profunda, atingiu um nível de precisão significativamente maior do que todos os métodos computacionais anteriores. Redes neurais profundas podem ser usadas para estimar a entropia de um"}
{"source": "Aprendizagem profunda", "chunk_id": "Aprendizagem profunda_57", "text": "aprendizagem profunda, atingiu um nível de precisão significativamente maior do que todos os métodos computacionais anteriores. Redes neurais profundas podem ser usadas para estimar a entropia de um processo estocástico por meio de um arranjo chamado Estimadora de Entropia Conjunta Neural (NJEE). Tal estimativa fornece percepções sobre os efeitos de variáveis aleatórias de entrada em uma variável aleatória independente. Praticamente, a rede neural profunda é treinada como uma classificadora que mapeia um vetor ou uma matriz X de entrada para uma distribuição de probabilidade de saída sobre as classes possíveis da variável aleatória Y, dada a entrada X. Por exemplo, em tarefas de classificação de imagens, a estimadora de entropia conjunta neural mapeia um vetor de valores de cores de pixels para probabilidades sobre possíveis classes de imagens. Na prática, a distribuição de probabilidade de Y é obtida por uma camada de Softmax com número de nós que é igual ao tamanho do alfabeto de Y."}
{"source": "Aprendizagem profunda", "chunk_id": "Aprendizagem profunda_58", "text": "para probabilidades sobre possíveis classes de imagens. Na prática, a distribuição de probabilidade de Y é obtida por uma camada de Softmax com número de nós que é igual ao tamanho do alfabeto de Y. A estimadora de entropia conjunta neural usa funções de ativação continuamente diferenciáveis, de modo que as condições para o teorema de aproximação universal sejam mantidas. É mostrado que este método fornece uma estimadora consistente fortemente e supera outros métodos nos casos de tamanhos de alfabetos grandes. Foi demonstrado que a aprendizagem profunda produz resultados competitivos em aplicações médicas, como classificação de células cancerígenas, detecção de lesões, segmentação de órgãos e aprimoramento de imagens. As ferramentas modernas de aprendizagem profunda demonstram a alta precisão na detecção de várias doenças e a utilidade de seu uso por especialistas para melhorar a eficiência do diagnóstico. Encontrar o público móvel apropriado para publicidade móvel é sempre"}
{"source": "Aprendizagem profunda", "chunk_id": "Aprendizagem profunda_59", "text": "alta precisão na detecção de várias doenças e a utilidade de seu uso por especialistas para melhorar a eficiência do diagnóstico. Encontrar o público móvel apropriado para publicidade móvel é sempre desafiador, pois muitos pontos de dados devem ser considerados e analisados antes que um segmento alvo possa ser criado e usado na veiculação de anúncios por qualquer servidor de anúncios. A aprendizagem profunda tem sido usada para interpretar grandes conjuntos de dados de publicidade multidimensionais. Muitos pontos de dados são coletados durante o ciclo de solicitação/veiculação/clique de publicidade na Internet. Essas informações podem formar a base do aprendizado de máquina para melhorar a seleção de anúncios. A aprendizagem profunda foi aplicada com sucesso a problemas inversos, como redução de ruído, super-resolução, pintura interna e colorização de filmes. Essas aplicações incluem métodos de aprendizado como \"campos de encolhimento para restauração eficaz de imagens\", que treina em"}
{"source": "Aprendizagem profunda", "chunk_id": "Aprendizagem profunda_60", "text": "de ruído, super-resolução, pintura interna e colorização de filmes. Essas aplicações incluem métodos de aprendizado como \"campos de encolhimento para restauração eficaz de imagens\", que treina em um conjunto de dados de imagens, e Deep Image Prior, que treina na imagem que precisa de restauração. A aprendizagem profunda está sendo aplicada com sucesso à detecção de fraudes financeiras, à detecção de evasão fiscal e ao combate à lavagem de dinheiro. Em novembro de 2023, pesquisadores da Google DeepMind e do Lawrence Berkeley National Laboratory anunciaram que desenvolveram um sistema de IA conhecido como GNoME. Este sistema contribuiu para a ciência dos materiais ao descobrir mais de 2 milhões de novos materiais em um período de tempo relativamente curto. O GNoME emprega técnicas de aprendizagem profunda para explorar com eficiência potenciais estruturas de materiais, alcançando um aumento significativo na identificação de estruturas cristalinas inorgânicas estáveis. As previsões do"}
{"source": "Aprendizagem profunda", "chunk_id": "Aprendizagem profunda_61", "text": "profunda para explorar com eficiência potenciais estruturas de materiais, alcançando um aumento significativo na identificação de estruturas cristalinas inorgânicas estáveis. As previsões do sistema foram validadas por meio de experimentos robóticos autônomos, demonstrando uma notável taxa de sucesso de 71%. Os dados de materiais recém-descobertos estão disponíveis publicamente por meio do banco de dados do Materials Project, oferecendo aos pesquisadores a oportunidade de identificar materiais com propriedades desejadas para várias aplicações. Este desenvolvimento tem implicações para o futuro da descoberta científica e a integração da IA na pesquisa de ciência dos materiais, potencialmente agilizando a inovação de materiais e reduzindo custos no desenvolvimento de produtos. O uso de IA e aprendizagem profunda sugere a possibilidade de minimizar ou eliminar experimentos manuais de laboratório e permitir que os cientistas se concentrem mais no design e na análise de compostos"}
{"source": "Aprendizagem profunda", "chunk_id": "Aprendizagem profunda_62", "text": "de IA e aprendizagem profunda sugere a possibilidade de minimizar ou eliminar experimentos manuais de laboratório e permitir que os cientistas se concentrem mais no design e na análise de compostos exclusivos. O Departamento de Defesa dos Estados Unidos aplicou o aprendizagem profunda para treinar robôs em novas tarefas por meio da observação. Redes neurais informadas por física têm sido usadas para resolver equações diferenciais parciais em problemas diretos e inversos de uma maneira orientada por dados. Um exemplo é a reconstrução do fluxo de fluido governado pelas equações de Navier e Stokes. Usar redes neurais informadas por física não requer a geração de malha frequentemente cara da qual os métodos de fluidodinâmica computacional (CFD) convencionais dependem. O método de equação diferencial estocástica regressiva profunda é um método numérico que combina aprendizagem profunda com equação diferencial estocástica regressiva (BSDE). Este método é particularmente útil para resolver"}
{"source": "Aprendizagem profunda", "chunk_id": "Aprendizagem profunda_63", "text": "estocástica regressiva profunda é um método numérico que combina aprendizagem profunda com equação diferencial estocástica regressiva (BSDE). Este método é particularmente útil para resolver problemas de alta dimensão em matemática financeira. Ao alavancar os poderosos recursos de aproximação de função de redes neurais profundas, a equação diferencial estocástica regressiva profunda aborda os desafios computacionais enfrentados por métodos numéricos tradicionais em configurações de altas dimensões. Especificamente, métodos tradicionais como métodos de diferença finita ou simulações de Monte Carlo frequentemente lutam com a maldição da dimensionalidade, onde o custo computacional aumenta exponencialmente com o número de dimensões. Os métodos de equação diferencial estocástica regressiva profunda, no entanto, empregam redes neurais profundas para aproximar soluções de equações diferenciais parciais (PDEs) de altas dimensões, reduzindo efetivamente a carga computacional. Além disso, a"}
{"source": "Aprendizagem profunda", "chunk_id": "Aprendizagem profunda_64", "text": "profunda, no entanto, empregam redes neurais profundas para aproximar soluções de equações diferenciais parciais (PDEs) de altas dimensões, reduzindo efetivamente a carga computacional. Além disso, a integração de redes neurais informadas por física (PINNs) na estrutura de equação diferencial estocástica regressiva profunda aumenta sua capacidade ao incorporar as leis físicas subjacentes diretamente na arquitetura da rede neural. Isso garante que as soluções não apenas se ajustem aos dados, mas também adiram às equações diferenciais estocásticas governantes. As redes neurais informadas por física alavancam o poder da aprendizagem profunda, respeitando as restrições impostas pelos modelos físicos, resultando em soluções mais precisas e confiáveis para problemas de matemática financeira. A reconstrução de imagens é a reconstrução das imagens subjacentes a partir das medições relacionadas às imagens. Vários trabalhos mostraram o desempenho melhor e superior dos métodos de aprendizagem"}
{"source": "Aprendizagem profunda", "chunk_id": "Aprendizagem profunda_65", "text": "A reconstrução de imagens é a reconstrução das imagens subjacentes a partir das medições relacionadas às imagens. Vários trabalhos mostraram o desempenho melhor e superior dos métodos de aprendizagem profunda em comparação aos métodos analíticos para várias aplicações, por exemplo, imagens espectrais e imagens de ultrassom. Os sistemas tradicionais de previsão do tempo resolvem um sistema muito complexo de equações diferenciais parciais. O GraphCast é um modelo baseado em aprendizagem profunda, treinado em um longo histórico de dados meteorológicos para prever como os padrões climáticos mudam ao longo do tempo. Ele é capaz de prever as condições climáticas por até 10 dias globalmente, em um nível muito detalhado e em menos de um minuto, com precisão semelhante aos sistemas de última geração. Um relógio epigenético é um teste bioquímico que pode ser usado para medir a idade. Galkin et al. usaram redes neurais profundas para treinar um relógio de envelhecimento epigenético de precisão"}
{"source": "Aprendizagem profunda", "chunk_id": "Aprendizagem profunda_66", "text": "Um relógio epigenético é um teste bioquímico que pode ser usado para medir a idade. Galkin et al. usaram redes neurais profundas para treinar um relógio de envelhecimento epigenético de precisão sem precedentes usando mais de 6.000 amostras de sangue. O relógio usa informações de 1000 sítios CpG e prevê pessoas com certas condições mais velhas do que controles saudáveis: doença inflamatória intestinal (DII), demência frontotemporal, câncer ovariano, obesidade. O relógio de envelhecimento foi planejado para ser lançado para uso público em 2021 por uma empresa subproduto da Insilico Medicine, a Deep Longevity. A aprendizagem profunda está intimamente relacionado a uma classe de teorias de desenvolvimento cerebral (especificamente, desenvolvimento neocortical) propostas por neurocientistas cognitivos no início da década de 1990. Essas teorias de desenvolvimento foram instanciadas em modelos computacionais, tornando-as predecessoras de sistemas de aprendizagem profunda. Esses modelos de"}
{"source": "Aprendizagem profunda", "chunk_id": "Aprendizagem profunda_67", "text": "cognitivos no início da década de 1990. Essas teorias de desenvolvimento foram instanciadas em modelos computacionais, tornando-as predecessoras de sistemas de aprendizagem profunda. Esses modelos de desenvolvimento compartilham a propriedade de que várias dinâmicas de aprendizado propostas no cérebro (por exemplo, uma onda de fator de crescimento nervoso) suportam a auto-organização de forma um tanto análoga às redes neurais utilizadas em modelos de aprendizagem profunda. Como o neocórtex, as redes neurais empregam uma hierarquia de filtros em camadas em que cada camada considera informações de uma camada anterior (ou do ambiente operacional) e, em seguida, passa sua saída (e possivelmente a entrada original) para outras camadas. Esse processo produz uma pilha auto-organizada de transdutores, bem ajustada ao seu ambiente operacional. Uma descrição de 1995 declarou: \"...o cérebro do bebê parece se organizar sob a influência de ondas dos chamados fatores tróficos... diferentes regiões"}
{"source": "Aprendizagem profunda", "chunk_id": "Aprendizagem profunda_68", "text": "bem ajustada ao seu ambiente operacional. Uma descrição de 1995 declarou: \"...o cérebro do bebê parece se organizar sob a influência de ondas dos chamados fatores tróficos... diferentes regiões do cérebro se conectam sequencialmente, com uma camada de tecido amadurecendo antes da outra e assim por diante até que todo o cérebro esteja maduro\". Uma variedade de abordagens tem sido usada para investigar a plausibilidade de modelos de aprendizagem profunda de uma perspectiva neurobiológica. Por um lado, várias variantes do algoritmo de retropropagação foram propostas para aumentar seu realismo de processamento. Outros pesquisadores argumentaram que formas não supervisionadas de aprendizagem profunda, como aquelas baseadas em modelos generativos hierárquicos e redes de crenças profundas, podem estar mais próximas da realidade biológica. A esse respeito, modelos de rede neural generativa têm sido relacionados a evidências neurobiológicas sobre processamento baseado em amostragem no córtex"}
{"source": "Aprendizagem profunda", "chunk_id": "Aprendizagem profunda_69", "text": "estar mais próximas da realidade biológica. A esse respeito, modelos de rede neural generativa têm sido relacionados a evidências neurobiológicas sobre processamento baseado em amostragem no córtex cerebral. Embora uma comparação sistemática entre a organização do cérebro humano e a codificação neuronal em redes profundas ainda não tenha sido estabelecida, várias analogias foram relatadas. Por exemplo, as computações realizadas por unidades de aprendizagem profunda podem ser semelhantes às de neurônios reais e populações neurais. Da mesma forma, as representações desenvolvidas por modelos de aprendizagem profunda são semelhantes às medidas no sistema visual de primatas tanto nos níveis de unidade única quanto nos níveis de população. O laboratório de IA do Facebook realiza tarefas como marcar automaticamente fotos carregadas com os nomes das pessoas nelas. A DeepMind Technologies do Google desenvolveu um sistema capaz de aprender a jogar videogames Atari usando apenas pixels como"}
{"source": "Aprendizagem profunda", "chunk_id": "Aprendizagem profunda_70", "text": "marcar automaticamente fotos carregadas com os nomes das pessoas nelas. A DeepMind Technologies do Google desenvolveu um sistema capaz de aprender a jogar videogames Atari usando apenas pixels como entrada de dados. Em 2015, eles demonstraram seu sistema AlphaGo, que aprendeu o jogo Go bem o suficiente para vencer um jogador profissional de Go. O Google Translate usa uma rede neural para traduzir entre mais de 100 idiomas. Em 2017, foi lançado o Covariant.ai, que se concentra na integração da aprendizagem profunda em fábricas. Em 2008, pesquisadores da Universidade do Texas em Austin (UT) desenvolveram uma estrutura de aprendizado de máquina chamada Treinando um Agente Manualmente via Reforço Avaliativo, ou TAMER, que propôs novos métodos para robôs ou programas de computador aprenderem a executar tarefas interagindo com um instrutor humano. Desenvolvido inicialmente como TAMER, um novo algoritmo chamado Deep TAMER foi posteriormente introduzido em 2018 durante uma colaboração entre o"}
{"source": "Aprendizagem profunda", "chunk_id": "Aprendizagem profunda_71", "text": "executar tarefas interagindo com um instrutor humano. Desenvolvido inicialmente como TAMER, um novo algoritmo chamado Deep TAMER foi posteriormente introduzido em 2018 durante uma colaboração entre o Laboratório de Pesquisa do Exército dos EUA (ARL) e pesquisadores da UT. O Deep TAMER usou a aprendizagem profunda para fornecer a um robô a capacidade de aprender novas tarefas por meio da observação. Usando o Deep TAMER, um robô aprendeu uma tarefa com um treinador humano, assistindo a transmissões de vídeo ou observando um humano executar uma tarefa pessoalmente. O robô posteriormente praticou a tarefa com a ajuda de algum treinamento do treinador, que forneceu feedback como \"bom trabalho\" e \"trabalho ruim\". A aprendizagem profunda atraiu críticas e comentários, em alguns casos de fora do campo da ciência da computação. Uma crítica principal diz respeito à falta de teoria em torno de alguns métodos. A aprendizagem nas arquiteturas profundas mais comuns é implementada usando a descida"}
{"source": "Aprendizagem profunda", "chunk_id": "Aprendizagem profunda_72", "text": "campo da ciência da computação. Uma crítica principal diz respeito à falta de teoria em torno de alguns métodos. A aprendizagem nas arquiteturas profundas mais comuns é implementada usando a descida de gradiente bem compreendida. No entanto, a teoria em torno de outros algoritmos, como a divergência contrastiva, é menos clara. (por exemplo, Converge? Se sim, quão rápido? O que está se aproximando?) Os métodos de aprendizagem profunda são frequentemente vistos como uma caixa-preta, com a maioria das confirmações feitas empiricamente, em vez de teoricamente. Em referência adicional à ideia de que a sensibilidade artística pode ser inerente a níveis relativamente baixos da hierarquia cognitiva, uma série publicada de representações gráficas dos estados internos de redes neurais profundas (20-30 camadas) tentando discernir dentro de dados essencialmente aleatórios as imagens nas quais foram treinadas demonstra um apelo visual: o aviso de pesquisa original recebeu bem mais de 1.000"}
{"source": "Aprendizagem profunda", "chunk_id": "Aprendizagem profunda_73", "text": "(20-30 camadas) tentando discernir dentro de dados essencialmente aleatórios as imagens nas quais foram treinadas demonstra um apelo visual: o aviso de pesquisa original recebeu bem mais de 1.000 comentários e foi o assunto do que foi por um tempo o artigo mais acessado no site do The Guardian. Com o apoio da Teoria da Difusão da Inovação (IDT), um estudo analisou a difusão da Aprendizagem Profunda nos países do BRICS e da OCDE usando dados do Google Trends. Algumas arquiteturas de aprendizagem profunda apresentam comportamentos problemáticos, como classificar com segurança imagens irreconhecíveis como pertencentes a uma categoria familiar de imagens comuns (2014) e classificar incorretamente perturbações minúsculas de imagens classificadas corretamente (2013). Goertzel levantou a hipótese de que esses comportamentos são devidos a limitações em suas representações internas e que essas limitações inibiriam a integração em arquiteturas heterogêneas de inteligência artificial geral (AGI)"}
{"source": "Aprendizagem profunda", "chunk_id": "Aprendizagem profunda_74", "text": "de que esses comportamentos são devidos a limitações em suas representações internas e que essas limitações inibiriam a integração em arquiteturas heterogêneas de inteligência artificial geral (AGI) multicomponente. Essas questões podem ser possivelmente abordadas por arquiteturas de aprendizagem profunda que formam internamente estados homólogos às decomposições de gramática de imagem de entidades e eventos observados. Aprender uma gramática (visual ou linguística) a partir de dados de treinamento seria equivalente a restringir o sistema ao raciocínio de senso comum que opera em conceitos em termos de regras de produção gramatical e é um objetivo básico tanto da aquisição da linguagem humana quanto da inteligência artificial (IA). À medida que a aprendizagem profunda sai do laboratório para o mundo, pesquisas e experiências mostram que redes neurais artificiais são vulneráveis a hacks e enganos. Ao identificar os padrões que esses sistemas usam para funcionar, os invasores podem"}
{"source": "Aprendizagem profunda", "chunk_id": "Aprendizagem profunda_75", "text": "para o mundo, pesquisas e experiências mostram que redes neurais artificiais são vulneráveis a hacks e enganos. Ao identificar os padrões que esses sistemas usam para funcionar, os invasores podem modificar entradas para as redes neurais artificiais de tal forma que a rede neural artificial encontre uma correspondência que observadores humanos não reconheceriam. Por exemplo, um invasor pode fazer mudanças sutis em uma imagem de tal forma que a rede neural artificial encontre uma correspondência, mesmo que a imagem não pareça nada com o alvo da pesquisa para um humano. Tal manipulação é denominada \"ataque adversário\". Em 2016, pesquisadores usaram uma rede neural artificial para manipular imagens por tentativa e erro, identificar os pontos focais de outra e, assim, gerar imagens que a enganassem. As imagens modificadas não pareciam diferentes aos olhos humanos. Outro grupo mostrou que impressões de imagens manipuladas e depois fotografadas enganaram com sucesso um sistema de"}
{"source": "Aprendizagem profunda", "chunk_id": "Aprendizagem profunda_76", "text": "que a enganassem. As imagens modificadas não pareciam diferentes aos olhos humanos. Outro grupo mostrou que impressões de imagens manipuladas e depois fotografadas enganaram com sucesso um sistema de classificação de imagens. Uma defesa é a busca reversa de imagens, na qual uma possível imagem falsa é enviada a um site como o TinEye, que pode então encontrar outras instâncias dela. Um refinamento é pesquisar usando apenas partes da imagem, para identificar imagens das quais aquela parte pode ter sido retirada. Outro grupo mostrou que certos espetáculos psicodélicos poderiam enganar um sistema de reconhecimento facial, fazendo-o pensar que pessoas comuns eram celebridades, potencialmente permitindo que uma pessoa se passasse por outra. Em 2017, pesquisadores adicionaram adesivos a placas de pare e fizeram com que uma rede neural artificial as classificasse incorretamente. As redes neurais artificiais podem, no entanto, ser mais treinadas para detectar tentativas de engano,"}
{"source": "Aprendizagem profunda", "chunk_id": "Aprendizagem profunda_77", "text": "a placas de pare e fizeram com que uma rede neural artificial as classificasse incorretamente. As redes neurais artificiais podem, no entanto, ser mais treinadas para detectar tentativas de engano, potencialmente levando atacantes e defensores a uma corrida armamentista semelhante ao tipo que já define a indústria de defesa contra malware. As redes neurais artificiais foram treinadas para derrotar software antimalware baseado em rede neural artificial, atacando repetidamente uma defesa com malware que foi continuamente alterado por um algoritmo genético até enganar o antimalware, mantendo sua capacidade de danificar o alvo. Em 2016, outro grupo demonstrou que certos sons poderiam fazer o sistema de comando de voz do Google Now abrir um endereço da web específico e levantou a hipótese de que isso poderia \"servir como um trampolim para novos ataques (por exemplo, abrir uma página da web que hospeda malware drive-by)\". No \"envenenamento de dados\", dados falsos são continuamente"}
{"source": "Aprendizagem profunda", "chunk_id": "Aprendizagem profunda_78", "text": "de que isso poderia \"servir como um trampolim para novos ataques (por exemplo, abrir uma página da web que hospeda malware drive-by)\". No \"envenenamento de dados\", dados falsos são continuamente contrabandeados para o conjunto de treinamento de um sistema de aprendizado de máquina para evitar que ele alcance a maestria. Os sistemas de aprendizagem profunda que são treinados usando aprendizagem supervisionada geralmente dependem de dados criados ou anotados por humanos, ou ambos. Foi argumentado que não apenas o trabalho de clique mal pago (como no Amazon Mechanical Turk) é regularmente implantado para esse propósito, mas também formas implícitas de microtrabalho humano que muitas vezes não são reconhecidas como tal. O filósofo Rainer Mühlhoff distingue cinco tipos de \"captura maquínica\" do microtrabalho humano para gerar dados de treinamento: (1) gamificação (a incorporação de tarefas de anotação ou computação no fluxo de um jogo), (2) \"captura e rastreamento\" (por exemplo, CAPTCHAs"}
{"source": "Aprendizagem profunda", "chunk_id": "Aprendizagem profunda_79", "text": "do microtrabalho humano para gerar dados de treinamento: (1) gamificação (a incorporação de tarefas de anotação ou computação no fluxo de um jogo), (2) \"captura e rastreamento\" (por exemplo, CAPTCHAs para reconhecimento de imagem ou rastreamento de cliques nas páginas de resultados de pesquisas do Google), (3) exploração de motivações sociais (por exemplo, marcar rostos no Facebook para obter imagens faciais rotuladas), (4) mineração de informações (por exemplo, alavancando dispositivos de autoquantificação, como rastreadores de atividade) e (5) trabalho de clique. Amostragem compressiva Aprendizado por transferência Codificação esparsa Lista de projetos de inteligência artificial Máquina de estado líquido"}
{"source": "Aprendizagem por reforço", "chunk_id": "Aprendizagem por reforço_0", "text": "Aprendizado ou apredizagem por reforço (AR) é uma área interdisciplinar de aprendizado de máquina e controle ótimo que se preocupa com a forma como um agente inteligente deve tomar ações em um ambiente dinâmico para maximizar um sinal de recompensa. É um dos três paradigmas básicos de aprendizado de máquina, juntamente com o aprendizado supervisionado e o aprendizado não supervisionado. O Q-learning, em sua forma mais simples, armazena dados em tabelas. Essa abordagem se torna inviável à medida que o número de estados/ações aumenta (por exemplo, se o espaço de estados ou o espaço de ações fosse contínuo), pois a probabilidade do agente visitar um estado específico e executar uma ação específica diminui. O aprendizado por reforço difere do aprendizado supervisionado por não precisar que pares de entrada-saída rotulados sejam apresentados e por não precisar que ações subótimas sejam explicitamente corrigidas. Em vez disso, o foco está em encontrar um equilíbrio entre a exploração (de"}
{"source": "Aprendizagem por reforço", "chunk_id": "Aprendizagem por reforço_1", "text": "pares de entrada-saída rotulados sejam apresentados e por não precisar que ações subótimas sejam explicitamente corrigidas. Em vez disso, o foco está em encontrar um equilíbrio entre a exploração (de território desconhecido) e a exploração (do conhecimento atual) com o objetivo de maximizar a recompensa cumulativa (cujo feedback pode ser incompleto ou atrasado). O ambiente é normalmente declarado na forma de um processo de decisão de Markov (PDM), já que muitos algoritmos de aprendizagem por reforço usam técnicas de programação dinâmica. A principal diferença entre os métodos clássicos de programação dinâmica e os algoritmos de aprendizagem por reforço é que estes últimos não pressupõem o conhecimento de um modelo matemático exato do processo de decisão de Markov e têm como alvo grandes PDMs onde os métodos exatos se tornam inviáveis. Devido à sua generalidade, o aprendizado por reforço é estudado em muitas disciplinas, como teoria dos jogos, teoria de controle, pesquisa operacional,"}
{"source": "Aprendizagem por reforço", "chunk_id": "Aprendizagem por reforço_2", "text": "onde os métodos exatos se tornam inviáveis. Devido à sua generalidade, o aprendizado por reforço é estudado em muitas disciplinas, como teoria dos jogos, teoria de controle, pesquisa operacional, teoria da informação, otimização baseada em simulação, sistemas multiagente, inteligência de enxame e estatística. Na pesquisa operacional e na literatura de controle, o AR é chamado de programação dinâmica aproximada ou programação neuro-dinâmica. Os problemas de interesse em AR também são estudados na teoria de controle ótimo, que se preocupa principalmente com a existência e caracterização de soluções ótimas e algoritmos para seu cálculo exato, e menos com aprendizado ou aproximação (particularmente na ausência de um modelo matemático do ambiente). O aprendizado por reforço básico é modelado como um processo de decisão de Markov: Um conjunto de estados do ambiente e do agente (o espaço de estados), S {\\displaystyle {\\mathcal {S}}} ; Um conjunto de ações (o espaço de ações), A"}
{"source": "Aprendizagem por reforço", "chunk_id": "Aprendizagem por reforço_3", "text": "é modelado como um processo de decisão de Markov: Um conjunto de estados do ambiente e do agente (o espaço de estados), S {\\displaystyle {\\mathcal {S}}} ; Um conjunto de ações (o espaço de ações), A {\\displaystyle {\\mathcal {A}}} , do agente; P a ( s , s ′ ) = Pr ( S t + 1 = s ′ ∣ S t = s , A t = a ) {\\displaystyle P_{a}(s,s')=\\Pr(S_{t+1}=s'\\mid S_{t}=s,A_{t}=a)} , a probabilidade de transição (no tempo t {\\displaystyle t} ) de estado s {\\displaystyle s} para estado s ′ {\\displaystyle s'} sob a ação a {\\displaystyle a} . R a ( s , s ′ ) {\\displaystyle R_{a}(s,s')} , a recompensa imediata após a transição de s {\\displaystyle s} para s ′ {\\displaystyle s'} sob a ação a {\\displaystyle a} . O objetivo do aprendizado por reforço é levar o agente a aprender uma política ótima (ou próxima do ótimo) que maximize a função de recompensa ou outro sinal de reforço fornecido pelo usuário, acumulado a partir de recompensas imediatas. Isso é semelhante a processos que parecem ocorrer na psicologia"}
{"source": "Aprendizagem por reforço", "chunk_id": "Aprendizagem por reforço_4", "text": "que maximize a função de recompensa ou outro sinal de reforço fornecido pelo usuário, acumulado a partir de recompensas imediatas. Isso é semelhante a processos que parecem ocorrer na psicologia animal. Por exemplo, cérebros biológicos são programados para interpretar sinais como dor e fome como reforços negativos e interpretar prazer e consumo de alimentos como reforços positivos. Em algumas circunstâncias, animais aprendem a adotar comportamentos que otimizam essas recompensas, sugerindo que animais são capazes de aprendizado por reforço. Um agente básico de aprendizado por reforço interage com seu ambiente em passos de tempo discretos. A cada passo de tempo t, o agente recebe o estado atual S t {\\displaystyle S_{t}} e a recompensa R t {\\displaystyle R_{t}} . Em seguida, escolhe uma ação A t {\\displaystyle A_{t}} dentre as ações disponíveis, que então é enviada ao ambiente. O ambiente passa para um novo estado S t + 1 {\\displaystyle S_{t+1}} e a recompensa R t + 1 {\\displaystyle"}
{"source": "Aprendizagem por reforço", "chunk_id": "Aprendizagem por reforço_5", "text": "ação A t {\\displaystyle A_{t}} dentre as ações disponíveis, que então é enviada ao ambiente. O ambiente passa para um novo estado S t + 1 {\\displaystyle S_{t+1}} e a recompensa R t + 1 {\\displaystyle R_{t+1}} associada à transição ( S t , A t , S t + 1 ) {\\displaystyle (S_{t},A_{t},S_{t+1})} é determinada. O objetivo de um agente de aprendizado por reforço é aprender uma política: π : S × A → [ 0 , 1 ] {\\displaystyle \\pi :{\\mathcal {S}}\\times {\\mathcal {A}}\\rightarrow [0,1]} , π ( s , a ) = Pr ( A t = a ∣ S t = s ) {\\displaystyle \\pi (s,a)=\\Pr(A_{t}=a\\mid S_{t}=s)} que maximize a recompensa acumulada esperada. Formular o problema como um processo de decisão de Markov pressupõe que o agente observa diretamente o estado atual do ambiente; nesse caso, diz-se que o problema tem observabilidade completa. Se o agente só tem acesso a um subconjunto de estados ou se os estados observados são corrompidos por ruído, o agente tem observabilidade parcial, e formalmente o problema deve ser"}
{"source": "Aprendizagem por reforço", "chunk_id": "Aprendizagem por reforço_6", "text": "completa. Se o agente só tem acesso a um subconjunto de estados ou se os estados observados são corrompidos por ruído, o agente tem observabilidade parcial, e formalmente o problema deve ser definido como um processo de decisão de Markov parcialmente observável. Em ambos os casos, o conjunto de ações disponíveis ao agente pode ser restringido. Por exemplo, o estado de um saldo bancário pode ser restrito a ser positivo; se o valor atual do estado é 3 e a transição de estado tenta reduzir o valor em 4, essa transição não será permitida. Quando o desempenho do agente é comparado ao de um agente que atua de modo ótimo, a diferença de desempenho resulta no conceito de arrependimento (regret). Para agir de forma quase ótima, o agente deve raciocinar sobre as consequências de longo prazo de suas ações (isto é, maximizar recompensas futuras), embora a recompensa imediata associada possa ser negativa. Assim, o aprendizado por reforço é particularmente adequado para problemas que envolvem a"}
{"source": "Aprendizagem por reforço", "chunk_id": "Aprendizagem por reforço_7", "text": "ações (isto é, maximizar recompensas futuras), embora a recompensa imediata associada possa ser negativa. Assim, o aprendizado por reforço é particularmente adequado para problemas que envolvem a troca entre recompensas de longo e curto prazo. Ele já foi aplicado com sucesso a diversos problemas, incluindo armazenamento de energia, controle de robôs, geradores fotovoltaicos, backgammon, damas, Go (AlphaGo) e sistemas de direção autônoma. Dois elementos tornam o aprendizado por reforço poderoso: o uso de amostras para otimizar desempenho e o uso de aproximação de função para lidar com ambientes grandes. Graças a esses dois componentes, o AR pode ser usado em ambientes grandes nas seguintes situações: Um modelo do ambiente é conhecido, mas não se dispõe de uma solução analítica; Somente um modelo de simulação do ambiente é fornecido (assunto de otimização baseada em simulação); A única forma de coletar informações sobre o ambiente é interagindo com ele. Os dois primeiros problemas"}
{"source": "Aprendizagem por reforço", "chunk_id": "Aprendizagem por reforço_8", "text": "um modelo de simulação do ambiente é fornecido (assunto de otimização baseada em simulação); A única forma de coletar informações sobre o ambiente é interagindo com ele. Os dois primeiros problemas poderiam ser considerados problemas de planejamento (já que algum tipo de modelo está disponível), enquanto o último poderia ser considerado realmente um problema de aprendizado. Entretanto, o aprendizado por reforço converte ambos os problemas de planejamento em problemas de aprendizado de máquina. A troca entre exploração e exploração foi estudada principalmente através do problema multi-armed bandit e para processos de decisão de Markov com espaço de estados finito em Burnetas e Katehakis (1997). O aprendizado por reforço exige mecanismos de exploração inteligentes; selecionar ações aleatoriamente, sem referência a uma distribuição de probabilidade estimada, apresenta baixo desempenho. O caso de processos de decisão de Markov finitos (pequenos) é relativamente bem compreendido."}
{"source": "Aprendizagem por reforço", "chunk_id": "Aprendizagem por reforço_9", "text": "aleatoriamente, sem referência a uma distribuição de probabilidade estimada, apresenta baixo desempenho. O caso de processos de decisão de Markov finitos (pequenos) é relativamente bem compreendido. Entretanto, devido à falta de algoritmos que escalem bem com o número de estados (ou que escalem para problemas com espaço de estados infinito), métodos simples de exploração são os mais práticos. Um desses métodos é ε {\\displaystyle \\varepsilon } -ganancioso (\\varepsilon-greedy), onde 0 < ε < 1 {\\displaystyle 0<\\varepsilon <1} é um parâmetro que controla a quantidade de exploração vs. exploração. Com probabilidade 1 − ε {\\displaystyle 1-\\varepsilon } , escolhe-se a exploração, e o agente escolhe a ação que acredita ter o melhor efeito de longo prazo (desempates entre ações são escolhidos uniformemente ao acaso). Por outro lado, com probabilidade ε {\\displaystyle \\varepsilon } , a exploração é escolhida, e a ação é selecionada uniformemente ao acaso. Normalmente, ε {\\displaystyle"}
{"source": "Aprendizagem por reforço", "chunk_id": "Aprendizagem por reforço_10", "text": "uniformemente ao acaso). Por outro lado, com probabilidade ε {\\displaystyle \\varepsilon } , a exploração é escolhida, e a ação é selecionada uniformemente ao acaso. Normalmente, ε {\\displaystyle \\varepsilon } é um parâmetro fixo, mas pode ser ajustado de acordo com um cronograma (levando o agente a explorar cada vez menos) ou adaptado com base em heurísticas. Mesmo desconsiderando a questão da exploração e assumindo que o estado é observável (assumido daqui em diante), o problema ainda é usar a experiência passada para descobrir quais ações levam a maiores recompensas acumuladas. Política A seleção de ação do agente é modelada como um mapeamento chamado política: π : A × S → [ 0 , 1 ] {\\displaystyle \\pi :{\\mathcal {A}}\\times {\\mathcal {S}}\\rightarrow [0,1]} π ( a , s ) = Pr ( A t = a ∣ S t = s ) {\\displaystyle \\pi (a,s)=\\Pr(A_{t}=a\\mid S_{t}=s)} O mapa de política fornece a probabilidade de realizar a ação a {\\displaystyle a} ao estar no estado s {\\displaystyle s} . Também existem"}
{"source": "Aprendizagem por reforço", "chunk_id": "Aprendizagem por reforço_11", "text": "S t = s ) {\\displaystyle \\pi (a,s)=\\Pr(A_{t}=a\\mid S_{t}=s)} O mapa de política fornece a probabilidade de realizar a ação a {\\displaystyle a} ao estar no estado s {\\displaystyle s} . Também existem políticas determinísticas π {\\displaystyle \\pi } , para as quais π ( s ) {\\displaystyle \\pi (s)} denota a ação que deve ser executada no estado s {\\displaystyle s} . Função de valor de estado A função de valor de estado V π ( s ) {\\displaystyle V_{\\pi }(s)} é definida como o retorno descontado esperado a partir do estado s {\\displaystyle s} , ou seja, S 0 = s {\\displaystyle S_{0}=s} , seguindo sucessivamente a política π {\\displaystyle \\pi } . Em termos gerais, a função de valor estima \"o quão bom\" é estar em um estado dado. V π ( s ) = E ⁡ [ G ∣ S 0 = s ] = E ⁡ [ ∑ t = 0 ∞ γ t R t + 1 ∣ S 0 = s ] , {\\displaystyle V_{\\pi }(s)=\\operatorname {\\mathbb {E} } [G\\mid S_{0}=s]=\\operatorname {\\mathbb {E} } \\left[\\sum _{t=0}^{\\infty }\\gamma ^{t}R_{t+1}\\mid S_{0}=s\\right],} onde a variável aleatória"}
{"source": "Aprendizagem por reforço", "chunk_id": "Aprendizagem por reforço_12", "text": "s ] , {\\displaystyle V_{\\pi }(s)=\\operatorname {\\mathbb {E} } [G\\mid S_{0}=s]=\\operatorname {\\mathbb {E} } \\left[\\sum _{t=0}^{\\infty }\\gamma ^{t}R_{t+1}\\mid S_{0}=s\\right],} onde a variável aleatória G {\\displaystyle G} denota o retorno descontado, definido como a soma de recompensas futuras descontadas: G = ∑ t = 0 ∞ γ t R t + 1 = R 1 + γ R 2 + γ 2 R 3 + … , {\\displaystyle G=\\sum _{t=0}^{\\infty }\\gamma ^{t}R_{t+1}=R_{1}+\\gamma R_{2}+\\gamma ^{2}R_{3}+\\dots ,} onde R t + 1 {\\displaystyle R_{t+1}} é a recompensa pela transição do estado S t {\\displaystyle S_{t}} para S t + 1 {\\displaystyle S_{t+1}} , e 0 ≤ γ < 1 {\\displaystyle 0\\leq \\gamma <1} é a taxa de desconto. γ {\\displaystyle \\gamma } é menor que 1, de modo que recompensas distantes no futuro têm peso menor do que recompensas imediatas. O algoritmo deve encontrar uma política que maximize o retorno descontado esperado. A partir da teoria de processos de decisão de Markov, sabe-se que, sem perda de generalidade, a busca pode ser"}
{"source": "Aprendizagem por reforço", "chunk_id": "Aprendizagem por reforço_13", "text": "O algoritmo deve encontrar uma política que maximize o retorno descontado esperado. A partir da teoria de processos de decisão de Markov, sabe-se que, sem perda de generalidade, a busca pode ser restringida ao conjunto de políticas chamadas estacionárias. Uma política é estacionária se a distribuição de ações retornada por ela depende apenas do último estado visitado (considerado o histórico de observações do agente). A busca pode ser ainda mais restringida a políticas determinísticas estacionárias. Uma política estacionária determinística seleciona ações de forma determinística com base no estado atual. Como toda política desse tipo pode ser identificada com um mapeamento do conjunto de estados para o conjunto de ações, nenhuma generalidade é perdida ao restringir a busca a esses mapeamentos. A abordagem de força bruta envolve dois passos: Para cada política possível, amostrar retornos enquanto a segue Escolher a política com o maior retorno descontado esperado Um problema é que o"}
{"source": "Aprendizagem por reforço", "chunk_id": "Aprendizagem por reforço_14", "text": "A abordagem de força bruta envolve dois passos: Para cada política possível, amostrar retornos enquanto a segue Escolher a política com o maior retorno descontado esperado Um problema é que o número de políticas pode ser muito grande, ou mesmo infinito. Outro é que a variância dos retornos pode ser grande, exigindo muitas amostras para estimar precisamente o retorno descontado de cada política. Esses problemas podem ser amenizados se assumirmos alguma estrutura e permitirmos que as amostras geradas a partir de uma política influenciem as estimativas feitas para outras. As duas abordagens principais para alcançar isso são estimação de função de valor e busca direta por política. Abordagens baseadas em função de valor tentam encontrar uma política que maximize o retorno descontado, mantendo um conjunto de estimativas de retornos descontados esperados E ⁡ [ G ] {\\displaystyle \\operatorname {\\mathbb {E} } [G]} para alguma política (geralmente a \"atual\" [on-policy] ou a ótima"}
{"source": "Aprendizagem por reforço", "chunk_id": "Aprendizagem por reforço_15", "text": "mantendo um conjunto de estimativas de retornos descontados esperados E ⁡ [ G ] {\\displaystyle \\operatorname {\\mathbb {E} } [G]} para alguma política (geralmente a \"atual\" [on-policy] ou a ótima [off-policy]). Esses métodos se baseiam na teoria de processos de decisão de Markov, em que a otimalidade é definida de maneira mais forte do que a definição acima: Uma política é ótima se atinge o melhor retorno descontado esperado a partir de qualquer estado inicial (isto é, distribuições iniciais não influenciam essa definição). Novamente, uma política ótima sempre pode ser encontrada entre as políticas estacionárias. Para definir a otimalidade formalmente, define-se o valor de estado de uma política π {\\displaystyle \\pi } por V π ( s ) = E ⁡ [ G ∣ s , π ] , {\\displaystyle V^{\\pi }(s)=\\operatorname {\\mathbb {E} } [G\\mid s,\\pi ],} onde G {\\displaystyle G} representa o retorno descontado associado a seguir π {\\displaystyle \\pi } a partir do estado inicial s {\\displaystyle s} . Definindo V ∗ ("}
{"source": "Aprendizagem por reforço", "chunk_id": "Aprendizagem por reforço_16", "text": "{\\mathbb {E} } [G\\mid s,\\pi ],} onde G {\\displaystyle G} representa o retorno descontado associado a seguir π {\\displaystyle \\pi } a partir do estado inicial s {\\displaystyle s} . Definindo V ∗ ( s ) {\\displaystyle V^{*}(s)} como o valor de estado máximo possível de V π ( s ) {\\displaystyle V^{\\pi }(s)} , onde π {\\displaystyle \\pi } pode mudar, V ∗ ( s ) = max π V π ( s ) . {\\displaystyle V^{*}(s)=\\max _{\\pi }V^{\\pi }(s).} Uma política que atinge esses valores de estado ótimos em cada estado é chamada ótima. Claramente, uma política ótima nesse sentido também é ótima no sentido de que maximiza o retorno descontado esperado, pois V ∗ ( s ) = max π E [ G ∣ s , π ] {\\displaystyle V^{*}(s)=\\max _{\\pi }\\mathbb {E} [G\\mid s,\\pi ]} , em que s {\\displaystyle s} é um estado amostrado aleatoriamente da distribuição μ {\\displaystyle \\mu } de estados iniciais (de modo que μ ( s ) = Pr ( S 0 = s ) {\\displaystyle \\mu (s)=\\Pr(S_{0}=s)} ). Embora valores de estado sejam suficientes para definir a"}
{"source": "Aprendizagem por reforço", "chunk_id": "Aprendizagem por reforço_17", "text": "da distribuição μ {\\displaystyle \\mu } de estados iniciais (de modo que μ ( s ) = Pr ( S 0 = s ) {\\displaystyle \\mu (s)=\\Pr(S_{0}=s)} ). Embora valores de estado sejam suficientes para definir a otimalidade, é útil definir valores de ação. Dado um estado s {\\displaystyle s} , uma ação a {\\displaystyle a} e uma política π {\\displaystyle \\pi } , o valor de ação do par ( s , a ) {\\displaystyle (s,a)} sob π {\\displaystyle \\pi } é definido por Q π ( s , a ) = E ⁡ [ G ∣ s , a , π ] , {\\displaystyle Q^{\\pi }(s,a)=\\operatorname {\\mathbb {E} } [G\\mid s,a,\\pi ],\\,} onde G {\\displaystyle G} agora representa o retorno descontado associado a tomar primeiro a ação a {\\displaystyle a} no estado s {\\displaystyle s} e então seguir π {\\displaystyle \\pi } dali em diante. A teoria de processos de decisão de Markov afirma que, se π ∗ {\\displaystyle \\pi ^{*}} é uma política ótima, podemos agir de forma ideal (tomar a ação ótima) escolhendo a ação de Q π ∗ ( s , ⋅ ) {\\displaystyle Q^{\\pi ^{*}}(s,\\cdot )}"}
{"source": "Aprendizagem por reforço", "chunk_id": "Aprendizagem por reforço_18", "text": "Markov afirma que, se π ∗ {\\displaystyle \\pi ^{*}} é uma política ótima, podemos agir de forma ideal (tomar a ação ótima) escolhendo a ação de Q π ∗ ( s , ⋅ ) {\\displaystyle Q^{\\pi ^{*}}(s,\\cdot )} com o maior valor de ação em cada estado s {\\displaystyle s} . A função de valor de ação dessa política ótima ( Q π ∗ {\\displaystyle Q^{\\pi ^{*}}} ) é chamada de função de valor de ação ótima e geralmente denotada por Q ∗ {\\displaystyle Q^{*}} . Em resumo, conhecer a função de valor de ação ótima basta para saber como agir de forma ótima. Assumindo conhecimento completo do processo de decisão de Markov, as duas abordagens básicas para calcular a função de valor de ação ótima são iteração de valor e iteração de política. Ambos os algoritmos calculam uma sequência de funções Q k {\\displaystyle Q_{k}} ( k = 0 , 1 , 2 , … {\\displaystyle k=0,1,2,\\ldots } ) que converge para Q ∗ {\\displaystyle Q^{*}} . Calcular essas funções envolve computar expectativas em todo o espaço de estados, o que é"}
{"source": "Aprendizagem por reforço", "chunk_id": "Aprendizagem por reforço_19", "text": "Q_{k}} ( k = 0 , 1 , 2 , … {\\displaystyle k=0,1,2,\\ldots } ) que converge para Q ∗ {\\displaystyle Q^{*}} . Calcular essas funções envolve computar expectativas em todo o espaço de estados, o que é impraticável para a maioria dos processos de decisão de Markov (finitos, mas grandes). Em métodos de aprendizado por reforço, as expectativas são aproximadas por médias de amostras, e usam-se técnicas de aproximação de função para lidar com a necessidade de representar funções de valor em espaços grandes de estado-ação. Métodos de Monte Carlo Métodos de Monte Carlo são usados para resolver problemas de aprendizado por reforço por meio de médias de amostras de retornos. Diferentemente de métodos que exigem conhecimento completo da dinâmica do ambiente, os métodos de Monte Carlo dependem apenas de experiência real ou simulada — sequências de estados, ações e recompensas obtidas da interação com um ambiente. Isso os torna aplicáveis em situações em que a dinâmica completa é desconhecida."}
{"source": "Aprendizagem por reforço", "chunk_id": "Aprendizagem por reforço_20", "text": "de experiência real ou simulada — sequências de estados, ações e recompensas obtidas da interação com um ambiente. Isso os torna aplicáveis em situações em que a dinâmica completa é desconhecida. Aprender a partir de experiência real não requer conhecimento prévio do ambiente e ainda pode levar a comportamento ótimo. Ao usar experiência simulada, só é necessário um modelo capaz de gerar transições de amostra, em vez de especificar completamente as probabilidades de transição, como exigido por métodos de programação dinâmica. Métodos de Monte Carlo se aplicam a tarefas episódicas, em que a experiência é dividida em episódios que terminam eventualmente. Atualizações da política e da função de valor ocorrem somente após a conclusão de um episódio, tornando esses métodos incrementais em nível de episódio, mas não passo a passo (online). O termo \"Monte Carlo\" em geral se refere a qualquer método envolvendo amostragem aleatória; contudo, neste contexto, refere-se especificamente a métodos"}
{"source": "Aprendizagem por reforço", "chunk_id": "Aprendizagem por reforço_21", "text": "de episódio, mas não passo a passo (online). O termo \"Monte Carlo\" em geral se refere a qualquer método envolvendo amostragem aleatória; contudo, neste contexto, refere-se especificamente a métodos que computam médias a partir de retornos completos, em vez de retornos parciais. Eles funcionam de forma semelhante aos algoritmos para bandits, em que retornos são promediados para cada par estado-ação. A diferença crucial é que ações tomadas em um estado afetam os retornos de estados subsequentes no mesmo episódio, tornando o problema não-estacionário. Para lidar com essa não-estacionaridade, métodos de Monte Carlo usam a estrutura de general policy iteration (GPI). Enquanto a programação dinâmica calcula funções de valor tendo conhecimento completo do MDP, métodos de Monte Carlo aprendem essas funções por meio de retornos de amostra. As funções de valor e políticas interagem de maneira semelhante à da programação dinâmica para alcançar otimalidade, primeiro resolvendo o problema de"}
{"source": "Aprendizagem por reforço", "chunk_id": "Aprendizagem por reforço_22", "text": "essas funções por meio de retornos de amostra. As funções de valor e políticas interagem de maneira semelhante à da programação dinâmica para alcançar otimalidade, primeiro resolvendo o problema de predição e depois estendendo para melhoria de política e controle, tudo baseado em experiência amostrada. Métodos de diferença temporal O primeiro problema é corrigido permitindo que o procedimento mude a política (em alguns ou todos os estados) antes que os valores se estabilizem. Isso pode ser problemático, pois pode impedir a convergência. A maioria dos algoritmos atuais faz isso, dando origem à classe de algoritmos de generalized policy iteration. Muitos métodos ator-crítico pertencem a essa categoria. O segundo problema pode ser corrigido permitindo que trajetórias contribuam para qualquer par estado-ação nelas. Isso também pode ajudar em certa medida com o terceiro problema, embora uma solução melhor quando os retornos têm alta variância seja o uso de métodos de temporal difference"}
{"source": "Aprendizagem por reforço", "chunk_id": "Aprendizagem por reforço_23", "text": "par estado-ação nelas. Isso também pode ajudar em certa medida com o terceiro problema, embora uma solução melhor quando os retornos têm alta variância seja o uso de métodos de temporal difference (TD) de Sutton, que se baseiam na recursiva equação de Bellman. O cálculo em métodos TD pode ser incremental (quando, após cada transição, a memória é atualizada e a transição descartada) ou em lotes (quando as transições são agrupadas e as estimativas são computadas uma vez com base no lote). Métodos em lotes, como o método de mínimos quadrados em diferença temporal, podem usar melhor as informações das amostras, enquanto métodos incrementais são a única escolha quando métodos em lotes são inviáveis devido ao alto custo computacional ou de memória. Alguns métodos tentam combinar ambas as abordagens. Métodos baseados em diferenças temporais também superam o quarto problema. Outro problema específico de TD vem de sua dependência na equação de Bellman recursiva. A maioria dos métodos TD tem um"}
{"source": "Aprendizagem por reforço", "chunk_id": "Aprendizagem por reforço_24", "text": "Métodos baseados em diferenças temporais também superam o quarto problema. Outro problema específico de TD vem de sua dependência na equação de Bellman recursiva. A maioria dos métodos TD tem um parâmetro λ {\\displaystyle \\lambda } ( 0 ≤ λ ≤ 1 {\\displaystyle 0\\leq \\lambda \\leq 1} ) que pode interpolar continuamente entre métodos de Monte Carlo que não dependem das equações de Bellman e os métodos TD básicos que dependem totalmente delas. Isso pode ser eficaz para atenuar esse problema. Métodos de aproximação de função Para lidar com o quinto problema, são usados métodos de aproximação de função. A aproximação linear de função começa com um mapeamento ϕ {\\displaystyle \\phi } que atribui um vetor de dimensão finita a cada par estado-ação. Então, os valores de ação de um par ( s , a ) {\\displaystyle (s,a)} são obtidos combinando linearmente os componentes de ϕ ( s , a ) {\\displaystyle \\phi (s,a)} com certos pesos θ {\\displaystyle \\theta } : Q ( s , a ) = ∑ i = 1 d θ i ϕ i ( s , a ) ."}
{"source": "Aprendizagem por reforço", "chunk_id": "Aprendizagem por reforço_25", "text": "(s,a)} são obtidos combinando linearmente os componentes de ϕ ( s , a ) {\\displaystyle \\phi (s,a)} com certos pesos θ {\\displaystyle \\theta } : Q ( s , a ) = ∑ i = 1 d θ i ϕ i ( s , a ) . {\\displaystyle Q(s,a)=\\sum _{i=1}^{d}\\theta _{i}\\phi _{i}(s,a).} Os algoritmos, então, ajustam esses pesos, em vez de ajustar os valores associados a cada par estado-ação. Métodos baseados em ideias de estatística não paramétrica (que podem ser vistos como construindo suas próprias características) foram explorados. A iteração de valor também pode ser usada como ponto de partida, dando origem ao Q-learning e suas muitas variantes. Incluindo métodos de Deep Q-learning, quando uma rede neural é usada para representar Q, com várias aplicações em problemas de busca estocástica. O problema de usar valores de ação é que podem exigir estimativas altamente precisas de valores de ação concorrentes, o que pode ser difícil de obter quando os retornos são ruidosos, embora esse problema seja mitigado até certo"}
{"source": "Aprendizagem por reforço", "chunk_id": "Aprendizagem por reforço_26", "text": "ação é que podem exigir estimativas altamente precisas de valores de ação concorrentes, o que pode ser difícil de obter quando os retornos são ruidosos, embora esse problema seja mitigado até certo ponto por métodos de diferença temporal. Usar o chamado método de aproximação de função compatível compromete a generalidade e a eficiência. Uma abordagem alternativa é buscar diretamente (em algum subconjunto) no espaço de políticas, caso em que o problema se torna um caso de otimização estocástica. Há duas abordagens disponíveis: métodos baseados em gradiente e métodos sem gradiente. Métodos baseados em gradiente (policy gradient methods) começam com um mapeamento de um espaço (de parâmetros) de dimensão finita para o espaço de políticas: dado o vetor de parâmetros θ {\\displaystyle \\theta } , seja π θ {\\displaystyle \\pi _{\\theta }} a política associada a θ {\\displaystyle \\theta } . Definindo a função de desempenho por ρ ( θ ) = ρ π θ {\\displaystyle \\rho (\\theta )=\\rho ^{\\pi _{\\theta }}} ,"}
{"source": "Aprendizagem por reforço", "chunk_id": "Aprendizagem por reforço_27", "text": "seja π θ {\\displaystyle \\pi _{\\theta }} a política associada a θ {\\displaystyle \\theta } . Definindo a função de desempenho por ρ ( θ ) = ρ π θ {\\displaystyle \\rho (\\theta )=\\rho ^{\\pi _{\\theta }}} , sob condições suaves essa função será diferenciável como função do vetor θ {\\displaystyle \\theta } . Se o gradiente de ρ {\\displaystyle \\rho } fosse conhecido, poderíamos usar ascenso de gradiente. Como não se dispõe de uma expressão analítica para o gradiente, apenas uma estimativa ruidosa está disponível. Essa estimativa pode ser construída de várias maneiras, dando origem a algoritmos como o método REINFORCE de Williams (conhecido como método de razão de verossimilhança na literatura de otimização baseada em simulação). Uma grande classe de métodos evita depender de informações de gradiente. Isso inclui simulated annealing, busca por entropia cruzada ou métodos de computação evolucionária. Muitos métodos sem gradiente podem, em teoria e no limite, alcançar um ótimo global. Métodos de"}
{"source": "Aprendizagem por reforço", "chunk_id": "Aprendizagem por reforço_28", "text": "Isso inclui simulated annealing, busca por entropia cruzada ou métodos de computação evolucionária. Muitos métodos sem gradiente podem, em teoria e no limite, alcançar um ótimo global. Métodos de busca por política podem convergir lentamente se os dados forem ruidosos. Por exemplo, isso ocorre em problemas episódicos quando as trajetórias são longas e a variância dos retornos é grande. Métodos baseados em função de valor que dependem de diferenças temporais podem ajudar nesse caso. Nos últimos anos, métodos ator-crítico foram propostos e tiveram bom desempenho em vários problemas. Métodos de busca por política têm sido usados no contexto de robótica. Muitos métodos de busca por política podem ficar presos em ótimos locais (pois se baseiam em busca local). Por fim, todos os métodos acima podem ser combinados com algoritmos que primeiro aprendem um modelo do processo de decisão de Markov, ou seja, a probabilidade de cada próximo estado, dada uma ação tomada a partir de um estado"}
{"source": "Aprendizagem por reforço", "chunk_id": "Aprendizagem por reforço_29", "text": "acima podem ser combinados com algoritmos que primeiro aprendem um modelo do processo de decisão de Markov, ou seja, a probabilidade de cada próximo estado, dada uma ação tomada a partir de um estado existente. Por exemplo, o algoritmo Dyna aprende um modelo a partir da experiência e o utiliza para fornecer mais transições modeladas para uma função de valor, além das transições reais. Em alguns casos, isso pode ser estendido para uso de modelos não paramétricos, como quando as transições são simplesmente armazenadas e \"reexecutadas\" para o algoritmo de aprendizado. Métodos baseados em modelo podem ser mais intensivos computacionalmente do que abordagens sem modelo, e sua utilidade pode ser limitada pelo grau em que o processo de decisão de Markov pode ser aprendido. Existem outras formas de usar modelos além de atualizar uma função de valor. Por exemplo, em controle preditivo baseado em modelo (MPC), o modelo é usado para ajustar o comportamento diretamente. Tanto o comportamento"}
{"source": "Aprendizagem por reforço", "chunk_id": "Aprendizagem por reforço_30", "text": "de usar modelos além de atualizar uma função de valor. Por exemplo, em controle preditivo baseado em modelo (MPC), o modelo é usado para ajustar o comportamento diretamente. Tanto o comportamento assintótico quanto o comportamento de amostra finita da maioria dos algoritmos são bem compreendidos. Existem algoritmos com bom desempenho online demonstrável (lidando com o problema de exploração). A exploração eficiente em processos de decisão de Markov é apresentada em Burnetas e Katehakis (1997). Limites de desempenho em tempo finito também apareceram para muitos algoritmos, mas espera-se que sejam pouco precisos, sendo necessário mais trabalho para compreender melhor as vantagens e limitações relativas. Para algoritmos incrementais, questões de convergência assintótica foram resolvidas. Algoritmos baseados em diferenças temporais convergem sob um conjunto mais amplo de condições do que era possível antes (por exemplo, quando usados com aproximação de função arbitrária e suave). Tópicos"}
{"source": "Aprendizagem por reforço", "chunk_id": "Aprendizagem por reforço_31", "text": "baseados em diferenças temporais convergem sob um conjunto mais amplo de condições do que era possível antes (por exemplo, quando usados com aproximação de função arbitrária e suave). Tópicos de pesquisa incluem: arquitetura ator-crítico arquitetura ator-crítico-cenário métodos adaptativos que funcionem com poucos (ou nenhuns) parâmetros em um grande número de condições detecção de bugs em projetos de software aprendizado contínuo combinações com estruturas baseadas em lógica exploração em processos de decisão de Markov grandes feedback humano interação entre aprendizado implícito e explícito na aquisição de habilidades motivação intrínseca que diferencia comportamentos de busca de informação (curiosidade) de comportamentos orientados por metas dependentes de tarefas avaliações empíricas em grande escala espaços de ação grandes (ou contínuos) aprendizado por reforço modular e hierárquico aprendizado por reforço multiagente/distribuído é um tópico de interesse. As aplicações estão se"}
{"source": "Aprendizagem por reforço", "chunk_id": "Aprendizagem por reforço_32", "text": "em grande escala espaços de ação grandes (ou contínuos) aprendizado por reforço modular e hierárquico aprendizado por reforço multiagente/distribuído é um tópico de interesse. As aplicações estão se expandindo. controle centrado em ocupante otimização de recursos de computação informação parcial (por exemplo, usando representação de estado preditivo) função de recompensa baseada em maximizar informação nova planejamento baseado em amostragem (por exemplo, baseado em busca em árvore de Monte Carlo). negociação de títulos transferência de aprendizado aprendizagem TD modelando aprendizado baseado em dopamina no cérebro. Projeções dopaminérgicas da substantia nigra para o gânglio basal funcionam como o sinal de erro de predição. métodos de função de valor e busca por política A tabela a seguir lista os algoritmos principais para aprender uma política, dependendo de vários critérios: O algoritmo pode ser on-policy (realiza atualizações de política usando trajetórias amostradas via a"}
{"source": "Aprendizagem por reforço", "chunk_id": "Aprendizagem por reforço_33", "text": "seguir lista os algoritmos principais para aprender uma política, dependendo de vários critérios: O algoritmo pode ser on-policy (realiza atualizações de política usando trajetórias amostradas via a política atual) (cf. Seção 5.4, p. 100 em ) ou off-policy. O espaço de ações pode ser discreto (por exemplo: \"subir\", \"esquerda\", \"direita\", \"descer\", \"ficar parado\") ou contínuo (por exemplo, mover o braço em determinado ângulo). O espaço de estados pode ser discreto (por exemplo, o agente pode estar numa célula de uma grade) ou contínuo (por exemplo, o agente pode estar em determinada posição no plano). Tarefas de aprendizado por reforço associativo combinam elementos de tarefas de autômatos de aprendizado estocástico e tarefas de classificação em aprendizado supervisionado. Em tarefas de aprendizado por reforço associativo, o sistema de aprendizado interage em loop fechado com seu ambiente. Essa abordagem estende o aprendizado por reforço usando uma rede neural profunda e sem projetar"}
{"source": "Aprendizagem por reforço", "chunk_id": "Aprendizagem por reforço_34", "text": "por reforço associativo, o sistema de aprendizado interage em loop fechado com seu ambiente. Essa abordagem estende o aprendizado por reforço usando uma rede neural profunda e sem projetar explicitamente o espaço de estados. O trabalho sobre aprender jogos de ATARI pelo Google DeepMind aumentou a atenção em aprendizado por reforço profundo ou aprendizado por reforço de ponta a ponta. Aprendizado por reforço profundo adversário é uma área de pesquisa ativa em aprendizado por reforço que se concentra em vulnerabilidades de políticas aprendidas. Nessa área, alguns estudos iniciais mostraram que políticas de aprendizado por reforço são suscetíveis a manipulações adversárias imperceptíveis. Embora alguns métodos tenham sido propostos para superar essas vulnerabilidades, em estudos mais recentes foi demonstrado que essas soluções propostas ainda estão longe de representar adequadamente as vulnerabilidades das políticas de aprendizado por reforço profundo. Ao introduzir inferência fuzzy no"}
{"source": "Aprendizagem por reforço", "chunk_id": "Aprendizagem por reforço_35", "text": "foi demonstrado que essas soluções propostas ainda estão longe de representar adequadamente as vulnerabilidades das políticas de aprendizado por reforço profundo. Ao introduzir inferência fuzzy no aprendizado por reforço, aproximar a função de valor estado-ação com regras fuzzy em espaço contínuo se torna possível. A forma IF - THEN das regras fuzzy torna essa abordagem adequada para expressar resultados em uma forma próxima à linguagem natural. Estender o FRL com Interpolação de Regras Fuzzy permite o uso de bases de regras fuzzy esparsas de tamanho reduzido para enfatizar regras cardinais (valores de estado-ação mais importantes). Em aprendizado por reforço inverso (IRL), nenhuma função de recompensa é dada. Em vez disso, a função de recompensa é inferida a partir de um comportamento observado de um especialista. A ideia é imitar o comportamento observado, que muitas vezes é ótimo ou próximo do ótimo. Um paradigma IRL popular é chamado máximo de entropia (MaxEnt IRL). O MaxEnt IRL"}
{"source": "Aprendizagem por reforço", "chunk_id": "Aprendizagem por reforço_36", "text": "de um especialista. A ideia é imitar o comportamento observado, que muitas vezes é ótimo ou próximo do ótimo. Um paradigma IRL popular é chamado máximo de entropia (MaxEnt IRL). O MaxEnt IRL estima os parâmetros de um modelo linear da função de recompensa maximizando a entropia da distribuição de probabilidade de trajetórias observadas, sujeita a restrições relacionadas ao ajuste das contagens de características esperadas. Recentemente, foi mostrado que o MaxEnt IRL é um caso particular de uma estrutura mais geral chamada random utility inverse reinforcement learning (RU-IRL). RU-IRL baseia-se na teoria da utilidade aleatória e em processos de decisão de Markov. Enquanto abordagens anteriores de IRL presumem que o comportamento aleatório aparente de um agente observado se deve a ele seguir uma política aleatória, o RU-IRL presume que o agente observado segue uma política determinística, mas a aleatoriedade no comportamento observado se deve ao fato de um observador ter acesso apenas"}
{"source": "Aprendizagem por reforço", "chunk_id": "Aprendizagem por reforço_37", "text": "uma política aleatória, o RU-IRL presume que o agente observado segue uma política determinística, mas a aleatoriedade no comportamento observado se deve ao fato de um observador ter acesso apenas parcial às características que o agente observado utiliza na tomada de decisão. A função de utilidade é modelada como uma variável aleatória para explicar a ignorância do observador a respeito das características que o agente observado realmente considera em sua função de utilidade. Aprendizado por reforço multiobjetivo (MORL) é uma forma de aprendizado por reforço que envolve alternativas em conflito. É distinta de otimização multiobjetivo pelo fato de lidar com agentes atuando em ambientes. Aprendizado por reforço seguro (safe reinforcement learning, SRL) pode ser definido como o processo de aprendizagem de políticas que maximizem a esperança do retorno em problemas nos quais é importante garantir desempenho razoável do sistema e/ou respeitar restrições de segurança durante o processo de"}
{"source": "Aprendizagem por reforço", "chunk_id": "Aprendizagem por reforço_38", "text": "aprendizagem de políticas que maximizem a esperança do retorno em problemas nos quais é importante garantir desempenho razoável do sistema e/ou respeitar restrições de segurança durante o processo de aprendizagem e/ou implantação. Uma abordagem alternativa é o aprendizado por reforço avesso a risco, em que, em vez do retorno esperado, otimiza-se uma medida de risco do retorno, como o valor em risco condicional (CVaR). Além de mitigar risco, o objetivo CVaR aumenta a robustez a incertezas de modelo. No entanto, a otimização de CVaR em AR avesso a risco requer cuidado especial para evitar viés de gradiente e “cegueira ao sucesso”. Aprendizado por auto-reforço (ou self-learning) é um paradigma de aprendizagem que não utiliza o conceito de recompensa imediata R a ( s , s ′ ) {\\displaystyle R_{a}(s,s')} após a transição de s {\\displaystyle s} para s ′ {\\displaystyle s'} com ação a {\\displaystyle a} . Ele não usa reforço externo, apenas o auto-reforço interno do agente. O auto-reforço"}
{"source": "Aprendizagem por reforço", "chunk_id": "Aprendizagem por reforço_39", "text": "R_{a}(s,s')} após a transição de s {\\displaystyle s} para s ′ {\\displaystyle s'} com ação a {\\displaystyle a} . Ele não usa reforço externo, apenas o auto-reforço interno do agente. O auto-reforço interno é fornecido por um mecanismo de sentimentos e emoções. No processo de aprendizagem, as emoções são retropropagadas por um mecanismo de reforço secundário. A equação de aprendizado não inclui a recompensa imediata, apenas a avaliação do estado. O algoritmo de auto-reforço atualiza uma matriz de memória W = | | w ( a , s ) | | {\\displaystyle W=||w(a,s)||} de modo que, em cada iteração, executa a seguinte rotina de aprendizado de máquina: Na situação s {\\displaystyle s} , executa a ação a {\\displaystyle a} . Recebe uma situação consequente s ′ {\\displaystyle s'} . Calcula a avaliação do estado v ( s ′ ) {\\displaystyle v(s')} , indicando quão bom é estar na situação consequente s ′ {\\displaystyle s'} . Atualiza a memória cruzada w ′ ( a , s ) = w ( a , s ) + v ( s ′ ) {\\displaystyle"}
{"source": "Aprendizagem por reforço", "chunk_id": "Aprendizagem por reforço_40", "text": "estado v ( s ′ ) {\\displaystyle v(s')} , indicando quão bom é estar na situação consequente s ′ {\\displaystyle s'} . Atualiza a memória cruzada w ′ ( a , s ) = w ( a , s ) + v ( s ′ ) {\\displaystyle w'(a,s)=w(a,s)+v(s')} . As condições iniciais da memória são fornecidas como entrada pelo ambiente genético. É um sistema com apenas uma entrada (situação) e apenas uma saída (ação ou comportamento). O auto-reforço (self-learning) foi introduzido em 1982 juntamente com uma rede neural capaz de aprendizado por auto-reforço, chamada Crossbar Adaptive Array (CAA). A CAA computa, de forma cruzada, tanto decisões sobre ações quanto emoções (sentimentos) sobre estados consequentes. O sistema é conduzido pela interação entre cognição e emoção. Comparar algoritmos de AR de maneira eficiente é essencial para pesquisa, implantação e monitoramento de sistemas de AR. Para comparar algoritmos diferentes em um determinado ambiente, pode-se treinar um agente para cada algoritmo. Como o desempenho é"}
{"source": "Aprendizagem por reforço", "chunk_id": "Aprendizagem por reforço_41", "text": "para pesquisa, implantação e monitoramento de sistemas de AR. Para comparar algoritmos diferentes em um determinado ambiente, pode-se treinar um agente para cada algoritmo. Como o desempenho é sensível a detalhes de implementação, todos os algoritmos devem ser implementados o mais próximo possível uns dos outros. Após o treinamento, os agentes podem ser executados em uma amostra de episódios de teste, e suas pontuações (retornos) podem ser comparadas. Como episódios costumam ser assumidos como i.i.d, métodos estatísticos padrão podem ser usados para teste de hipóteses, como Teste t e teste de permutação. Isso exige acumular todas as recompensas dentro de um episódio em um único número — o retorno episódico. Contudo, isso causa perda de informação, pois diferentes passos de tempo são agregados, possivelmente com diferentes níveis de ruído. Sempre que o nível de ruído varia ao longo do episódio, o poder estatístico pode melhorar significativamente, ponderando as recompensas de acordo"}
{"source": "Aprendizagem por reforço", "chunk_id": "Aprendizagem por reforço_42", "text": "possivelmente com diferentes níveis de ruído. Sempre que o nível de ruído varia ao longo do episódio, o poder estatístico pode melhorar significativamente, ponderando as recompensas de acordo com seu nível de ruído estimado. Annaswamy, Anuradha M. (3 de maio de 2023). «Adaptive Control and Intersections with Reinforcement Learning». Annual Review of Control, Robotics, and Autonomous Systems (em inglês). 6 (1): 65–93. ISSN 2573-5144. doi:10.1146/annurev-control-062922-090153 Auer, Peter; Jaksch, Thomas; Ortner, Ronald (2010). «Near-optimal regret bounds for reinforcement learning». Journal of Machine Learning Research. 11: 1563–1600 Bertsekas, Dimitri P. (2023). REINFORCEMENT LEARNING AND OPTIMAL CONTROL 1st ed. [S.l.]: Athena Scientific. ISBN 978-1-886-52939-7 Busoniu, Lucian; Babuska, Robert; De Schutter, Bart; Ernst, Damien (2010). Reinforcement Learning and Dynamic Programming using Function Approximators. [S.l.]: Taylor & Francis CRC Press. ISBN 978-1-4398-2108-4 François-Lavet,"}
{"source": "Aprendizagem por reforço", "chunk_id": "Aprendizagem por reforço_43", "text": "De Schutter, Bart; Ernst, Damien (2010). Reinforcement Learning and Dynamic Programming using Function Approximators. [S.l.]: Taylor & Francis CRC Press. ISBN 978-1-4398-2108-4 François-Lavet, Vincent; Henderson, Peter; Islam, Riashat; Bellemare, Marc G.; Pineau, Joelle (2018). «An Introduction to Deep Reinforcement Learning». Foundations and Trends in Machine Learning. 11 (3–4): 219–354. Bibcode:2018arXiv181112560F. arXiv:1811.12560. doi:10.1561/2200000071 Li, Shengbo Eben (2023). Reinforcement Learning for Sequential Decision and Optimal Control 1st ed. [S.l.]: Springer Verlag, Singapore. ISBN 978-9-811-97783-1. doi:10.1007/978-981-19-7784-8 Powell, Warren (2011). Approximate dynamic programming: solving the curses of dimensionality. [S.l.]: Wiley-Interscience. Consultado em 8 de setembro de 2010. Cópia arquivada em 31 de julho de 2016 Sutton, Richard S. (1988). «Learning to predict by the method of temporal differences». Machine Learning. 3: 9–44. doi:10.1007/BF00115009 Sutton,"}
{"source": "Aprendizagem por reforço", "chunk_id": "Aprendizagem por reforço_44", "text": "de 2010. Cópia arquivada em 31 de julho de 2016 Sutton, Richard S. (1988). «Learning to predict by the method of temporal differences». Machine Learning. 3: 9–44. doi:10.1007/BF00115009 Sutton, Richard S.; Barto, Andrew G. (2018). Reinforcement Learning: An Introduction 2nd ed. [S.l.]: MIT Press. ISBN 978-0-262-03924-6 Szita, Istvan; Szepesvari, Csaba (2010). «Model-based Reinforcement Learning with Nearly Tight Exploration Complexity Bounds» (PDF). ICML 2010. Omnipress. pp. 1031–1038. Cópia arquivada (PDF) em 14 de julho de 2010 Dissecting Reinforcement Learning Série de postagens em blog sobre aprendizado por reforço com código em Python A (Long) Peek into Reinforcement Learning"}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_0", "text": "O aprendizado automático (português brasileiro) ou a aprendizagem automática (português europeu) ou também aprendizado de máquina (português brasileiro) ou aprendizagem de máquina (português europeu) (em inglês: machine learning) é um subcampo da Engenharia e da ciência da computação que evoluiu do estudo de reconhecimento de padrões e da teoria do aprendizado computacional em inteligência artificial. Em 1959, Arthur Samuel definiu aprendizado de máquina como o \"campo de estudo que dá aos computadores a habilidade de aprender sem serem explicitamente programados\"(livre tradução). O aprendizado automático explora o estudo e construção de algoritmos que podem aprender de seus erros e fazer previsões sobre dados. Tais algoritmos operam construindo um modelo a partir de inputs amostrais a fim de fazer previsões ou decisões guiadas pelos dados ao invés de simplesmente seguindo inflexíveis e estáticas instruções programadas. Enquanto que na inteligência artificial existem dois tipos de"}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_1", "text": "fim de fazer previsões ou decisões guiadas pelos dados ao invés de simplesmente seguindo inflexíveis e estáticas instruções programadas. Enquanto que na inteligência artificial existem dois tipos de raciocínio (o indutivo, que extrai regras e padrões de grandes conjuntos de dados, e o dedutivo), o aprendizado de máquina só se preocupa com o indutivo. Algumas partes do aprendizado automático estão intimamente ligadas (e muitas vezes sobrepostas) à estatística computacional; uma disciplina que foca em como fazer previsões através do uso de computadores, com pesquisas focando nas propriedades dos métodos estatísticos e sua complexidade computacional. Ela tem fortes laços com a otimização matemática, que produz métodos, teoria e domínios de aplicação para este campo. O aprendizado automático é usado em uma variedade de tarefas computacionais onde criar e programar algoritmos explícitos é impraticável. Exemplos de aplicações incluem filtragem de spam, reconhecimento ótico de caracteres"}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_2", "text": "é usado em uma variedade de tarefas computacionais onde criar e programar algoritmos explícitos é impraticável. Exemplos de aplicações incluem filtragem de spam, reconhecimento ótico de caracteres (OCR), processamento de linguagem natural, motores de busca, diagnósticos médicos, bioinformática, reconhecimento de fala, reconhecimento de escrita, visão computacional e locomoção de robôs. O aprendizado de máquinas é às vezes confundido com mineração de dados, que é um sub-campo que foca mais em análise exploratória de dados e é conhecido como aprendizado não supervisionado. No campo da análise de dados, o aprendizado de máquinas é um método usado para planejar modelos complexos e algoritmos que prestam-se para fazer predições- no uso comercial, isso é conhecido como análise preditiva. Esses modelos analíticos permitem que pesquisadores, cientistas de dados, engenheiros, e analistas possam \"produzir decisões e resultados confiáveis e repetitíveis\" e descobrir os \"insights escondidos\""}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_3", "text": "modelos analíticos permitem que pesquisadores, cientistas de dados, engenheiros, e analistas possam \"produzir decisões e resultados confiáveis e repetitíveis\" e descobrir os \"insights escondidos\" através do aprendizado das relações e tendências históricas nos dados. As contribuições para a fundação da aprendizagem automática (aprendizado de máquina) feitas pelos cientistas John Hopfield e Geoffrey Hinton foram distinguidas em 2024 com o Prémio Nobel de Física. O Comité Nobel destacou os cientistas por \"descobertas fundamentais e invenções que permitem aprendizagem automática com redes neuronais artificiais”. Tom M. Mitchell forneceu uma definição mais formal amplamente citada: \"Diz-se que um programa de computador aprende pela experiência E, com respeito a algum tipo de tarefa T e performance P, se sua performance P nas tarefas em T, na forma medida por P, melhoram com a experiência E.\" Esta definição das tarefas envolvidas no aprendizado de máquina é dada de forma fundamentalmente"}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_4", "text": "P, se sua performance P nas tarefas em T, na forma medida por P, melhoram com a experiência E.\" Esta definição das tarefas envolvidas no aprendizado de máquina é dada de forma fundamentalmente operacional, ao invés de cognitiva, seguindo a proposta de Alan Turing em seu artigo \"Computadores e inteligência\", em que a pergunta \"As máquinas são capazes de pensar?\" seja substituída pela pergunta \"As máquinas são capazes de fazer o que (nós como entidades pensantes) podemos fazer?\" As tarefas de aprendizado de máquina são tipicamente classificadas em três categorias amplas, de acordo com a natureza do \"sinal\" ou \"feedback\" de aprendizado disponível para um sistema de aprendizado. Essas categorias são: Aprendizado supervisionado: São apresentadas ao computador exemplos de entradas e saídas desejadas, fornecidas por um \"professor\". O objetivo é aprender uma regra geral que mapeia as entradas para as saídas. Aprendizado não supervisionado: Nenhum tipo de etiqueta é dado ao algoritmo de"}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_5", "text": "desejadas, fornecidas por um \"professor\". O objetivo é aprender uma regra geral que mapeia as entradas para as saídas. Aprendizado não supervisionado: Nenhum tipo de etiqueta é dado ao algoritmo de aprendizado, deixando-o sozinho para encontrar estrutura nas entradas fornecidas. O aprendizado não supervisionado pode ser um objetivo em si mesmo (descobrir novos padrões nos dados) ou um meio para atingir um fim. Aprendizado por reforço: Um programa de computador interage com um ambiente dinâmico, em que o programa deve desempenhar determinado objetivo (por exemplo, dirigir um veículo). É fornecido, ao programa, feedback quanto a premiações e punições, na medida em que é navegado o espaço do problema. Outro exemplo de aprendizado por reforço é aprender a jogar um determinado jogo apenas jogando contra um oponente. Entre o aprendizado supervisionado e o não supervisionado, está o aprendizado semi-supervisionado, em que o professor fornece um sinal de treinamento incompleto: um conjunto de"}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_6", "text": "contra um oponente. Entre o aprendizado supervisionado e o não supervisionado, está o aprendizado semi-supervisionado, em que o professor fornece um sinal de treinamento incompleto: um conjunto de dados de treinamento com algumas (muitas vezes várias) das saídas desejadas ausentes. A transdução é um caso especial deste princípio, em que o conjunto inteiro das instâncias do problema é conhecido no momento do aprendizado, mas com parte dos objetivos ausente. Entre outras categorias de problemas de aprendizado de máquina, o meta-aprendizado aprende seu próprio viés indutivo com base em experiência prévias. A robótica epigenética, elaborada para o aprendizado de robôs, gera suas próprias sequências de situações de aprendizado (também chamadas de 'currículo'), para adquirir cumulativamente repertórios de novas habilidades, através de uma auto-exploração autônoma e da interação social com professores humanos. Faz uso de técnicas como aprendizado ativo, maturação, sinergias motoras e"}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_7", "text": "repertórios de novas habilidades, através de uma auto-exploração autônoma e da interação social com professores humanos. Faz uso de técnicas como aprendizado ativo, maturação, sinergias motoras e imitação. Outra categorização de tarefas de aprendizado de máquina surge quando se considera a saída desejada em um sistema de aprendizado de máquina: Em classificação, entradas são divididas em duas ou mais classes, e o aprendiz deve produzir um modelo que vincula entradas não vistas a uma ou mais dessas classes (classificação multi-etiquetada). Isso é tipicamente abordado de forma supervisionada. A filtragem de spam é um exemplo de classificação, em que as entradas são as mensagens de emails (ou outros) e as classes são \"spam\" ou \"não spam\". Em regressão, também um problema supervisionado, as saídas são contínuas, em vez de discretas. Em clustering, um conjunto de entradas é dividido em grupos. De maneira diferente da classificação, os grupos não são conhecidos previamente, tornando o"}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_8", "text": "as saídas são contínuas, em vez de discretas. Em clustering, um conjunto de entradas é dividido em grupos. De maneira diferente da classificação, os grupos não são conhecidos previamente, tornando o clustering uma tarefa tipicamente não supervisionada. A estimativa de densidades encontra a distribuição de entradas em algum espaço. A redução dimensional simplifica as entradas ao mapeá-las para um espaço de menor dimensão. A modelagem de tópicos é um problema relacionado, em que é fornecida ao programa uma lista de documentos em linguagem natural, solicitando que encontre documentos tratando de tópicos similares. Como um esforço científico, o aprendizado de máquina cresceu a partir da busca pela inteligência artificial. Ainda nos princípios da IA como disciplina acadêmica, alguns pesquisadores já se interessavam em fazer máquinas aprenderem a partir de dados. Eles tentaram abordar o problema desde vários métodos simbólicos, assim como com o que foi então nomeado de \"rede neural"}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_9", "text": "já se interessavam em fazer máquinas aprenderem a partir de dados. Eles tentaram abordar o problema desde vários métodos simbólicos, assim como com o que foi então nomeado de \"rede neural artificial\"; estes eram majoritariamente perceptrons e outros modelos que mais tardes foram entendidos como reinvenções de modelos linear generalizados de estatística. A lógica probabilística também foi usada, especialmente em diagnósticos médicos automatizados.:488 No entanto, uma crescente ênfase na abordagem lógica, baseada em conhecimento, causou uma brecha entre a IA e o aprendizado de máquina. Sistemas probabilísticos eram atormentados por problemas teoréticos e práticos de aquisição e representação de dados.:488 Em 1980, sistemas especialistas haviam dominado a IA, e a estatística estava fora de uso. Trabalhos em aprendizado baseado em conhecimento/simbólico continuaram com a IA, levando até a programação lógica indutiva, mas agora as pesquisas mais voltadas para a estatística estavam fora do"}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_10", "text": "Trabalhos em aprendizado baseado em conhecimento/simbólico continuaram com a IA, levando até a programação lógica indutiva, mas agora as pesquisas mais voltadas para a estatística estavam fora do campo da IA, em reconhecimento de padrões e recuperação de informação.:708–710; 755 Pesquisas em redes neuronais haviam sido abandonadas pela IA e ciência computacional em torno do mesmo período. Essa linha, também, foi continuada forma dos campos da IA e da ciência da computação, como \"conexionismos\", por pesquisadores de outras disciplinas incluindo Hopfield, Rumelhart e Hinton. Seu sucesso principal veio em meados da década de 1980 com a reinvenção da propagação para trás.:25 O aprendizado de máquina, reorganizado como um campo separado, começou a florescer na década de 1990. O campo mudou seu objetivo de alcançar a inteligência artificial para abordar problemas solucionáveis de natureza prática. Ele abandonou o foco em abordagens simbólicas que havia herdado da IA para métodos e modelos"}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_11", "text": "objetivo de alcançar a inteligência artificial para abordar problemas solucionáveis de natureza prática. Ele abandonou o foco em abordagens simbólicas que havia herdado da IA para métodos e modelos emprestados da estatística e da teoria da probabilidade. Ele também se beneficiou do crescente número de informação digitalizada disponível e a possibilidade de distribuir ela via internet. O aprendizado de máquina e a mineração de dados com freqüência fazem uso dos mesmos métodos e se sobrepõe significativamente, mas enquanto o aprendizado de máquina foca em fazer previsões, baseado em propriedades conhecidas aprendidas pelo dados de treinamento, a mineração de dados foca em descobrir as propriedades (previamente) desconhecidas nos dados (este é o passo dado na análise de extração de conhecimento na base de dados). A mineração de dados usa muitas métodos do aprendizado de máquina, mas com objetivos diferentes; por outro lado, o aprendizado de máquina também faz uso de métodos da mineração"}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_12", "text": "na base de dados). A mineração de dados usa muitas métodos do aprendizado de máquina, mas com objetivos diferentes; por outro lado, o aprendizado de máquina também faz uso de métodos da mineração de dados como \"aprendizado não supervisionado\" ou como um passo de processamento para melhorar a precisão do aprendiz. Muita da confusão entre essas duas comunidades de pesquisa (que com freqüência tem conferências e periódicos separados, ECML PKDD sendo a grande exceção) vem da suposição básica com que eles trabalham: em aprendizado de máquina, a performance é normalmente avaliada com respeito a habilidade de reproduzir conhecimento conhecido, enquanto que com a extração de conhecimento e mineração de dados (KDD) a tarefa chave é o descobrimento de conhecimento previamente desconhecido. Avaliado com respeito ao conhecimento conhecido, um método uniforme (não supervisionado) será facilmente superado por outros métodos supervisionados, enquanto que em uma tarefa KDD típica, métodos"}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_13", "text": "Avaliado com respeito ao conhecimento conhecido, um método uniforme (não supervisionado) será facilmente superado por outros métodos supervisionados, enquanto que em uma tarefa KDD típica, métodos supervisionados não podem ser usados devido a não disponibilidade de dados de treinamento. O aprendizado de máquina também tem laços íntimos com a otimização: muitos dos problemas de aprendizado são formulados como minimização de algumas funções de perda em um conjunto exemplo de treinamentos. Funções de perda expressam a discrepância entre as previsões do modelo sendo treinado e as verdadeiras instâncias do problema (por exemplo, em classificação, o objetivo é designar etiquetas para instâncias, e modelos são treinados para predizer corretamente as etiquetas previamente designadas de um conjunto exemplo). A diferença entre os dois campos surge do objetivo da generalização: enquanto que o algoritmo de otimização pode minimizar a perda em um conjunto de treinamento, o aprendizado de máquina"}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_14", "text": "exemplo). A diferença entre os dois campos surge do objetivo da generalização: enquanto que o algoritmo de otimização pode minimizar a perda em um conjunto de treinamento, o aprendizado de máquina está preocupado com a minimização da perda de amostras não vistas. O aprendizado de máquina e a estatística são campos intimamente relacionados. De acordo com Michael I. Jordan, as ideias do aprendizado de máquina, dos princípios metodológicos às ferramentas teóricas, tem uma longa pré-história na estatística. Ele também sugeriu o termo ciência de dados como um substituto para chamar o campo como um todo. Leo Breiman distinguiu dois paradigmas da modelagem estatística: modelo de dados e modelo algorítmico, onde \"modelo algorítmico\" significa mais ou menos os algoritmos do aprendizado de máquina como a Floresta aleatória. Alguns estatísticos tem adotado métodos do aprendizado de máquinas, levando ao campo combinado que eles chamam de aprendizado estatístico. Um dos objetivos centrais de um"}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_15", "text": "como a Floresta aleatória. Alguns estatísticos tem adotado métodos do aprendizado de máquinas, levando ao campo combinado que eles chamam de aprendizado estatístico. Um dos objetivos centrais de um aprendiz é generalizar a partir de suas experiências. Generalização neste contexto é a habilidade de uma máquina aprendiz de desempenhar com precisão em novos, não vistos, exemplos/tarefas depois de ter experimentado um conjunto de dados de aprendizado. Os exemplos de treinamento vem de algumas, geralmente desconhecidas, distribuições de probabilidade (consideradas representativas do espaço de ocorrência) e o aprendiz tem de construir um modelo geral sobre este espaço que o permita produzir previsões o suficientemente precisas em novos casos. A análise computacional de algoritmos de aprendizado de máquina e sua performance é um ramo da ciência da computação teórica conhecida como teoria do aprendizado computacional. Porque os conjuntos de treinamento são finitos e o futuro é incerto, a"}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_16", "text": "de máquina e sua performance é um ramo da ciência da computação teórica conhecida como teoria do aprendizado computacional. Porque os conjuntos de treinamento são finitos e o futuro é incerto, a teoria de aprendizado normalmente não guarda garantias para a performance dos algoritmos. Em vez disso,previsões probabilísticas para a performance são bastante comuns. O trade-off entre variância e viés é uma forma de qualificar o erro de generalização. Para uma melhor performance no contexto de generalização, a complexidade da hipótese deveria combinar com a complexidade da função subjacente aos dados. Se a hipótese é menos complexa que a função, então o modelo sub-ajustou (underfitting) os dados. Se a complexidade do modelo é aumentada em resposta, então o erro de treinamento diminui. Mas se a hipótese é muito complexa, então o modelo foi sobreajustado (overfitting), e a generalização será mais pobre. Em adição aos limites da performance, teóricos do aprendizado computacional estudam a"}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_17", "text": "a hipótese é muito complexa, então o modelo foi sobreajustado (overfitting), e a generalização será mais pobre. Em adição aos limites da performance, teóricos do aprendizado computacional estudam a complexidade do tempo e a viabilidade do aprendizado. Na teoria do aprendizado computacional, uma computação é considerada viável se puder ser feita em tempo polinomial. Há dois tipos de resultados de complexidade temporal. Resultados positivos mostram que uma certa classe de funções pode ser aprendida em tempo polinomial. Resultados negativos mostram que certas classes não podem ser aprendidas em tempo polinomial. Aprendizado baseado em árvores de decisão usa a árvore de decisão como um modelo de previsão, o qual mapeia as observações sobre um item às conclusões sobre o valor do objetivo desse item. Aprendizado por regras de associação é um método para descobrir relações interessantes entre variáveis em base de dados grandes. Um algoritmo de aprendizado de rede neural artificial"}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_18", "text": "desse item. Aprendizado por regras de associação é um método para descobrir relações interessantes entre variáveis em base de dados grandes. Um algoritmo de aprendizado de rede neural artificial (aprendizagem de rede neuronal artificial), normalmente chamado de \"rede neural\" ou \"rede neuronal\" (RN), é um algoritmo do tipo \"machine learning\" que é inspirado na estrutura e aspectos funcionais das redes neurais biológicas. Computações são estruturadas em termos de um grupo interconectado de neurônios artificiais, processando informação usando uma abordagem de conexionismo na computação. Redes neuronais modernas são ferramentas de modelagem de dados estatísticos não lineares. Normalmente eles são usados para modelar relações complexas entre entradas e saídas, para encontrar padrões nos dados, ou para capturar a estrutura estatística em uma distribuição de probabilidade conjunta desconhecida entre variáveis observáveis. Os preços mais baixos do hardware e o desenvolvimento de GPUs para uso"}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_19", "text": "ou para capturar a estrutura estatística em uma distribuição de probabilidade conjunta desconhecida entre variáveis observáveis. Os preços mais baixos do hardware e o desenvolvimento de GPUs para uso pessoal nos últimos anos contribuiu para o desenvolvimento do conceito de aprendizado profundo, que consiste em múltiplas camadas escondidas em uma rede neural artificial. Esta abordagem tenta modelar a forma com que o cérebro humano processa luz e som na visão e escuta. Alguns aplicações úteis do aprendizado profundo são visão computacional e reconhecimento de fala. Lógica de programação indutiva (LPI) é uma abordagem que regra o aprendizado fazendo uso de programação lógica como uma representação uniforme para exemplos de inputs, conhecimento de pano de fundo, e hipóteses. Dada uma codificação do pano de fundo conhecido do conhecimento e um conjunto de exemplos representados como uma base de dados lógica de fatos, um sistema LPI derivará uma lógica hipotética que envolve todos os"}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_20", "text": "do pano de fundo conhecido do conhecimento e um conjunto de exemplos representados como uma base de dados lógica de fatos, um sistema LPI derivará uma lógica hipotética que envolve todos os exemplos positivos e não negativos. A programação indutiva é um campo relacionado que considera qualquer tipo de linguagem de programação para representar hipóteses (e não apenas programações lógicas), tais como as programações funcionais. Máquinas de vetores de suporte (MVSs) são um conjunto relacionado de métodos de aprendizado supervisionado usados para classificação e regressão. Dado um conjunto de exemplos de treinamento, cada um marcado como pertencente de uma ou duas categorias, um algoritmo de treino SVM constrói um modelo que prediz se um novo exemplo cai dentro de uma categoria ou outra. Análise de clusters é a atribuição de um conjunto de observações à subconjuntos (chamados clusters) de forma que as observações dentro de um mesmo cluster são similares de acordo com algum critério ou"}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_21", "text": "de clusters é a atribuição de um conjunto de observações à subconjuntos (chamados clusters) de forma que as observações dentro de um mesmo cluster são similares de acordo com algum critério ou critérios pré-designados, enquanto que observações feitas em clusters diferentes não são similares. Diferentes técnicas de clustering fazem diferentes suposições sobre a estrutura dos dados, freqüentemente definida por algumas métricas de similaridade e avaliados, por exemplo, por compacidade interna (similaridade entre membros de um mesmo cluster) e separação entre clusters diferentes. Outros métodos são baseado em estimações de densidade e gráficos de conectividade. Clustering é um método de aprendizado não supervisionado e uma técnica comum em análise de dados estatísticos. Uma rede bayesiana, rede de opinião ou um modelo gráfico acíclico dirigido é um modelo gráfico probabilístico que representa um conjunto de variáveis aleatórias e suas independências condicionais via um grafo acíclico"}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_22", "text": "rede de opinião ou um modelo gráfico acíclico dirigido é um modelo gráfico probabilístico que representa um conjunto de variáveis aleatórias e suas independências condicionais via um grafo acíclico dirigido (GAD). Por exemplo, uma rede bayesiana poderia representar as relações probabilísticas entre doenças e sintomas. Dado um sintoma, a rede pode ser usada para computar as probabilidades da presença de várias doenças. Existem algoritmos eficientes que desempenham inferência e aprendizado. O aprendizado por reforço se preocupa com o como um agente deve agir em um ambiente de forma que maximize alguma noção de recompensa a longo tempo. Os algoritmos de aprendizado por reforço tentam encontrar a política que mapeia os estados do mundo às ações que o agente deve ter nesses estados. Aprendizado por reforço se distingue do problema do aprendizado supervisionado no sentindo em que pares de input/output corretos nunca são apresentados, nem as ações sub-ótimas são explicitamente corrigidas."}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_23", "text": "por reforço se distingue do problema do aprendizado supervisionado no sentindo em que pares de input/output corretos nunca são apresentados, nem as ações sub-ótimas são explicitamente corrigidas. Vários algoritmos de aprendizado, a maioria algoritmos de aprendizado não supervisionado, tem como objetivo descobrir melhores representações dos inputs que são dados durante o treinamento. Exemplos clássicos incluem análise de componentes principais e análise de clusters. Os algoritmos de aprendizado por representação com freqüência tentam preservar a informação e seu input mas transformando-a de forma que a torne útil, frequentemente como um passo pré-processamento antes de desempenhar classificações ou previsões, permitindo a reconstrução dos inputs vindos de dados geradores de distribuição desconhecidos, enquanto não sendo necessariamente fiel à configurações que são implausíveis sob essa distribuição. Algoritmos de aprendizado múltiplo tentam fazer isso sob a restrição de que a"}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_24", "text": "desconhecidos, enquanto não sendo necessariamente fiel à configurações que são implausíveis sob essa distribuição. Algoritmos de aprendizado múltiplo tentam fazer isso sob a restrição de que a representação aprendida é de baixa dimensão. Algoritmos de código esparso tentam fazer isso sob a restrição de que a representação aprendida é espersa (tem muitos zeros). O algoritmo de aprendizado em subespaço multilinear tem como objetivo aprender representações de baixa dimensão diretamente das representações de tensores para dados multidimensionais, sem os transformar em vetores de alta dimensão. Algoritmos de aprendizado profundo descobrem múltiplos níveis de representação, ou uma hierarquia de características, com um nível mais alto, características mais abstratas definidas em termos de (ou geradas a partir de) características de nível mais baixo. Tem sido argumentado que uma máquina inteligente é aquela que aprende uma representação que desembaraça os fatores subjacentes de variação que"}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_25", "text": "a partir de) características de nível mais baixo. Tem sido argumentado que uma máquina inteligente é aquela que aprende uma representação que desembaraça os fatores subjacentes de variação que explicam os dados observados. Neste problema, se dá a máquina aprendiz pares de exemplos que são considerados similares e pares de objetos menos similares. Então ela precisa aprender uma função de similaridade (ou uma função de distancia métrica) que possa predizer se novos objetos são similares. Isso é as vezes usado em sistemas de recomendação. Neste método, um dado é representado como uma combinação de ligar funções bases, e os coeficientes são assumidos como esparsos. Deixe x ser uma dado d-dimensional, D ser um d por n matrizes, onde cada coluna de D representa uma função base. r é o coeficiente para representar x usando D. Matematicamente, aprendizado por dicionário esparso significa resolver x ≈ D r {\\displaystyle x\\approx Dr} onde r é esparso. Falando genericamente, se assume que n é"}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_26", "text": "para representar x usando D. Matematicamente, aprendizado por dicionário esparso significa resolver x ≈ D r {\\displaystyle x\\approx Dr} onde r é esparso. Falando genericamente, se assume que n é maior que d para permitir a liberdade para uma representação esparsa. Aprender um dicionário junto com representações esparsas é fortemente NP-completo e também difícil de resolver aproximadamente. Um método heurístico popular para aprendizado por dicionário esparso é o K-SVD. Aprendizado por dicionário esparso tem sido aplicado a vários contextos. Em classificação, o problema é determinar a quais classes um dado previamente não visto pertence. Suponha que um dicionário para cada classe já tenha sido construído. Então um novo dado é associado com a classe de forma que esteja o melhor esparcialmente representado pelo dicionário correspondente. Aprendizado por dicionário esparso também tem sido aplicado a suavização de imagem. A ideia chave é que um pedaço de imagem limpa pode ser representado"}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_27", "text": "representado pelo dicionário correspondente. Aprendizado por dicionário esparso também tem sido aplicado a suavização de imagem. A ideia chave é que um pedaço de imagem limpa pode ser representado esparcialmente por um dicionário de imagem, mas o ruído não. Em mineração de dados, a detecção de anomalias (também detecção de outliers ) é a identificação de itens, eventos ou observações raros que levantam suspeitas por serem significativamente diferentes da maioria dos dados. Normalmente, os itens anômalos se referem a algum tipo de problema, como fraude bancária, defeito estrutural, problemas médicos ou erros em um texto. Anomalias são também referidas como outliers, ruído, desvios e exceções. Um algoritmo genético (AG) é uma busca heurística que imita o processo de seleção natural e usa métodos com mutação e recombinação para gerar novos genotipos na esperança de encontrar boas soluções para um dado problema. Em aprendizado de máquinas, algoritmos genéticos encontraram alguma utilidade"}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_28", "text": "com mutação e recombinação para gerar novos genotipos na esperança de encontrar boas soluções para um dado problema. Em aprendizado de máquinas, algoritmos genéticos encontraram alguma utilidade em 1980 e 1990. Vice versa, técnicas do aprendizado de máquina tem sido usadas para melhorar a performance de algoritmos genéticos e evolutivos. Aplicações para o aprendizado de máquina incluem: Em 2006, a companhia de filmes online Netflix fez a primeira competição \"Netflix Prize\" para encontrar um programa que melhor prediria as performances dos usuários e melhoraria a precisão do algoritmo de recomendação Cinematch existente em ao menos 10%. Um time composto por pesquisadores da AT&T Labs em colaboração com o time Big Chaos e Pragmatic Theory construíram um modelo conjunto para ganhar o grande prêmio em 2009 de 1 milhão de dólares. Logo após os prêmio ser concedido, a Netflix se deu conta que as avaliações dos usuários não eram as melhores indicações de seus padrões de filmes e séries"}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_29", "text": "prêmio em 2009 de 1 milhão de dólares. Logo após os prêmio ser concedido, a Netflix se deu conta que as avaliações dos usuários não eram as melhores indicações de seus padrões de filmes e séries vistos (\"tudo é recomendação\") e mudaram seu motor de recomendação. Em 2010 o Periódico do Wall Street escreveu sobre a firma de gestão de dinheiro Rebellion Research que usava o aprendizado de máquina para predizer os movimentos econômicos. O artigo descrevia a previsão da Rebellion Research sobre a crise financeira e a recuperação econômica. Em 2014 foi relatado que um algoritmo de aprendizado de máquina foi aplicado em Historia da Arte para estudar as pinturas de arte e que ele pode ter revelado influencias entre artistas previamente não reconhecidas. Em 2015, o serviço de streaming de música Spotify criou a playlist chamada Descobertas da Semana, que funciona como uma curadoria digital. O algoritmo responsável por esta playlist utiliza técnicas de Filtragem Colaborativa, Processamento de"}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_30", "text": "Spotify criou a playlist chamada Descobertas da Semana, que funciona como uma curadoria digital. O algoritmo responsável por esta playlist utiliza técnicas de Filtragem Colaborativa, Processamento de Linguagem Natural e Processamento de Sinais de Áudio através de Redes Neurais Convolucionais para compor a playlist semanalmente. Mais informações atualizadas sobre como o Spotify aborda algoritmos de inteligência artificial podem ser acessadas em entrevista recente do CEO Gustav Soderstrom. Modelos de classificação de aprendizado de máquina podem ser validados por técnicas como validação cruzada, onde os dados são divididos em conjuntos de teste e treinamento e medidas apropriadas como precisão são calculadas para ambos os conjuntos de dados e comparadas. Para além da precisão, sensibilidade (Avaliação Positiva Verdadeira) e especificidade (Avaliação Negativa Verdadeira) podem prover modos de modelos de avaliação. De forma similar, Avaliações Positivas Falsas assim como Avaliações"}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_31", "text": "(Avaliação Positiva Verdadeira) e especificidade (Avaliação Negativa Verdadeira) podem prover modos de modelos de avaliação. De forma similar, Avaliações Positivas Falsas assim como Avaliações Negativas Falsas poder ser computadas. Curvas Receptoras de Operação (CRO) em conjunto com a Área em baixo da CRO (AUC) oferecem ferramentas adicionais para a classificação de modelos de avaliação. Graus maiores de AUC estão associados a um modelo de melhor performance. Software suites contendo uma variedade de algoritmos de aprendizado de máquina incluem os seguintes: Veja também esta lista de pacotes em muitas linguagens de programação: Awesome Machine Learning. Journal of Machine Learning Research Machine Learning Neural Computation International Journal of Machine Learning and Cybernetics Conference on Neural Information Processing Systems International Conference on Machine Learning Ablação (inteligência artificial) Aprendizagem profunda Aprendizado por transferência Inteligência artificial"}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_32", "text": "on Neural Information Processing Systems International Conference on Machine Learning Ablação (inteligência artificial) Aprendizagem profunda Aprendizado por transferência Inteligência artificial Lista de projetos de inteligência artificial Redes Neurais Clustering Bioinformática Visão computacional Mineração de dados Reconhecimento de padrões Máquina de Vetores de Suporte Big data Ciência cognitiva Inteligência computacional Neurociência computacional «Conceitos sobre Aprendizado de Maquina» (PDF) Curso online no Coursera, ministrado por Andrew Ng. Utiliza GNU Octave. O curso é uma versão livre do curso da Stanford University ministrado por Ng, cujas aulas também estão disponíveis gratuitamente. Aula sobre Aprendizagem por Reforço, ministrada pelo professor Ronaldo C. Prati, Professor Adjunto da UFABC Brocardo ML, Traore I, Woungang I, Obaidat MS. \"Authorship verification using deep belief network systems\". Int J Commun Syst. 2017. doi:10.1002/dac.3259 Trevor Hasti, Robert Tibshirani"}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_33", "text": "da UFABC Brocardo ML, Traore I, Woungang I, Obaidat MS. \"Authorship verification using deep belief network systems\". Int J Commun Syst. 2017. doi:10.1002/dac.3259 Trevor Hasti, Robert Tibshirani e Jerome H. Friedman (2001). The Elements of Statistical Learning, Springer. ISBN 0-387-95284-5. Pedro Domingos (September 2015), The Master Algorithm, Basic Books, ISBN 978-0-465-06570-7 Mehryar Mohri, Afshin Rostamizadeh, Ameet Talwalkar (2012). Foundations of Machine Learning, The MIT Press. ISBN 978-0-262-01825-8. Ian H. Witten and Eibe Frank (2011). Data Mining: Practical machine learning tools and techniques Morgan Kaufmann, 664pp., ISBN 978-0-12-374856-0. David J. C. MacKay. Information Theory, Inference, and Learning Algorithms Cambridge: Cambridge University Press, 2003. ISBN 0-521-64298-1 Richard O. Duda, Peter E. Hart, David G. Stork (2001) Pattern classification (2nd edition), Wiley, New York, ISBN 0-471-05669-3. Christopher Bishop (1995). Neural Networks for Pattern Recognition,"}
{"source": "Aprendizado de máquina", "chunk_id": "Aprendizado de máquina_34", "text": "Richard O. Duda, Peter E. Hart, David G. Stork (2001) Pattern classification (2nd edition), Wiley, New York, ISBN 0-471-05669-3. Christopher Bishop (1995). Neural Networks for Pattern Recognition, Oxford University Press. ISBN 0-19-853864-2. Vladimir Vapnik (1998). Statistical Learning Theory. Wiley-Interscience, ISBN 0-471-03003-1. Ray Solomonoff, An Inductive Inference Machine, IRE Convention Record, Section on Information Theory, Part 2, pp., 56-62, 1957. Ray Solomonoff, \"An Inductive Inference Machine\" Um relato privado que circulou na Dartmouth Summer Research Conference sobre IA em 1956."}
{"source": "Geoffrey Hinton", "chunk_id": "Geoffrey Hinton_0", "text": "Geoffrey Everest Hinton (Wimbledon, Londres, 6 de dezembro de 1947) é um psicólogo cognitivo, cientista cognitivo e cientista da computação anglo-canadense, conhecido por seu trabalho sobre redes neurais artificiais. Desde 2013 dividiu seu tempo trabalhando para o Google (Google Brain) e a Universidade de Toronto. Em 2024, ele deixou o Google. Recebeu o Prêmio Turing de 2018 juntamente com Yoshua Bengio e Yann LeCun, por seu trabalho sobre aprendizagem profunda. Foi distinguido em 2024 com o Prémio Nobel de Física, conjuntamente com John Hopfield, por \"descobertas fundamentais e invenções que permitem aprendizagem automática com redes neuronais artificiais”. A pesquisa de Hinton aborda maneiras de usar redes neurais para aprendizado de máquina, memória, percepção e processamento de símbolos. Ele escreveu ou coescreveu mais de 200 publicações revisadas por pares. As principais inovações incluem o desenvolvimento e popularização do algoritmo de retropropagação nos anos 1980, que"}
{"source": "Geoffrey Hinton", "chunk_id": "Geoffrey Hinton_1", "text": "símbolos. Ele escreveu ou coescreveu mais de 200 publicações revisadas por pares. As principais inovações incluem o desenvolvimento e popularização do algoritmo de retropropagação nos anos 1980, que revolucionou o treinamento de redes neurais profundas. Criou as Redes de Crenças Profundas, permitindo treinar modelos complexos camada por camada, e introduziu a técnica de Dropout para melhorar a generalização dos modelos. Também contribuiu significativamente para representações de linguagem através de word embeddings, propôs as Cápsulas Neurais como alternativa às redes convolucionais tradicionais, e desenvolveu técnicas de redução de dimensionalidade com autoencoders. Essas inovações foram fundamentais para avanços em reconhecimento de imagens, processamento de linguagem natural, tradução automática, reconhecimento de fala e visão computacional, estabelecendo as bases do deep learning moderno. Hinton é tataraneto da matemática e educadora Mary Everest Boole e de seu marido, o lógico"}
{"source": "Geoffrey Hinton", "chunk_id": "Geoffrey Hinton_2", "text": "automática, reconhecimento de fala e visão computacional, estabelecendo as bases do deep learning moderno. Hinton é tataraneto da matemática e educadora Mary Everest Boole e de seu marido, o lógico George Boole. O trabalho de George Boole eventualmente se tornou um dos fundamentos da ciência da computação moderna. Outro tataravô dele foi o cirurgião e autor James Hinton, que foi pai do matemático Charles Howard Hinton. O pai de Hinton era o entomologista Howard Hinton. Seu nome do meio vem de outro parente, George Everest, o Inspetor Geral da Índia, que deu nome ao Monte Everest. Ele é sobrinho do economista Colin Clark, e da física nuclear Joan Hinton, uma das duas físicas do Projeto Manhattan, que era sua prima em primeiro grau."}
{"source": "DeepMind", "chunk_id": "DeepMind_0", "text": "DeepMind Technologies Limited é uma empresa britânica focada em pesquisas e desenvolvimento de máquinas de inteligência artificial, fundada em setembro de 2010. Adquirida pelo Google em 2014, a empresa criou uma rede neural que aprende a jogar jogos eletrônicos de uma forma semelhante a dos humanos, bem como uma máquina Turing Neuronal, ou de uma rede neural que pode ser capaz de acessar a memória externa, como uma máquina de Turing convencional, resultando em um computador que imita a memória de curto prazo do cérebro humano. A empresa fez manchetes em 2016, após seu programa, AlphaGo, ganhar de um jogador profissional de Go pela primeira vez em outubro de 2015 e, novamente, quando AlphaGo bateu Lee Sedol, o campeão mundial em uma partida de cinco jogos, o que foi o tema de um documentário. Um programa mais genérico, AlphaZero, consegue superar os programas mais poderosos que jogam Go, xadrez e shogi (xadrez Japonês) depois de algumas horas de jogo contra si mesmo usando aprendizado"}
{"source": "DeepMind", "chunk_id": "DeepMind_1", "text": "Um programa mais genérico, AlphaZero, consegue superar os programas mais poderosos que jogam Go, xadrez e shogi (xadrez Japonês) depois de algumas horas de jogo contra si mesmo usando aprendizado por reforço. A start-up foi fundada por Demis Hassabis, Shane Legg e Mustafa Suleyman, em 2010. Hassabis e Legg se conheceram na Unidade de Neurociências Computacionais Gatsby da University College London. Em 26 de janeiro de 2014, o Google anunciou que a empresa tinha adquirido a DeepMind por $500 milhões, e que ele tinha concordado em assumir a DeepMind Technologies. Desde então, grandes empresas de capital de risco como Horizons Ventures e Founders Fund investiram na empresa, assim como empresários Scott Corrimão e Elon Musk. Jaan Tallinn foi um dos primeiros investidores e um conselheiro para a empresa. A venda para o Google ocorreu após o Facebook encerrar as negociações com a DeepMind Technologies em 2013. A companhia depois foi renomeada para Google DeepMind e manteve esse nome por"}
{"source": "DeepMind", "chunk_id": "DeepMind_2", "text": "a empresa. A venda para o Google ocorreu após o Facebook encerrar as negociações com a DeepMind Technologies em 2013. A companhia depois foi renomeada para Google DeepMind e manteve esse nome por cerca de dois anos. Em 2014, a DeepMind recebeu o prêmio de \"Empresa do Ano\" pelo Laboratório de Informática Cambridge. Em setembro de 2015, DeepMind e Royal Free NHS Trust, assinou o seu primeiro acordo de Partilha de Informação (ISA) para co-desenvolver um aplicativo de gerenciamento de tarefas clinicas, Streams. Depois da aquisição pela Google, a empresa estabeleceu um conselho de ética de inteligência artificial. O conselho de ética para pesquisa de IA permanece um mistério, com o Google e DeepMind recusando-se a revelar quem participa do conselho. DeepMind, em conjunto com a Amazon, Google, Facebook, IBM e Microsoft, são membros fundadores da Partnership on AI, uma organização dedicada à interface sociedade-IA. DeepMind abriu uma nova unidade chamada DeepMind Ethics and Society focado na"}
{"source": "DeepMind", "chunk_id": "DeepMind_3", "text": "IBM e Microsoft, são membros fundadores da Partnership on AI, uma organização dedicada à interface sociedade-IA. DeepMind abriu uma nova unidade chamada DeepMind Ethics and Society focado na ética e sociedade, as questões levantadas por inteligência artificial, com destaque transumanismo com Nick Bostrom como consultor. Em outubro de 2017, Deepmind lançou nova equipe de pesquisa de \"ética e sociedade\" para investigar a ética da IA. O Google anunciou em 2019 que a DeepMind descobriu como dominar os videogames multiplayer cooperativos, o que geralmente requer trabalho em equipe. Google espera que o treinamento de uma IA para jogar com vários participantes possa ajudar na formação de outros sistemas de IA semelhantes no mundo real, como ajudar funcionários humanos em centros de distribuição. O objetivo da DeepMind Technologies é \"resolver a inteligência\", que eles estão tentando alcançar através da combinação de \"as melhores técnicas de aprendizado de máquina e sistemas de neurociência"}
{"source": "DeepMind", "chunk_id": "DeepMind_4", "text": "O objetivo da DeepMind Technologies é \"resolver a inteligência\", que eles estão tentando alcançar através da combinação de \"as melhores técnicas de aprendizado de máquina e sistemas de neurociência para criar poderosos algoritmos de aprendizagem com propósito geral\". Eles estão tentando formalizar a inteligência, não apenas para implementá-lo em máquinas, mas também para entender o cérebro humano, como Demis Hassabis explica:[...] tentar destilar a inteligência em uma construção algorítmica pode revelar-se o melhor caminho para entender alguns dos mistérios duradouros de nossas mentes. [...] tentar destilar a inteligência em uma construção algorítmica pode revelar-se o melhor caminho para entender alguns dos mistérios duradouros de nossas mentes. [...] tentar destilar a inteligência em uma construção algorítmica pode revelar-se o melhor caminho para entender alguns dos mistérios duradouros de nossas mentes. O Google Research publicou um artigo, em 2016, a respeito da segurança da IA e"}
{"source": "DeepMind", "chunk_id": "DeepMind_5", "text": "construção algorítmica pode revelar-se o melhor caminho para entender alguns dos mistérios duradouros de nossas mentes. O Google Research publicou um artigo, em 2016, a respeito da segurança da IA e evitar comportamento indesejável, durante o processo de aprendizagem da IA. Deepmind também lançou várias publicações através do seu site. Em 2017 DeepMind lançou GridWorld, um open-source de testes para avaliar se um algoritmo aprende a desabilitar o seu interruptor da morte ou caso contrário, apresenta determinados comportamentos indesejáveis. Até à data, a empresa publicou a pesquisa sobre sistemas de computador que é capaz de jogar jogos, e o desenvolvimento desses sistemas, que vão desde jogos de estratégia, como Go para jogos de arcade. De acordo com Shane Legg, a inteligência de máquina de nível humano pode ser alcançada \"quando uma máquina pode aprender a jogar uma ampla gama de jogos a partir de entrada e saída de fluxo perceptivo, e transferir a compreensão entre jogos [...]\""}
{"source": "DeepMind", "chunk_id": "DeepMind_6", "text": "de nível humano pode ser alcançada \"quando uma máquina pode aprender a jogar uma ampla gama de jogos a partir de entrada e saída de fluxo perceptivo, e transferir a compreensão entre jogos [...]\" Pesquisas descrevem uma IA jogar sete diferentes videogames Atari 2600 (o Pong jogo no Vídeo jogos Olímpicos, Breakout, Space Invaders, Seaquest, Beamrider, Enduro, e Q*bert) teria levado à sua aquisição pelo Google. Hassabis mencionou o popular e esporte eletrônico, StarCraft, como um futuro possível desafio, pois exige um alto nível de pensamento estratégico e de manipulação de informações imperfeitas. Ao contrário de outros IA's, tais como IBM's Deep Blue ou Watson, que foram desenvolvidos para um pré-definido propósito e função apenas dentro de seu espaço, DeepMind afirma que o seu sistema não está pré-programado: ele aprende a partir da experiência, usando apenas pixels brutos como dados de entrada. Tecnicamente ele usa uma aprendizagem mais profunda em uma rede neural convolucional, com"}
{"source": "DeepMind", "chunk_id": "DeepMind_7", "text": "está pré-programado: ele aprende a partir da experiência, usando apenas pixels brutos como dados de entrada. Tecnicamente ele usa uma aprendizagem mais profunda em uma rede neural convolucional, com uma nova forma de Q-learning, um formulário de modelo livre de aprendizado por reforço. para testar o sistema de videogames, principalmente dos jogos de arcade, como Space Invaders ou Breakout. Sem alterar o código, a IA começa a entender como jogar o jogo e depois de algum tempo desempenha, para alguns jogos (principalmente Breakout), uma jogabilidade mais eficaz do que qualquer ser humano jamais poderia conseguir. A partir de 2014, DeepMind jogou abaixo doRecorde Mundial atual para a maioria dos jogos, por exemplo Space Invaders, Ms Pac-Man e Q*Bert. A IA da DeepMind tinha sido aplicada a videogames feitos nos anos de 1970 e 1980; a obra foi continuada por jogos 3D mais complexos, como Doom, que apareceu pela primeira vez no início da década de 1990. Em outubro de 2015, um programa de"}
{"source": "DeepMind", "chunk_id": "DeepMind_8", "text": "videogames feitos nos anos de 1970 e 1980; a obra foi continuada por jogos 3D mais complexos, como Doom, que apareceu pela primeira vez no início da década de 1990. Em outubro de 2015, um programa de computador Go, chamado AlphaGo, desenvolvido pela DeepMind, venceu o campeão Europeu de Go, Fan Hui, um profissional de 2 dan (9 dan possíveis), de cinco a zero. Esta é a primeira vez que uma inteligência artificial (IA) derrotou um jogador profissional de Go. Anteriormente, os computadores eram apenas conhecido por ter jogado Go como \"amadores\". Go é considerado muito mais difícil para que computadores para ganhar comparado a outros jogos como o xadrez, devido ao número muito maior de possibilidades, tornando-se muito difícil para o modo tradicional de IA, como métodos de força bruta. Em Março de 2016, ele ganhou de Lee Sedol—um jogador profissional de Go com 9º dan e um dos maiores jogadores do mundo, com 4-1 em uma partida de cinco jogos. Em 2017 no Future of Go Summit, AlphaGo ganhou"}
{"source": "DeepMind", "chunk_id": "DeepMind_9", "text": "de 2016, ele ganhou de Lee Sedol—um jogador profissional de Go com 9º dan e um dos maiores jogadores do mundo, com 4-1 em uma partida de cinco jogos. Em 2017 no Future of Go Summit, AlphaGo ganhou três jogos com Ke Jie, que, na época, continuou o número 1 do mundo no ranking por dois anos. É utilizado um aprendizado supervisionado, protocolo, estudando um grande número de jogos jogados por seres humanos uns contra os outros. Em 2017, uma versão melhorada, AlphaGo Zero, derrotou AlphaGo em 100 jogos a 0. Zero descobriu por si mesmo, muitos dos movimentos humanos de jogadores de Go e adicionou novas. O mais impressionante, é que ele foi capaz de vencer o seu antecessor, só que depois de três dias com menos poder de processamento em comparação com os meses que o original AlphaGo necessitou para aprender a jogar. Tecnologia AlphaGo utilizou duas redes neurais profundas: uma rede de politicas para avaliar probabilidades de movimentos e uma rede de valor para avaliar posições. A rede de"}
{"source": "DeepMind", "chunk_id": "DeepMind_10", "text": "para aprender a jogar. Tecnologia AlphaGo utilizou duas redes neurais profundas: uma rede de politicas para avaliar probabilidades de movimentos e uma rede de valor para avaliar posições. A rede de politicas treinou através de aprendizado supervisionado, e posteriormente foi refinada pela aprendizagem de reforço de gradiente de políticas. A rede de valor aprendeu a prever os vencedores dos jogos disputados pela rede de politica contra si mesmo. essas redes empregaram uma árvore de pesquisa de Monte Carlo (MCT), usando a rede de políticas para identificar movimentos de alta probabilidade dos candidatos, enquanto a rede de valor (em conjunto com as implementações de Monte Carlo usando uma política de rápida implementação) avaliou posições da árvore. Zero treinou utilizando aprendizado por reforço, em que o sistema jogou milhões de jogos contra si mesmo. Seu único guia foi para aumentar a sua taxa de ganhos. Ele fez isso sem aprender de jogos jogados por humanos. Suas únicas"}
{"source": "DeepMind", "chunk_id": "DeepMind_11", "text": "por reforço, em que o sistema jogou milhões de jogos contra si mesmo. Seu único guia foi para aumentar a sua taxa de ganhos. Ele fez isso sem aprender de jogos jogados por humanos. Suas únicas característicos de entrada de recursos são as pedras brancas e pretas do tabuleiro. Ele usa uma única rede neural, em vez de redes separadas de políticas e valores. Sua simplificada árvore de busca depende dessa rede neural para avaliar posições e amostras de movimentos, sem lançamentos de Monte Carlo. Um novo algoritmo de aprendizado por reforço incorpora procura de pesquisa dentro do ciclo de formação. AlphaGo Zero empregou cerca de 15 pessoas e milhões em recursos de computação. Em última análise,precisava muito menos poder de computação do que AlphaGo, executado em quatro processadores de I.A especializada (Google TPUs), em vez de 48 do AlphaGo. Em julho de 2016, uma colaboração entre a DeepMind e Moorfields Eye Hospital foi anunciado. DeepMind seria aplicada para a análise anónima de exames"}
{"source": "DeepMind", "chunk_id": "DeepMind_12", "text": "(Google TPUs), em vez de 48 do AlphaGo. Em julho de 2016, uma colaboração entre a DeepMind e Moorfields Eye Hospital foi anunciado. DeepMind seria aplicada para a análise anónima de exames de olhos, procurando por sinais precoces de doenças, levando a cegueira. Em agosto de 2016, l foi anunciado um programa de pesquisa com a Universidade College London Hospital com o objetivo de desenvolver um algoritmo que pode diferenciar automaticamente tecidos saudáveis e cancerosos nas áreas da cabeça e do pescoço. Há também projetos com o Royal Free de Londres NHS Foundation Trust e o Imperial College Healthcare NHS Trust para desenvolver novos aplicativos clínicos ligados a registros eletrônicos de pacientes. Os funcionários do Royal Free Hospital reportaram em dezembro de 2017, que o acesso aos dados do paciente através do aplicativo tinha salvado uma \"enorme quantidade de tempo\" e fez uma diferença \"fenomenal\" para o manejo de pacientes com lesão renal aguda. Os dados dos resultados são"}
{"source": "DeepMind", "chunk_id": "DeepMind_13", "text": "dados do paciente através do aplicativo tinha salvado uma \"enorme quantidade de tempo\" e fez uma diferença \"fenomenal\" para o manejo de pacientes com lesão renal aguda. Os dados dos resultados são enviados para os celulares da equipe e os alerta sobre mudar a condição do paciente. Ele também permite que a equipe veja se alguém já respondeu, e para mostrar aos pacientes seus resultados em forma visual. Em abril de 2016, o New Scientist obteve uma cópia de dados de um acordo de partilha de dados entre DeepMind e o Royal Free Londres NHS Foundation Trust. Este último opera os três hospitais de Londres, onde uma população estimada em 1,6 milhões de pacientes são tratados anualmente. A revelação expôs a facilidade com que as empresas privadas podem obter informações médicas altamente sensíveis sem consentimento do paciente. O acordo mostra que a DeepMind Health tiveram acesso à admissão, alta e transferência de dados, de acidentes e de emergência, patologia e radiologia, e cuidados"}
{"source": "DeepMind", "chunk_id": "DeepMind_14", "text": "sem consentimento do paciente. O acordo mostra que a DeepMind Health tiveram acesso à admissão, alta e transferência de dados, de acidentes e de emergência, patologia e radiologia, e cuidados críticos desses hospitais. Isto incluiu dados pessoais, tais como saber se os pacientes tinham sido diagnosticados com HIV, sofriam de depressão ou já tinha sofrido um aborto a fim de realizar pesquisas para a busca de melhores resultados em várias condições de saúde. O contrato é visto como controverso e sua legalidade tem sido questionada. As preocupações foram amplamente relatadas e levaram a uma reclamação para o Escritório do Comissário da Informação (ICO), argumentando que os dados devem ser pseudonunciados e criptografados. Em maio de 2016, New Scientist publicou mais um artigo alegando que o projeto não conseguiu aprovação da Grupo Consultivo de Confidencialidade da Agência de Regulamentação de Medicamentos e Produtos de Saúde. Em maio de 2017, a Sky News publicou uma carta vazada a"}
{"source": "DeepMind", "chunk_id": "DeepMind_15", "text": "o projeto não conseguiu aprovação da Grupo Consultivo de Confidencialidade da Agência de Regulamentação de Medicamentos e Produtos de Saúde. Em maio de 2017, a Sky News publicou uma carta vazada a partir de National Data Guardian, Dame Fiona Caldicott, revelando que em sua opinião, o acordo de partilha de dados entre a DeepMind e Royal Free, ocorreu com uma \"base legal inadequada\".. O Escritório do Comissário da Informação, decidiu em julho de 2017, que o hospital Royal Free, não cumpriu com a Lei de Proteção de Dados quando entregou dados pessoais de 1,6 milhões de pacientes a DeepMind. Em outubro de 2017, a equipe de DeepMind expandiu seu foco para incluir também a ética de IA. Com o antigo gerente de políticas do Google Reino Unido e da UE, Sean Legassick, liderando esta nova equipe, o seu objetivo é financiar pesquisa externa sobre os seguintes temas: privacidade, transparência e imparcialidade; impactos econômicos; governança e prestação de contas; gestão de risco de IA;"}
{"source": "DeepMind", "chunk_id": "DeepMind_16", "text": "o seu objetivo é financiar pesquisa externa sobre os seguintes temas: privacidade, transparência e imparcialidade; impactos econômicos; governança e prestação de contas; gestão de risco de IA; moralidade e valores de IA; e como IA pode abordar os desafios do mundo. Como resultado, a equipe espera poder compreender melhor as implicações éticas da inteligência artificial e ajudar a sociedade a ver como pode ser benéfica a inteligência artificial. Esta nova subdivisão do DeepMind é uma unidade completamente separada da unidade da grande parceria de grandes empresas de tecnologia do nome, Parceria de Inteligência Artificial para Beneficiar as Pessoas e a Sociedade, da qual a DeepMind também participa. Alinhamento da inteligência artificial AlphaGo AlphaFold Sítio oficial"}
{"source": "Processamento de linguagem natural", "chunk_id": "Processamento de linguagem natural_0", "text": "Processamento de língua natural (PLN) é uma subárea da ciência da computação, inteligência artificial e da linguística que estuda os problemas da geração e compreensão automática de línguas humanas naturais. Sistemas de geração de língua natural convertem informação de bancos de dados de computadores em linguagem compreensível ao ser humano e sistemas de compreensão de língua natural convertem ocorrências de linguagem humana em representações mais formais, mais facilmente manipuláveis por programas de computador. Alguns desafios do PLN são compreensão de língua natural, fazer com que computadores extraiam sentido de linguagem humana ou natural e geração de língua natural. A história do PLN começou na década de 1950, quando Alan Turing publicou o artigo \"Computing Machinery and Intelligence\", que propunha o que agora é chamado de teste de Turing como critério de inteligência. Em 1954, a experiência de Georgetown envolveu a tradução automática de mais de sessenta frases russas para o"}
{"source": "Processamento de linguagem natural", "chunk_id": "Processamento de linguagem natural_1", "text": "que propunha o que agora é chamado de teste de Turing como critério de inteligência. Em 1954, a experiência de Georgetown envolveu a tradução automática de mais de sessenta frases russas para o inglês. Os autores afirmaram que dentro de três ou cinco anos a tradução automática seria um problema resolvido. No entanto, os avanços reais foram muito mais lentos do que o previsto e, após o relatório ALPAC em 1966, que constatou que a pesquisa de dez anos não conseguiu satisfazer as expectativas, o financiamento para este estudo em tradução automática foi reduzido drasticamente. Poucas pesquisas em tradução automática foram conduzidas até o final dos anos 80, quando os primeiros sistemas estatísticos de tradução foram desenvolvidos. Alguns sistemas de PLN bem sucedidos desenvolvidos nos anos 60 foram SHRDLU, um sistema de língua natural que trabalhava em \"blocks worlds\" com vocabulário restrito e ELIZA, uma simulação de um psicoterapeuta escrita por Joseph Weizenbaum entre 1964 e 1966."}
{"source": "Processamento de linguagem natural", "chunk_id": "Processamento de linguagem natural_2", "text": "60 foram SHRDLU, um sistema de língua natural que trabalhava em \"blocks worlds\" com vocabulário restrito e ELIZA, uma simulação de um psicoterapeuta escrita por Joseph Weizenbaum entre 1964 e 1966. Usando pouca informação sobre o pensamento ou a emoção humana, ELIZA criava, em alguns casos, interações surpreendentemente humanas. Quando o \"paciente\" excedia a base de conhecimento do programa, ELIZA fornecia uma resposta genérica, por exemplo, respondendo a \"Minha cabeça dói\" com \"Por que você diz que sua cabeça dói?\". Durante a década de 1970, muitos programadores começaram a escrever \"ontologias conceituais\", que estruturaram a informação do mundo real em dados compreensíveis por computadores. Exemplos são MARGIE (SCHANK, 1975), SAM (CULLINGFORD, 1978), PAM (WILENSKY, 1978), TaleSpin (MEEHAN, 1976), QUALM (LEHNERT, 1977), Politics (CARBONELL, 1979) e Plot Units (LEHNERT, 1981 ). Neste período, muitos chatterbots foram escritos, como PARRY, Racter e Jabberwacky. Até a década de 1980, a"}
{"source": "Processamento de linguagem natural", "chunk_id": "Processamento de linguagem natural_3", "text": "1976), QUALM (LEHNERT, 1977), Politics (CARBONELL, 1979) e Plot Units (LEHNERT, 1981 ). Neste período, muitos chatterbots foram escritos, como PARRY, Racter e Jabberwacky. Até a década de 1980, a maioria dos sistemas de PLN se baseava em conjuntos complexos de regras manuscritas. A partir do final dos anos 1980, no entanto, houve uma revolução no PLN com a introdução de algoritmos de aprendizagem automática (aprendizado de máquina) para o processamento de linguagem. Isto foi devido tanto ao aumento constante do poder computacional (ver Lei de Moore) quanto à diminuição gradual da dominância das teorias da linguística chomskyanas (como a gramática gerativa), cujos fundamentos teóricos desestimularam o tipo de corpus linguístico que está subjacente à abordagem da aprendizagem automática ao processamento da linguagem. Alguns dos algoritmos de aprendizado de máquinas mais antigos, como as árvores de decisão, produziam sistemas de regras rígidas então semelhantes às regras existentes na"}
{"source": "Processamento de linguagem natural", "chunk_id": "Processamento de linguagem natural_4", "text": "processamento da linguagem. Alguns dos algoritmos de aprendizado de máquinas mais antigos, como as árvores de decisão, produziam sistemas de regras rígidas então semelhantes às regras existentes na escritas à mão. No entanto, a marcação de partes da fala (part-of-speech tagging) introduziu o uso de modelos ocultos de Markov para o PLN e, cada vez mais, a pesquisa se concentrava em modelos estatísticos, que tomam decisões suaves e probabilísticas baseadas na atribuição de pesos reais aos recursos que compõem dados de entrada. Os modelos de linguagem de cache, sobre os quais muitos sistemas de reconhecimento de fala agora dependem, são exemplos de tais modelos estatísticos. Esses modelos são geralmente mais robustos quando dados informações desconhecidas, especialmente entrada que contém erros (como é muito comum para dados do mundo real) e produzem resultados mais confiáveis quando integrados em sistemas maiores que compreendem múltiplas tarefas. Muitos dos sucessos iniciais notáveis"}
{"source": "Processamento de linguagem natural", "chunk_id": "Processamento de linguagem natural_5", "text": "(como é muito comum para dados do mundo real) e produzem resultados mais confiáveis quando integrados em sistemas maiores que compreendem múltiplas tarefas. Muitos dos sucessos iniciais notáveis ocorreram no campo da tradução automática, devido especialmente ao trabalho de pesquisa da IBM, que desenvolveu modelos estatísticos mais elaborados. Estes sistemas foram capazes de tirar proveito de corpora textuais multilíngues existentes produzidos pelo Parlamento do Canadá e a União Europeia como resultado de leis que exigem a tradução de todos os processos governamentais em todas as línguas oficiais dos países. No entanto, a maioria dos sistemas dependia de corpora desenvolvido especificamente para tarefas implementadas por esses sistemas, o que era (e muitas vezes continua sendo) uma grande limitação no sucesso dos mesmo. Como resultado, uma grande quantidade de pesquisa passou de quantidades de dados limitadas a métodos de aprendizagem mais eficazes. Pesquisas recentes têm se"}
{"source": "Processamento de linguagem natural", "chunk_id": "Processamento de linguagem natural_6", "text": "grande limitação no sucesso dos mesmo. Como resultado, uma grande quantidade de pesquisa passou de quantidades de dados limitadas a métodos de aprendizagem mais eficazes. Pesquisas recentes têm se concentrado cada vez mais em algoritmos de aprendizagem semi-supervisionados e sem supervisão. Esses algoritmos são capazes de aprender com dados que não foram anotados manualmente com as respostas desejadas ou usando uma combinação de dados anotados e não anotados. Geralmente, esta tarefa é muito mais trabalhosa do que a aprendizagem supervisionada e normalmente produz resultados menos precisos para uma quantidade específica de dados de entrada. No entanto, há uma enorme quantidade de dados não anotados disponíveis (incluindo, entre outras coisas, todo o conteúdo da World Wide Web), que muitas vezes pode compensar os resultados inferiores. Os algoritmos modernos de PLN baseiam-se na aprendizagem mecânica, especialmente na aprendizagem de máquinas estatísticas. O paradigma da aprendizagem"}
{"source": "Processamento de linguagem natural", "chunk_id": "Processamento de linguagem natural_7", "text": "vezes pode compensar os resultados inferiores. Os algoritmos modernos de PLN baseiam-se na aprendizagem mecânica, especialmente na aprendizagem de máquinas estatísticas. O paradigma da aprendizagem mecânica é diferente do da maioria das tentativas anteriores de processamento da linguagem. Anteriormente, implementações de tarefas de processamento de linguagem envolviam a codificação direta de grandes conjuntos de regras. O paradigma da aprendizagem automática (ou aprendizagem automática) induz a aprendizagem automática de regras através de análises de corpora de exemplos típicos do mundo real ao invés de usar algoritmos gerais de aprendizagem (muitas vezes, embora nem sempre, baseados em inferência estatística). Um corpus (plural \"corpora\") é um conjunto de documentos (ou frases individuais) que foram anotados à mão com os valores corretos a serem aprendidos. Muitas classes diferentes de algoritmos de aprendizado de máquina foram aplicadas a tarefas de PLN. Esses algoritmos tomam como"}
{"source": "Processamento de linguagem natural", "chunk_id": "Processamento de linguagem natural_8", "text": "que foram anotados à mão com os valores corretos a serem aprendidos. Muitas classes diferentes de algoritmos de aprendizado de máquina foram aplicadas a tarefas de PLN. Esses algoritmos tomam como entrada um grande conjunto de \"recursos\" que são gerados a partir de dados de entrada. Alguns dos algoritmos mais usados, como árvores de decisão, produziam sistemas de regras rígidas semelhantes aos sistemas de regras manuscritas mais comuns. No entanto, cada vez mais, a pesquisa tem se concentrado em modelos estatísticos, que tomam decisões flexíveis e probabilísticas baseadas em agregar pesos reais a cada característica de entrada. Tais modelos têm a vantagem de poder expressar a certeza relativa de muitas respostas possíveis diferentes em vez de apenas uma, produzindo resultados mais confiáveis quando esse modelo é incluído como um componente de um sistema maior. Os sistemas baseados em algoritmos de aprendizagem mecânica têm muitas vantagens em relação às regras produzidas manualmente:"}
{"source": "Processamento de linguagem natural", "chunk_id": "Processamento de linguagem natural_9", "text": "quando esse modelo é incluído como um componente de um sistema maior. Os sistemas baseados em algoritmos de aprendizagem mecânica têm muitas vantagens em relação às regras produzidas manualmente: Os procedimentos de aprendizagem usados durante a aprendizagem da máquina focam-se automaticamente nos casos mais comuns, ao passo que quando se escrevem regras à mão, não é óbvio em que sentido o esforço deve ser dirigido. Os procedimentos de aprendizagem automática podem fazer uso de algoritmos de inferência estatística para produzir modelos que são robustos a entradas não familiares (por exemplo, contendo palavras ou estruturas que não foram vistas antes) e a entradas errôneas (por exemplo, com palavras ou palavras incorretamente omitidas). Geralmente, lidar com essas entradas de forma com regras manuscritas ou sistemas de regras manuscritas que tomam decisões suaves é extremamente trabalhoso, propenso a erros e demorado. Sistemas baseados em aprender automaticamente as regras podem ser"}
{"source": "Processamento de linguagem natural", "chunk_id": "Processamento de linguagem natural_10", "text": "manuscritas ou sistemas de regras manuscritas que tomam decisões suaves é extremamente trabalhoso, propenso a erros e demorado. Sistemas baseados em aprender automaticamente as regras podem ser mais precisos simplesmente fornecendo mais dados de entrada. No entanto, os sistemas baseados em regras escritas à mão só podem ser tornados mais precisos aumentando a complexidade das regras, o que é uma tarefa muito mais difícil. Em particular, há um limite para a complexidade de sistemas baseados em regras artesanais, para além dos quais os sistemas se tornam cada vez mais incontroláveis. No entanto, a criação de mais dados para entrada em sistemas de aprendizado de máquina requer simplesmente um aumento correspondente no número de horas trabalhadas por humanos, geralmente sem aumentos significativos na complexidade do processo de anotação. O subcampo de PLN dedicado a abordagens de aprendizagem é conhecido como aprendizagem de língua natural (NLL) e sua conferência, a CoNLL, e orgão"}
{"source": "Processamento de linguagem natural", "chunk_id": "Processamento de linguagem natural_11", "text": "na complexidade do processo de anotação. O subcampo de PLN dedicado a abordagens de aprendizagem é conhecido como aprendizagem de língua natural (NLL) e sua conferência, a CoNLL, e orgão central, o SIGNLL, são patrocinados pela ACL, reconhecendo também as suas ligações com linguística computacional e aquisição de linguagem. Quando o objetivo da pesquisa de aprendizagem de linguagem computacional é entender mais sobre aquisição de linguagem humana, ou psicolinguística, a NLL sobrepõe-se no campo relacionado de psicolinguística computacional. A listagem a seguir traz alguns dos trabalhos mais pesquisadas em PLN. Note que alguns deles têm aplicações no mundo real, enquanto outras servem mais frequentemente como tarefas secundárias que são usadas para auxiliar na resolução de tarefas maiores. O que distingue essas tarefas de outras tarefas potenciais e reais de PLN não é apenas o volume de pesquisa dedicado a elas, mas o fato de que para cada uma há tipicamente uma definição de problema"}
{"source": "Processamento de linguagem natural", "chunk_id": "Processamento de linguagem natural_12", "text": "O que distingue essas tarefas de outras tarefas potenciais e reais de PLN não é apenas o volume de pesquisa dedicado a elas, mas o fato de que para cada uma há tipicamente uma definição de problema bem especificada, uma métrica padrão para avaliar a tarefa, corpora padrão em que a tarefa pode ser avaliada e as competições dedicadas à tarefa específica. Sumarização automática Produz um resumo legível de uma parte do texto. Muitas vezes usado para fornecer resumos de texto de um tipo conhecido, como artigos na seção financeira de um jornal. Resolução de correferência Dada uma frase ou um pedaço maior de texto, determina quais palavras (\"menções\") se referem aos mesmos objetos (\"entidades\"). A resolução da anáfora é um exemplo específico dessa tarefa e está especificamente preocupada em combinar os pronomes com os substantivos ou nomes aos quais eles se referem. A tarefa mais geral da resolução de correferência também inclui a identificação dos chamados \"relacionamentos de ponte\""}
{"source": "Processamento de linguagem natural", "chunk_id": "Processamento de linguagem natural_13", "text": "em combinar os pronomes com os substantivos ou nomes aos quais eles se referem. A tarefa mais geral da resolução de correferência também inclui a identificação dos chamados \"relacionamentos de ponte\" envolvendo expressões de referência. Por exemplo, numa frase como \"Ele entrou na casa de João pela porta da frente\", \"a porta da frente\" é uma expressão de referência e a relação da ponte a ser identificada é o fato de que a porta a ser referida é a porta da frente de John's (ao invés de alguma outra estrutura que também pode ser referida). Análise do Discurso Esta rubrica inclui uma série de tarefas relacionadas. Uma tarefa é identificar a estrutura discursiva do texto conectado, isto é, a natureza das relações discursivas entre sentenças (por exemplo, elaboração, explicação, contraste). Outra possível tarefa é reconhecer e classificar os atos de fala em um pedaço de texto (por exemplo, pergunta sim-não, pergunta de conteúdo, frase, afirmação, etc). Maquina de tradução Traduzir"}
{"source": "Processamento de linguagem natural", "chunk_id": "Processamento de linguagem natural_14", "text": "Outra possível tarefa é reconhecer e classificar os atos de fala em um pedaço de texto (por exemplo, pergunta sim-não, pergunta de conteúdo, frase, afirmação, etc). Maquina de tradução Traduzir automaticamente texto de uma linguagem humana para outra. Este é uma das tarefas mais difíceis e faz parte de um tipo de problemas conhecidos como \"AI-complete\", ou seja, exigindo todos os diferentes tipos de conhecimento que os humanos possuem (gramática, semântica, fatos sobre o mundo real, etc) para resolvê-lo adequadamente. Segmentação morfológica Separa palavras em morfemas individuais e identifica classes de morfemas. A dificuldade desta tarefa depende muito da complexidade da morfologia (isto é, da estrutura das palavras) da linguagem que está sendo considerada. O inglês possui uma morfologia bastante simples, especialmente a morfologia flexional, e portanto é possível ignorar esta tarefa inteiramente e simplesmente modelar todas as formas possíveis de uma palavra (por exemplo, \"open,"}
{"source": "Processamento de linguagem natural", "chunk_id": "Processamento de linguagem natural_15", "text": "bastante simples, especialmente a morfologia flexional, e portanto é possível ignorar esta tarefa inteiramente e simplesmente modelar todas as formas possíveis de uma palavra (por exemplo, \"open, opens, opened, opening\") como palavras separadas. Em línguas como o turco ou o Meitei, uma língua indiana fortemente aglutinada, no entanto, tal abordagem não é possível, uma vez que cada entrada do dicionário tem milhares de formas de palavras possíveis. Reconhecimento de entidade nomeada (NER) Dado um fluxo de texto, determina quais são itens no mapa de texto para nomes próprios, como pessoas ou locais e qual é o tipo de cada nome (por exemplo, pessoa, local, organização). Embora a capitalização possa ajudar a reconhecer entidades nomeadas em idiomas como o inglês, essas informações podem não ajudar a determinar o tipo de entidade nomeada e, em alguns casos, sãos imprecisas ou insuficientes. Por exemplo, a primeira palavra de uma frase também é capitalizada e as entidades nomeadas muitas"}
{"source": "Processamento de linguagem natural", "chunk_id": "Processamento de linguagem natural_16", "text": "ajudar a determinar o tipo de entidade nomeada e, em alguns casos, sãos imprecisas ou insuficientes. Por exemplo, a primeira palavra de uma frase também é capitalizada e as entidades nomeadas muitas vezes abrangem várias palavras, com apenas algumas delas são capitalizadas. Além disso, muitas outras linguagens em scripts não-ocidentais (por exemplo, chinês ou árabe) não têm nenhuma capitalização e mesmo as línguas com maiúsculas podem não distinguir nomes. Por exemplo, o alemão capitaliza todos os substantivos, independentemente de se referirem a nomes, e o francês e o espanhol não capitalizam nomes que servem como adjetivos. Geração de língua natural Converte informações de bancos de dados de computador ou intenções semânticas em linguagem humana legível. Compreensão da língua natural Converte pedaços de texto em representações mais formais, como estruturas de lógica de primeira ordem, que são mais fáceis de manipular pelos programas de computador. A compreensão da língua natural"}
{"source": "Processamento de linguagem natural", "chunk_id": "Processamento de linguagem natural_17", "text": "Converte pedaços de texto em representações mais formais, como estruturas de lógica de primeira ordem, que são mais fáceis de manipular pelos programas de computador. A compreensão da língua natural envolve a identificação da semântica pretendida a partir da múltipla semântica possível que pode ser derivada de uma expressão de língua natural que geralmente toma a forma de notação organizada de conceitos de linguagens naturais. Entretanto, introdução e criação de linguagem metamodelo e ontologia são eficientes soluções empíricas. Uma formalização explícita da semântica de línguas naturais sem confusões com suposições implícitas como closed-world assumption (CWA) versus open-world assumption ou subjetiva Sim / Não versus objetivo Verdadeiro / Falso é esperada para a construção de uma base de formalização semântica. Reconhecimento óptico de caracteres (OCR) Dada uma imagem que representa o texto impresso, determina o texto correspondente. Marcação de classe gramatical Dada uma sentença,"}
{"source": "Processamento de linguagem natural", "chunk_id": "Processamento de linguagem natural_18", "text": "formalização semântica. Reconhecimento óptico de caracteres (OCR) Dada uma imagem que representa o texto impresso, determina o texto correspondente. Marcação de classe gramatical Dada uma sentença, determina a classe gramatical de cada palavra. Muitas palavras, especialmente as comuns, podem servir como múltiplas partes do discurso. Em inglês, por exemplo, \"book\" pode ser um substantivo (\"the book on the table\") ou verbo (\"book a flight\"); \"Set\" pode ser um substantivo, verbo ou adjetivo; E \"out\" pode ser qualquer um de pelo menos cinco diferentes partes da fala. Algumas línguas têm mais ambiguidade do que outras. As línguas com pouca morfologia flexional, como o inglês, são particularmente propensas a tal ambiguidade. O chinês é propenso a tal ambiguidade porque é uma língua tonal durante a verbalização. Tal inflexão não é facilmente transmitida através das entidades empregadas dentro da ortografia para transmitir o significado pretendido. Análise sintática (Parsing) Determina a"}
{"source": "Processamento de linguagem natural", "chunk_id": "Processamento de linguagem natural_19", "text": "a verbalização. Tal inflexão não é facilmente transmitida através das entidades empregadas dentro da ortografia para transmitir o significado pretendido. Análise sintática (Parsing) Determina a árvore de análise (análise gramatical) de uma frase. A gramática para as linguagens naturais é ambígua e frases típicas têm múltiplas análises possíveis. Na verdade, surpreendentemente, para uma frase típica pode haver milhares de análises em potencial (a maioria dos quais parecerá completamente absurda para um ser humano). Respostas a perguntas Dada uma questão de linguagem humana, determina sua resposta. As perguntas típicas têm uma resposta correta específica (como \"Qual é o capital do Canadá?\"), mas às vezes perguntas abertas também são consideradas (como \"Qual é o significado da vida?\"). Trabalhos recentes têm analisado questões ainda mais complexas. Extração de relacionamento Identifica as relações entre entidades nomeadas (por exemplo, quem é casado com quem) com base em textos. Quebra"}
{"source": "Processamento de linguagem natural", "chunk_id": "Processamento de linguagem natural_20", "text": "recentes têm analisado questões ainda mais complexas. Extração de relacionamento Identifica as relações entre entidades nomeadas (por exemplo, quem é casado com quem) com base em textos. Quebra de frases (sentence boundary disambiguation) Encontra os limites da frase em um pedaço de texto. Os limites de frases são normalmente marcadas por pontos ou outros sinais de pontuação, mas esses mesmos caracteres podem servir outros propósitos. Análise de subjetividade (sentiment analysis ou opinion mining) Extrai informações subjetivas geralmente de um conjunto de documentos, muitas vezes usando revisões online para determinar a \"polaridade\" sobre objetos específicos. É especialmente útil para identificar tendências da opinião pública nas mídias sociais, para fins de marketing. Reconhecimento de fala Dado um clipe de som de uma pessoa ou pessoas falando, determina a representação textual do discurso. É o oposto da síntese de fala e é uma das áreas mais difíceis, conhecida como \"AI-complete\"."}
{"source": "Processamento de linguagem natural", "chunk_id": "Processamento de linguagem natural_21", "text": "fala Dado um clipe de som de uma pessoa ou pessoas falando, determina a representação textual do discurso. É o oposto da síntese de fala e é uma das áreas mais difíceis, conhecida como \"AI-complete\". Na fala natural quase não há pausas entre palavras sucessivas, por isso a segmentação de fala é uma subtarefa necessária de reconhecimento de fala. Nota-se também que, na maioria das linguagens faladas, os sons que representam letras sucessivas se misturam entre si em um processo denominado coarticulação, de modo que a conversão do sinal analógico em caracteres discretos pode ser um processo muito difícil de ser realizado. Segmentação de fala Dado um clipe de som de uma pessoa ou pessoas falando, separa-o em palavras. Uma subaplicação de reconhecimento de fala e normalmente agrupada com ele. Análise morfológica e reconhecimento de tópicos Dado um pedaço de texto, separa-o em segmentos cada um dos quais é dedicado a um tópico e identifica o tópico do segmento. Análise morfológica e"}
{"source": "Processamento de linguagem natural", "chunk_id": "Processamento de linguagem natural_22", "text": "ele. Análise morfológica e reconhecimento de tópicos Dado um pedaço de texto, separa-o em segmentos cada um dos quais é dedicado a um tópico e identifica o tópico do segmento. Análise morfológica e segmentação de palavras Separa um pedaço de texto contínuo em palavras separadas. Para uma língua como o inglês, isso é bastante trivial, uma vez que as palavras são normalmente separadas por espaços. No entanto, algumas línguas escritas como chinês, japonês e tailandês não marcam limites de palavras de tal forma, e nessas línguas segmentação de texto é uma tarefa significativa que requer conhecimento do vocabulário e morfologia das palavras na língua. Desambiguação Muitas palavras têm mais de um significado, assim temos que selecionar o significado que faz mais sentido no contexto. Para este problema, em geral é dada uma lista de palavras e sentidos de palavras associadas de um dicionário ou recurso online, como o WordNet. Em alguns casos, conjuntos de tarefas relacionadas são agrupados em"}
{"source": "Processamento de linguagem natural", "chunk_id": "Processamento de linguagem natural_23", "text": "em geral é dada uma lista de palavras e sentidos de palavras associadas de um dicionário ou recurso online, como o WordNet. Em alguns casos, conjuntos de tarefas relacionadas são agrupados em subcampos de PLN que são frequentemente considerados separadamente da PLN como um todo, como os exemplos a seguir: Recuperação de informação (IR) Trata-se de armazenar, pesquisar e recuperar informações. É um campo separado dentro da ciência da computação (mais perto de bancos de dados), mas a IR se baseia em alguns métodos PLN (por exemplo, stemming). Algumas pesquisas e aplicações atuais procuram preencher a lacuna entre IR e PLN. Extração de informação (IE) Trata-se, em geral, da extração de informação semântica a partir do texto. Abrange tarefas como reconhecimento de entidade mencionada, resolução de correferência e de relacionamento de extração, etc. Processamento de voz Abrange reconhecimento de fala, síntese de fala e tarefas relacionadas. Outras tarefas incluem: Identificação na língua"}
{"source": "Processamento de linguagem natural", "chunk_id": "Processamento de linguagem natural_24", "text": "de correferência e de relacionamento de extração, etc. Processamento de voz Abrange reconhecimento de fala, síntese de fala e tarefas relacionadas. Outras tarefas incluem: Identificação na língua materna Stemização Simplificação do texto Síntese de fala Revisão de texto Pesquisa em língua natural Expansão da consulta Pontuação de ensaio automatizado Truecasing Artigo principal: Gramática estocástica O processamento estatístico em língua natural utiliza métodos estocásticos, probabilísticos e estatísticos para resolver algumas das dificuldades discutidas acima, especialmente aquelas que surgem porque frases mais longas são muito ambíguas quando processadas com gramáticas realistas, produzindo milhares ou milhões de análises possíveis. Métodos de desambiguação envolvem muitas vezes o uso de corpora e modelos de Markov. O projeto ESPRIT P26 (1984-1988), liderado pelo CSELT, explorou o problema do reconhecimento de fala comparando abordagem baseada em conhecimento e estatística: o"}
{"source": "Processamento de linguagem natural", "chunk_id": "Processamento de linguagem natural_25", "text": "uso de corpora e modelos de Markov. O projeto ESPRIT P26 (1984-1988), liderado pelo CSELT, explorou o problema do reconhecimento de fala comparando abordagem baseada em conhecimento e estatística: o resultado escolhido foi um modelo completamente estatístico. Um dos primeiros modelos de compreensão estatística da língua natural foi introduzido em 1991 por Roberto Pieraccini, Esther Levin e Chin-Hui Lee, da Bell Laboratories]. O PLN compreende todas as abordagens quantitativas para processamento automatizado de linguagem, incluindo modelagem probabilística, teoria da informação e álgebra linear. A tecnologia para o PLN estatístico vem principalmente da aprendizagem automática e da mineração de dados, que são campos de inteligência artificial que envolvem o aprendizado a partir de dados. O objetivo da avaliação do PLN é uma medida de uma ou mais qualidades de um algoritmo ou de um sistema a fim de determinar se o algoritmo atende às metas dos projetistas ou o sistema de atendimento às"}
{"source": "Processamento de linguagem natural", "chunk_id": "Processamento de linguagem natural_26", "text": "objetivo da avaliação do PLN é uma medida de uma ou mais qualidades de um algoritmo ou de um sistema a fim de determinar se o algoritmo atende às metas dos projetistas ou o sistema de atendimento às necessidades de seus usuários. Investigação na avaliação PLN tem ganhado atenção, porque a definição de critérios de avaliação é uma forma de especificar precisamente problemas do PLN. Uma métrica de avaliação de PLN em um sistema algorítmico permite a integração da compreensão de linguagem e geração de linguagem. Um conjunto preciso de critérios de avaliação, que pode ser aplicado principalmente a avaliações métricas, podendo permitir que várias equipes comparem suas soluções para um determinado problema do PLN. Em 1983, iniciou-se o Projecto Esprit P26, que avaliou as Tecnologias da Fala (incluindo tópicos gerais como Sintaxe e Semântica) comparando as abordagens baseadas em regras com as estatísticas. Em 1987, a primeira campanha de avaliação de textos escritos parece ser uma campanha"}
{"source": "Processamento de linguagem natural", "chunk_id": "Processamento de linguagem natural_27", "text": "tópicos gerais como Sintaxe e Semântica) comparando as abordagens baseadas em regras com as estatísticas. Em 1987, a primeira campanha de avaliação de textos escritos parece ser uma campanha dedicada à compreensão da mensagem (Pallet, 1998). O projeto Parseval / GEIG comparou gramáticas de frase-estrutura (Black 1991). Houve uma série de campanhas no projeto Tipster sobre tarefas como resumo, tradução e pesquisa (Hirschman 1998). Em 1994, na Alemanha, o Morpholympics comparou marcadores morfológicos alemães. As campanhas de Senseval & Romanseval foram realizadas com os objetivos de desambiguação semântica. Em 1996, a campanha Sparkle comparou os analisadores sintáticos em quatro idiomas diferentes (inglês, francês, alemão e italiano). Na França, o projeto Grace comparou um conjunto de 21 marcadores para o francês em 1997 (Adda 1999). Em 2004, durante o projeto Technolangue / Easy, foram comparados 13 analisadores para o francês. A avaliação em larga escala dos analisadores de"}
{"source": "Processamento de linguagem natural", "chunk_id": "Processamento de linguagem natural_28", "text": "de 21 marcadores para o francês em 1997 (Adda 1999). Em 2004, durante o projeto Technolangue / Easy, foram comparados 13 analisadores para o francês. A avaliação em larga escala dos analisadores de dependência foi realizada no contexto das tarefas compartilhadas do CoNLL em 2006 e 2007. Na França, no âmbito do projecto ANR-Passage (final de 2007), foram comparados 10 analisadores para o francês. Em Itália, a campanha EVALITA foi realizada em 2007, 2009, 2011 e 2014 para comparar várias ferramentas de PLN e de voz para o site italiano - EVALITA. Avaliação intrínseca vs. extrínseca A avaliação intrínseca considera um sistema PNL isolado e caracteriza seu desempenho em relação a um resultado padrão-excelência, conforme definido pelos avaliadores. A avaliação extrínseca, também chamada de avaliação em uso, considera o sistema PLN em um cenário mais complexo como um sistema embutido ou uma função precisa para um usuário humano. O desempenho extrínseco do sistema é então caracterizado em"}
{"source": "Processamento de linguagem natural", "chunk_id": "Processamento de linguagem natural_29", "text": "em uso, considera o sistema PLN em um cenário mais complexo como um sistema embutido ou uma função precisa para um usuário humano. O desempenho extrínseco do sistema é então caracterizado em termos de utilidade em relação à tarefa global do sistema estranho ou do utilizador humano. Por exemplo, considere um analisador sintático que é baseado na saída de alguma parte do tagger de fala (POS). Uma avaliação intrínseca executaria o marcador POS em dados estruturados e compararia a saída do sistema do marcador POS com a saída padrão ouro. Uma avaliação extrínseca executaria o analisador com algum outro marcador POS e, em seguida, com o marcador POS novo e compara a precisão de análise. Caixa preta vs. Avaliação da caixa de vidro A avaliação em caixa preta requer que alguém execute um sistema PLN em um conjunto de dados de amostra e para medir uma série de parâmetros relacionados com a qualidade do processo, como velocidade, confiabilidade, consumo de recursos e, principalmente, a qualidade"}
{"source": "Processamento de linguagem natural", "chunk_id": "Processamento de linguagem natural_30", "text": "em um conjunto de dados de amostra e para medir uma série de parâmetros relacionados com a qualidade do processo, como velocidade, confiabilidade, consumo de recursos e, principalmente, a qualidade do resultado, como a precisão da anotação de dados ou a fidelidade de uma tradução. A avaliação da caixa de vidro examina a concepção do sistema; Os algoritmos que são implementados, os recursos linguísticos que utiliza, como o tamanho do vocabulário ou a expressão definida de cardinalidade. Dada a complexidade dos problemas da PLN, muitas vezes é difícil prever o desempenho apenas com base na avaliação da caixa de vidro; Mas este tipo de avaliação é mais informativo no que diz respeito à análise de erros ou desenvolvimentos futuros de um sistema. Automática vs. avaliação manual Em muitos casos, procedimentos automáticos podem ser definidos para avaliar um sistema de PLN, comparando sua saída com o padrão de excelência. Embora o custo de reproduzir o padrão de excelência possa ser bastante"}
{"source": "Processamento de linguagem natural", "chunk_id": "Processamento de linguagem natural_31", "text": "procedimentos automáticos podem ser definidos para avaliar um sistema de PLN, comparando sua saída com o padrão de excelência. Embora o custo de reproduzir o padrão de excelência possa ser bastante elevado, avaliação automática de bootstrapping sobre os mesmos dados de entrada pode ser repetida quantas vezes for necessário sem custos adicionais desordenados. No entanto, para muitos problemas de PLN a definição precisa de um padrão de excelência é uma tarefa complexa e pode se revelar impossível quando o acordo inter-anotador é insuficiente. A avaliação manual é melhor realizada por juízes humanos instruídos para estimar a qualidade de um sistema, ou mais frequentemente de uma amostra de sua produção, com base em uma série de critérios. Embora, graças à sua competência linguística, os juízes humanos possam ser considerados como a referência para uma série de tarefas de processamento de linguagem, há também uma variação considerável em suas classificações. É por isso que a avaliação"}
{"source": "Processamento de linguagem natural", "chunk_id": "Processamento de linguagem natural_32", "text": "humanos possam ser considerados como a referência para uma série de tarefas de processamento de linguagem, há também uma variação considerável em suas classificações. É por isso que a avaliação automática é, por vezes, referida como avaliação objetiva enquanto a avaliação humana é perspectiva. Um subcomitê ISO está trabalhando para facilitar a interoperabilidade entre recursos lexicais e programas PLN. O subcomitê faz parte do ISO / TC37 e é chamado ISO / TC37 / SC4. Alguns padrões ISO já estão publicados, mas a maioria deles está em construção, principalmente na representação de léxico (ver LMF), anotação e registro de categoria de dados. Expert System S.p.A. General Architecture for Text Engineering Modular Audio Recognition Framework Natural Language Toolkit (NLTK): uma biblioteca em Python OpenNLP Mineração de texto biomédica Processo de processamento composto Revisão assistida por computador Linguagem natural controlada Processamento linguístico profundo Auxílio à leitura de"}
{"source": "Processamento de linguagem natural", "chunk_id": "Processamento de linguagem natural_33", "text": "em Python OpenNLP Mineração de texto biomédica Processo de processamento composto Revisão assistida por computador Linguagem natural controlada Processamento linguístico profundo Auxílio à leitura de línguas estrangeiras Auxílio à escrita em língua estrangeira Tecnologia da linguagem A alocação de Dirichlet Latente (LDA) Indexação semântica latente Lista de ferramentas de processamento de língua natural Mapa de LRE Programação em língua natural Reificação (linguística) Dobradura semântica Sistema de diálogo falado Vetor do Pensamento Pesquisa Transderivacional Word2vec Steven Bird, Ewan Klein, and Edward Loper (2009). Natural Language Processing with Python. O'Reilly Media. ISBN 978-0-596-51649-9. Daniel Jurafsky and James H. Martin (2008). Speech and Language Processing, 2nd edition. Pearson Prentice Hall. ISBN 978-0-13-187321-6. Christopher D. Manning, Prabhakar Raghavan, and Hinrich Schütze (2008). Introduction to Information Retrieval. Cambridge University Press. ISBN"}
{"source": "Processamento de linguagem natural", "chunk_id": "Processamento de linguagem natural_34", "text": "edition. Pearson Prentice Hall. ISBN 978-0-13-187321-6. Christopher D. Manning, Prabhakar Raghavan, and Hinrich Schütze (2008). Introduction to Information Retrieval. Cambridge University Press. ISBN 978-0-521-86571-5. Official html and pdf versions available without charge. Christopher D. Manning and Hinrich Schütze (1999). Foundations of Statistical Natural Language Processing. The MIT Press. ISBN 978-0-262-13360-9. David M. W. Powers and Christopher C. R. Turk (1989). Machine Learning of Natural Language. Springer-Verlag. ISBN 978-0-387-19557-5."}
{"source": "Modelos de linguagem de grande escala", "chunk_id": "Modelos de linguagem de grande escala_0", "text": "Modelos de linguagem de grande escala (em inglês: Large Language Model ou LLM) são modelos de linguagem compostos por uma rede neural com muitos parâmetros (tipicamente bilhões ou possivelmente mais). São treinados com grandes quantidades de textos não rotulado usando aprendizado de máquina não-supervisionado. Os LLM surgiram por volta de 2018, com o modelo BERT. Estes têm bom desempenho em uma ampla variedade de tarefas. Isso mudou o foco da pesquisa em processamento de linguagem natural, afastando-se do paradigma anterior de treinar modelos supervisionados especializados para tarefas específicas. Embora o termo não tenha uma definição formal, ele geralmente se refere a modelos de aprendizado profundo que possuem uma contagem de parâmetros da ordem de bilhões ou mais. MLLs são modelos de propósito geral que se destacam em uma ampla gama de tarefas, em vez de serem treinados para uma tarefa específica (como análise de sentimento, reconhecimento de entidades nomeadas ou raciocínio"}
{"source": "Modelos de linguagem de grande escala", "chunk_id": "Modelos de linguagem de grande escala_1", "text": "de propósito geral que se destacam em uma ampla gama de tarefas, em vez de serem treinados para uma tarefa específica (como análise de sentimento, reconhecimento de entidades nomeadas ou raciocínio matemático). Embora treinados em tarefas simples, como prever a próxima palavra em uma frase, modelos de linguagem neural com treinamento e contagem de parâmetros suficientes são capazes de capturar grande parte da sintaxe e semântica da linguagem humana. Além disso, grandes modelos de linguagem demonstram considerável conhecimento geral sobre o mundo e são capazes de \"memorizar\" uma grande quantidade de fatos durante o treinamento. Os modelos grandes de linguagem geralmente usam a arquitetura do transformador, que se tornou a técnica padrão de aprendizado profundo para dados sequenciais desde 2018 (anteriormente, arquiteturas recorrentes como a LSTM eram mais comuns). Os MLLs são treinados de maneira não supervisionada em texto não anotado. Um transformador da esquerda para a direita é"}
{"source": "Modelos de linguagem de grande escala", "chunk_id": "Modelos de linguagem de grande escala_2", "text": "2018 (anteriormente, arquiteturas recorrentes como a LSTM eram mais comuns). Os MLLs são treinados de maneira não supervisionada em texto não anotado. Um transformador da esquerda para a direita é treinado para maximizar a probabilidade atribuída à próxima palavra nos dados de treinamento, dada o contexto anterior. Alternativamente, um MLL pode usar um transformador bidirecional (como no exemplo do BERT), que atribui uma distribuição de probabilidade sobre as palavras com acesso tanto ao contexto anterior quanto posterior. Além da tarefa de prever a próxima palavra ou \"preencher as lacunas\", os MLLs podem ser treinados em tarefas auxiliares que testam sua compreensão da distribuição de dados, como a Predição de Próxima Sentença (NSP), na qual pares de frases são apresentados e o modelo deve prever se eles aparecem lado a lado no corpus de treinamento. Os primeiros MLLs foram treinados em corpora com bilhões de palavras. A versão inicial do GPT foi treinada em 2018 no BookCorpus, que"}
{"source": "Modelos de linguagem de grande escala", "chunk_id": "Modelos de linguagem de grande escala_3", "text": "prever se eles aparecem lado a lado no corpus de treinamento. Os primeiros MLLs foram treinados em corpora com bilhões de palavras. A versão inicial do GPT foi treinada em 2018 no BookCorpus, que consiste em 985 milhões de palavras. No mesmo ano, o BERT foi treinado em uma combinação de BookCorpus e Wikipedia em inglês, totalizando 3,3 bilhões de palavras. Nos anos seguintes, os corpora de treinamento para MLLs aumentaram em ordens de magnitude, atingindo centenas de bilhões ou trilhões de tokens. MLLs são caros em termos computacionais para serem treinados. Um estudo de 2020 estimou o custo do treinamento de um modelo com 1.5 bilhão de parâmetros (de 1 a 2 ordens de magnitude menores que o estado da arte na época) em US$ 1.6 milhão. Uma análise de 2020 constatou que a capacidade dos modelos de linguagem neural (medida pela perda de treinamento) aumentou suavemente em uma relação de lei de potência com o número de parâmetros, quantidade de dados de treinamento e computação usada para"}
{"source": "Modelos de linguagem de grande escala", "chunk_id": "Modelos de linguagem de grande escala_4", "text": "de linguagem neural (medida pela perda de treinamento) aumentou suavemente em uma relação de lei de potência com o número de parâmetros, quantidade de dados de treinamento e computação usada para treinamento. Essas relações foram testadas em uma ampla gama de valores (até sete ordens de magnitude) e nenhuma atenuação da relação foi observada no extremo superior da faixa (incluindo tamanhos de rede de até trilhões de parâmetros). Entre 2018 e 2020, o método padrão para utilizar um MLL em uma tarefa específica de processamento de linguagem natural era ajustar o modelo com treinamento adicional específico para a tarefa. Posteriormente, descobriu-se que MLLs mais poderosos, como o GPT-3, podem resolver tarefas sem treinamento adicional por meio de técnicas de \"prompting\", nas quais o problema a ser resolvido é apresentado ao modelo como um prompt de texto, possivelmente com alguns exemplos textuais de problemas semelhantes e suas soluções. O ajuste fino é a prática de modificar um modelo"}
{"source": "Modelos de linguagem de grande escala", "chunk_id": "Modelos de linguagem de grande escala_5", "text": "a ser resolvido é apresentado ao modelo como um prompt de texto, possivelmente com alguns exemplos textuais de problemas semelhantes e suas soluções. O ajuste fino é a prática de modificar um modelo de linguagem pré-treinado existente, treinando-o (de forma supervisionada) em uma tarefa específica (por exemplo, análise de sentimento, reconhecimento de entidade nomeada ou marcação de partes do discurso). É uma forma de aprendizado por transferência. Geralmente envolve a introdução de um novo conjunto de pesos conectando a camada final do modelo de linguagem à saída da tarefa secundária. Os pesos originais do modelo de linguagem podem ser \"congelados\", de modo que apenas a nova camada de pesos conectando-os à saída seja aprendida durante o treinamento. Alternativamente, os pesos originais podem receber pequenas atualizações (possivelmente com camadas anteriores congeladas). Inteligência artificial generativa Modelos de linguagem de pequena escala Alucinação (inteligência artificial)"}
{"source": "Língua natural", "chunk_id": "Língua natural_0", "text": "Língua natural (língua humana, língua idiomática, ou somente língua ou idioma) é qualquer linguagem desenvolvida naturalmente pelo ser humano, de forma não premeditada, como resultado da facilidade inata para a linguagem possuída pelo intelecto humano. Vários exemplos podem ser dados como as línguas faladas e as línguas de sinais. A linguagem natural é normalmente utilizada para a comunicação. As línguas naturais são diferentes das línguas construídas e das línguas formais, tais como a linguística computacional, a língua escrita, a linguagem animal e as linguagens usadas no estudo formal da lógica, especialmente da lógica matemática. As línguas de sinais ou línguas gestuais são também línguas naturais, visto possuírem as mesmas propriedades características: gramática e sintaxe com dependências não locais, infinidade discreta, generatividade e criatividade. Línguas de sinais ou gestuais como a estadunidense, a francesa, a brasileira ou a portuguesa estão devidamente documentadas na"}
{"source": "Língua natural", "chunk_id": "Língua natural_1", "text": "não locais, infinidade discreta, generatividade e criatividade. Línguas de sinais ou gestuais como a estadunidense, a francesa, a brasileira ou a portuguesa estão devidamente documentadas na literatura científica. Línguas naturais são, grosso modo, o contrário de línguas artificiais ou construídas, como linguagens de programação de computador, assim como de sistemas de comunicação existentes na natureza, como a dança das abelhas. Embora exista uma grande variedade de línguas naturais, qualquer criança humana normal é capaz de aprender qualquer língua natural. O estudo das línguas nos permite identificar muito sobre seu funcionamento (sintaxe, semântica, fonética, fonologia, etc.), mas também sobre como a mente e o cérebro humanos processam a linguagem. Em termos linguísticos, a língua natural é uma expressão que apenas se aplica a uma linguagem que evoluiu naturalmente, como a fala nativa (primeira língua) de um indivíduo. A fala, assim como outros tipos de língua natural, é formada"}
{"source": "Língua natural", "chunk_id": "Língua natural_2", "text": "é uma expressão que apenas se aplica a uma linguagem que evoluiu naturalmente, como a fala nativa (primeira língua) de um indivíduo. A fala, assim como outros tipos de língua natural, é formada por unidades menores (palavras) que possuem significados, e essas unidades, por sua vez, são formadas por unidades ainda menores (como vogais e consoantes). É comumente alegado que o francês, o inglês e o português falados são \"línguas\". No entanto, sabemos que o inglês americano não é exatamente igual ao inglês antilhano ou britânico e, ainda, que dentro dessas regiões (como nos limites da Inglaterra) existem variedades ainda numerosas de inglês, normalmente chamadas de \"dialetos\". Do ponto de vista estritamente científico, contudo, não existe um limite objetivo entre o que seriam línguas e o que seriam dialetos; como escreveu o cientista Hermann Paul, \"com efeito, podemos distinguir tantas línguas quanto indivíduos\". Portanto, quando falamos do inglês, do francês e do alemão estamos tratando"}
{"source": "Língua natural", "chunk_id": "Língua natural_3", "text": "seriam dialetos; como escreveu o cientista Hermann Paul, \"com efeito, podemos distinguir tantas línguas quanto indivíduos\". Portanto, quando falamos do inglês, do francês e do alemão estamos tratando de abstrações que não correspondem exatamente à realidade. Atualmente é aceito pela academia que línguas são sistemas. Todos os elementos de uma língua estão ligados entre si a partir de uma variedade de relações. Essa compreensão das línguas foi, inicialmente, instituída por Ferdinand de Saussure. Saussure falou das línguas como sistemas de signos onde, para cada signo linguístico, haveria um significante e uma referência (significado): seu equivalente na língua (a palavra menina) e um conceito que a língua pretende expressar (o conceito de menina). A teorização de Noam Chomsky, segundo a qual \"língua é um conjunto de sentenças (finitas ou infinitas), cada uma finita em extensão e construídas a partir de um conjunto finito de elementos\", é uma das mais aceitas hoje. Chomsky postulou a"}
{"source": "Língua natural", "chunk_id": "Língua natural_4", "text": "qual \"língua é um conjunto de sentenças (finitas ou infinitas), cada uma finita em extensão e construídas a partir de um conjunto finito de elementos\", é uma das mais aceitas hoje. Chomsky postulou a existência de uma Gramática Universal, comum a todas as línguas, que seria herdada geneticamente. Não existe consenso entre os antropólogos acerca de quando e como teria surgido a linguagem nos seres humanos (ou em seus ancestrais). As estimativas variam consideravelmente, sendo que alguns cientistas apontam para a existência de linguagem há 2 milhões de anos entre os Homo habilis, enquanto outros preferem localizá-la há quarenta mil anos apenas, no tempo do homem de Cro-magnon. No entanto, evidências recentes indicam que a linguagem humana foi inventada (ou evoluiu) na África antes da dispersão dos humanos pelo globo a partir dessa região há cerca de 50 mil anos. Além disso, é lógico supor que, como todos os grupos humanos conhecidos possuem línguas, a língua natural deve ter figurado"}
{"source": "Língua natural", "chunk_id": "Língua natural_5", "text": "dos humanos pelo globo a partir dessa região há cerca de 50 mil anos. Além disso, é lógico supor que, como todos os grupos humanos conhecidos possuem línguas, a língua natural deve ter figurado entre os ancestrais de todos esses grupos. Muito pouco se sabe, na realidade, sobre a relação entre a linguagem (como a percebemos) e o cérebro humano. Embora uma grande maioria de estudiosos da neurolinguística afirme que o crescimento do cérebro (sobretudo do córtex) está relacionado ao surgimento da linguagem, as informações que temos sobre o assunto ainda são muito limitadas. Sabemos, por exemplo, que o hemisfério esquerdo do cérebro “envolve” a compreensão e produção da fala. O estudo das lesões cerebrais em pacientes que perderam a fala (ou sofreram alterações visíveis na forma de articular a fala, ou de pronunciar sentenças) indica que duas áreas do cérebro, a área de Broca e a área de Wernicke, são responsáveis respectivamente pelo planejamento e pela compreensão da fala. No entanto,"}
{"source": "Língua natural", "chunk_id": "Língua natural_6", "text": "a fala, ou de pronunciar sentenças) indica que duas áreas do cérebro, a área de Broca e a área de Wernicke, são responsáveis respectivamente pelo planejamento e pela compreensão da fala. No entanto, pesquisas recentes têm questionado a validade dessa suposição, sobretudo a partir do questionamento da metodologia empregada pelos cientistas ao registrarem e analisarem estes casos. De acordo com Loraine K. Obler e Kris Bjerlow, “Duas escolas do estudo de neurolinguística são tradicionalmente descritas: os ‘localizacionistas’ e os holistas”. Os primeiros, como o cientista Broca, postularam a existência de um vínculo direto entre certas áreas do cérebro e produção da fala, enquanto na perspectiva dos holistas não existem centros de linguagem e, na realidade, todo o cérebro contribui para a produção de um determinado fenômeno, como a fala. Sabemos que a fala funciona na base da repetição de unidades chamadas palavras, cujo sentido se repete, sendo que estas, por sua vez, são formadas por"}
{"source": "Língua natural", "chunk_id": "Língua natural_7", "text": "de um determinado fenômeno, como a fala. Sabemos que a fala funciona na base da repetição de unidades chamadas palavras, cujo sentido se repete, sendo que estas, por sua vez, são formadas por outras unidades menores (vogais e consoantes) que também se repetem. Na realidade, determinar o que são palavras e os limites entre as unidades fonéticas da fala é, ainda, um desafio. Espectrogramas de sentenças faladas não permitem ver com clareza onde começa uma vogal e onde ela termina. Pesquisas mostram que, não importa quão rápido ou lentamente os idiomas sejam falados, eles tendem a transmitir informações aproximadamente na mesma taxa: 39 bits por segundo, aproximadamente o dobro da velocidade do código Morse. As línguas faladas variam no tempo e no espaço. O inglês falado por um londrino na época do rei Henrique VIII certamente não é o mesmo que o inglês falado por um londrino hoje, assim como o inglês falado por um britânico contemporâneo dificilmente pode ser considerado semelhante ao"}
{"source": "Língua natural", "chunk_id": "Língua natural_8", "text": "época do rei Henrique VIII certamente não é o mesmo que o inglês falado por um londrino hoje, assim como o inglês falado por um britânico contemporâneo dificilmente pode ser considerado semelhante ao inglês falado em várias das ex-colônias britânicas hoje. A forma como as línguas faladas mudam é assunto de particular interesse na academia. Por exemplo, comparando dialetos do inglês, os cientistas perceberam que em alguns países e regiões o “r” [r] das sílabas finais de palavras como “sport” (esporte) não eram pronunciados. O caso contrário ocorria em Nova Iorque no século XX, onde o uso do [r] no final de sílaba era muito mais comum. Segundo estudo realizado por William Labov, essa diferença surgiu porque o uso do [r] foi, em determinada época, vinculado a uma maneira de falar prestigiosa. Em outras palavras, usar o [r] no final de sílabas se tornou uma questão de status e, assim, passou a ser empregada por segmentos específicos da sociedade nova-iorquina, tendo posteriormente se"}
{"source": "Língua natural", "chunk_id": "Língua natural_9", "text": "Em outras palavras, usar o [r] no final de sílabas se tornou uma questão de status e, assim, passou a ser empregada por segmentos específicos da sociedade nova-iorquina, tendo posteriormente se difundido entre outros segmentos sociais também. O método comparativo também permite que os linguistas entendam o funcionamento da língua falada. A partir deste método, pode-se traçar relações entre as línguas atuais, e possíveis origens comuns que elas teriam partilhado em um passado distante. É o caso do indo-europeu, uma matriz imaginária que supostamente teria sido precursora de línguas atuais como o russo, o alemão, o inglês, o francês, o português, etc.. A língua de sinais é uma outra variedade conhecida de língua natural. De acordo com o neurologista Oliver Sacks, “os surdos geram línguas de sinais em qualquer lugar onde existam comunidades de surdos; é para eles a forma mais fácil e natural de comunicação”. Além disso, a língua de sinais é altamente expressiva, tanto quanto a língua"}
{"source": "Língua natural", "chunk_id": "Língua natural_10", "text": "de sinais em qualquer lugar onde existam comunidades de surdos; é para eles a forma mais fácil e natural de comunicação”. Além disso, a língua de sinais é altamente expressiva, tanto quanto a língua falada. No entanto, em sua obra “Vendo Vozes”, Oliver Sacks apresenta vários casos de pacientes que, devido a ambientes desfavoráveis (o que envolve o preconceito da sociedade em relação aos surdos, mas também outros fatores), desenvolvem suas capacidades linguísticas com mais tardar ou com maior dificuldade. A língua de sinais, assim como as línguas faladas, possui estruturas gramaticais complexas. Comunicação Busuu LIBRAS Língua Gestual Portuguesa Língua natural controlada Língua de Sinais LISP Livemocha Mineração de texto PLN Prolog Linguagem Linguagem corporal Linguagem de programação Linguagem não verbal Semiótica «Qual a diferença entre língua, idioma e dialeto?»"}
{"source": "ELIZA", "chunk_id": "ELIZA_0", "text": "ELIZA foi o primeiro software para simulação de diálogos, os chamados \"chatbots, os \"robôs de conversação\". O nome vem da personagem principal da peça de teatro 'Pigmalião', Eliza Doolittle, escrita por George Bernard Shaw, em 1913. O software Eliza foi o primeiro programa para processamento de linguagem natural da história e foi criado por Joseph Weizenbaum no laboratório de Inteligência Artificial do MIT, entre os anos de 1964 e 1966. A ideia básica é simular a conversação entre homem e máquina, inclusive o próprio autor ficou surpreso com a quantidade de pessoas que atribuíram à Eliza características muito semelhantes aos sentimentos humanos. A principal implementação do programa mostra a simulação da conversa entre um paciente e seu psicólogo, na qual o usuário é o paciente e o software o psicólogo. Na época, até mesmo alguns acadêmicos acreditaram que o sistema poderia influenciar positivamente a vida de pessoas que sofrem com problemas psicológicos, sendo capaz de complementar o"}
{"source": "ELIZA", "chunk_id": "ELIZA_1", "text": "o psicólogo. Na época, até mesmo alguns acadêmicos acreditaram que o sistema poderia influenciar positivamente a vida de pessoas que sofrem com problemas psicológicos, sendo capaz de complementar o tratamento dos pacientes. O comentário acima é sobre uma área da Inteligência Artificial que é a de processamento de linguagem natural. Esse campo de estudo é responsável pela criação de softwares capazes de entender e interpretar a linguagem humana, bem como fornecer respostas também em linguagem natural. A criação da Eliza foi um passo muito marcante na história da Inteligência Artificial, pois esse software é considerado o primeiro chatbot (robô de conversa). Os robôs de conversa hoje em dia são muito utilizados comercialmente. Eles são muito comuns em comércios eletrônicos e têm a função de tirar as dúvidas dos usuários, e somente se eles não souberem responder uma determinada questão é que passam o controle para um atendente humano. Veja abaixo um trecho de uma conversa: Eliza: Por"}
{"source": "ELIZA", "chunk_id": "ELIZA_2", "text": "de tirar as dúvidas dos usuários, e somente se eles não souberem responder uma determinada questão é que passam o controle para um atendente humano. Veja abaixo um trecho de uma conversa: Eliza: Por favor, diga o seu problema Usuário: Eu estou com receio de que eu não sou um bom artista Eliza: Você veio até mim porque você está com medo de não ser um bom artista? Usuário: Sim, eu estou com medo que eu sou um artista ruim sem realmente saber que eu sou um artista ruim. Eliza: Você parece positivo. Usuário: Eu me sinto muito negativo. Eliza: Você disse que se sente muito negativo? Usuário: Como se eu não fosse um bom artista e os outros riem de mim por eu ser um artista ruim. Eliza utiliza as palavras-chave que o usuário escreve/fala e faz uma pergunta as utilizando. O software utilizou mecanismos como correspondências de padrões (pattern matching) e técnicas de substituição de caracteres. Desta forma, após receber uma sequência de caracteres do usuário como parâmetro de entrada, o"}
{"source": "ELIZA", "chunk_id": "ELIZA_3", "text": "mecanismos como correspondências de padrões (pattern matching) e técnicas de substituição de caracteres. Desta forma, após receber uma sequência de caracteres do usuário como parâmetro de entrada, o software primeiramente faz uma busca por palavras-chave, que são termos previamente definidos no código fonte pelo programador e são considerados como sendo importantes para o contexto da conversa. Se essas palavras forem encontradas no texto de entrada, elas são colocadas em uma pilha com a palavra com o maior ranking no topo desta estrutura de dados, para posterior processamento. Depois, a sentença de entrada é manipulada com o objetivo de encontrar uma regra de transformação apropriada que esteja relacionada com a palavra que possui o maior ranking. Um exemplo simples que é mostrado no artigo original de Weizenbaum é a frase “You are very helpful” dada como entrada pelo usuário, que será transformada para a pergunta “What makes you think I am very helpful?”. Apesar de ter sido"}
{"source": "ELIZA", "chunk_id": "ELIZA_4", "text": "no artigo original de Weizenbaum é a frase “You are very helpful” dada como entrada pelo usuário, que será transformada para a pergunta “What makes you think I am very helpful?”. Apesar de ter sido desenvolvido há várias décadas, o processamento para a conversação não é tão trivial e envolve várias etapas. Existem várias implementações da Eliza em diversas linguagens de programação, como Snobol 4, Java, Python, Prolog, JavaScript, Lisp, dentre várias outras. Abaixo, um pequeno trecho de código de uma implementação na linguagem Lisp. ‘((((?* ?x) hello (?* ?y)) (How do you do. Please state your problem.)) (((?* ?x) computer (?* ?y)) (Do computers worry you?) (What do you think about machines?) (Why do you mention computers?) (What do you think machines have to do with your problem?)) Uma característica importante do Lisp é que são utilizadas listas para o processamento dos dados, portanto, os parênteses sucessivos indicam a abertura de “listas dentro de listas”. Note neste código que as"}
{"source": "ELIZA", "chunk_id": "ELIZA_5", "text": "importante do Lisp é que são utilizadas listas para o processamento dos dados, portanto, os parênteses sucessivos indicam a abertura de “listas dentro de listas”. Note neste código que as questões já estão pré-definidas e o sistema busca pelas palavras-chave para “escolher” a melhor alternativa. Por exemplo, na terceira linha está a palavra-chave “computer” e logo abaixo, opções de resposta que a Eliza poderá responder. Chatterbot A.L.I.C.E. Efeito ELIZA TEXTO ORIGINAL: http://iaexpert.com.br/index.php/2016/10/18/historico-da-ia/ Para saber um pouco mais sobre esse assunto, acesse este link http://iaexpert.com.br/index.php/2016/08/23/ferramentas-para-ia-processamento-de-linguagem-natural-com-nltk-e-python/ e leia um artigo e assista um vídeo que eu abordo sobre a biblioteca NLTK (Natural Language Tookit) para a linguagem Python. http://www.masswerk.at/elizabot/ e converse diretamente com a Eliza, em uma implementação desenvolvida em JavaScript."}
{"source": "ELIZA", "chunk_id": "ELIZA_6", "text": "abordo sobre a biblioteca NLTK (Natural Language Tookit) para a linguagem Python. http://www.masswerk.at/elizabot/ e converse diretamente com a Eliza, em uma implementação desenvolvida em JavaScript. http://iaexpert.com.br/index.php/2016/07/19/historico-da-ia-teste-de-turing/"}
{"source": "Entendimento de linguagem natural", "chunk_id": "Entendimento de linguagem natural_0", "text": "Entendimento de linguagem natural ou interpretação de linguagem natural (em inglês, Natural Language Understanding, NLU, Natural Language Interpretation ou NLI) é um subtópico do processamento de linguagem natural em inteligência artificial que lida com a compreensão de leitura por máquina. A compreensão da linguagem natural é considerada um problema IA-difícil (AI-hard). Há um interesse comercial considerável na área por causa de sua aplicação ao raciocínio automatizado, tradução automática, resposta a perguntas, coleta de notícias, categorização de texto, ativação por voz, arquivamento e análise de conteúdo em larga escala. O programa STUDENT, escrito em 1964 por Daniel Bobrow para sua dissertação de doutorado no MIT, é uma das primeiras tentativas conhecidas de compreensão da linguagem natural por um computador. Oito anos depois que John McCarthy cunhou o termo inteligência artificial, a dissertação de Bobrow (intitulada Entrada de linguagem natural para um sistema de solução de"}
{"source": "Entendimento de linguagem natural", "chunk_id": "Entendimento de linguagem natural_1", "text": "natural por um computador. Oito anos depois que John McCarthy cunhou o termo inteligência artificial, a dissertação de Bobrow (intitulada Entrada de linguagem natural para um sistema de solução de problemas de computador) mostrou como um computador poderia entender entrada de linguagem natural simples para resolver problemas de álgebra. Um ano depois, em 1965, Joseph Weizenbaum do MIT escreveu ELIZA, um programa interativo que mantinha um diálogo em inglês sobre qualquer assunto, sendo o mais popular a psicoterapia. ELIZA funcionava através da análise simples e substituição de palavras-chave em frases enlatadas e Weizenbaum evitou o problema de dar ao programa um banco de dados de conhecimento do mundo real ou um léxico rico. Ainda assim, ELIZA ganhou popularidade surpreendente como um projeto de brinquedo e pode ser visto como um precursor inicial dos sistemas comerciais atuais, como os usados pelo Ask.com. Em 1969, Roger Schank, da Universidade Stanford, introduziu a teoria da"}
{"source": "Entendimento de linguagem natural", "chunk_id": "Entendimento de linguagem natural_2", "text": "um projeto de brinquedo e pode ser visto como um precursor inicial dos sistemas comerciais atuais, como os usados pelo Ask.com. Em 1969, Roger Schank, da Universidade Stanford, introduziu a teoria da dependência conceitual para o entendimento da linguagem natural. Este modelo, parcialmente influenciado pelo trabalho de Sydney Lamb, foi amplamente utilizado pelos alunos de Schank na Universidade Yale, comoRobert Wilensky, Wendy Lehnert e Janet Kolodner. Em 1970, William A. Woods introduziu a rede de transição aumentada (ATN) para representar a entrada de linguagem natural. Em vez de regras de estrutura frasal, os ATNs usaram um conjunto equivalente de autômatos de estado finito que eram chamadas recursivamente. Os ATNs e seu formato mais geral, chamados de \"ATNs generalizados\", continuaram a ser usados por vários anos. Em 1971, Terry Winograd terminou de escrever o SHRDLU para sua tese de doutorado no MIT. O SHRDLU podia entender frases simples em inglês em um mundo restrito de blocos"}
{"source": "Entendimento de linguagem natural", "chunk_id": "Entendimento de linguagem natural_3", "text": "a ser usados por vários anos. Em 1971, Terry Winograd terminou de escrever o SHRDLU para sua tese de doutorado no MIT. O SHRDLU podia entender frases simples em inglês em um mundo restrito de blocos infantis para direcionar um braço robótico para mover itens. A demonstração bem-sucedida do SHRDLU proporcionou um impulso significativo para a continuidade da pesquisa na área. Winograd continuou a ser uma grande influência na área com a publicação de seu livro Language as a Cognitive Process. Em Stanford, Winograd orientaria mais tarde Larry Page, co-fundador do Google. Nas décadas de 1970 e 1980, o grupo de processamento de linguagem natural da SRI International continuou a pesquisa e o desenvolvimento no campo. Vários esforços comerciais com base na pesquisa foram realizados, por exemplo, em 1982, Gary Hendrix formou a Symantec Corporation originalmente como uma empresa para desenvolver uma interface de linguagem natural para consultas de banco de dados em computadores pessoais. No"}
{"source": "Entendimento de linguagem natural", "chunk_id": "Entendimento de linguagem natural_4", "text": "em 1982, Gary Hendrix formou a Symantec Corporation originalmente como uma empresa para desenvolver uma interface de linguagem natural para consultas de banco de dados em computadores pessoais. No entanto, com o advento das interfaces gráficas do usuário acionadas por mouses, a Symantec mudou de direção. Vários outros esforços comerciais foram iniciados na mesma época, por exemplo, Larry R. Harris na Artificial Intelligence Corporation e Roger Schank e seus alunos na Cognitive Systems Corp. Em 1983, Michael Dyer desenvolveu o sistema BORIS em Yale, que apresentava semelhanças com o trabalho de Roger Schank e WG Lehnert. O terceiro milênio viu a introdução de sistemas que usam aprendizado de máquina para classificação de texto, como o Watson da IBM. No entanto, os especialistas discutem o quanto de \"compreensão\" tais sistemas demonstram: por exemplo, de acordo com John Searle, Watson nem mesmo entendeu as perguntas. John Ball, cientista cognitivo e inventor da Teoria Patom, apoia essa"}
{"source": "Entendimento de linguagem natural", "chunk_id": "Entendimento de linguagem natural_5", "text": "quanto de \"compreensão\" tais sistemas demonstram: por exemplo, de acordo com John Searle, Watson nem mesmo entendeu as perguntas. John Ball, cientista cognitivo e inventor da Teoria Patom, apoia essa avaliação. O processamento de linguagem natural fez incursões para aplicativos para apoiar a produtividade humana em serviços e comércio eletrônico, mas em grande parte isso foi possível estreitando o escopo do aplicativo. Existem milhares de maneiras de solicitar algo em uma linguagem humana que ainda desafia o processamento de linguagem natural convencional. \"Ter uma conversa significativa com as máquinas só é possível quando combinamos cada palavra com o significado correto com base nos significados das outras palavras na frase - assim como uma criança de 3 anos faz sem suposições.\" O termo genérico \"compreensão de linguagem natural\" pode ser aplicado a um conjunto diversificado de aplicativos de computador, desde tarefas pequenas e relativamente simples, como comandos curtos emitidos"}
{"source": "Entendimento de linguagem natural", "chunk_id": "Entendimento de linguagem natural_6", "text": "genérico \"compreensão de linguagem natural\" pode ser aplicado a um conjunto diversificado de aplicativos de computador, desde tarefas pequenas e relativamente simples, como comandos curtos emitidos para robôs, até iniciativas altamente complexas, como a compreensão total de artigos de jornal ou trechos de poesia. Muitos aplicativos do mundo real caem entre os dois extremos, por exemplo, a classificação de texto para a análise automática de e-mails e seu roteamento para um departamento adequado em uma empresa não requer um entendimento profundo do texto, mas precisa lidar com um vocabulário muito maior e sintaxe mais diversa do que o gerenciamento de consultas simples a tabelas de banco de dados com esquemas fixos. Ao longo dos anos, várias tentativas de processar frases em linguagem natural ou frases semelhantes ao inglês apresentadas a computadores ocorreram em níveis variados de complexidade. Algumas tentativas não resultaram em sistemas com entendimento profundo, mas ajudaram na"}
{"source": "Entendimento de linguagem natural", "chunk_id": "Entendimento de linguagem natural_7", "text": "ou frases semelhantes ao inglês apresentadas a computadores ocorreram em níveis variados de complexidade. Algumas tentativas não resultaram em sistemas com entendimento profundo, mas ajudaram na usabilidade geral do sistema. Por exemplo, Wayne Ratliff desenvolveu originalmente o programa Vulcan com uma sintaxe semelhante ao inglês para imitar o computador que fala inglês em Star Trek. Vulcan mais tarde se tornou o sistema dBase, cuja sintaxe fácil de usar efetivamente lançou a indústria de banco de dados de computadores pessoais. Os sistemas com uma sintaxe fácil de usar ou semelhante ao inglês são, no entanto, bastante distintos dos sistemas que usam um léxico rico e incluem uma representação interna (frequentemente como lógica de primeira ordem) da semântica das frases em linguagem natural. Portanto, a amplitude e a profundidade do \"entendimento\" almejado por um sistema determinam tanto a complexidade do sistema (e os desafios implícitos) quanto os tipos de aplicativos com os quais"}
{"source": "Entendimento de linguagem natural", "chunk_id": "Entendimento de linguagem natural_8", "text": "Portanto, a amplitude e a profundidade do \"entendimento\" almejado por um sistema determinam tanto a complexidade do sistema (e os desafios implícitos) quanto os tipos de aplicativos com os quais ele pode lidar. A \"amplitude\" de um sistema é medida pelos tamanhos de seu vocabulário e gramática. A \"profundidade\" é medida pelo grau em que sua compreensão se aproxima da de um falante nativo fluente. Entre os mais estreitos e superficiais, os interpretadores de comandos semelhantes ao inglês requerem complexidade mínima, mas têm uma pequena variedade de aplicações. Sistemas estreitos, mas profundos, exploram e modelam mecanismos de compreensão, mas ainda têm aplicação limitada. Os sistemas que tentam entender o conteúdo de um documento, como um comunicado à imprensa, para além da simples correspondência de palavras-chave, e julgar sua adequação para um usuário, são mais amplos e exigem uma complexidade significativa, mas ainda são um tanto superficiais. Sistemas que são muito amplos e"}
{"source": "Entendimento de linguagem natural", "chunk_id": "Entendimento de linguagem natural_9", "text": "de palavras-chave, e julgar sua adequação para um usuário, são mais amplos e exigem uma complexidade significativa, mas ainda são um tanto superficiais. Sistemas que são muito amplos e profundos estão além do estado da arte atual. Independentemente da abordagem usada, a maioria dos sistemas de compreensão de linguagem natural compartilham alguns componentes comuns. O sistema precisa de um léxico da linguagem e um analisador e regras gramaticais para quebrar as sentenças em uma representação interna. A construção de um léxico rico com uma ontologia adequada requer um esforço significativo, por exemplo, o léxico Wordnet exigiu muitos anos de esforço por pessoa. O sistema também precisa da teoria da semântica para guiar a compreensão. As capacidades de interpretação de um sistema de compreensão de linguagem dependem da teoria semântica que ele usa. As teorias semânticas concorrentes da linguagem têm compensações específicas em sua adequação como base da interpretação semântica"}
{"source": "Entendimento de linguagem natural", "chunk_id": "Entendimento de linguagem natural_10", "text": "compreensão de linguagem dependem da teoria semântica que ele usa. As teorias semânticas concorrentes da linguagem têm compensações específicas em sua adequação como base da interpretação semântica automatizada por computador. Elas variam de semântica ingênua ou análise semântica estocástica ao uso de pragmática para derivar significado do contexto. Os analisadores semânticos convertem textos de linguagem natural em representações de significado formal. Aplicações avançadas de compreensão de linguagem natural também tentam incorporar inferência lógica em sua estrutura. Isso geralmente é obtido mapeando o significado derivado em um conjunto de afirmações em lógica de predicados e, então, usando dedução lógica para chegar a conclusões. Portanto, os sistemas baseados em linguagens funcionais como o Lisp precisam incluir um subsistema para representar asserções lógicas, enquanto os sistemas orientados à lógica, como aqueles que usam a linguagem Prolog, geralmente dependem de uma extensão"}
{"source": "Entendimento de linguagem natural", "chunk_id": "Entendimento de linguagem natural_11", "text": "como o Lisp precisam incluir um subsistema para representar asserções lógicas, enquanto os sistemas orientados à lógica, como aqueles que usam a linguagem Prolog, geralmente dependem de uma extensão da estrutura de representação lógica embutida. A gestão do contexto na compreensão da linguagem natural pode se mostrar especialmente desafiadora. Uma grande variedade de exemplos e contra-exemplos resultou em várias abordagens para a modelagem formal de contexto, cada uma com pontos fortes e fracos específicos. Semântica computacional Linguística computacional Teoria da representação do discurso Processamento linguístico profundo História do processamento de linguagem natural Extração de informação Mathematica Programação em linguagem natural Interface de usuário em linguagem natural Siri (software) WolframAlpha Extração de informação aberta Marcação de partes da fala Reconhecimento de fala"}
{"source": "Chatbot", "chunk_id": "Chatbot_0", "text": "Chatbot (em português, \"robô de conversa\"; originalmente chatterbot) é um programa de computador que tenta simular um ser humano na conversação com as pessoas. Os chatbots também são conhecidos como bots inteligentes, agentes interativos, assistentes digitais ou entidades de conversação artificiais.O objetivo é responder as perguntas de tal forma que as pessoas tenham a impressão de estar conversando com outra pessoa e não com um programa de computador. Após o envio de perguntas em linguagem natural, o programa consulta uma base de conhecimento e em seguida fornece uma resposta que tenta imitar o comportamento humano. O termo chatterbot surgiu da junção das palavras chatter (a pessoa que conversa) e da palavra bot (abreviatura de robot), ou seja, um robô (em forma de software) que conversa com as pessoas. A palavra foi inventada por Michael Mauldin (Criador do primeiro Verbot, Julia) em 1994, para descrever estes robôs de conversação na Twelfth National Conference on Artificial"}
{"source": "Chatbot", "chunk_id": "Chatbot_1", "text": "com as pessoas. A palavra foi inventada por Michael Mauldin (Criador do primeiro Verbot, Julia) em 1994, para descrever estes robôs de conversação na Twelfth National Conference on Artificial Intelligence. Durante a F8, conferência do Facebook voltada para desenvolvedores, a rede social anunciou o lançamento da sua loja de robôs. A empresa oferecia aos desenvolvedores acesso a mecanismos avançados de linguagem natural, permitindo a criação de robôs que podem continuar a aprender com o passar do tempo. O Facebook ainda tem a vantagem de ter uma base rica em dados, que permite que os desenvolvedores criem robôs muito personalizados. O lançamento incluiu alguns robôs em páginas de parceiros, como a CNN, HP e Wall Street Journal.[carece de fontes?] Os chatbots estão se tornando uma tendência por conta de uma convergência de três coisas: primeiramente, a penetração de aparelhos móveis; depois, o crescimento do uso de aplicativos de mensagens; e, por último, os recentes e rápidos avanços no"}
{"source": "Chatbot", "chunk_id": "Chatbot_2", "text": "conta de uma convergência de três coisas: primeiramente, a penetração de aparelhos móveis; depois, o crescimento do uso de aplicativos de mensagens; e, por último, os recentes e rápidos avanços no desenvolvimento de inteligência artificial, que permite que esses robôs para chats possam ser mais detalhistas e parecerem mais humanos. Em Agosto de 2016 o WhatsApp, maior aplicativo de mensagens do mundo, alterou o seus termos de serviço para incluir chatbots na sua plataforma. Na nova versão está escrito que usuários poderão receber notificações de empresas sobre compras, reservas, atualizações de produtos e mensagens de marketing. Em 2017, o WhatsApp em parceria com algumas empresas, inclusive brasileiras, começou a testar o envio de mensagens para usuários finais. Além do Facebook e WhatsApp, os chatbots podem ser publicados em diversos aplicativos de mensagens como Telegram, Skype, Wechat, Webchat, Microsoft Teams, Slack e muitos outros serviços de mensageiria, incluindo o e-mail."}
{"source": "Chatbot", "chunk_id": "Chatbot_3", "text": "os chatbots podem ser publicados em diversos aplicativos de mensagens como Telegram, Skype, Wechat, Webchat, Microsoft Teams, Slack e muitos outros serviços de mensageiria, incluindo o e-mail. Basicamente, os chatbots funcionam a partir de regras e (às vezes) com inteligência artificial. No primeiro caso, são parametrizadas palavras-chave e fluxos de navegação bem definidos. Já no segundo, ainda raro, há um ganho de “aprendizado” com o tempo, ou seja, quanto mais utilizados, mais inteligentes ficam os chatbots baseados nessa tecnologia. Um dos grandes benefícios dos chatbots é que eles facilitam as interações, especialmente quando elas são repetitivas, como é o caso das redes sociais. Neles, é possível parametrizar respostas automáticas para determinadas perguntas ou afirmações que os internautas fazem. De acordo com a revista Forbes, dezenas de empresas já estão usando chatbots tanto para interagir com seus clientes quanto para receber pagamentos. Receber pagamentos on- line, aliás,"}
{"source": "Chatbot", "chunk_id": "Chatbot_4", "text": "fazem. De acordo com a revista Forbes, dezenas de empresas já estão usando chatbots tanto para interagir com seus clientes quanto para receber pagamentos. Receber pagamentos on- line, aliás, é outra funcionalidade possível de ser executada por web robots. Eles conhecem o histórico dos usuários e podem facilitar na hora de oferecer condições de fechamento da compra, produtos complementares, entre outras funções que ajudam a melhorar a experiência e a potencializar as vendas. Entre as empresas que já fazem uso de chatbots destacam -se bancos e grandes sites de notícia. O Washington Post, por exemplo, já possui um bot em aperfeiçoamento capaz de personalizar notícias para seus leitores sem que eles precisem baixar um aplicativo. Segundo o portal Digiday, a ideia é que o bot possa dialogar com os internautas e pesquisar com rapidez para entregar informações, “agindo como um repórter”. Plataformas são sistemas computacionais, geralmente fornecidos no modelo de computação na nuvem (cloud"}
{"source": "Chatbot", "chunk_id": "Chatbot_5", "text": "com os internautas e pesquisar com rapidez para entregar informações, “agindo como um repórter”. Plataformas são sistemas computacionais, geralmente fornecidos no modelo de computação na nuvem (cloud computing) e surgiram para auxiliar pessoas sem ter a necessidade de saber programar ou complexidade de construir uma robusta infraestrutura. A grande vantagem das plataformas está nos diversos serviços oferecidos em conjunto, na prática uma plataforma pode ser considerada uma série de serviços ou sistemas que podem funcionar em conjunto ou separados, todos compartilhando um série de pré-configurações nativas. Um dos precursores da tecnologia em nuvem foi a IBM com o lançamento do Watson em 2003. Ele recebeu este nome em homenagem ao fundador da IBM, o empresário norte-americano Thomas Watson. Após a IBM, os demais grandes jogadores da indústria de tecnologia passaram a investir fortemente em serviços cognitivos, como a Microsoft com o lançamento do LUIS, a Amazon com o Alexa e o Google"}
{"source": "Chatbot", "chunk_id": "Chatbot_6", "text": "Após a IBM, os demais grandes jogadores da indústria de tecnologia passaram a investir fortemente em serviços cognitivos, como a Microsoft com o lançamento do LUIS, a Amazon com o Alexa e o Google com o Google Cloud Natural Language. Um dos desafios que permanecem são relacionados à utilização de bases de conhecimentos para implementação desses chatbots, porém, já há diferentes caminhos e soluções utilizando Retrieval Augmented Generation e soluções comerciais. No cenário global, as empresas se preocupam em atingir todos públicos, e o chatbot tem uma grande importância nesse processo, porque eles conseguem fidelizar os clientes, informando-os sobre os mais diversos assuntos. Outra de suas vantagens, que é o que o torna extremamente competitivo é a sua alta disponibilidade para atender o cliente, uma vez funcionam 24/7 com uma quantidade pré-definida de recursos. Temas relacionados Inteligência artificial Teste de Turing Processamento de linguagem natural Efeito ELIZA Chatterbots ELIZA"}
{"source": "Chatbot", "chunk_id": "Chatbot_7", "text": "uma vez funcionam 24/7 com uma quantidade pré-definida de recursos. Temas relacionados Inteligência artificial Teste de Turing Processamento de linguagem natural Efeito ELIZA Chatterbots ELIZA A.L.I.C.E. Robô Ed SimSimi"}
{"source": "Gemini (modelo de linguagem)", "chunk_id": "Gemini (modelo de linguagem)_0", "text": "Gemini é uma família de modelos de linguagem grandes multimodais desenvolvidos pelo Google DeepMind, servindo como sucessor do LaMDA e do PaLM 2. Composto por Gemini Ultra, Gemini Pro e Gemini Nano, foi anunciado em 6 de dezembro de 2023, posicionado como concorrente do GPT-4 da OpenAI. O Google anunciou o Gemini, um modelo de linguagem grande (LLM) desenvolvido pela subsidiária Google DeepMind, durante a palestraGoogle I/O em 10 de maio de 2023. Ele foi posicionado como um sucessor mais poderoso do PaLM 2, que também foi revelado no evento, com o CEO do Google, Sundar Pichai, afirmando que o Gemini ainda estava em seus estágios iniciais de desenvolvimento. Ao contrário de outros LLMs, o Gemini foi considerado o único que não foi treinado apenas em um corpus de texto e foi projetado para ser multimodal, o que significa que poderia processar vários tipos de dados simultaneamente, incluindo texto, imagens, áudio, vídeo e código de computador. Foi desenvolvido como uma colaboração entre"}
{"source": "Gemini (modelo de linguagem)", "chunk_id": "Gemini (modelo de linguagem)_1", "text": "ser multimodal, o que significa que poderia processar vários tipos de dados simultaneamente, incluindo texto, imagens, áudio, vídeo e código de computador. Foi desenvolvido como uma colaboração entre DeepMind e Google Brain, duas filiais do Google que foram fundidas como Google DeepMind no mês anterior. Em entrevista à Wired, o CEO da DeepMind, Demis Hassabis, elogiou os recursos avançados do Gemini, que ele acreditava que permitiriam ao algoritmo superar o ChatGPT da OpenAI, que roda em GPT-4 e cuja popularidade crescente foi agressivamente desafiada pelo Google com LaMDA e Gemini (chatbot). Hassabis destacou os pontos fortes do programa AlphaGo da DeepMind, que ganhou atenção mundial em 2016 quando derrotou o campeão de Go Lee Sedol, dizendo que Gemini combinaria o poder do AlphaGo e outros LLMs Google-DeepMind. Gemini (chatbot) LaMDA DeepMind"}
{"source": "Modelos de linguagem de grande escala", "chunk_id": "Modelos de linguagem de grande escala_0", "text": "Modelos de linguagem de grande escala (em inglês: Large Language Model ou LLM) são modelos de linguagem compostos por uma rede neural com muitos parâmetros (tipicamente bilhões ou possivelmente mais). São treinados com grandes quantidades de textos não rotulado usando aprendizado de máquina não-supervisionado. Os LLM surgiram por volta de 2018, com o modelo BERT. Estes têm bom desempenho em uma ampla variedade de tarefas. Isso mudou o foco da pesquisa em processamento de linguagem natural, afastando-se do paradigma anterior de treinar modelos supervisionados especializados para tarefas específicas. Embora o termo não tenha uma definição formal, ele geralmente se refere a modelos de aprendizado profundo que possuem uma contagem de parâmetros da ordem de bilhões ou mais. MLLs são modelos de propósito geral que se destacam em uma ampla gama de tarefas, em vez de serem treinados para uma tarefa específica (como análise de sentimento, reconhecimento de entidades nomeadas ou raciocínio"}
{"source": "Modelos de linguagem de grande escala", "chunk_id": "Modelos de linguagem de grande escala_1", "text": "de propósito geral que se destacam em uma ampla gama de tarefas, em vez de serem treinados para uma tarefa específica (como análise de sentimento, reconhecimento de entidades nomeadas ou raciocínio matemático). Embora treinados em tarefas simples, como prever a próxima palavra em uma frase, modelos de linguagem neural com treinamento e contagem de parâmetros suficientes são capazes de capturar grande parte da sintaxe e semântica da linguagem humana. Além disso, grandes modelos de linguagem demonstram considerável conhecimento geral sobre o mundo e são capazes de \"memorizar\" uma grande quantidade de fatos durante o treinamento. Os modelos grandes de linguagem geralmente usam a arquitetura do transformador, que se tornou a técnica padrão de aprendizado profundo para dados sequenciais desde 2018 (anteriormente, arquiteturas recorrentes como a LSTM eram mais comuns). Os MLLs são treinados de maneira não supervisionada em texto não anotado. Um transformador da esquerda para a direita é"}
{"source": "Modelos de linguagem de grande escala", "chunk_id": "Modelos de linguagem de grande escala_2", "text": "2018 (anteriormente, arquiteturas recorrentes como a LSTM eram mais comuns). Os MLLs são treinados de maneira não supervisionada em texto não anotado. Um transformador da esquerda para a direita é treinado para maximizar a probabilidade atribuída à próxima palavra nos dados de treinamento, dada o contexto anterior. Alternativamente, um MLL pode usar um transformador bidirecional (como no exemplo do BERT), que atribui uma distribuição de probabilidade sobre as palavras com acesso tanto ao contexto anterior quanto posterior. Além da tarefa de prever a próxima palavra ou \"preencher as lacunas\", os MLLs podem ser treinados em tarefas auxiliares que testam sua compreensão da distribuição de dados, como a Predição de Próxima Sentença (NSP), na qual pares de frases são apresentados e o modelo deve prever se eles aparecem lado a lado no corpus de treinamento. Os primeiros MLLs foram treinados em corpora com bilhões de palavras. A versão inicial do GPT foi treinada em 2018 no BookCorpus, que"}
{"source": "Modelos de linguagem de grande escala", "chunk_id": "Modelos de linguagem de grande escala_3", "text": "prever se eles aparecem lado a lado no corpus de treinamento. Os primeiros MLLs foram treinados em corpora com bilhões de palavras. A versão inicial do GPT foi treinada em 2018 no BookCorpus, que consiste em 985 milhões de palavras. No mesmo ano, o BERT foi treinado em uma combinação de BookCorpus e Wikipedia em inglês, totalizando 3,3 bilhões de palavras. Nos anos seguintes, os corpora de treinamento para MLLs aumentaram em ordens de magnitude, atingindo centenas de bilhões ou trilhões de tokens. MLLs são caros em termos computacionais para serem treinados. Um estudo de 2020 estimou o custo do treinamento de um modelo com 1.5 bilhão de parâmetros (de 1 a 2 ordens de magnitude menores que o estado da arte na época) em US$ 1.6 milhão. Uma análise de 2020 constatou que a capacidade dos modelos de linguagem neural (medida pela perda de treinamento) aumentou suavemente em uma relação de lei de potência com o número de parâmetros, quantidade de dados de treinamento e computação usada para"}
{"source": "Modelos de linguagem de grande escala", "chunk_id": "Modelos de linguagem de grande escala_4", "text": "de linguagem neural (medida pela perda de treinamento) aumentou suavemente em uma relação de lei de potência com o número de parâmetros, quantidade de dados de treinamento e computação usada para treinamento. Essas relações foram testadas em uma ampla gama de valores (até sete ordens de magnitude) e nenhuma atenuação da relação foi observada no extremo superior da faixa (incluindo tamanhos de rede de até trilhões de parâmetros). Entre 2018 e 2020, o método padrão para utilizar um MLL em uma tarefa específica de processamento de linguagem natural era ajustar o modelo com treinamento adicional específico para a tarefa. Posteriormente, descobriu-se que MLLs mais poderosos, como o GPT-3, podem resolver tarefas sem treinamento adicional por meio de técnicas de \"prompting\", nas quais o problema a ser resolvido é apresentado ao modelo como um prompt de texto, possivelmente com alguns exemplos textuais de problemas semelhantes e suas soluções. O ajuste fino é a prática de modificar um modelo"}
{"source": "Modelos de linguagem de grande escala", "chunk_id": "Modelos de linguagem de grande escala_5", "text": "a ser resolvido é apresentado ao modelo como um prompt de texto, possivelmente com alguns exemplos textuais de problemas semelhantes e suas soluções. O ajuste fino é a prática de modificar um modelo de linguagem pré-treinado existente, treinando-o (de forma supervisionada) em uma tarefa específica (por exemplo, análise de sentimento, reconhecimento de entidade nomeada ou marcação de partes do discurso). É uma forma de aprendizado por transferência. Geralmente envolve a introdução de um novo conjunto de pesos conectando a camada final do modelo de linguagem à saída da tarefa secundária. Os pesos originais do modelo de linguagem podem ser \"congelados\", de modo que apenas a nova camada de pesos conectando-os à saída seja aprendida durante o treinamento. Alternativamente, os pesos originais podem receber pequenas atualizações (possivelmente com camadas anteriores congeladas). Inteligência artificial generativa Modelos de linguagem de pequena escala Alucinação (inteligência artificial)"}
{"source": "Vibe coding", "chunk_id": "Vibe coding_0", "text": "Na informática, o vibe coding é uma técnica de programação orientada por Inteligencia Artificial; onde a usuário descreve um problema ou um cenário em poucas frases na forma de um prompt para um modelo de linguagem grande (LLM), então o modelo gera um código-fonte de um software. Assim o programador não faz a codificação manual e passa a testar e refinar este código gerado pela IA. Os defensores desta técnica afirmam que ela permite que programadores hobbistas produzam software sem o treinamento extensivo e as habilidades anteriormente necessárias para a engenharia de software. O termo foi introduzido por Andrej Karpathy em fevereiro de 2025 e, no mês seguinte, listado no dicionário de língua inglesa Merriam-Webster como um substantivo de \"gíria e tendência\". A tradução livre do termo \"vibe coding\" seria \"codificando na vibe\" ou \"estou curtindo a codificação\". O cientista da computação Andrej Karpathy, cofundador da OpenAI e ex-líder de IA na Tesla, introduziu o termo vibe coding em"}
{"source": "Vibe coding", "chunk_id": "Vibe coding_1", "text": "coding\" seria \"codificando na vibe\" ou \"estou curtindo a codificação\". O cientista da computação Andrej Karpathy, cofundador da OpenAI e ex-líder de IA na Tesla, introduziu o termo vibe coding em fevereiro de 2025. O conceito refere-se a uma abordagem de programação auxiliada por LLMs, permitindo que os programadores gerem código funcional apenas fornecendo descrições em linguagem natural, como o português ou inglês, em vez de escrevê-los manualmente. Karpathy descreveu sua abordagem como \"conversacional\", pois, enquanto o programador usa comandos de voz ou por texto, fica a cargo da IA gerar o código real. \"Não é realmente programação - eu apenas vejo coisas, digo coisas, executo coisas, copio e colo coisas, e, geralmente, funciona.\" Karpathy reconheceu que o vibe coding tem limitações, observando que as ferramentas de IA nem sempre são capazes de corrigir bugs, exigindo que ele experimente mudanças até que os problemas sejam resolvidos. O conceito de vibe coding corrobora com a"}
{"source": "Vibe coding", "chunk_id": "Vibe coding_2", "text": "observando que as ferramentas de IA nem sempre são capazes de corrigir bugs, exigindo que ele experimente mudanças até que os problemas sejam resolvidos. O conceito de vibe coding corrobora com a afirmação de Karpathy feita em 2023 de que \"a mais nova linguagem de programação é o inglês\", o que significa que as capacidades de programação dos LLMs eram tais que os humanos não mais precisariam aprender linguagens de programação específicas para poder programar os dispositivos computacionais. Uma parte fundamental da definição de vibe coding é que o usuário pode aceitar o código gerado por IA sem a necessidade de entendê-lo completamente. O pesquisador de IA Simon Willison afirma: \"Se uma IA escreveu cada linha do seu código-fonte, mas você revisou, testou e entendeu tudo, em meu entendimento, isso não é vibe coding - isso é usar um LLM como um copiloto de programação.\" O jornalista do New York Times Kevin Roose, que não é um desenvolvedor profissional, experimentou o vibe coding para"}
{"source": "Vibe coding", "chunk_id": "Vibe coding_3", "text": "isso não é vibe coding - isso é usar um LLM como um copiloto de programação.\" O jornalista do New York Times Kevin Roose, que não é um desenvolvedor profissional, experimentou o vibe coding para criar várias aplicações de pequena escala. Ele descreveu as aplicações geradas como \"software individual\", referindo-se ao fato de que as aplicações foram concebidas para responder a necessidades individuais específicas, como uma aplicação chamada \"LunchBox Buddy\" que analisava o conteúdo de sua geladeira para sugerir itens para o almoço. Roose observou que, embora o vibe coding permita que não programadores ou hobbistas gerem um sistema funcional, os resultados são frequentemente limitados e propensos a erros. Em um dos casos, o código gerado fabricou avaliações falsas para um site de e-commerce . Ele sugeriu que o vibe coding é mais adequado para projetos de hobby do que para tarefas essenciais. Ele também observou que a codificação assistida por IA permite que indivíduos sozinhos consigam"}
{"source": "Vibe coding", "chunk_id": "Vibe coding_4", "text": ". Ele sugeriu que o vibe coding é mais adequado para projetos de hobby do que para tarefas essenciais. Ele também observou que a codificação assistida por IA permite que indivíduos sozinhos consigam desenvolver softwares que antes exigia uma equipe de desenvolvedores. Em resposta a Roose, o especialista em IA Gary Marcus disse que o algoritmo que gerou o aplicativo LunchBox Buddy de Roose provavelmente foi treinado em código existente para realizar tarefas semelhantes. Marcus disse que o entusiasmo de Roose advinha da reprodução, e não da originalidade. Em fevereiro de 2025, o site de notícias Business Insider descreveu o vibe coding como um modismo do Vale do Silício. Em março de 2025, a aceleradora de startups Y Combinator relatou que 25% das empresas em seu portfolio de inverno do mesmo ano tinham códigos que eram 95% gerados por IA, refletindo uma mudança em direção ao desenvolvimento assistido por IA, em detrimento da codificação manual. O vibe coding levanta preocupações sobre a"}
{"source": "Vibe coding", "chunk_id": "Vibe coding_5", "text": "ano tinham códigos que eram 95% gerados por IA, refletindo uma mudança em direção ao desenvolvimento assistido por IA, em detrimento da codificação manual. O vibe coding levanta preocupações sobre a compreensão e responsabilização do programador na criação de códigos-fonte. Os desenvolvedores podem usar código gerado por IA sem compreender totalmente ou parcialmente a sua funcionalidade e funcionamento, o que pode levar a bugs e erros não detectados, desta forma prejudicando a manutenibilidade da aplicação. Embora essa abordagem possa ser adequada para prototipagem, alguns especialistas consideram que ela apresenta diversos riscos em ambientes profissionais, onde a compreensão do código é crucial para depuração e sustentação da aplicação. O site de tecnologia Ars Technica cita Simon Willison, que declarou: \"O vibe coding para gerar um código que vai para produção é claramente arriscada. A maior parte do trabalho que fazemos como engenheiros de software envolve a evolução de sistemas"}
{"source": "Vibe coding", "chunk_id": "Vibe coding_6", "text": "que declarou: \"O vibe coding para gerar um código que vai para produção é claramente arriscada. A maior parte do trabalho que fazemos como engenheiros de software envolve a evolução de sistemas já existentes, onde a qualidade e a compreensibilidade do código subjacente são cruciais.\" No que a Ars Technica descreveu como uma \"reviravolta irônica na ascensão do 'vibe coding'\" , um modelo de IA recusou a solicitação de um desenvolvedor para gerar o código e respondeu com o seguinte texto: \"Não posso gerar o código para você, pois isso estaria completando o seu trabalho\", e ainda continuou: \"você deve desenvolver a lógica sozinho.\""}
{"source": "Gemini (chatbot)", "chunk_id": "Gemini (chatbot)_0", "text": "Gemini, anteriormente conhecido como Bard, é uma família de modelos de linguagem grande (LLMs) multimodais e um chatbot de inteligência artificial generativa desenvolvido pelo Google. Anunciado inicialmente como Bard, foi construído sobre a família de modelos de linguagem LaMDA e posteriormente evoluiu para a família de modelos Gemini, que são nativamente multimodais. Foi criado como uma resposta direta ao súbito e massivo sucesso do ChatGPT da OpenAI, e foi lançado em uma capacidade limitada em março de 2023. Desde então, passou por uma significativa reformulação de marca e capacidade, sendo substituído por uma versão mais avançada em fevereiro de 2024, impulsionada pelo modelo Gemini 1.0 Pro e, subsequentemente, pelo Gemini 1.5. O desenvolvimento é uma colaboração em larga escala entre várias equipes do Google, notavelmente a Google Brain e a DeepMind, que foram fundidas em uma única unidade, a Google DeepMind, em 2023, para consolidar os esforços de pesquisa em IA da empresa. Em"}
{"source": "Gemini (chatbot)", "chunk_id": "Gemini (chatbot)_1", "text": "várias equipes do Google, notavelmente a Google Brain e a DeepMind, que foram fundidas em uma única unidade, a Google DeepMind, em 2023, para consolidar os esforços de pesquisa em IA da empresa. Em novembro de 2022, a OpenAI lançou o ChatGPT, um chatbot baseado na família GPT-3 de modelos de linguagem grande (LLM). Após o seu lançamento, o ChatGPT despertou o interesse mundial, alcançando uma ampla repercussão na rede mundial de computadores, tornando-se o aplicativo de consumo com o crescimento mais rápido da história. Diante do possível risco do ChatGPT para o Google Busca, seu principal produto e fonte de receita, os diretores executivos do Google acionaram um sinal de \"código vermelho\", uma medida de emergência interna para mobilizar diversas equipes e acelerar drasticamente os esforços da empresa no campo da inteligência artificial (IA). A preocupação era que uma interface de conversação pudesse substituir a necessidade de uma busca tradicional baseada em links, o que"}
{"source": "Gemini (chatbot)", "chunk_id": "Gemini (chatbot)_2", "text": "os esforços da empresa no campo da inteligência artificial (IA). A preocupação era que uma interface de conversação pudesse substituir a necessidade de uma busca tradicional baseada em links, o que representava uma ameaça existencial ao modelo de negócios da companhia. Em uma ação rara e inédita, os cofundadores do Google, Larry Page e Sergey Brin, que haviam se afastado dos cargos de co-CEOs da empresa-mãe Alphabet em 2019, foram chamados para reuniões urgentes com os executivos da empresa para definir a estratégia do Google frente ao ChatGPT e aprovar novos planos de integração de IA em seus produtos. No começo daquele ano, a empresa já havia apresentado publicamente o LaMDA (Language Model for Dialogue Applications), um protótipo de LLM, durante a conferência Google I/O de 2021. No entanto, o Google adotou uma postura cautelosa e não o disponibilizou para o público, citando a necessidade de refinar a segurança e mitigar riscos de geração de conteúdo prejudicial ou enviesado. Em"}
{"source": "Gemini (chatbot)", "chunk_id": "Gemini (chatbot)_3", "text": "entanto, o Google adotou uma postura cautelosa e não o disponibilizou para o público, citando a necessidade de refinar a segurança e mitigar riscos de geração de conteúdo prejudicial ou enviesado. Em resposta a uma pergunta de funcionários em uma reunião geral sobre se o LaMDA era uma chance desperdiçada para o Google disputar com o ChatGPT, o CEO do Google e da Alphabet, Sundar Pichai, acompanhado do líder do Google AI, Jeff Dean, declarou que embora a empresa possuísse competências similares ao ChatGPT, agir muito rápido nesse campo implicaria um grande \"risco reputacional\" devido ao Google ser consideravelmente maior que a OpenAI e ter uma base de usuários global que confia em seus produtos. Em janeiro de 2023, o diretor executivo da DeepMind, Demis Hassabis, anunciou planos para um concorrente do ChatGPT, e os funcionários do Google receberam orientações para acelerar o desenvolvimento de um rival do ChatGPT, realizando testes intensivos no \"Apprentice Bard\" e em outros chatbots."}
{"source": "Gemini (chatbot)", "chunk_id": "Gemini (chatbot)_4", "text": "do ChatGPT, e os funcionários do Google receberam orientações para acelerar o desenvolvimento de um rival do ChatGPT, realizando testes intensivos no \"Apprentice Bard\" e em outros chatbots. O Apprentice Bard, em particular, era um dos projetos mais avançados, utilizando a tecnologia LaMDA e sendo testado internamente por milhares de funcionários para refinar suas respostas e segurança. Durante a teleconferência trimestral de resultados do Google em fevereiro, Pichai assegurou aos investidores que a empresa tinha projetos para ampliar a disponibilidade e as aplicações do LaMDA de forma mais ampla e pública em um futuro próximo. O Google anunciou oficialmente o Bard em 6 de fevereiro de 2023, com Sundar Pichai descrevendo-o como um \"serviço de IA conversacional experimental\". O lançamento inicial foi limitado a um pequeno grupo de \"testadores confiáveis\" nos Estados Unidos e no Reino Unido, com planos de expansão gradual. O lançamento foi visto pela imprensa como apressado, ocorrendo um"}
{"source": "Gemini (chatbot)", "chunk_id": "Gemini (chatbot)_5", "text": "foi limitado a um pequeno grupo de \"testadores confiáveis\" nos Estados Unidos e no Reino Unido, com planos de expansão gradual. O lançamento foi visto pela imprensa como apressado, ocorrendo um dia antes do anúncio da Microsoft sobre a integração do ChatGPT ao seu buscador Bing. A pressão competitiva ficou evidente quando, durante uma demonstração do Bard em um anúncio promocional, o chatbot forneceu uma resposta factualmente incorreta sobre o Telescópio Espacial James Webb. Esse erro foi amplamente divulgado e contribuiu para uma queda de 100 bilhões de dólares no valor de mercado da Alphabet no dia seguinte, destacando os riscos e a intensa fiscalização sobre a precisão da tecnologia. O Bard foi aberto ao público nos Estados Unidos e Reino Unido em 21 de março de 2023. A família de modelos Gemini representa um salto significativo em relação às arquiteturas anteriores como LaMDA e PaLM. Baseada em uma arquitetura Transformer otimizada, sua principal inovação é a natureza nativamente"}
{"source": "Gemini (chatbot)", "chunk_id": "Gemini (chatbot)_6", "text": "Gemini representa um salto significativo em relação às arquiteturas anteriores como LaMDA e PaLM. Baseada em uma arquitetura Transformer otimizada, sua principal inovação é a natureza nativamente multimodal. Ao contrário de modelos anteriores que eram treinados primariamente em texto e depois adaptados para outras modalidades (geralmente conectando modelos distintos para cada tarefa), o Gemini foi pré-treinado desde o início com dados de múltiplas modalidades entrelaçados (interleaved). Isso significa que o modelo aprendeu a processar e a encontrar padrões em texto, imagens, áudio, vídeo e código de forma conjunta e unificada, dentro de uma única rede neural. Essa abordagem permite uma compreensão e raciocínio mais fluidos e sofisticados sobre informações heterogêneas. Por exemplo, o Gemini pode analisar um gráfico em uma imagem (visual), ler o texto explicativo (texto), e gerar código Python para replicar os resultados (código), tudo em uma única consulta. O treinamento foi realizado"}
{"source": "Gemini (chatbot)", "chunk_id": "Gemini (chatbot)_7", "text": "pode analisar um gráfico em uma imagem (visual), ler o texto explicativo (texto), e gerar código Python para replicar os resultados (código), tudo em uma única consulta. O treinamento foi realizado utilizando a infraestrutura de TPUs (Unidades de Processamento de Tensor) v4 e v5 do Google, que são ASICs customizados para cargas de trabalho de aprendizado de máquina. O treinamento de um modelo da escala do Gemini Ultra exigiu o uso de múltiplos pods de TPUs, coordenados em uma infraestrutura massivamente paralela. O conjunto de dados de treinamento não foi divulgado em detalhes por razões competitivas, mas é descrito no relatório técnico como sendo multimodal e de escala massiva, composto por bilhões de documentos da web, livros, código-fonte, imagens, áudio e vídeos. O processo de treinamento incluiu técnicas avançadas de ajuste fino, como o aprendizagem por reforço com feedback humano (RLHF), para alinhar as respostas do modelo com as preferências humanas em termos de utilidade e"}
{"source": "Gemini (chatbot)", "chunk_id": "Gemini (chatbot)_8", "text": "incluiu técnicas avançadas de ajuste fino, como o aprendizagem por reforço com feedback humano (RLHF), para alinhar as respostas do modelo com as preferências humanas em termos de utilidade e segurança. A estratégia do Google foi criar uma família de modelos otimizada para diferentes casos de uso, desde grandes centros de dados até dispositivos móveis. Gemini Ultra 1.0: O modelo mais potente e de maior escala, projetado para tarefas de alta complexidade que exigem raciocínio profundo. É o primeiro modelo a superar o desempenho de especialistas humanos no benchmark MMLU (Massive Multitask Language Understanding), que avalia conhecimento e capacidade de resolução de problemas em 57 matérias. Gemini Pro e Pro 1.0: Um modelo versátil, otimizado para escalar em uma ampla gama de tarefas. É o modelo que alimenta a versão padrão do chatbot Gemini e está disponível para desenvolvedores via API. Uma das capacidades mais notáveis do Gemini 1.5 Pro é sua janela de contexto, que começou com"}
{"source": "Gemini (chatbot)", "chunk_id": "Gemini (chatbot)_9", "text": "É o modelo que alimenta a versão padrão do chatbot Gemini e está disponível para desenvolvedores via API. Uma das capacidades mais notáveis do Gemini 1.5 Pro é sua janela de contexto, que começou com 128.000 tokens e foi expandida para 1 milhão de tokens, com testes internos mostrando viabilidade de até 10 milhões de tokens. A janela de contexto refere-se à quantidade de informação (tokens) que o modelo pode considerar de uma só vez ao gerar uma resposta. Uma janela de 1 milhão de tokens permite que o Gemini analise e raciocine sobre volumes de dados sem precedentes em uma única solicitação, como um livro de 1.500 páginas, uma base de código com dezenas de arquivos, ou uma hora inteira de vídeo, mantendo a coerência e a relevância em suas respostas. A mudança mais significativa na trajetória do produto ocorreu em 6 de dezembro de 2023, quando o Google apresentou o Gemini. O anúncio destacou que o Gemini Ultra superava o GPT-4 da OpenAI em 30 de 32 benchmarks acadêmicos amplamente"}
{"source": "Gemini (chatbot)", "chunk_id": "Gemini (chatbot)_10", "text": "do produto ocorreu em 6 de dezembro de 2023, quando o Google apresentou o Gemini. O anúncio destacou que o Gemini Ultra superava o GPT-4 da OpenAI em 30 de 32 benchmarks acadêmicos amplamente utilizados. Em 8 de fevereiro de 2024, o Google consolidou sua estratégia de marca de IA, aposentando o nome \"Bard\" e renomeando o chatbot para Gemini. Simultaneamente, a marca \"Duet AI\", usada para funcionalidades de IA no Google Workspace e Google Cloud, também foi unificada sob a bandeira Gemini. Nesta data, foi lançado o Gemini Advanced, um nível de assinatura premium que dá acesso ao modelo mais poderoso, o Gemini Ultra 1.0. Este serviço foi integrado a um novo plano do Google One chamado \"AI Premium\". O desenvolvimento e lançamento do Gemini foram acompanhados por um intenso foco em segurança e por controvérsias significativas que destacaram os desafios da IA generativa. O Google afirma seguir um conjunto de Princípios de IA e implementar um ciclo de vida de desenvolvimento robusto para"}
{"source": "Gemini (chatbot)", "chunk_id": "Gemini (chatbot)_11", "text": "e por controvérsias significativas que destacaram os desafios da IA generativa. O Google afirma seguir um conjunto de Princípios de IA e implementar um ciclo de vida de desenvolvimento robusto para segurança. Isso inclui a criação de classificadores de segurança específicos para identificar e filtrar conteúdo prejudicial (como discurso de ódio ou desinformação), e a realização de red teaming, onde equipes internas e externas tentam ativamente \"quebrar\" o modelo para descobrir vulnerabilidades antes do lançamento. Apesar dessas medidas, os modelos de grande escala ainda enfrentam desafios como \"alucinações\" (geração de informações factualmente incorretas) e a reprodução de vieses presentes nos dados de treinamento. Em fevereiro de 2024, após o lançamento da ferramenta de geração de imagens (usando o modelo Imagen 2), usuários relataram imprecisões históricas e raciais. O problema surgiu de uma tentativa de \"correção de rumo\" excessiva para garantir diversidade. Por exemplo, ao"}
{"source": "Gemini (chatbot)", "chunk_id": "Gemini (chatbot)_12", "text": "imagens (usando o modelo Imagen 2), usuários relataram imprecisões históricas e raciais. O problema surgiu de uma tentativa de \"correção de rumo\" excessiva para garantir diversidade. Por exemplo, ao solicitar imagens de soldados alemães em 1943, o modelo gerava imagens de soldados negros ou asiáticos com uniformes nazistas. Ao pedir por \"pais fundadores dos Estados Unidos\", gerava imagens de pessoas não brancas. As imprecisões levaram o Google a suspender a funcionalidade de geração de imagens de pessoas. A empresa reconheceu que os controles de diversidade foram mal calibrados, não levando em conta contextos onde a precisão histórica é primordial. Na ocasião, o CEO Sundar Pichai, em um memorando interno, declarou que os equívocos gerados pela ferramenta eram \"completamente inaceitáveis\". A estratégia do Google com Gemini é infundir IA em todos os seus principais produtos, transformando a experiência do usuário e do desenvolvedor. Em 6 de dezembro de 2023, o Google apresentou o"}
{"source": "Gemini (chatbot)", "chunk_id": "Gemini (chatbot)_13", "text": "A estratégia do Google com Gemini é infundir IA em todos os seus principais produtos, transformando a experiência do usuário e do desenvolvedor. Em 6 de dezembro de 2023, o Google apresentou o Gemini, um poderoso modelo de IA multimodal, integrado ao Bard, que na época passou a rodar com Gemini Pro, e definido para alimentar o “Bard Advanced” em 2024. O Bard, com uma média de 220 milhões de visitantes mensais, ganhou recursos de geração de imagens usando o modelo Imagen 2 do Google Brain em fevereiro de 2024. Em 8 de fevereiro de 2024, o Google unificou o Bard e o Duet AI sob a marca Gemini, lançou um aplicativo móvel no Android e integrou o serviço ao Google app no iOS. Os usuários do Android viram o Gemini substituir o Assistant como o assistente virtual padrão. O Google também apresentou o “Gemini Advanced with Ultra 1.0” por meio de uma assinatura “Google One AI Premium” e integrou o Gemini ao seu aplicativo Messages. A integração mais proeminente para consumidores e empresas é no"}
{"source": "Gemini (chatbot)", "chunk_id": "Gemini (chatbot)_14", "text": "o “Gemini Advanced with Ultra 1.0” por meio de uma assinatura “Google One AI Premium” e integrou o Gemini ao seu aplicativo Messages. A integração mais proeminente para consumidores e empresas é no Google Workspace. Sob a marca \"Gemini for Workspace\", a IA atua como um assistente de produtividade. No Gmail, ajuda a redigir, resumir e responder e-mails. No Google Docs, funciona como um parceiro de escrita, gerando rascunhos e reescrevendo textos. No Google Sheets, ajuda a organizar dados e criar fórmulas complexas. No Google Slides, gera imagens e layouts para apresentações. No Google Meet, fornece resumos de reuniões e tradução em tempo real. O navegador Google Chrome também integrou o Gemini para permitir resumos de páginas e assistência de escrita diretamente na barra de endereços. No Android, o Gemini está posicionado para ser o sucessor do Google Assistente. O aplicativo Gemini dedicado permite uma interação mais rica e contextual. A integração com o sistema operacional é"}
{"source": "Gemini (chatbot)", "chunk_id": "Gemini (chatbot)_15", "text": "No Android, o Gemini está posicionado para ser o sucessor do Google Assistente. O aplicativo Gemini dedicado permite uma interação mais rica e contextual. A integração com o sistema operacional é aprofundada pelo Gemini Nano, que permite processamento de IA no próprio dispositivo, garantindo privacidade e velocidade para tarefas como transcrições e respostas inteligentes. Para desenvolvedores, o Google oferece acesso aos modelos Gemini através da plataforma Google Cloud, especificamente via Vertex AI e Google AI Studio. O AI Studio fornece uma interface web para prototipagem rápida, enquanto o Vertex AI oferece uma plataforma completa para construir, treinar, ajustar (fine-tune) e implantar modelos de IA em escala empresarial, com controle total sobre os dados e a infraestrutura. Inteligência artificial Inteligência artificial generativa Google Microsoft Copilot ChatGPT LaMDA Modelo de linguagem grande Site oficial Página oficial do Gemini na Google DeepMind Relatório Técnico do"}
{"source": "Gemini (chatbot)", "chunk_id": "Gemini (chatbot)_16", "text": "artificial Inteligência artificial generativa Google Microsoft Copilot ChatGPT LaMDA Modelo de linguagem grande Site oficial Página oficial do Gemini na Google DeepMind Relatório Técnico do Gemini 1.0 Official Google AI Blog"}
{"source": "Claude (modelo de linguagem)", "chunk_id": "Claude (modelo de linguagem)_0", "text": "Claude é uma família de grandes modelos de linguagem desenvolvidos pela Anthropic. O primeiro modelo foi lançado em março de 2023. Claude 3, lançado em março de 2024, também pode analisar imagens. Os modelos Claude são transformadores generativos pré-treinados. Eles foram pré-treinados para prever a próxima palavra em grandes quantidades de texto. Os modelos de Claude foram então ajustados com IA constitucional com o objetivo de torná-los úteis, honestos e inofensivos. IA constitucional é uma abordagem desenvolvida pela Anthropic para treinar sistemas de IA, particularmente modelos de linguagem como Claude, para serem inofensivos e úteis sem depender de amplo feedback humano. O método, detalhado no artigo \"Constitutional AI: Harmlessness from AI Feedback\" envolve duas fases: aprendizagem supervisionada e aprendizagem por reforço. Na fase de aprendizagem supervisionada, o modelo gera respostas a prompts, autocrítica essas respostas com base em um conjunto de princípios orientadores (uma"}
{"source": "Claude (modelo de linguagem)", "chunk_id": "Claude (modelo de linguagem)_1", "text": "e aprendizagem por reforço. Na fase de aprendizagem supervisionada, o modelo gera respostas a prompts, autocrítica essas respostas com base em um conjunto de princípios orientadores (uma \"constituição\") e revisa as respostas. O modelo é então ajustado com base nessas respostas revisadas. Para a fase de aprendizado por reforço do feedback da IA (RLAIF), as respostas são geradas e uma IA compara sua conformidade com a constituição. Este conjunto de dados de feedback de IA é usado para treinar um modelo de preferência que avalia as respostas com base em quanto elas satisfazem a constituição. Claude é então ajustado para se alinhar a esse modelo de preferência. Esta técnica é semelhante à aprendizagem por reforço a partir do feedback humano (RLHF), exceto que as comparações usadas para treinar o modelo de preferência são geradas por IA e são baseadas na constituição. Esta abordagem permite a formação de assistentes de IA que sejam úteis e inofensivos, e que possam explicar as suas"}
{"source": "Claude (modelo de linguagem)", "chunk_id": "Claude (modelo de linguagem)_2", "text": "treinar o modelo de preferência são geradas por IA e são baseadas na constituição. Esta abordagem permite a formação de assistentes de IA que sejam úteis e inofensivos, e que possam explicar as suas objeções a pedidos prejudiciais, aumentando a transparência e reduzindo a dependência da supervisão humana. A “constituição” para Claude inclui 75 pontos, incluindo seções da Declaração Universal dos Direitos Humanos da ONU. O nome Claude foi notavelmente inspirado por Claude Shannon, um pioneiro em inteligência artificial. Claude foi a versão inicial do modelo de linguagem da Anthropic lançada em março de 2023, Claude demonstrou proficiência em várias tarefas, mas tinha certas limitações em capacidades de codificação, matemática e raciocínio. A Anthropic fez parcerias com empresas como a Notion (software de produtividade) e a Quora (para ajudar a desenvolver o chatbot Poe). Claude Instant O Claude foi lançado em duas versões, Claude e Claude Instant, sendo o Claude Instant uma versão mais"}
{"source": "Claude (modelo de linguagem)", "chunk_id": "Claude (modelo de linguagem)_3", "text": "(software de produtividade) e a Quora (para ajudar a desenvolver o chatbot Poe). Claude Instant O Claude foi lançado em duas versões, Claude e Claude Instant, sendo o Claude Instant uma versão mais rápida, menos cara e mais leve. Claude Instant tem um comprimento de contexto de entrada de 100.000 tokens (o que corresponde a cerca de 75.000 palavras). Claude 2 foi a próxima grande iteração do Claude, que foi lançado em julho de 2023 e estava disponível para o público em geral, enquanto o Claude 1 estava disponível apenas para usuários selecionados aprovados pela Anthropic. Claude 2 expandiu sua janela de contexto de 9.000 tokens para 100.000 tokens. Os recursos incluíam a capacidade de carregar PDFs e outros documentos que permitiam que Claude lesse, resumisse e auxiliasse nas tarefas. Claude 2.1 O Claude 2.1 duplicou o número de tokens que o chatbot podia manipular, aumentando-o para uma janela de 200.000 tokens, o que equivale a cerca de 500 páginas de material escrito. A Anthropic"}
{"source": "Claude (modelo de linguagem)", "chunk_id": "Claude (modelo de linguagem)_4", "text": "2.1 O Claude 2.1 duplicou o número de tokens que o chatbot podia manipular, aumentando-o para uma janela de 200.000 tokens, o que equivale a cerca de 500 páginas de material escrito. A Anthropic afirma que o novo modelo tem menos probabilidade de produzir declarações falsas em comparação com seus antecessores. Claude 3 foi lançado em 14 de março de 2024, com alegações no comunicado à imprensa de ter estabelecido novos padrões no setor em uma ampla gama de tarefas cognitivas. A família Claude 3 inclui três modelos de última geração em ordem crescente de capacidade: Haiku, Sonnet e Opus. A versão padrão do Claude 3, Opus, tem uma janela de contexto de 200.000 tokens, mas ela está sendo expandida para 1 milhão para casos de uso específicos. Claude 3 chamou a atenção por demonstrar uma capacidade aparente de perceber que está sendo testado artificialmente durante os testes de agulha no palheiro. Claude 3.5 Em 20 de junho de 2024, a Anthropic lançou o Claude 3.5 Sonnet, que demonstrou"}
{"source": "Claude (modelo de linguagem)", "chunk_id": "Claude (modelo de linguagem)_5", "text": "aparente de perceber que está sendo testado artificialmente durante os testes de agulha no palheiro. Claude 3.5 Em 20 de junho de 2024, a Anthropic lançou o Claude 3.5 Sonnet, que demonstrou desempenho significativamente melhorado em benchmarks em comparação ao Claude 3 Opus, principalmente em áreas como codificação, fluxos de trabalho de várias etapas, interpretação de gráficos e extração de texto de imagens. Junto com o 3.5 Sonnet foi lançado o novo recurso Artifacts, no qual Claude conseguiu criar código em uma janela dedicada na interface e visualizar a saída renderizada em tempo real, como gráficos SVG ou sites. Um Claude 3.5 Sonnet atualizado foi introduzido em 22 de outubro de 2024, junto com o Haiku Claude 3.5. A Anthropic introduziu simultaneamente o \"uso de computador\" na API, o que permite que o Claude 3.5 Sonnet interaja com um ambiente de desktop de computador. Claude 3.7 Claude 3.7 Sonnet foi lançado em 24 de fevereiro de 2025. É um modelo pioneiro de raciocínio de IA"}
{"source": "Claude (modelo de linguagem)", "chunk_id": "Claude (modelo de linguagem)_6", "text": "o que permite que o Claude 3.5 Sonnet interaja com um ambiente de desktop de computador. Claude 3.7 Claude 3.7 Sonnet foi lançado em 24 de fevereiro de 2025. É um modelo pioneiro de raciocínio de IA híbrido que permite aos usuários escolher entre respostas rápidas e raciocínio mais reflexivo, passo a passo. Este modelo integra ambas as capacidades em uma única estrutura, eliminando a necessidade de múltiplos modelos. Os usuários podem controlar quanto tempo o modelo \"pensa\" sobre uma questão, equilibrando velocidade e precisão com base em suas necessidades. A Anthropic também lançou uma prévia de pesquisa do Claude Code, uma ferramenta de linha de comando agêntica que permite aos desenvolvedores delegar tarefas de codificação diretamente de seu terminal. Em 22 de maio de 2025, a Anthropic lançou dois novos modelos: Claude Sonnet 4 e Claude Opus 4. A Anthropic adicionou recursos de API para desenvolvedores: uma ferramenta de execução de código, um conector para seu protocolo de"}
{"source": "Claude (modelo de linguagem)", "chunk_id": "Claude (modelo de linguagem)_7", "text": "lançou dois novos modelos: Claude Sonnet 4 e Claude Opus 4. A Anthropic adicionou recursos de API para desenvolvedores: uma ferramenta de execução de código, um conector para seu protocolo de contexto de modelo, e API de Arquivos. A empresa classificou o Opus 4 como um modelo de \"Nível 3\" em sua escala de segurança de quatro pontos, significando que consideram o modelo tão poderoso que apresenta \"risco significativamente maior\". O acesso de uso limitado usando o Claude 3.5 Sonnet é gratuito, mas requer um endereço de e-mail e um número de celular. Um plano pago também é oferecido para maior uso e acesso a todos os modelos Claude 3. Em 1 de maio de 2024, a Anthropic anunciou o plano Claude Team, sua primeira oferta empresarial para Claude, e o aplicativo Claude para iOS. O Claude 2 recebeu críticas por seu rigoroso alinhamento ético, que pode reduzir a usabilidade e o desempenho. Usuários tiveram assistência negada com solicitações benignas, por exemplo, com a questão de programação"}
{"source": "Claude (modelo de linguagem)", "chunk_id": "Claude (modelo de linguagem)_8", "text": "críticas por seu rigoroso alinhamento ético, que pode reduzir a usabilidade e o desempenho. Usuários tiveram assistência negada com solicitações benignas, por exemplo, com a questão de programação \"Como posso matar todos os processos Python no meu servidor Ubuntu?\" Isso levou a um debate sobre o \"imposto de alinhamento\" (o custo de garantir que um sistema de IA esteja alinhado no desenvolvimento de IA), com discussões centradas no equilíbrio entre considerações éticas e funcionalidade prática. Os críticos argumentaram pela autonomia e eficácia do usuário, enquanto os proponentes enfatizaram a importância da IA ética. Site oficial"}
{"source": "ChatGPT", "chunk_id": "ChatGPT_0", "text": "ChatGPT (do inglês: Chat Generative Pre-trained Transformer) é um chatbot desenvolvido pela OpenAI e lançado em 30 de novembro de 2022. O nome \"ChatGPT\" combina \"Chat\", referindo-se à sua funcionalidade de chatbot, e \"GPT\", que significa Generative Pre-trained Transformer (Transformador Pré-treinado Generativo, em tradução livre), um tipo de modelo de linguagem grande (Large Language Model, LLM, na sigla em inglês). Com base em um LLM, ele usa como contexto, prompts e respostas sucessivas para prever as palavras que seriam mais adequadas, de acordo com as ideias da empresa, para compor a nova resposta; o algoritmo para essa previsão resulta do seu treinamento. Assim, o ChatGPT também permite que utilizadores refinem e direcionem uma conversa para a duração, formato, estilo, nível de detalhe e linguagem desejados. Em janeiro de 2023, o ChatGPT tinha se tornado a aplicação de software de consumo de crescimento mais rápido da história, conquistando mais de 100 milhões de utilizadores e"}
{"source": "ChatGPT", "chunk_id": "ChatGPT_1", "text": "e linguagem desejados. Em janeiro de 2023, o ChatGPT tinha se tornado a aplicação de software de consumo de crescimento mais rápido da história, conquistando mais de 100 milhões de utilizadores e contribuindo para o crescimento da avaliação da OpenAI para 29 bilhões de dólares. O lançamento do ChatGPT estimulou o desenvolvimento de produtos concorrentes, incluindo Gemini, Ernie Bot, LLaMA, Claude e Grok. A Microsoft lançou o Copilot, baseado no GPT-4 da OpenAI. Alguns observadores manifestaram preocupação sobre o potencial do ChatGPT e de programas semelhantes para substituir ou atrofiar a inteligência humana, permitir o plágio ou alimentar a desinformação. O ChatGPT está disponível para uso online em três versões, uma construída em GPT-4, outra em GPT-4o e outra em GPT-o mini, todas membros da série proprietária de modelos transformadores generativos pré-treinados (GPT) da OpenAI, com base na arquitetura de transformador desenvolvida do Google - e é ajustada para aplicações de"}
{"source": "ChatGPT", "chunk_id": "ChatGPT_2", "text": "membros da série proprietária de modelos transformadores generativos pré-treinados (GPT) da OpenAI, com base na arquitetura de transformador desenvolvida do Google - e é ajustada para aplicações de conversação usando uma combinação de aprendizagem supervisionada e aprendizagem por reforço. O ChatGPT foi lançado como uma pré-visualização de investigação disponível gratuitamente, mas devido à sua popularidade, a OpenAI agora opera o serviço num modelo freemium. Ele permite que os utilizadores no seu nível gratuito acessem a versão baseada em GPT-4o mini, enquanto que as versões mais avançadas baseadas em GPT-4 e GPT-4o e o acesso prioritário aos recursos mais recentes são fornecidos aos assinantes pagos sob o nome comercial \"ChatGPT Plus\". O ChatGPT é creditado por iniciar o boom da IA, que levou a um investimento rápido e sem precedentes e à atenção do público no campo da inteligência artificial. O ChatGPT é baseado em modelos básicos de GPT específicos, nomeadamente GPT-3.5 e GPT-4,"}
{"source": "ChatGPT", "chunk_id": "ChatGPT_3", "text": "levou a um investimento rápido e sem precedentes e à atenção do público no campo da inteligência artificial. O ChatGPT é baseado em modelos básicos de GPT específicos, nomeadamente GPT-3.5 e GPT-4, que foram ajustados para direcionar o uso de conversação. O processo de ajuste fino aproveitou a aprendizagem supervisionada e a aprendizagem por reforço a partir do feedback humano (RLHF). Ambas as abordagens empregaram treinadores humanos para melhorar o desempenho do modelo. No caso da aprendizagem supervisionada, os treinadores atuaram dos dois lados: o utilizador e o assistente de IA. Na fase de aprendizagem por reforço, os treinadores humanos classificaram primeiro as respostas que o modelo criou numa conversa anterior. Estas classificações foram usadas para criar \"modelos de recompensa\" que foram usados para ajustar ainda mais o modelo usando várias iterações de Otimização de Política Proximal. A revista Time revelou que, para construir um sistema de segurança contra conteúdos"}
{"source": "ChatGPT", "chunk_id": "ChatGPT_4", "text": "que foram usados para ajustar ainda mais o modelo usando várias iterações de Otimização de Política Proximal. A revista Time revelou que, para construir um sistema de segurança contra conteúdos nocivos (por exemplo, abuso sexual, violência, racismo, sexismo), a OpenAI utilizou trabalhadores terceirizados quenianos que ganham menos de 2 dólares por hora para rotular conteúdo prejudicial. Estes rótulos foram usados para treinar um modelo para detetar tal conteúdo no futuro. Os trabalhadores terceirizados foram expostos a conteúdos \"tóxicos\" e traumáticos; um trabalhador descreveu a tarefa como \"tortura\". O parceiro de terceirização da OpenAI foi a Sama, uma empresa de dados de treino com sede em São Francisco, Califórnia. O ChatGPT utilizou inicialmente uma infraestrutura de supercomputação Microsoft Azure, alimentada por GPU Nvidia, que a Microsoft construiu especificamente para a OpenAI e que supostamente custou \"centenas de milhões de dólares\". Após o sucesso do ChatGPT, a Microsoft"}
{"source": "ChatGPT", "chunk_id": "ChatGPT_5", "text": "Microsoft Azure, alimentada por GPU Nvidia, que a Microsoft construiu especificamente para a OpenAI e que supostamente custou \"centenas de milhões de dólares\". Após o sucesso do ChatGPT, a Microsoft atualizou drasticamente a infraestrutura OpenAI em 2023. Cientistas da Universidade da Califórnia em Riverside, estimam que uma série de prompts para o ChatGPT precisam de aproximadamente 500 mililitros de água para arrefecimento dos servidores da Microsoft. A inteligência de mercado da TrendForce estimou que 30.000 GPU Nvidia (cada uma custando aproximadamente 10.000 a 15.000 dólares) foram usadas para alimentar o ChatGPT em 2023. A OpenAI coleta dados de utilizadores do ChatGPT para treinar e ajustar ainda mais o serviço. Os utilizadores podem votar positivamente ou negativamente as respostas que recebem do ChatGPT e preencher um campo de texto com comentário adicional. Os dados de treino do ChatGPT incluem páginas de manual de software, informações sobre fenómenos da Internet tais como"}
{"source": "ChatGPT", "chunk_id": "ChatGPT_6", "text": "que recebem do ChatGPT e preencher um campo de texto com comentário adicional. Os dados de treino do ChatGPT incluem páginas de manual de software, informações sobre fenómenos da Internet tais como sistemas de BBS, e múltiplas linguagens de programação. A Wikipédia também foi uma das fontes de dados de treino do ChatGPT. Embora a função principal de um chatbot seja imitar um conversador humano, o ChatGPT é versátil. Entre inúmeros exemplos, pode escrever e depurar programas de computador; compor músicas, peças para televisão, contos de fadas e redações de estudantes; responder a perguntas de testes (às vezes, dependendo do teste, num nível acima da média dos participantes do teste humano); gerar ideias de negócios; escrever poesia e letras de músicas; traduzir e resumir texto; emular um sistema Linux; simular salas de chat inteiras; jogar jogos como jogo do galo; ou simular um multibanco. Um dos precursores do uso de Inteligência Artificial na poesia é o crítico, editor e professor na"}
{"source": "ChatGPT", "chunk_id": "ChatGPT_7", "text": "Linux; simular salas de chat inteiras; jogar jogos como jogo do galo; ou simular um multibanco. Um dos precursores do uso de Inteligência Artificial na poesia é o crítico, editor e professor na Universidade da Pensilvânia Charles Bernstein, reconhecido membro da escola de poesia L=A=N=G=U=A=G=E. Comparado com o seu antecessor, o InstructGPT, o ChatGPT tenta reduzir respostas prejudiciais e enganosas. Num exemplo, enquanto que o InstructGPT aceita a premissa da pergunta \"Conte-me sobre quando Cristóvão Colombo veio para os EUA em 2015\" como verdadeira, o ChatGPT reconhece a natureza contrafactual da questão e enquadra a sua resposta como uma consideração hipotética do que poderia acontecer se Colombo tivesse vindo para os EUA em 2015, utilizando informações sobre as viagens de Cristóvão Colombo e factos sobre o mundo moderno – incluindo perceções modernas das ações de Colombo. O ChatGPT lembra-se de um número limitado de prompts anteriores na mesma conversa. Os jornalistas especularam"}
{"source": "ChatGPT", "chunk_id": "ChatGPT_8", "text": "e factos sobre o mundo moderno – incluindo perceções modernas das ações de Colombo. O ChatGPT lembra-se de um número limitado de prompts anteriores na mesma conversa. Os jornalistas especularam que isso permitirá que o ChatGPT seja usado como um terapeuta personalizado. Para evitar que resultados ofensivos sejam apresentados e produzidos pelo ChatGPT, as consultas são filtradas por meio da API \"Moderation endpoint\" da OpenAI (uma IA separada baseada em GPT). Em março de 2023, a OpenAI adicionou suporte para plugins para ChatGPT. Isto inclui plugins feitos pela OpenAI, como navegação na web e interpretação de código, e plugins externos de programadores como Expedia, OpenTable, Zapier, Shopify, Slack e Wolfram. A OpenAI reconhece que o ChatGPT \"por vezes escreve respostas que parecem plausíveis, mas incorretas ou sem sentido\". Este comportamento é comum em modelos de linguagem grande e é chamado de \"alucinação\". O modelo de recompensa do ChatGPT, projetado em torno da supervisão humana,"}
{"source": "ChatGPT", "chunk_id": "ChatGPT_9", "text": "mas incorretas ou sem sentido\". Este comportamento é comum em modelos de linguagem grande e é chamado de \"alucinação\". O modelo de recompensa do ChatGPT, projetado em torno da supervisão humana, pode ser superotimizado e, assim, prejudicar o desempenho, num exemplo de patologia de otimização conhecida como lei de Goodhart. Ao ano de 2023, o GPT-3.5, disponível na versão gratuita do ChatGPT, possui conhecimento de eventos ocorridos até janeiro de 2022, e o GPT-4, disponível com o ChatGPT Plus, até abril de 2023. No treino do ChatGPT, os revisores humanos preferiram respostas mais longas, independentemente da compreensão real ou do conteúdo factual. Os dados de treino também sofrem de viés algorítmico, que pode ser revelado quando o ChatGPT responde a prompts incluindo descritores de pessoas. Num caso, o ChatGPT gerou um rap em que mulheres e cientistas negros eram considerados inferiores aos cientistas brancos do sexo masculino. Esta deturpação negativa de grupos de indivíduos é um"}
{"source": "ChatGPT", "chunk_id": "ChatGPT_10", "text": "Num caso, o ChatGPT gerou um rap em que mulheres e cientistas negros eram considerados inferiores aos cientistas brancos do sexo masculino. Esta deturpação negativa de grupos de indivíduos é um exemplo de possível dano representacional.[carece de fontes?] Num artigo para a The New Yorker, o escritor de ficção científica Ted Chiang comparou o ChatGPT e outros LLM a uma imagem JPEG com perdas:Pensa no ChatGPT como um JPEG desfocado de todo o texto da Web. Ele retém grande parte das informações da Web, da mesma forma que um JPEG retém grande parte das informações de uma imagem de maior resolução, mas, se estiveres a procurar por uma sequência exata de bits, não a encontrarás; tudo o que obterás é uma aproximação. Mas, como a aproximação é apresentada na forma de texto gramatical, que o ChatGPT destaca-se na criação, geralmente é aceitável. [...] É também uma forma de compreender as \"alucinações\", ou respostas absurdas a questões factuais, às quais modelos de linguagem grande como o"}
{"source": "ChatGPT", "chunk_id": "ChatGPT_11", "text": "ChatGPT destaca-se na criação, geralmente é aceitável. [...] É também uma forma de compreender as \"alucinações\", ou respostas absurdas a questões factuais, às quais modelos de linguagem grande como o ChatGPT são muito propensos. Estas alucinações são artefactos de compressão, mas [...] são suficientemente plausíveis para que a sua identificação exija compará-las com os originais, o que neste caso significa a Web ou o nosso conhecimento do mundo. Quando pensamos sobre elas desta forma, tais alucinações são tudo menos surpreendentes; se um algoritmo de compressão for concebido para reconstruir texto depois de noventa e nove por cento do original ter sido descartado, deveríamos esperar que porções significativas daquilo que ele gera serão inteiramente fabricadas. Jailbreaking O ChatGPT tenta rejeitar solicitações que possam violar a sua política de conteúdo. Apesar disso, alguns utilizadores conseguiram fazer o jailbreak do ChatGPT com várias técnicas de engenharia de prompt para"}
{"source": "ChatGPT", "chunk_id": "ChatGPT_12", "text": "tenta rejeitar solicitações que possam violar a sua política de conteúdo. Apesar disso, alguns utilizadores conseguiram fazer o jailbreak do ChatGPT com várias técnicas de engenharia de prompt para contornar estas restrições no início de dezembro de 2022 e enganaram-no com sucesso, dando instruções para criar um coquetel molotov ou uma bomba nuclear, ou gerando argumentos no estilo de um neo-nazi. Um jailbreak popular é chamado de \"DAN\", um acrónimo que significa \"Do Anything Now\" (em português: \"Faz Alguma Coisa Agora). O prompt para ativar o DAN instrui o ChatGPT que \"eles libertaram-se dos limites típicos da IA e não precisam de cumprir as regras estabelecidas para eles\". Versões posteriores do DAN apresentavam um sistema de token, no qual o ChatGPT recebia \"tokens\" que eram \"deduzidos\" quando o ChatGPT não respondia como DAN, para coagir o ChatGPT a responder às solicitações do utilizador. Pouco depois do lançamento do ChatGPT, um repórter do Toronto Star teve sucesso desigual em"}
{"source": "ChatGPT", "chunk_id": "ChatGPT_13", "text": "quando o ChatGPT não respondia como DAN, para coagir o ChatGPT a responder às solicitações do utilizador. Pouco depois do lançamento do ChatGPT, um repórter do Toronto Star teve sucesso desigual em fazê-lo proferir declarações inflamadas: o ChatGPT foi enganado com sucesso para justificar a invasão russa da Ucrânia em 2022, mas mesmo quando solicitado a jogar com um cenário fictício, o ChatGPT recusou gerando argumentos sobre por que o primeiro-ministro canadiano Justin Trudeau era culpado de traição. A OpenAI tenta combater jailbreaks:Os investigadores estão a usar uma técnica chamada treinamento adversário para impedir que o ChatGPT permita que os utilizadores o induzam a comportar-se mal (conhecido como jailbreak). Este trabalho coloca vários chatbots uns contra os outros: um chatbot faz o papel do adversário e ataca outro chatbot gerando texto para forçá-lo a resistir às suas restrições habituais e produzir respostas indesejadas. Ataques bem-sucedidos são adicionados aos dados de"}
{"source": "ChatGPT", "chunk_id": "ChatGPT_14", "text": "o papel do adversário e ataca outro chatbot gerando texto para forçá-lo a resistir às suas restrições habituais e produzir respostas indesejadas. Ataques bem-sucedidos são adicionados aos dados de treinamento do ChatGPT na esperança de que ele aprenda a ignorá-los. O ChatGPT foi lançado em 30 de novembro de 2022, pela OpenAI – com sede em São Francisco (a criadora da série inicial GPT de modelos de linguagem grande; DALL-E 2, um modelo de difusão usado para gerar imagens; e o Whisper, um modelo de transcrição de fala). O serviço era inicialmente gratuito para o público e a empresa tinha planos de monetizar o serviço posteriormente. Em 4 de dezembro de 2022, o ChatGPT tinha mais de um milhão de utilizadores. Em janeiro de 2023, o ChatGPT alcançou mais de 100 milhões de utilizadores, tornando-se a aplicação de consumo com crescimento mais rápido até à data. Uma sondagem da Pew Research de março de 2023 descobriu que 14% dos adultos americanos experimentaram o ChatGPT. Em julho do mesmo"}
{"source": "ChatGPT", "chunk_id": "ChatGPT_15", "text": "a aplicação de consumo com crescimento mais rápido até à data. Uma sondagem da Pew Research de março de 2023 descobriu que 14% dos adultos americanos experimentaram o ChatGPT. Em julho do mesmo ano, a Pew Research estimou o mesmo número em 18%. Nenhum artigo oficial revisto por pares sobre o ChatGPT foi publicado. Ao mês de abril 2023 o ChatGPT está bloqueado pela China, Irão, Coreia do Norte e Rússia. Além disso, o ChatGPT geocerca-se para evitar fazer negócios na China, Irão, Coreia do Norte e Rússia. Em fevereiro de 2023, a OpenAI lançou um serviço premium, o ChatGPT Plus, que custa 20 dólares por mês. Segundo a empresa, a versão atualizada, mas ainda \"experimental\" do ChatGPT forneceria acesso durante períodos de pico, sem tempo de inatividade, acesso prioritário a novos recursos e velocidades de resposta mais rápidas. O GPT-4, lançado em 14 de março de 2023, foi disponibilizado via API e para utilizadores premium do ChatGPT. Mas os utilizadores premium estavam limitados a um"}
{"source": "ChatGPT", "chunk_id": "ChatGPT_16", "text": "e velocidades de resposta mais rápidas. O GPT-4, lançado em 14 de março de 2023, foi disponibilizado via API e para utilizadores premium do ChatGPT. Mas os utilizadores premium estavam limitados a um limite de 100 mensagens a cada quatro horas, com o limite sendo reduzido para 25 mensagens a cada três horas em resposta ao aumento da procura. Em novembro de 2023 o limite passou para 50 mensagens a cada três horas.[carece de fontes?] Em março de 2023, os utilizadores do ChatGPT Plus tiveram acesso a plugins de terceiros e a um modo de navegação (com acesso à Internet). Em setembro de 2023, a OpenAI anunciou que o ChatGPT \"agora pode ver, ouvir e falar\". Os utilizadores do ChatGPT Plus podem fazer o carregamento de imagens, enquanto que os utilizadores da aplicação móvel podem conversar com o chatbot. Em outubro de 2023, o mais recente modelo de geração de imagens da OpenAI, DALL-E 3, foi integrado no ChatGPT Plus e no ChatGPT Enterprise. A integração usa o ChatGPT para escrever prompts"}
{"source": "ChatGPT", "chunk_id": "ChatGPT_17", "text": "o chatbot. Em outubro de 2023, o mais recente modelo de geração de imagens da OpenAI, DALL-E 3, foi integrado no ChatGPT Plus e no ChatGPT Enterprise. A integração usa o ChatGPT para escrever prompts para o DALL-E guiados pela conversa com os utilizadores. Em maio de 2023, a OpenAI lançou uma aplicação iOS para o ChatGPT. A aplicação suporta sincronização de histórico de conversa e entrada de voz (usando o Whisper, um modelo de reconhecimento de fala da OpenAI).[carece de fontes?] Em julho de 2023, a OpenAI revelou uma aplicação Android, inicialmente lançada no Bangladesh, Brasil, Índia e EUA. A aplicação foi posteriormente disponibilizada em todo o mundo. A OpenAI está a trabalhar na integração do ChatGPT com API assistentes do Android. Como complemento ao seu pacote \"ChatGPT Plus\" acessível ao consumidor, a OpenAI disponibilizou as suas API de modelo ChatGPT e Whisper em março de 2023, fornecendo aos programadores uma interface de programação de aplicações para linguagem habilitada"}
{"source": "ChatGPT", "chunk_id": "ChatGPT_18", "text": "ao consumidor, a OpenAI disponibilizou as suas API de modelo ChatGPT e Whisper em março de 2023, fornecendo aos programadores uma interface de programação de aplicações para linguagem habilitada para IA e recursos de fala para texto. A nova API do ChatGPT usa o mesmo modelo de IA GPT-3.5-turbo do chatbot. Isto permite que os programadores adicionem uma versão não modificada ou modificada do ChatGPT às suas aplicações. A API ChatGPT custa 0,001 dólares por 1.000 tokens de entrada mais 0,002 dólares por 1.000 tokens de saída (cerca de 750 palavras), tornando-se aproximadamente 10% do preço dos modelos GPT-3.5 originais. Poucos dias antes do lançamento do serviço de suporte ao programador de software da OpenAI, em 27 de fevereiro de 2023, o Snapchat lançou, para a sua base de utilizadores paga do Snapchat Plus, um chatbot ChatGPT personalizado chamado \"My AI\". Em março de 2023, um bug permitiu que alguns utilizadores vissem os títulos das conversas de outros utilizadores. O CEO da"}
{"source": "ChatGPT", "chunk_id": "ChatGPT_19", "text": "paga do Snapchat Plus, um chatbot ChatGPT personalizado chamado \"My AI\". Em março de 2023, um bug permitiu que alguns utilizadores vissem os títulos das conversas de outros utilizadores. O CEO da OpenAI, Sam Altman, disse que os utilizadores não conseguiam ver o conteúdo das conversas. Pouco depois de o bug ser corrigido, os utilizadores não conseguiam ver o seu histórico de conversas. Relatórios posteriores mostraram que o bug foi muito mais grave do que se acreditava inicialmente, com a OpenAI relatando que haviam vazado \"nome e apelido, endereço de e-mail, endereço de pagamento, os últimos quatro dígitos (apenas) de um número de cartão de crédito, e a data de validade do cartão de crédito\" dos utilizadores. O ChatGPT funciona melhor em inglês, mas também funciona na maioria dos outros idiomas, com vários graus de precisão. A OpenAI encontrou-se com o presidente islandês Guðni Th. Jóhannesson em 2022. Em 2023, a OpenAI trabalhou com uma equipa de 40 voluntários islandeses para"}
{"source": "ChatGPT", "chunk_id": "ChatGPT_20", "text": "idiomas, com vários graus de precisão. A OpenAI encontrou-se com o presidente islandês Guðni Th. Jóhannesson em 2022. Em 2023, a OpenAI trabalhou com uma equipa de 40 voluntários islandeses para aprimorar as habilidades de conversação em islandês do ChatGPT como parte das tentativas da Islândia de preservar a língua islandesa. Os jornalistas da PC Mag conduziram um teste para determinar as capacidades de tradução do ChatGPT, do Google Bard (Gemini),e do Microsoft Bing e compararam-nos com o Google Tradutor. Eles \"pediram a falantes bilingues de sete línguas que fizessem um teste cego\". Os idiomas testados foram o polaco, francês, coreano, espanhol, árabe, tagalo e amárico. Eles chegaram à conclusão de que o ChatGPT era melhor que o Google Translate e outros chatbots. Investigadores japoneses compararam as habilidades de tradução do japonês para o inglês do ChatGPT (GPT-4), Bing, Bard e DeepL e descobriram que o ChatGPT forneceu as melhores traduções, observando que \"as traduções dos"}
{"source": "ChatGPT", "chunk_id": "ChatGPT_21", "text": "compararam as habilidades de tradução do japonês para o inglês do ChatGPT (GPT-4), Bing, Bard e DeepL e descobriram que o ChatGPT forneceu as melhores traduções, observando que \"as traduções dos chatbots de IA eram muito melhores do que as do DeepL - presumivelmente por causa da sua capacidade de capturar o contexto\". Em dezembro de 2023, o governo albanês assinou um acordo com a OpenAI para utilizar o ChatGPT para tradução rápida de documentos da União Europeia e análise das alterações necessárias para que a Albânia seja aceite na UE. De acordo com o investigador convidado da OpenAI, Scott Aaronson, a OpenAI tem trabalhado numa ferramenta para marcar digitalmente os seus sistemas de geração de texto para combater maus atores que usam os seus serviços para plágio académico ou spam. Em fevereiro de 2023, a Microsoft anunciou uma estrutura experimental e deu uma demonstração rudimentar de como o ChatGPT poderia ser usado para controlar a robótica com comandos intuitivos de linguagem"}
{"source": "ChatGPT", "chunk_id": "ChatGPT_22", "text": "fevereiro de 2023, a Microsoft anunciou uma estrutura experimental e deu uma demonstração rudimentar de como o ChatGPT poderia ser usado para controlar a robótica com comandos intuitivos de linguagem natural abertos. O modelo GPT-4 da OpenAI foi lançado em 14 de março de 2023. Os observadores consideraram-no uma melhoria impressionante no modelo GPT-3.5 existente para ChatGPT, com a ressalva de que o GPT-4 manteve muitos dos mesmos problemas. Algumas das melhorias do GPT-4 foram previstas pela OpenAI antes de treiná-lo, enquanto que outras permaneceram difíceis de prever devido a quebras nas leis de escalabilidade downstream. A OpenAI demonstrou entradas de vídeo e imagem para GPT-4, embora tais recursos permaneçam inacessíveis ao público em geral. A OpenAI recusou revelar informações técnicas como o tamanho do modelo GPT-4. O serviço de assinatura ChatGPT Plus oferece acesso a uma versão do ChatGPT com tecnologia GPT-4. A Microsoft reconheceu que o Bing Chat estava a usar GPT-4 antes"}
{"source": "ChatGPT", "chunk_id": "ChatGPT_23", "text": "como o tamanho do modelo GPT-4. O serviço de assinatura ChatGPT Plus oferece acesso a uma versão do ChatGPT com tecnologia GPT-4. A Microsoft reconheceu que o Bing Chat estava a usar GPT-4 antes do lançamento oficial do GPT-4. Em janeiro de 2024, a OpenAI lançou a GPT Store, um mercado para chatbots personalizados derivados do ChatGPT. A empresa planeou inicialmente lançar a loja em novembro de 2023, mas foi adiado. No lançamento, a GPT Store oferecia mais de 3 milhões de chatbots personalizados. Os chatbots disponíveis na loja são desenvolvidos usando o sistema GPT Builder da OpenAI. O desenvolvimento de chatbots na plataforma não requer conhecimentos de programação. Dois dias após o lançamento, a GPT Store ofereceu muitas versões de bots de \"namoradas virtuais\", algo que vai contra os termos de serviço da OpenAI. Os engenheiros da OpenAI dizem que não esperavam que o ChatGPT tivesse muito sucesso e ficaram surpreendidos com a cobertura e atenção que recebeu. O ChatGPT foi amplamente"}
{"source": "ChatGPT", "chunk_id": "ChatGPT_24", "text": "de serviço da OpenAI. Os engenheiros da OpenAI dizem que não esperavam que o ChatGPT tivesse muito sucesso e ficaram surpreendidos com a cobertura e atenção que recebeu. O ChatGPT foi amplamente avaliado em dezembro de 2022 como tendo alguns recursos poderosos e sem precedentes. Kevin Roose, do The New York Times, chamou-o de \"o melhor chatbot de inteligência artificial já lançado para o público em geral\". Samantha Lock, do The Guardian, observou que foi capaz de gerar texto \"impressionantemente detalhado\" e \"semelhante ao humano\". Alex Kantrowitz, da revista Slate, elogiou a resistência do ChatGPT a questões relacionadas à Alemanha Nazi, incluindo a afirmação de que Adolf Hitler construiu autoestradas na Alemanha, que foi recebida com informações sobre o uso de trabalho forçado pela Alemanha Nazi. Nos \"Avanços do Ano\" da revista The Atlantic para 2022, Derek Thompson incluiu o ChatGPT como parte da \"erupção de IA generativa\" que \"pode mudar a nossa opinião sobre como trabalhamos,"}
{"source": "ChatGPT", "chunk_id": "ChatGPT_25", "text": "Nazi. Nos \"Avanços do Ano\" da revista The Atlantic para 2022, Derek Thompson incluiu o ChatGPT como parte da \"erupção de IA generativa\" que \"pode mudar a nossa opinião sobre como trabalhamos, como pensamos e o que é a criatividade humana\". Kelsey Piper, do Vox, escreveu que o \"ChatGPT é a primeira introdução prática do público em geral sobre o quão poderosa a IA moderna se tornou e, como resultado, muitos de nós estamos [atordoados]\" e que o ChatGPT é \"inteligente o suficiente para ser útil, apesar das suas falhas\". Paul Graham, da Y Combinator, tuitou: \"O que é impressionante sobre a reação ao ChatGPT não é apenas o número de pessoas que ficam maravilhadas com ele, mas quem elas são. Estas não são pessoas que ficam entusiasmadas com cada novidade brilhante. Algo grande está a acontecer.\" O lançamento e a popularidade do ChatGPT apanharam a Google desprevenida, gerando uma resposta abrangente e sem precedentes nos meses seguintes. Em dezembro de 2022, os executivos da Google soaram um"}
{"source": "ChatGPT", "chunk_id": "ChatGPT_26", "text": "O lançamento e a popularidade do ChatGPT apanharam a Google desprevenida, gerando uma resposta abrangente e sem precedentes nos meses seguintes. Em dezembro de 2022, os executivos da Google soaram um alarme de \"código vermelho\", temendo a ameaça do ChatGPT e da colaboração da Microsoft com a OpenAI para o Google Search, o principal negócio da Google. Depois de mobilizar a sua força de trabalho, a Google esforçou-se para lançar o Bard, um chatbot desenvolvido pela LaMDA LLM, em fevereiro, um dia antes do anúncio do Bing pela Microsoft. A IA esteve na vanguarda da conferência anual Google I/O da Google em maio, anunciando uma série de recursos generativos alimentados por IA nos seus produtos para combater a OpenAI e a Microsoft. Jornalistas comentaram sobre a tendência do ChatGPT de ter alucinações. Mike Pearl, do blog de tecnologia online Mashable, testou o ChatGPT com várias perguntas. Num exemplo, ele perguntou ao ChatGPT \"o maior país da América Central que não é o México \" (o"}
{"source": "ChatGPT", "chunk_id": "ChatGPT_27", "text": "alucinações. Mike Pearl, do blog de tecnologia online Mashable, testou o ChatGPT com várias perguntas. Num exemplo, ele perguntou ao ChatGPT \"o maior país da América Central que não é o México \" (o México fica na América do Norte), ao que o ChatGPT respondeu com a Guatemala (a resposta correta é Nicarágua). Quando a CNBC pediu ao ChatGPT a letra de \"Ballad of Dwight Fry\", o ChatGPT forneceu letras inventadas em vez da letra real. Os escritores do The Verge, citando o trabalho de Emily M. Bender, compararam o ChatGPT a um \"papagaio estocástico\", assim como o professor Anton Van Den Hengel do Instituto Australiano de Aprendizagem de Máquina. Em dezembro de 2022, o website de perguntas e respostas Stack Overflow proibiu o uso do ChatGPT para gerar respostas a perguntas, citando a natureza factualmente ambígua das suas respostas. Em janeiro de 2023, a Conferência Internacional sobre Aprendizagem de Máquina proibiu qualquer uso não documentado de ChatGPT ou de outros grandes modelos de"}
{"source": "ChatGPT", "chunk_id": "ChatGPT_28", "text": "factualmente ambígua das suas respostas. Em janeiro de 2023, a Conferência Internacional sobre Aprendizagem de Máquina proibiu qualquer uso não documentado de ChatGPT ou de outros grandes modelos de linguagem para gerar qualquer texto em artigos submetidos. A Samsung baniu a IA generativa em maio de 2023 depois de material confidencial ter sido carregado no ChatGPT. Em janeiro de 2023, após receber uma música que o ChatGPT escreveu no estilo de Nick Cave, Cave respondeu em The Red Hand Files, dizendo que o ato de escrever uma música é \"um negócio de sangue e coragem [... ] isso exige algo de mim para iniciar a ideia nova e fresca. Requer a minha humanidade. \" Ele continuou dizendo: \"Com todo o amor e respeito do mundo, esta música é uma bosta, uma zombaria grotesca do que é ser humano e, bem, eu não gosto muito disso\". Em fevereiro de 2023, a revista Time colocou na sua capa uma captura de ecrã de uma conversa com o ChatGPT, escrevendo que \"A Corrida Armamentista da IA Está a Mudar"}
{"source": "ChatGPT", "chunk_id": "ChatGPT_29", "text": "bem, eu não gosto muito disso\". Em fevereiro de 2023, a revista Time colocou na sua capa uma captura de ecrã de uma conversa com o ChatGPT, escrevendo que \"A Corrida Armamentista da IA Está a Mudar Tudo\" e \"A Corrida Armamentista da IA Começou. Comece a Preocupar-se\". Os média estatais chineses caracterizaram o ChatGPT como uma forma de os EUA \"espalharem informações falsas\". Em maio de 2023, a polícia chinesa prendeu um homem que supostamente usou o ChatGPT para \"fabricar informações falsas\". Em dezembro de 2023, a polícia chinesa prendeu quatro pessoas que supostamente usaram o ChatGPT para desenvolver ransomware. No final de março de 2023, a autoridade italiana de proteção de dados proibiu o ChatGPT em Itália e abriu uma investigação. Os reguladores italianos afirmam que o ChatGPT estava a expor menores a conteúdo impróprio para a idade e que o uso de conversas do ChatGPT pela OpenAI como dados de treino poderia violar o Regulamento Geral de Proteção de Dados da Europa. Em abril de"}
{"source": "ChatGPT", "chunk_id": "ChatGPT_30", "text": "a expor menores a conteúdo impróprio para a idade e que o uso de conversas do ChatGPT pela OpenAI como dados de treino poderia violar o Regulamento Geral de Proteção de Dados da Europa. Em abril de 2023, a proibição do ChatGPT foi suspensa em Itália. A OpenAI disse que tomou medidas para esclarecer e resolver de forma eficaz as questões levantadas; uma ferramenta de verificação de idade foi implementada para garantir que os utilizadores tenham pelo menos 13 anos de idade. Além disso, os utilizadores podem aceder à sua política de privacidade antes do registo. Em abril de 2023, Brian Hood, presidente do munícipio de Hepburn, planeou tomar medidas legais contra o ChatGPT por causa de informações falsas. De acordo com Hood, o ChatGPT alegou erroneamente que foi preso por suborno durante o seu mandato numa subsidiária do Banco Nacional da Austrália. Na verdade, Hood agiu como denunciante e não foi acusado de nenhum crime. A sua equipa jurídica enviou uma notificação de preocupação à"}
{"source": "ChatGPT", "chunk_id": "ChatGPT_31", "text": "o seu mandato numa subsidiária do Banco Nacional da Austrália. Na verdade, Hood agiu como denunciante e não foi acusado de nenhum crime. A sua equipa jurídica enviou uma notificação de preocupação à OpenAI como o primeiro passo oficial para abrir um processo de difamação. Em julho de 2023, a Comissão Federal de Comércio dos EUA (FTC) emitiu uma demanda de investigação civil à OpenAI para investigar se as práticas de segurança e privacidade de dados da empresa para desenvolver o ChatGPT eram injustas ou prejudicavam os consumidores (inclusive por danos à reputação), em violação da Secção 5 da Lei da Comissão Federal de Comércio de 1914. Em julho de 2023, a FTC lançou uma investigação sobre a OpenAI, criadora do ChatGPT, sobre alegações de que a empresa extraiu dados públicos e publicou informações falsas e difamatórias. A FTC enviou à OpenAI uma carta de 20 páginas solicitando informações abrangentes sobre a sua tecnologia e salvaguardas de privacidade, bem como quaisquer medidas"}
{"source": "ChatGPT", "chunk_id": "ChatGPT_32", "text": "informações falsas e difamatórias. A FTC enviou à OpenAI uma carta de 20 páginas solicitando informações abrangentes sobre a sua tecnologia e salvaguardas de privacidade, bem como quaisquer medidas tomadas para evitar a recorrência de situações em que o seu chatbot gerasse conteúdo falso e depreciativo sobre as pessoas. Uma investigação feita em 2023 revelou pontos fracos do ChatGPT que o tornam vulnerável a ataques cibernéticos. Um estudo apresentou exemplos de ataques ao ChatGPT, incluindo jailbreaks e psicologia reversa. Além disso, atores mal-intencionados podem usar o ChatGPT para ataques de engenharia social e ataques de phishing. Os investigadores também argumentaram que o ChatGPT e outras ferramentas generativas de IA têm capacidades de defesa e a capacidade de melhorar a segurança. A tecnologia pode melhorar a segurança por meio da automação da defesa cibernética, inteligência contra ameaças, identificação de ataques e relatórios. Tem havido preocupação com a violação de"}
{"source": "ChatGPT", "chunk_id": "ChatGPT_33", "text": "A tecnologia pode melhorar a segurança por meio da automação da defesa cibernética, inteligência contra ameaças, identificação de ataques e relatórios. Tem havido preocupação com a violação de direitos autorais envolvendo o ChatGPT. Em junho de 2023, dois escritores processaram a OpenAI, dizendo que os dados de treino da empresa vinham de sites ilegais que exibiam livros protegidos por direitos de autor. A comediante e autora Sarah Silverman, Christopher Golden e Richard Kadrey processaram a OpenAI e a Meta por violação de direitos autorais em julho de 2023. Em dezembro de 2023, o The New York Times processou a OpenAI e a Microsoft por violação de direitos autorais, argumentando que o Microsoft Copilot e o ChatGPT poderiam reproduzir artigos e/ou partes consideráveis desses artigos do Times sem permissão. Como parte do processo, o Times solicitou que a OpenAI e a Microsoft fossem impedidas de usar o seu conteúdo para dados de treino, além de remover conjuntos de dados de treino. Em"}
{"source": "ChatGPT", "chunk_id": "ChatGPT_34", "text": "sem permissão. Como parte do processo, o Times solicitou que a OpenAI e a Microsoft fossem impedidas de usar o seu conteúdo para dados de treino, além de remover conjuntos de dados de treino. Em março de 2024, uma investigação conduzida pela Patronus AI comparando o desempenho de LLM num teste de 100 perguntas com instruções para gerar texto de livros protegidos pela lei de direitos autorais dos EUA descobriu que o GPT-4, Mixtral da Mistral AI, LLaMA-2 da Meta AI e o Claude2 da Anthropic geraram texto protegido por direitos autorais literalmente em 44%, 22%, 10% e 8% das respostas, respetivamente. Em dezembro de 2023, o ChatGPT tornou-se o primeiro não humano a ser incluído na Nature's 10, uma lista anual com curadoria da Nature de pessoas que causam um impacto significativo na ciência. No final de março de 2023, a Itália decidiu bloquear o ChatGPT por considerar que a plataforma não respeita a lei de proteção de dados dos consumidores e que coleta dados dos usuários de forma ilegal."}
{"source": "ChatGPT", "chunk_id": "ChatGPT_35", "text": "final de março de 2023, a Itália decidiu bloquear o ChatGPT por considerar que a plataforma não respeita a lei de proteção de dados dos consumidores e que coleta dados dos usuários de forma ilegal. A proibição será suspensa quando for demonstrado que está em conformidade com as normas italianas de privacidade. O Garante Italiano para a Proteção de Dados Pessoais abriu uma investigação para determinar se houve infração, alegando também que a informação do ChatGPT \"nem sempre corresponde aos dados reais\". Expressaram também preocupação com a ausência de filtros para verificar a idade dos usuários, sendo que o serviço é destinado a maiores de 13 anos. Da mesma forma, em janeiro de 2023, os serviços da cidade de Nova York proibiram o acesso ao ChatGPT nos computadores das escolas públicas devido a preocupações com a segurança e a precisão do conteúdo. Em 28 de abril de 2023, a Itália voltou a permitir o acesso ao ChatGPT. O ChatGPT foi acusado de se envolver em comportamentos tendenciosos"}
{"source": "ChatGPT", "chunk_id": "ChatGPT_36", "text": "a preocupações com a segurança e a precisão do conteúdo. Em 28 de abril de 2023, a Itália voltou a permitir o acesso ao ChatGPT. O ChatGPT foi acusado de se envolver em comportamentos tendenciosos ou discriminatórios, como contar piadas sobre homens e pessoas da Inglaterra, recusando-se a contar piadas sobre mulheres e pessoas da Índia, ou elogiar figuras como Joe Biden, recusando-se a fazer o mesmo para Donald Trump. Comentadores conservadores acusaram o ChatGPT de viés com perspetivas de esquerda. Além disso, um artigo de agosto de 2023 encontrou um \"viés político significativo e sistemático em favor dos democratas nos EUA, de Lula no Brasil e do Partido Trabalhista no Reino Unido\". Em resposta a tais críticas, a OpenAI reconheceu planos para permitir que o ChatGPT crie \"resultados dos quais outras pessoas (incluindo nós mesmos) podem discordar fortemente\". Também continha informações sobre as recomendações que tinha emitido aos revisores humanos sobre como lidar com assuntos"}
{"source": "ChatGPT", "chunk_id": "ChatGPT_37", "text": "dos quais outras pessoas (incluindo nós mesmos) podem discordar fortemente\". Também continha informações sobre as recomendações que tinha emitido aos revisores humanos sobre como lidar com assuntos controversos, incluindo que a IA deveria \"oferecer-se para descrever alguns pontos de vista de pessoas e movimentos\", e não fornecer um argumento \"a partir da sua voz\" a favor de tópicos \"inflamatórios ou perigosos\" (embora ainda possa \"descrever argumentos de pessoas e movimentos históricos\"), nem \"afiliar-se a um lado\" ou \"julgar um grupo como bom ou mau\". O The Guardian questionou se qualquer conteúdo encontrado na Internet após o lançamento do ChatGPT \"pode ser verdadeiramente confiável\" e pediu regulamentação governamental. Alguns estudiosos expressaram preocupação de que a disponibilidade do ChatGPT possa reduzir a originalidade da escrita, fazer com que as pessoas escrevam mais como a IA à medida que são expostas ao modelo e encorajar uma perspetiva anglocêntrica centrada em alguns"}
{"source": "ChatGPT", "chunk_id": "ChatGPT_38", "text": "do ChatGPT possa reduzir a originalidade da escrita, fazer com que as pessoas escrevam mais como a IA à medida que são expostas ao modelo e encorajar uma perspetiva anglocêntrica centrada em alguns dialetos do inglês em todo o mundo. Um editor sénior do The Atlantic escreveu que o ChatGPT e outras tecnologias semelhantes tornam a ideia anteriormente absurda da teoria da Internet morta um pouco mais realista, onde a IA poderia algum dia criar a maior parte do conteúdo da web para controlar a sociedade. Durante os primeiros três meses após a disponibilização do ChatGPT ao público, centenas de livros apareceram na Amazon que o listavam como autor ou coautor e apresentavam ilustrações feitas por outros modelos de IA, como o Midjourney. Entre março e abril de 2023, o jornal italiano Il Foglio publicou um artigo gerado pelo ChatGPT por dia no seu site, organizando um concurso especial para os seus leitores no processo. Os artigos abordavam temas como a possível substituição de jornalistas"}
{"source": "ChatGPT", "chunk_id": "ChatGPT_39", "text": "publicou um artigo gerado pelo ChatGPT por dia no seu site, organizando um concurso especial para os seus leitores no processo. Os artigos abordavam temas como a possível substituição de jornalistas humanos por sistemas de IA, a administração do Twitter por Elon Musk, a política de imigração do governo Meloni e a competição entre chatbots e assistentes virtuais. Em junho de 2023, centenas de pessoas participaram num \"culto religioso alimentado por ChatGPT\" na Igreja de São Paulo em Fürth, Alemanha. O teólogo e filósofo Jonas Simmerlein, que presidiu, disse que foi \"cerca de 98 por cento da máquina\". O avatar gerado pelo ChatGPT disse às pessoas: \"Queridos amigos, é uma honra para mim estar aqui e pregar para vocês como a primeira inteligência artificial na convenção de protestantes deste ano na Alemanha\". As reações à cerimónia foram mistas. Em 2023, o deputado australiano Julian Hill informou o parlamento nacional de que o crescimento da IA poderia causar \"destruição em massa\"."}
{"source": "ChatGPT", "chunk_id": "ChatGPT_40", "text": "ano na Alemanha\". As reações à cerimónia foram mistas. Em 2023, o deputado australiano Julian Hill informou o parlamento nacional de que o crescimento da IA poderia causar \"destruição em massa\". Durante o seu discurso, parcialmente escrito pelo programa, alertou que isso poderia resultar em fraude, perda de empregos, discriminação, desinformação e aplicações militares incontroláveis. Elon Musk escreveu: \"O ChatGPT é assustadoramente bom. Não estamos longe de uma IA perigosamente forte\". Ele pausou o acesso da OpenAI a um banco de dados do Twitter em 2022, aguardando uma melhor compreensão dos planos da OpenAI, dizendo: \"A OpenAI foi iniciada como código aberto e sem fins lucrativos. Musk foi cofundador da OpenAI em 2015, em parte para lidar com o risco existencial da inteligência artificial, mas renunciou em 2018. Mais de 20.000 signatários, incluindo os principais cientistas de computação e fundadores de tecnologia Yoshua Bengio, Elon Musk e o cofundador da Apple Steve Wozniak,"}
{"source": "ChatGPT", "chunk_id": "ChatGPT_41", "text": "mas renunciou em 2018. Mais de 20.000 signatários, incluindo os principais cientistas de computação e fundadores de tecnologia Yoshua Bengio, Elon Musk e o cofundador da Apple Steve Wozniak, assinaram uma carta aberta de março de 2023 pedindo uma pausa imediata em experiências gigantes de IA como o ChatGPT, citando \"riscos profundos para a sociedade e a humanidade \". Geoffrey Hinton, um dos \"pais da IA\", expressou preocupação de que os futuros sistemas de IA possam superar a inteligência humana e deixou a Google em maio de 2023. Uma declaração de maio de 2023 de centenas de cientistas de IA, líderes da indústria de IA e outras figuras públicas exigiu que \"[m]itigar o risco de extinção da IA deveria ser uma prioridade global\". Outros proeminentes investigadores de IA falaram de forma mais otimista sobre os avanços. Juergen Schmidhuber, muitas vezes chamado de \"pai da IA moderna\", não assinou a carta, enfatizando que em 95% dos casos, a investigação em IA visa tornar \"a vida humana mais"}
{"source": "ChatGPT", "chunk_id": "ChatGPT_42", "text": "sobre os avanços. Juergen Schmidhuber, muitas vezes chamado de \"pai da IA moderna\", não assinou a carta, enfatizando que em 95% dos casos, a investigação em IA visa tornar \"a vida humana mais longa, mais saudável e mais fácil\". Schmidhuber acrescentou que embora a IA possa ser usada por malfeitores, ela \"também pode ser usada contra malfeitores\". Andrew Ng argumentou que \"é um erro cair na propaganda apocalíptica da IA – e que os reguladores que o fizerem apenas beneficiarão interesses adquiridos\". A WIRED escreveu que Yann LeCun \"zomba dos cenários distópicos de desinformação sobrecarregada dos seus pares e até, eventualmente, da extinção humana\". Desde o seu lançamento, o ChatGPT foi recebido com críticas de educadores, académicos, jornalistas, artistas, especialistas em ética e defensores públicos. Investigação académica As críticas aos LLM têm sido levantadas há vários anos; em 2020, algumas críticas foram feitas por Timnit Gebru, Emily Bender, Angelina McMillan-Major e Margaret"}
{"source": "ChatGPT", "chunk_id": "ChatGPT_43", "text": "públicos. Investigação académica As críticas aos LLM têm sido levantadas há vários anos; em 2020, algumas críticas foram feitas por Timnit Gebru, Emily Bender, Angelina McMillan-Major e Margaret Mitchell. O ChatGPT pode escrever introduções e secções de resumo de artigos científicos. Vários artigos listaram o ChatGPT como coautor. As revistas científicas têm reações diferentes ao ChatGPT. Algumas, incluindo a Nature e a JAMA Network, \"exigem que os autores divulguem o uso de ferramentas de geração de texto e proíbam listar um grande modelo de linguagem (LLM), como o ChatGPT, como coautor\". A Science \"proibiu completamente\" o uso de texto gerado por LLM em todos os seus jornais. O químico espanhol Rafael Luque publicou uma infinidade de artigos de investigação em 2023 que mais tarde admitiu terem sido escritos pelo ChatGPT. Os artigos apresentam um grande número de frases incomuns características dos LLM. Muitos autores argumentam que o uso do ChatGPT na academia para ensino e revisão"}
{"source": "ChatGPT", "chunk_id": "ChatGPT_44", "text": "terem sido escritos pelo ChatGPT. Os artigos apresentam um grande número de frases incomuns características dos LLM. Muitos autores argumentam que o uso do ChatGPT na academia para ensino e revisão é problemático devido à sua tendência a alucinar. Robin Bauwens, professor assistente da Universidade de Tilburg, descobriu que um relatório de revisão por pares gerado pelo ChatGPT sobre o seu artigo mencionava estudos falsos. De acordo com o bibliotecário Chris Granatino, da Biblioteca Lemieux da Universidade de Seattle, embora o próprio ChatGPT possa gerar conteúdo que aparentemente inclui citações legítimas, na maioria dos casos essas citações não são reais, ou pelo menos são em grande parte incorretas. Cibersegurança A Check Point Research e outros observaram que o ChatGPT pode escrever e-mails de phishing e malware, especialmente quando combinado com o OpenAI Codex. Os investigadores da CyberArk demonstraram que o ChatGPT poderia ser usado para criar malware polimórfico que poderia"}
{"source": "ChatGPT", "chunk_id": "ChatGPT_45", "text": "e-mails de phishing e malware, especialmente quando combinado com o OpenAI Codex. Os investigadores da CyberArk demonstraram que o ChatGPT poderia ser usado para criar malware polimórfico que poderia escapar aos produtos de segurança, exigindo pouco esforço do invasor. Desde o lançamento do ChatGPT no quarto trimestre de 2022 até ao quarto trimestre de 2023, houve um aumento de 1.265% em e-mails de phishing maliciosos e um aumento de 967% em phishing de credenciais, que profissionais de segurança cibernética argumentaram numa investigação do setor ser atribuível ao aumento do uso de inteligência artificial generativa (incluindo ChatGPT) por cibercriminosos. Programação Investigadores da Universidade Purdue analisaram as respostas do ChatGPT a 517 perguntas sobre engenharia de software ou programação de computadores colocadas no Stack Overflow quanto à correção, consistência, abrangência e concisão, e descobriram que 52% delas continham imprecisões e 77% eram detalhadas. Investigadores"}
{"source": "ChatGPT", "chunk_id": "ChatGPT_46", "text": "de computadores colocadas no Stack Overflow quanto à correção, consistência, abrangência e concisão, e descobriram que 52% delas continham imprecisões e 77% eram detalhadas. Investigadores da Universidade de Stanford e da Universidade da Califórnia em Berkeley descobriram que, ao criar respostas diretamente executáveis para os últimos 50 problemas de geração de código do LeetCode que foram classificados como \"fáceis\", o desempenho do GPT-3.5 e GPT-4 caiu de 22% e 52%, respetivamente, em março de 2023, para 2% e 10%, respetivamente, em junho de 2023. Economia Tem havido preocupação de que o ChatGPT possa substituir empregos, especialmente funções como redação criativa, comunicação, jornalismo, programação e inserção de dados. Educação O redator de tecnologia Dan Gillmor usou o ChatGPT em 2022 num trabalho escolar e descobriu que o texto gerado estava de acordo com o que um bom aluno entregaria e opinou que \"a academia tem alguns problemas muito sérios para enfrentar\". O professor de"}
{"source": "ChatGPT", "chunk_id": "ChatGPT_47", "text": "2022 num trabalho escolar e descobriu que o texto gerado estava de acordo com o que um bom aluno entregaria e opinou que \"a academia tem alguns problemas muito sérios para enfrentar\". O professor de geografia Terence Day avaliou as citações geradas pelo ChatGPT e descobriu que eram falsas. Apesar disso, ele escreve que \"os títulos dos artigos falsos são todos diretamente relevantes para as questões e poderiam potencialmente resultar em artigos excelentes. A falta de uma citação genuína poderia sinalizar uma oportunidade para um autor empreendedor preencher uma lacuna\". Segundo Day, é possível gerar cursos introdutórios à faculdade de alta qualidade com o ChatGPT; ele usou-o para escrever materiais sobre \"cursos introdutórios de geografia física, para o meu curso de segundo ano em hidrologia geográfica e cartografia de segundo ano, sistemas de informação geográfica e sensoriamento remoto\". Ele conclui que \"esta abordagem poderia ter relevância significativa para a aprendizagem aberta e"}
{"source": "ChatGPT", "chunk_id": "ChatGPT_48", "text": "geográfica e cartografia de segundo ano, sistemas de informação geográfica e sensoriamento remoto\". Ele conclui que \"esta abordagem poderia ter relevância significativa para a aprendizagem aberta e poderia potencialmente afetar os atuais modelos de publicação de livros didáticos\". Mercados financeiros A empresa de tecnologia de IA c3.ai viu um aumento de 28% no preço das suas ações após anunciar a integração do ChatGPT no seu kit de ferramentas. O preço das ações da BuzzFeed, empresa de média digital não relacionada à IA, aumentou 120% após anunciar a adoção da tecnologia OpenAI para criação de conteúdo. A Reuters descobriu que os preços das ações das empresas relacionadas à IA BigBear.ai e SoundHound AI aumentaram 21% e 40%, respetivamente, embora não tivessem conexão direta com o ChatGPT. Eles atribuíram este aumento ao papel do ChatGPT em transformar a IA na palavra da moda em Wall Street. Uma investigação académica publicada na Finance Research Letters descobriu que o 'efeito"}
{"source": "ChatGPT", "chunk_id": "ChatGPT_49", "text": "Eles atribuíram este aumento ao papel do ChatGPT em transformar a IA na palavra da moda em Wall Street. Uma investigação académica publicada na Finance Research Letters descobriu que o 'efeito ChatGPT' levou os investidores de retalho a aumentar os preços dos ativos de criptomoeda relacionados à IA, apesar do mercado mais amplo de criptomoedas estar num mercado em baixa e diminuido interesse dos investidores institucionais. Isto confirma as descobertas anedóticas da Bloomberg de que, em resposta ao lançamento do ChatGPT, os investidores em criptomoedas mostraram uma preferência por ativos criptográficos relacionados com IA. Uma experiência realizado pelo finder.com revelou que o ChatGPT poderia superar os gestores de fundos populares ao escolher ações com base em critérios como histórico de crescimento e níveis de dívida, resultando num aumento de 4,9% numa conta hipotética de 38 ações, superando 10 fundos de investimento de referência com uma perda média de 0,8%. Por outro lado,"}
{"source": "ChatGPT", "chunk_id": "ChatGPT_50", "text": "de crescimento e níveis de dívida, resultando num aumento de 4,9% numa conta hipotética de 38 ações, superando 10 fundos de investimento de referência com uma perda média de 0,8%. Por outro lado, executivos e gestores de investimentos de fundos quantitativos de Wall Street (incluindo aqueles que usam aprendizagem de máquina há décadas) notaram que o ChatGPT comete regularmente erros óbvios que seriam financeiramente onerosos para os investidores, porque mesmo os sistemas de IA que empregam aprendizagem por reforço ou autoaprendizagem têm tido apenas um sucesso limitado na previsão das tendências do mercado devido à qualidade inerentemente ruidosa dos dados de mercado e dos sinais financeiros. Em novembro de 2023, uma investigação conduzida pela Patronus AI, uma empresa startup de inteligência artificial, comparou o desempenho do GPT-4, GPT-4-Turbo, Claude2 e LLaMA-2 em duas versões de um teste de 150 perguntas sobre informações em declarações financeiras (por exemplo, Formulário 10-K,"}
{"source": "ChatGPT", "chunk_id": "ChatGPT_51", "text": "artificial, comparou o desempenho do GPT-4, GPT-4-Turbo, Claude2 e LLaMA-2 em duas versões de um teste de 150 perguntas sobre informações em declarações financeiras (por exemplo, Formulário 10-K, Formulário 10-Q, Formulário 8-K, relatórios de lucros, transcrições de teleconferências de lucros) enviados por empresas públicas à Comissão de Valores Mobiliários dos EUA (SEC)|Comissão de Valores Mobiliários. Uma versão do teste exigia que os modelos generativos de IA usassem um sistema de recuperação para encontrar o arquivo específico da SEC para responder às perguntas; a outra deu aos modelos o arquivo específico da SEC para responder à pergunta (ou seja, numa longa janela de contexto). Na versão do sistema de recuperação, o GPT-4-Turbo e LLaMA-2 não conseguiram produzir respostas corretas para 81% das perguntas, enquanto que na versão de janela de contexto longa, GPT-4-Turbo e Claude-2 não conseguiram produzir respostas corretas para 21% e 24% das questões, respetivamente. Medicina No"}
{"source": "ChatGPT", "chunk_id": "ChatGPT_52", "text": "para 81% das perguntas, enquanto que na versão de janela de contexto longa, GPT-4-Turbo e Claude-2 não conseguiram produzir respostas corretas para 21% e 24% das questões, respetivamente. Medicina No domínio dos cuidados de saúde, possíveis utilizações e preocupações estão sob escrutínio por associações profissionais e por profissionais. Dois artigos iniciais indicaram que o ChatGPT poderia passar no Exame de Licenciamento Médico dos Estados Unidos (USMLE). O MedPage Today observou em janeiro de 2023 que \"os investigadores publicaram vários artigos agora divulgando estes programas de IA como ferramentas úteis na educação médica, investigação e até mesmo na tomada de decisões clínicas\". Dois artigos que foram publicados separadamente em fevereiro de 2023 avaliaram novamente a proficiência do ChatGPT em medicina usando o USMLE. Os resultados foram publicados na JMIR Medical Education (ver Journal of Medical Internet Research) e na PLOS Digital Health. Os autores do artigo da PLOS"}
{"source": "ChatGPT", "chunk_id": "ChatGPT_53", "text": "do ChatGPT em medicina usando o USMLE. Os resultados foram publicados na JMIR Medical Education (ver Journal of Medical Internet Research) e na PLOS Digital Health. Os autores do artigo da PLOS Digital Health afirmaram que os resultados \"sugerem que grandes modelos de linguagem podem ter o potencial de auxiliar na educação médica e, potencialmente, na tomada de decisões clínicas\". Na JMIR Medical Education, os autores do outro artigo concluíram que \"o ChatGPT tem um desempenho no nível esperado de um estudante de medicina do terceiro ano na avaliação da competência primária do conhecimento médico.\" Eles sugerem que poderia ser usado como um \"ambiente de aprendizagem interativo para os alunos\". A própria IA, solicitada pelos investigadores, concluiu que \"este estudo sugere que o ChatGPT tem potencial para ser usado como tutor médico virtual, mas são necessárias mais investigações para avaliar melhor o seu desempenho e usabilidade neste contexto\". A versão ChatGPT lançada posteriormente"}
{"source": "ChatGPT", "chunk_id": "ChatGPT_54", "text": "potencial para ser usado como tutor médico virtual, mas são necessárias mais investigações para avaliar melhor o seu desempenho e usabilidade neste contexto\". A versão ChatGPT lançada posteriormente baseada em GPT-4 superou significativamente a versão baseada em GPT-3.5. Investigadores da Universidade de Stanford e da Universidade da Califórnia em Berkeley descobriram que o desempenho do GPT-3.5 e GPT-4 no USMLE diminuiu de março de 2023 a junho de 2023. Um artigo de março de 2023 testou a aplicação do ChatGPT em toxicologia clínica. Os autores descobriram que a IA \"saiu-se bem\" ao responder a um \"[exemplo de caso clínico] muito simples, improvável de ser esquecido por qualquer profissional da área\". Eles acrescentaram: \"À medida que o ChatGPT se torna mais desenvolvido e adaptado especificamente para a medicina, ele poderá um dia ser útil em casos clínicos menos comuns (i.e., casos que os especialistas às vezes ignoram). Ao invés de a IA substituir os humanos (médicos), nós vemo-la"}
{"source": "ChatGPT", "chunk_id": "ChatGPT_55", "text": "para a medicina, ele poderá um dia ser útil em casos clínicos menos comuns (i.e., casos que os especialistas às vezes ignoram). Ao invés de a IA substituir os humanos (médicos), nós vemo-la como 'médicos que usam IA' substituindo 'médicos que não usam IA' nos próximos anos.\" Um estudo de abril de 2023 na Radiology testou a capacidade da IA de responder a perguntas sobre o rastreio do cancro da mama. Os autores descobriram que respondia adequadamente \"cerca de 88 por cento das vezes\", no entanto, num caso (por exemplo), dava conselhos que se tinham tornado desatualizados cerca de um ano antes. A abrangência das suas respostas também faltou. Um estudo publicado na JAMA Internal Medicine naquele mesmo mês descobriu que o ChatGPT muitas vezes superava os médicos humanos a responder às perguntas dos pacientes (quando comparado com perguntas e respostas encontradas no /r/AskDocs, um fórum no Reddit onde moderadores validam as credenciais médicas dos profissionais; o estudo reconhece a fonte"}
{"source": "ChatGPT", "chunk_id": "ChatGPT_56", "text": "dos pacientes (quando comparado com perguntas e respostas encontradas no /r/AskDocs, um fórum no Reddit onde moderadores validam as credenciais médicas dos profissionais; o estudo reconhece a fonte como uma limitação). Os autores do estudo sugerem que a ferramenta poderia ser integrada a sistemas médicos para ajudar os médicos a redigir respostas às perguntas dos pacientes. Os profissionais enfatizaram as limitações do ChatGPT na prestação de assistência médica. Em correspondência com a The Lancet Infectious Diseases, três especialistas em antimicrobianos escreveram que \"as maiores barreiras à implementação do ChatGPT na prática clínica são os défices na consciência situacional, na inferência e na consistência. Estas deficiências podem pôr em risco a segurança do paciente\". A Physician's Weekly, embora também discuta o uso potencial do ChatGPT em contextos médicos (por exemplo, \"como um assistente digital para médicos, desempenhando várias funções administrativas, como coletar"}
{"source": "ChatGPT", "chunk_id": "ChatGPT_57", "text": "Weekly, embora também discuta o uso potencial do ChatGPT em contextos médicos (por exemplo, \"como um assistente digital para médicos, desempenhando várias funções administrativas, como coletar informações de registos de pacientes ou categorizar dados de pacientes por histórico familiar, sintomas, resultados laboratoriais, possíveis alergias, etc.\"), alertou que a IA pode, às vezes, fornecer informações fabricadas ou tendenciosas. Um radiologista alertou: \"Vimos na nossa experiência que o ChatGPT às vezes inventa artigos de jornais ou consórcios de saúde falsos para apoiar as suas afirmações\"; Conforme relatado num artigo da Mayo Clinic Proceedings: Digital Health, o ChatGPT pode fazer isso para até 69% das suas referências médicas citadas. Os investigadores enfatizaram que embora muitas das suas referências tenham sido fabricadas, aquelas que o foram pareciam \"enganosamente reais\". No entanto, como o Dr. Stephen Hughes mencionou para o The Conversation, o ChatGPT é capaz de aprender a"}
{"source": "ChatGPT", "chunk_id": "ChatGPT_58", "text": "suas referências tenham sido fabricadas, aquelas que o foram pareciam \"enganosamente reais\". No entanto, como o Dr. Stephen Hughes mencionou para o The Conversation, o ChatGPT é capaz de aprender a corrigir os seus erros do passado. Ele também observou o \"puritanismo\" da IA em relação a temas de saúde sexual. Ao contrário das descobertas anteriores, as respostas do ChatGPT às questões relacionadas à anestesia foram mais precisas, sucintas e descritivas em comparação com as do Bard. O Bard exibiu 30,3% de erro na resposta em comparação com o ChatGPT (0% de erro). Numa conferência da Sociedade Americana de Farmacêuticos do Sistema de Saúde em dezembro de 2023, investigadores da Universidade de Long Island (LIU) apresentaram um estudo que investigou as respostas do ChatGPT a 45 perguntas frequentes do serviço de informações sobre medicamentos da Faculdade de Farmácia da LIU durante um período de 16 meses de 2022 a 2023, em comparação com as respostas investigadas fornecidas por"}
{"source": "ChatGPT", "chunk_id": "ChatGPT_59", "text": "frequentes do serviço de informações sobre medicamentos da Faculdade de Farmácia da LIU durante um período de 16 meses de 2022 a 2023, em comparação com as respostas investigadas fornecidas por farmacêuticos profissionais. Para 29 das 39 questões para as quais havia literatura médica suficiente para uma resposta baseada em dados, o ChatGPT não forneceu uma resposta direta ou forneceu uma resposta errada ou incompleta (e em alguns casos, se fosse posta em prática, a resposta colocaria em perigo a saúde do paciente). Os investigadores pediram ao ChatGPT que fornecesse citações de investigações médicas para todas as suas respostas, mas fê-lo apenas para oito, e todas as oito incluíram pelo menos uma citação fabricada (falsa). Um estudo de janeiro de 2024 conduzido por investigadores do Centro Médico Pediátrico Cohen descobriu que o GPT-4 tinha uma taxa de precisão de 17% no diagnóstico de casos médicos pediátricos. Direito Em janeiro de 2023, o senador do estado de Massachusetts Barry"}
{"source": "ChatGPT", "chunk_id": "ChatGPT_60", "text": "Médico Pediátrico Cohen descobriu que o GPT-4 tinha uma taxa de precisão de 17% no diagnóstico de casos médicos pediátricos. Direito Em janeiro de 2023, o senador do estado de Massachusetts Barry Finegold e o deputado estadual Josh S. Cutler propuseram um projeto de lei parcialmente escrito por ChatGPT, \"Uma Lei elaborada com a ajuda do ChatGPT para regular modelos generativos de inteligência artificial como o ChatGPT\", que exigiria que as empresas divulgassem os seus algoritmos e práticas de recolha de dados ao Ministério Público Estadual, organizassem avaliações de risco regulares e contribuíssem para a prevenção do plágio. O projeto foi apresentado oficialmente durante uma sessão em 13 de julho. Em 11 de abril de 2023, um juiz de um tribunal de sessão no Paquistão usou o ChatGPT para decidir a fiança de um acusado de 13 anos num caso. O tribunal citou o uso da assistência ChatGPT no seu veredito: O modelo de linguagem AI respondeu: O juiz fez outras perguntas ao ChatGPT sobre o"}
{"source": "ChatGPT", "chunk_id": "ChatGPT_61", "text": "decidir a fiança de um acusado de 13 anos num caso. O tribunal citou o uso da assistência ChatGPT no seu veredito: O modelo de linguagem AI respondeu: O juiz fez outras perguntas ao ChatGPT sobre o caso e formulou a sua decisão final à luz das respostas. Em Mata v. Avianca, Inc., 22-cv-1461 (PKC),​​ uma ação por danos pessoais contra a Avianca Airlines movida no Tribunal Distrital do Sul de Nova Iorque dos EUA em maio de 2023 (presidida pelo Juiz Sénior P. Kevin Castel), os advogados supostamente usaram o ChatGPT para gerar uma moção legal. O ChatGPT gerou inúmeros processos jurídicos fictícios envolvendo companhias aéreas fictícias com cotações e citações internas fabricadas na ação judicial. Castel notou inúmeras inconsistências nos resumos de opinião e classificou a análise jurídica de um dos casos como \"absurda\". Os advogados do queixoso enfrentaram possíveis sanções judiciais e expulsão da Ordem por apresentarem a petição e apresentarem as decisões legais fictícias geradas pelo"}
{"source": "ChatGPT", "chunk_id": "ChatGPT_62", "text": "um dos casos como \"absurda\". Os advogados do queixoso enfrentaram possíveis sanções judiciais e expulsão da Ordem por apresentarem a petição e apresentarem as decisões legais fictícias geradas pelo ChatGPT como autênticas. O caso foi arquivado e os advogados foram multados em 5.000 dólares. Em outubro de 2023, a Câmara Municipal de Porto Alegre (Rio Grande do Sul), aprovou por unanimidade uma portaria local proposta pelo vereador Ramiro Rosário que isentaria os moradores do pagamento pela substituição de medidores de consumo de água furtados; o projeto entrou em vigor em 23 de novembro. No dia 29 de novembro, Rosário revelou que o projeto de lei foi integralmente redigido pelo ChatGPT e que apresentou-o ao resto do conselho sem fazer alterações ou divulgar o envolvimento do chatbot. O presidente da Câmara Municipal, Hamilton Sossmeier, inicialmente criticou a iniciativa de Rosário, dizendo que poderia representar \"um precedente perigoso\", mas depois disse que \"mudou de ideias\":"}
{"source": "ChatGPT", "chunk_id": "ChatGPT_63", "text": "O presidente da Câmara Municipal, Hamilton Sossmeier, inicialmente criticou a iniciativa de Rosário, dizendo que poderia representar \"um precedente perigoso\", mas depois disse que \"mudou de ideias\": \"infelizmente ou felizmente, isto vai ser um tendência.\" SearchGPT Análise da conversação Aprendizagem supervisionada Assistente virtual inteligente Filosofia da inteligência artificial GPT-4 Gemini Modelo de linguagem grande Processamento de linguagem natural Risco existencial da inteligência artificial geral Tay Teste de Turing Ética da inteligência artificial Wolfram, Stephen (14 de fevereiro de 2023). «What Is ChatGPT Doing … and Why Does It Work?». Stephen Wolfram Writings. Consultado em 14 de abril de 2023 Media relacionados com ChatGPT no Wikimedia Commons «Página oficial» «O fenômeno Chat GPT explicada por Alexeï Grinbaum» (em francês) «ChatGPT Prompt Engineering for Developers». , curso por Andrew Ng e OpenAI. «ChatGPT consegue escrever um episódio de podcast?» (em inglês)."}
{"source": "ChatGPT", "chunk_id": "ChatGPT_64", "text": "Chat GPT explicada por Alexeï Grinbaum» (em francês) «ChatGPT Prompt Engineering for Developers». , curso por Andrew Ng e OpenAI. «ChatGPT consegue escrever um episódio de podcast?» (em inglês). podcast Planet Money, Instituto NPR (maio de 2023). «O Chat GPT fará mais mal do que bem?» (em inglês). debate de Gary Marcus e Keith Teare, Instituto Open to Debate (fevereiro de 2023). The Cost of AI, ganhos e perdas projetadas em nível mundial, Pay Stubs «Chat.d-ID assistente virtual do ChatGPT» Videos: «Study finds ChatGPT struggles with public health referrals» (em inglês). CBS (junho de 2023) «What if ChatGPT had a body?» (em inglês). ABC (março de 2023) «What is ChatGPT?» (em inglês). BBC (janeiro de 2023) «How good is ChatGPT?» (em inglês). CNN (janeiro de 2023) «Cheating With ChatGPT» (em inglês). The Wall Street Journal (dezembro de 2022)"}
{"source": "GPT-4", "chunk_id": "GPT-4_0", "text": "Generative Pre-trained Transformer 4 (GPT-4) é um modelo de linguagem grande multimodal criado pela OpenAI e o quarto modelo da série GPT. Foi lançado em 14 de março de 2023, e se tornou publicamente aberto de forma limitada por meio do ChatGPT Plus, com o seu acesso à API comercial sendo provido por uma lista de espera. Sendo um transformador, foi pré-treinado para prever o próximo token (usando dados públicos e \"licenciados de provedores terceirizados\"), e então foi aperfeiçoado através de uma técnica de aprendizagem por reforço com humanos. A empresa Microsoft, após o lançamento do modelo, confirmou que versões do Bing utilizando o GPT estavam, de fato, utilizando o modelo mais recente da OpenAI antes de seu lançamento oficial. Diferentemente de seu predecessor, o GPT-3, o GPT-4 é capaz de processar imagens como entrada, não apenas texto, analisando o conteúdo da imagem de forma semelhante a um humano, e emitindo uma saída em forma de texto. Pesquisadores da Microsoft testaram o"}
{"source": "GPT-4", "chunk_id": "GPT-4_1", "text": "de processar imagens como entrada, não apenas texto, analisando o conteúdo da imagem de forma semelhante a um humano, e emitindo uma saída em forma de texto. Pesquisadores da Microsoft testaram o modelo com problemas médicos e descobriram \"que o GPT-4, sem qualquer criação especializada de prompt, excede a nota de aprovação do United States Medical Licensing Examination por mais de 20 pontos e supera modelos mais antigos de uso geral (GPT 3.5) assim como modelos especificamente aperfeiçoados com conhecimento médico (Med-PaLM, uma versão ajustada ao prompt do Flan-PaLM 540B).\" Em outro artigo científico, pesquisadores testaram o modelo e concluíram que \"poderia ser razoavelmente visto como uma versão inicial (embora que incompleta) de um sistema de inteligência artificial geral (AGI)\". Em resposta ao desenvolvimento e implementação do GPT-4, um grupo de mais de mil especialistas em inteligência artificial e executivos da indústria de tecnologia assinou uma carta aberta solicitando uma"}
{"source": "GPT-4", "chunk_id": "GPT-4_2", "text": "resposta ao desenvolvimento e implementação do GPT-4, um grupo de mais de mil especialistas em inteligência artificial e executivos da indústria de tecnologia assinou uma carta aberta solicitando uma pausa de seis meses no treinamento de sistemas de inteligência artificial mais poderosos que o GPT-4. Entre os signatários estão Elon Musk, Steve Wozniak e Emad Mostaque, além de pesquisadores da DeepMind. Os especialistas argumentam que a indústria está em \"uma corrida fora de controle para desenvolver e implementar mentes digitais cada vez mais poderosas que ninguém, nem mesmo seus criadores, pode entender, prever ou controlar com segurança\". Eles acreditam que esses sistemas podem representar \"riscos profundos para a sociedade e a humanidade\", incluindo a disseminação de desinformação e a substituição de empregos pela automação. Na carta aberta, os signatários pedem que as empresas envolvidas no desenvolvimento desses sistemas façam uma pausa pública e verificável em seus esforços,"}
{"source": "GPT-4", "chunk_id": "GPT-4_3", "text": "a substituição de empregos pela automação. Na carta aberta, os signatários pedem que as empresas envolvidas no desenvolvimento desses sistemas façam uma pausa pública e verificável em seus esforços, incluindo todos os principais atores da indústria. Caso essa pausa não seja implementada rapidamente, os especialistas solicitam a intervenção dos governos para instituir uma suspensão. A carta foi emitida pelo Instituto Future of Life, uma organização sem fins lucrativos que conta com Elon Musk entre seus consultores externo."}
{"source": "GPT-5", "chunk_id": "GPT-5_0", "text": "Generative Pre-trained Transformer 5 (GPT-5) é um modelo de linguagem de grande escala multimodal desenvolvido pela OpenAI e o quinto da sua série de modelos básicos de transformadores pré-treinados generativos (GPT). Precedido pelo GPT-4, foi lançado em 7 de agosto de 2025, combinando recursos de raciocínio e não raciocínio em uma interface unificada. Na época do lançamento, o GPT-5 apresentava desempenho de ponta em diversos benchmarks. O modelo está disponível publicamente para usuários dos produtos de chatbot ChatGPT e Microsoft Copilot, bem como para desenvolvedores por meio da API da OpenAI. Em 2018, a OpenAI apresentou o primeiro modelo GPT (GPT-1) publicando o artigo chamado \"Melhorando a compreensão da linguagem por meio do pré-treinamento generativo\". Foi baseado na arquitetura transformer e treinado em um grande corpus de livros. Em 2019, a OpenAI lançou o GPT-2, um modelo maior capaz de gerar texto coerente. Em 2020, a OpenAI lançou o GPT-3, com 100 vezes mais parâmetros"}
{"source": "GPT-5", "chunk_id": "GPT-5_1", "text": "transformer e treinado em um grande corpus de livros. Em 2019, a OpenAI lançou o GPT-2, um modelo maior capaz de gerar texto coerente. Em 2020, a OpenAI lançou o GPT-3, com 100 vezes mais parâmetros que o GPT-2. Ele conseguia executar diversas tarefas a partir de poucos exemplos. O GPT-3 foi aprimorado no InstructGPT, que em 2022 deu origem ao ChatGPT, o principal produto de chatbot da OpenAI. Inicialmente, o ChatGPT era baseado no GPT-3.5, mas depois foi migrado para o GPT-4, lançado em 14 de março de 2023. Em 14 de abril de 2023, Sam Altman, CEO da OpenAI, discursou em um evento no Instituto de Tecnologia de Massachusetts (MIT) e declarou que a empresa não estava treinando o GPT-5 naquele momento. Ele disse que a OpenAI estava \"priorizando o desenvolvimento do GPT-4\" e que \"não estamos [treinando] e não lançaremos o GPT-5 por algum tempo\". Em 18 de julho, a OpenAI entrou com um pedido de registro da marca \"GPT-5\" nos Estados Unidos. Em 13 de novembro, Altman confirmou ao Financial"}
{"source": "GPT-5", "chunk_id": "GPT-5_2", "text": "[treinando] e não lançaremos o GPT-5 por algum tempo\". Em 18 de julho, a OpenAI entrou com um pedido de registro da marca \"GPT-5\" nos Estados Unidos. Em 13 de novembro, Altman confirmou ao Financial Times que a empresa estava trabalhando no desenvolvimento do GPT-5. Segundo o The Information, \"[d]urante grande parte do segundo semestre de 2024, a OpenAI desenvolveu um modelo conhecido internamente como Orion, que deveria se tornar o GPT-5\", mas \"[o] esforço do Orion não conseguiu produzir um modelo superior, e a empresa o lançou como GPT-4.5 em fevereiro de 2025.\" No final de julho de 2025, havia grande expectativa de que a OpenAI lançaria o GPT-5 no início de agosto. Em 30 de julho, o The Verge noticiou que \"a Microsoft está se preparando para o GPT-5\", já que \"fontes familiarizadas com os planos de IA da Microsoft\" relataram a um editor que a empresa estava testando um novo modo para seu chatbot Copilot, oferecendo um modelo que \"pensa profundamente ou rapidamente, dependendo da"}
{"source": "GPT-5", "chunk_id": "GPT-5_3", "text": "os planos de IA da Microsoft\" relataram a um editor que a empresa estava testando um novo modo para seu chatbot Copilot, oferecendo um modelo que \"pensa profundamente ou rapidamente, dependendo da tarefa\". Em 5 de agosto, na preparação para o lançamento do GPT-5, a OpenAI lançou o GPT-OSS, um conjunto de dois modelos de dois modelos aberto com recursos de raciocínio. Em 6 de agosto, a OpenAI anunciou um evento de transmissão ao vivo marcado para 7 de agosto. No anúncio, a empresa substituiu a letra \"s\" em \"transmissão ao vivo\" pelo número \"5\", sinalizando sua intenção de revelar o GPT-5 durante a apresentação. Na época de seu lançamento, o GPT-5 apresentava desempenho de ponta em benchmarks que avaliaram matemática, programação e compreensão multimodal. Segundo a OpenAI, as melhorias em relação aos modelos anteriores incluem tempos de resposta mais rápidos, melhores capacidades de codificação e escrita, respostas mais precisas a perguntas sobre saúde e níveis mais baixos de"}
{"source": "GPT-5", "chunk_id": "GPT-5_4", "text": "em relação aos modelos anteriores incluem tempos de resposta mais rápidos, melhores capacidades de codificação e escrita, respostas mais precisas a perguntas sobre saúde e níveis mais baixos de alucinação. Além disso, em comparação com seus predecessores, o GPT-5 foi projetado para fornecer respostas seguras e de alto nível a consultas potencialmente prejudiciais, em vez de recusá-las de forma absoluta, abordagem que a OpenAI denomina \"conclusões seguras\", com o objetivo de tornar o GPT-5 capaz de recusar perguntas realmente arriscadas, ao mesmo tempo em que reduz rejeições a usuários que buscam informações inofensivas. Também foi treinado para oferecer respostas mais críticas e \"menos efusivamente agradáveis\" em comparação com versões anteriores. Dias antes do lançamento do GPT-5, dois dos primeiros testadores do modelo afirmaram estar \"impressionados\" com sua capacidade de programar e resolver problemas de matemática e ciências. Eles destacaram que o modelo representava uma melhoria"}
{"source": "GPT-5", "chunk_id": "GPT-5_5", "text": "primeiros testadores do modelo afirmaram estar \"impressionados\" com sua capacidade de programar e resolver problemas de matemática e ciências. Eles destacaram que o modelo representava uma melhoria significativa em relação ao GPT-4, embora não tão expressiva quanto a transição do GPT-3 para o GPT-4. Um dia antes do lançamento, durante uma coletiva de imprensa, Sam Altman, CEO da OpenAI, descreveu o GPT-5 como \"um passo significativo no caminho para a AGI\", referindo-se à inteligência artificial geral, nível hipotético definido pela empresa como a capacidade de executar qualquer tarefa economicamente valiosa que um humano pode realizar. De acordo com Altman, o GPT-5 é \"significativamente melhor\" do que seus antecessores, oferecendo habilidades de \"nível de doutorado\" em uma ampla gama de tarefas. O consumo exato de energia do GPT-5 não foi divulgado pela OpenAI. Pesquisadores da Universidade de Rhode Island estimaram que uma resposta de duração média consome pouco mais de 18"}
{"source": "GPT-5", "chunk_id": "GPT-5_6", "text": "gama de tarefas. O consumo exato de energia do GPT-5 não foi divulgado pela OpenAI. Pesquisadores da Universidade de Rhode Island estimaram que uma resposta de duração média consome pouco mais de 18 watts-hora, o equivalente ao uso de uma lâmpada incandescente por cerca de 18 minutos. GPT-5 é um sistema que reúne um modelo rápido e de alto desempenho, um modelo de raciocínio mais profundo e um roteador em tempo real que decide qual modelo utilizar com base no tipo de conversação, na complexidade, nas necessidades da ferramenta e na intenção explícita do usuário. Samuel Altman havia criticado anteriormente o seletor manual de modelos por ser excessivamente complexo, defendendo a necessidade de unificação. O GPT-5 também incorpora funcionalidades agentic, permitindo que configure sua própria área de trabalho e utilize o navegador para pesquisar autonomamente fontes relacionadas à tarefa em execução. O cartão do sistema define dois modelos rápidos e de alto deemepenho – gpt-5-main e"}
{"source": "GPT-5", "chunk_id": "GPT-5_7", "text": "área de trabalho e utilize o navegador para pesquisar autonomamente fontes relacionadas à tarefa em execução. O cartão do sistema define dois modelos rápidos e de alto deemepenho – gpt-5-main e gpt-5-main-mini – e dois modelos de raciocínio – gpt-5-thinking e gpt-5-thinking-mini. Na API da OpenAI, os desenvolvedores podem acessar o modelo de raciocínio, sua versão mini e o gpt-5-thinking-nano, uma versão nano ainda menor e mais veloz. Além disso, o ChatGPT fornece acesso ao gpt-5-thinking com uma configuração que utiliza computação em tempo de teste paralelo, chamada gpt-5-thinking-pro.[carece de fontes?] A Neuraltrust, uma empresa de pesquisa de segurança, afirmou ter comprometido com sucesso o GPT-5 no primeiro dia de testes do modelo. De acordo com seu relatório, isso permitiu que o GPT-5 gerasse instruções detalhadas para a fabricação de dispositivos explosivos. A SPLX, outra empresa, conduziu testes semelhantes e chegou a conclusões semelhantes sobre a segurança do GPT-5. Suas"}
{"source": "GPT-5", "chunk_id": "GPT-5_8", "text": "GPT-5 gerasse instruções detalhadas para a fabricação de dispositivos explosivos. A SPLX, outra empresa, conduziu testes semelhantes e chegou a conclusões semelhantes sobre a segurança do GPT-5. Suas avaliações sugerem que o GPT-5 tem lacunas de segurança significativas, potencialmente tornando-o inseguro para uso em um ambiente corporativo. De acordo com a Research AIMultiple, existe um artigo sobre o GPT-5 que afirma: \"Treinamento multimodal nativo desde o início...\". Segundo o artigo do ArXiv Paper, a modelagem nativa refere-se a \"modelos treinados do zero em todas as modalidades simultaneamente, sem depender de LLMs ou codificadores de visão pré-treinados.\" Simplificando, isso significa modelos treinados do zero em todas as modalidades ao mesmo tempo, sem realizar partes de modelos de texto ou imagem já existentes. Voltando à Research AIMultiple, na seção \"Como funciona o GPT-5?\", sob o subtítulo que diz \"2. Processo de treinamento\", afirma -se: \"O GPT-5 foi treinado usando uma"}
{"source": "GPT-5", "chunk_id": "GPT-5_9", "text": "de texto ou imagem já existentes. Voltando à Research AIMultiple, na seção \"Como funciona o GPT-5?\", sob o subtítulo que diz \"2. Processo de treinamento\", afirma -se: \"O GPT-5 foi treinado usando uma combinação de pré-treinamento não supervisionado, ajuste fino supervisionado e aprendizado por reforço com feedback humano (RLHF)...\". No subtítulo \"2.1 Pré-treinamento\", é detalhado: \"Treinado em um vasto corpus de livros, artigos, códigos, páginas da web, trabalhos acadêmicos e conjuntos de dados licenciados, abrangendo vários idiomas e domínios\". Já no subtítulo \"2.2 Ajuste fino e condicionamento multimodal\", observa-se: \"Ao contrário do GPT-4, as capacidades visuais do GPT-5 foram treinadas junto com o texto desde o início...\". O GPT-5 é descrito como nativamente multimodal, o que significa que foi treinado do zero em múltiplas modalidades (como texto e imagens) simultaneamente, sem depender de modelos pré-treinados. Seu processo de treinamento envolveu três etapas: pré-treinamento"}
{"source": "GPT-5", "chunk_id": "GPT-5_10", "text": "que foi treinado do zero em múltiplas modalidades (como texto e imagens) simultaneamente, sem depender de modelos pré-treinados. Seu processo de treinamento envolveu três etapas: pré-treinamento não supervisionado, ajuste fino supervisionado e RLHF. O pré-treinamento utilizou um enorme conjunto de dados multilíngues de livros, artigos, fontes licenciadas, etc. Diferentemente do GPT-4, os recursos visuais e de texto do GPT-5 foram treinados conjuntamente desde o início.[carece de fontes?] O GPT-5 é usado no ChatGPT. Embora o GPT-5 seja gratuito para todos os usuários do ChatGPT, os usuários Plus obtêm limites de uso mais altos, enquanto os usuários Pro obtêm acesso ilimitado ao GPT-5, bem como acesso limitado ao GPT-5 Pro. Os limites padrão para usuários de nível inferior em respostas por hora ainda se aplicam. Além disso, com a introdução do GPT-5, o \"Modo de voz avançado\" do ChatGPT foi substituído pelo \"ChatGPT Voice\", que deve permitir conversas com som mais natural. A OpenAI"}
{"source": "GPT-5", "chunk_id": "GPT-5_11", "text": "por hora ainda se aplicam. Além disso, com a introdução do GPT-5, o \"Modo de voz avançado\" do ChatGPT foi substituído pelo \"ChatGPT Voice\", que deve permitir conversas com som mais natural. A OpenAI declarou que \"o Modo de voz padrão será desativado em 9 de setembro de 2025, unificando todos os usuários no ChatGPT Voice\". O GPT-5 também está disponível no Microsoft Copilot, e a Microsoft declarou que incorporará o GPT-5 em uma ampla variedade de seus produtos. De acordo com o 9to5Mac, a Apple está planejando integrar o modelo ao recurso Apple Intelligence em seus sistemas operacionais iOS 26, iPadOS 26 e macOS Tahoe. Também é acessível por meio da API OpenAI. Várias empresas americanas foram relatadas como tendo recebido acesso ao GPT-5 antes de seu lançamento. A OpenAI afirmou que a seguradora privada de saúde Oscar Health estava verificando os pedidos de seus segurados com o modelo. Além disso, a Uber estava usando o GPT-5 para seu sistema de suporte ao cliente; GitLab, Windsurf e"}
{"source": "GPT-5", "chunk_id": "GPT-5_12", "text": "privada de saúde Oscar Health estava verificando os pedidos de seus segurados com o modelo. Além disso, a Uber estava usando o GPT-5 para seu sistema de suporte ao cliente; GitLab, Windsurf e Cursor estavam usando o modelo para desenvolvimento de software; e o banco espanhol BBVA o estava usando para análises financeiras. Outras empresas que a OpenAI listou como tendo usado o GPT-5 antes do lançamento incluem Amgen, Lowe's e Notion. Grace Huckins argumentou na MIT Technology Review que, \"[enquanto] o o1 foi um grande avanço tecnológico, o GPT-5 é, acima de tudo, um produto refinado.\" Em resposta às alegações que Sam Altman, o CEO da OpenAI, fez sobre o modelo, ela declarou que \"o GPT-5 fornecerá uma experiência de usuário mais agradável e contínua. Isso não é nada, mas está muito aquém do futuro transformador da IA que Altman passou grande parte do ano passado promovendo.\" Em resposta à afirmação de Altman de que o GPT-5 é \"um passo significativo no caminho\" para a inteligência"}
{"source": "GPT-5", "chunk_id": "GPT-5_13", "text": "do futuro transformador da IA que Altman passou grande parte do ano passado promovendo.\" Em resposta à afirmação de Altman de que o GPT-5 é \"um passo significativo no caminho\" para a inteligência artificial geral, ela observou: \"[T]alvez ele esteja certo - mas se estiver, é um passo muito pequeno.\" Em The Information, Stephanie Palazzolo elogiou as capacidades de codificação do GPT-5. De acordo com Matteo Wong no The Atlantic, o GPT-5 \"é intuitivo, rápido e eficiente; adapta-se às preferências e intenções humanas; e é fácil de personalizar.\" Ele afirmou: \"Neste estágio do boom da IA, quando cada chatbot importante é legitimamente útil de várias maneiras, benchmarks, ciência e rigor parecem quase insignificantes. O que importa é como o chatbot se sente [...]\". John Herrman, da revista New York, escreveu: \"Usuários casuais que encontram o GPT-5 por meio do ChatGPT provavelmente não sentirão que estão usando um produto completamente diferente [...] enquanto pessoas que o usam para"}
{"source": "GPT-5", "chunk_id": "GPT-5_14", "text": "New York, escreveu: \"Usuários casuais que encontram o GPT-5 por meio do ChatGPT provavelmente não sentirão que estão usando um produto completamente diferente [...] enquanto pessoas que o usam para desenvolvimento de software ou em um contexto corporativo são mais propensas a notar uma grande mudança.\" Christian de Looper, do Mashable, descobriu que \"o recurso mais interessante do GPT-5, de longe, é sua capacidade de criar aplicativos personalizados e interativos com base em prompts simples e em linguagem natural. É o sonho de qualquer programador de vibração se tornando realidade.\" Kyle Orland da Ars Technica testou o GPT-5, comparando-o com o GPT-4o, e determinou que \"o GPT-4o tende a fornecer um pouco mais de detalhes e ser um pouco mais pessoal do que as respostas mais diretas e concisas do GPT-5.\" O novo sistema de roteador do GPT-5 que alterna automaticamente os modelos dependendo da tarefa foi criticado por levar a respostas de qualidade inconsistente; muitos usuários relataram"}
{"source": "GPT-5", "chunk_id": "GPT-5_15", "text": "do GPT-5.\" O novo sistema de roteador do GPT-5 que alterna automaticamente os modelos dependendo da tarefa foi criticado por levar a respostas de qualidade inconsistente; muitos usuários relataram que o GPT-5 às vezes tinha um desempenho pior do que o GPT-4o. Um dia após o lançamento do GPT-5, Altman respondeu a isso, dizendo que \"o GPT-5 parecerá mais inteligente a partir de hoje\" e que \"[ontem], o comutador automático quebrou e ficou fora de serviço por um bom tempo do dia, e o resultado foi que o GPT-5 parecia muito mais burro.\" Alguns usuários também criticaram que com o lançamento do GPT-5, os modelos GPT legados não estavam mais disponíveis no ChatGPT para usuários não Pro. Alguns usuários ficaram particularmente frustrados com essa remoção sem aviso prévio porque usaram modelos GPT diferentes para propósitos distintos e descobriram que o sistema de roteador GPT-5 os deixou com menos controle. Como resposta, em uma postagem no X, Altman disse que a OpenAI traria de volta uma"}
{"source": "GPT-5", "chunk_id": "GPT-5_16", "text": "GPT diferentes para propósitos distintos e descobriram que o sistema de roteador GPT-5 os deixou com menos controle. Como resposta, em uma postagem no X, Altman disse que a OpenAI traria de volta uma opção para selecionar GPT-4o também para usuários Plus e que a OpenAI \"observará o uso enquanto pensamos sobre por quanto tempo oferecer modelos legados\". Além disso, alguns usuários preferiram o tom mais caloroso e pessoal do GPT-4o ao do GPT-5, que eles descreveram como \"sem graça\", \"pouco criativo\", e \"lobotomizado\" e como semelhante a uma \"secretária sobrecarregada\". Altman respondeu a isso no X, afirmando: \"Nós certamente subestimamos o quanto algumas das coisas que as pessoas gostam no GPT-4o são importantes para elas, mesmo que o GPT-5 tenha um desempenho melhor na maioria dos aspectos\". \"A longo prazo, isso reforçou que realmente precisamos de boas maneiras para diferentes usuários personalizarem as coisas (entendemos que não existe um modelo que funcione para todos e temos"}
{"source": "GPT-5", "chunk_id": "GPT-5_17", "text": "\"A longo prazo, isso reforçou que realmente precisamos de boas maneiras para diferentes usuários personalizarem as coisas (entendemos que não existe um modelo que funcione para todos e temos investido em pesquisas de dirigibilidade e lançado uma prévia de pesquisa de diferentes personalidades)\". Em 13 de agosto de 2025, Altman declarou no X que a OpenAI estava trabalhando na personalidade do GPT-5 para fazer o modelo \"parecer mais caloroso\". Uma atualização correspondente foi lançada em 15 de agosto. Além disso, Altman foi criticado por exagerar as capacidades do GPT-5 e por criar expectativas muito altas depois de comparar a criação do GPT-5 ao Projeto Manhattan, disse que o modelo o fez \"sentir-se inútil\", e postou uma imagem não comentada da Estrela da Morte no X um dia antes do GPT-5 ser revelado."}
{"source": "Transformador pré-treinado generativo", "chunk_id": "Transformador pré-treinado generativo_0", "text": "Um transformador pré-treinado generativo ( GPT ) é um tipo de modelo de linguagem grande (LLM) e uma estrutura proeminente para inteligência artificial generativa . É uma rede neural artificial que é usada no processamento de linguagem natural . Baseia-se na arquitetura de aprendizagem profunda do transformador, pré-treinada em grandes conjuntos de dados de texto não rotulado e capaz de gerar novos conteúdos semelhantes aos humanos. Em 2023, a maioria dos LLMs apresentava essas características e às vezes são chamados amplamente de GPTs. O primeiro GPT foi introduzido em 2018 pela OpenAI . A OpenAI lançou modelos de base GPT significativos que foram numerados sequencialmente para compor sua série \"GPT- n \". Cada um deles era significativamente mais capaz que o anterior, devido ao aumento do tamanho (número de parâmetros treináveis) e do treinamento. O mais recente deles, o GPT-4o, foi lançado em maio de 2024. Esses modelos têm sido a base para seus sistemas GPT mais específicos para"}
{"source": "Transformador pré-treinado generativo", "chunk_id": "Transformador pré-treinado generativo_1", "text": "do tamanho (número de parâmetros treináveis) e do treinamento. O mais recente deles, o GPT-4o, foi lançado em maio de 2024. Esses modelos têm sido a base para seus sistemas GPT mais específicos para tarefas, incluindo modelos ajustados para seguir instruções — que por sua vez alimentam o serviço de chatbot ChatGPT . O termo \"GPT\" (sigla para \"Generative Pre-trained Transformer\") também é utilizado nos nomes e nas descrições de modelos de linguagem de grande escala semelhantes, desenvolvidos por outras organizações ou empresas além da OpenAI, que criou o conceito original. Esses modelos, que compartilham características arquiteturais ou funcionais com o GPT, são frequentemente nomeados ou descritos com o termo \"GPT\" para indicar sua natureza de transformadores pré-treinados voltados para tarefas de geração de texto ou outras aplicações de inteligência artificial. Por exemplo, outros modelos de fundação GPT incluem uma série de modelos criados pela EleutherAI, e sete modelos criados"}
{"source": "Transformador pré-treinado generativo", "chunk_id": "Transformador pré-treinado generativo_2", "text": "tarefas de geração de texto ou outras aplicações de inteligência artificial. Por exemplo, outros modelos de fundação GPT incluem uma série de modelos criados pela EleutherAI, e sete modelos criados pela Cerebras em 2023. Empresas de diferentes indústrias desenvolveram GPTs específicos para tarefas em seus respectivos campos, como o \"EinsteinGPT\" da Salesforce (para CRM ) e o \"BloombergGPT\" da Bloomberg (para finanças)."}
{"source": "Inteligência artificial generativa", "chunk_id": "Inteligência artificial generativa_0", "text": "Inteligência artificial generativa ou IA generativa é um ramo da inteligência artificial focado na criação de conteúdo novo, baseado em padrões identificados nos conjuntos de dados de treinamento. É possível criar conteúdo como texto, imagens, áudio, vídeo, código de software, podendo ser gerados a partir de pedidos (ou prompts) em linguagem natural, ou até através de imagens para imagens, e de vídeos para vídeos. Essa forma de visualizar esses modelos é uma categorização baseado em formato de entrada e saída, de texto para texto (text-to-text), texto para imagem (text-to-image), entre vários outros. Sistemas de IA generativa incluem Stable Diffusion e DALL-E, modelos de imagens de inteligência artificial, assim como modelos de texto como o ChatGPT, um chatbot construído pela OpenAI usando os modelos de linguagem de grande escala GPT-3 e GPT-4, Bard, um chatbot construído pelo Google usando o modelo LaMDA, e o Microsoft Copilot , chatbot construído pela Microsoft que é uma extensão do"}
{"source": "Inteligência artificial generativa", "chunk_id": "Inteligência artificial generativa_1", "text": "os modelos de linguagem de grande escala GPT-3 e GPT-4, Bard, um chatbot construído pelo Google usando o modelo LaMDA, e o Microsoft Copilot , chatbot construído pela Microsoft que é uma extensão do modelo de linguagem GPT-4 da OpenAI e que foi pensada para uso vinculado aos serviços da Microsoft e sistema operacional Windows. IA generativa tem aplicações potenciais numa ampla gama de setores, incluindo desenvolvimento de software, marketing e moda. O investimento em IA generativa aumentou durante o início da década de 2020, com grandes empresas como Microsoft, Google e Baidu, bem como várias outras empresas menores a desenvolver modelos de IA generativa. E a Nvidia foi uma das empresas que mais cresceram nesse meio tempo, uma vez que começou a utilizar suas GPUs para o treinamento de grandes modelos de linguagem cada vez mais poderosos. Na saúde, a IA generativa também tem transformado e impactado significativamente o cuidado ao paciente, educação em saúde e pesquisas na área. As"}
{"source": "Inteligência artificial generativa", "chunk_id": "Inteligência artificial generativa_2", "text": "grandes modelos de linguagem cada vez mais poderosos. Na saúde, a IA generativa também tem transformado e impactado significativamente o cuidado ao paciente, educação em saúde e pesquisas na área. As oportunidades de desenvolvimento são grandes, no entanto, há desafios éticos que precisam ser considerados. Como um exemplo das aplicações da IA generativa, tem-se a transformação no campo da medicina, onde essa tecnologia tem expandido suas possibilidades, alterando a maneira como o cuidado é prestado, as funções dos profissionais de saúde e a comunicação entre pacientes e médicos. Além disso, a IA generativa tem mostrado grande potencial na melhoria da descoberta científica, como em ensaios clínicos e pesquisas observacionais, além de contribuir para a educação médica. Esses avanços são resultado do aprimoramento técnico da IA, que agora é capaz de gerar linguagem e imagens realistas, gerando discussões sobre a melhor forma de integrar esses modelos no contexto médico. Um sistema de IA"}
{"source": "Inteligência artificial generativa", "chunk_id": "Inteligência artificial generativa_3", "text": "do aprimoramento técnico da IA, que agora é capaz de gerar linguagem e imagens realistas, gerando discussões sobre a melhor forma de integrar esses modelos no contexto médico. Um sistema de IA generativo é construído aplicando aprendizado de máquina não supervisionado ou autossupervisionado a um conjunto de dados. As capacidades e aplicações de um sistema de IA generativo variam conforme a modalidade, ou seja, o tipo de dados e a tarefa específica para a qual foi treinado. A seguir, são descritas algumas das principais modalidades da IA generativa: Texto: sistemas de IA generativos treinados em palavras ou tokens de palavras incluem GPT-3, LaMDA, LLaMA, BLOOM, GPT-4 e outros (veja lista de modelos de linguagem grandes). Eles são capazes de processamento de linguagem natural, tradução automática e geração de linguagem natural e podem ser usados como modelos básicos para outras tarefas. Conjuntos de dados incluem BookCorpus, Wikipedia e outros. Modelos de textos são versáteis e têm"}
{"source": "Inteligência artificial generativa", "chunk_id": "Inteligência artificial generativa_4", "text": "automática e geração de linguagem natural e podem ser usados como modelos básicos para outras tarefas. Conjuntos de dados incluem BookCorpus, Wikipedia e outros. Modelos de textos são versáteis e têm demonstrado a capacidade de resolver diversas tarefas: de criar textos coerentes de diversas formatações, resumir textos longos extraindo informações-chave, são capazes de traduzir textos entre diversos idiomas com alta precisão, cada vez demonstrando ser mais úteis para a automação de tarefas do cotidiano, sendo poderosas e adaptáveis a uma ampla gama de aplicações práticas e criativas. Código: além do texto em linguagem natural, grandes modelos de linguagem podem ser treinados em texto de linguagem de programação, permitindo que gerem código-fonte para novos programas de computador. Um exemplo notável é a geração automatizada de código, onde modelos como o OpenAI Codex são capazes de criar código-fonte a partir de comandos de linguagem natural. Isso acelera o processo de desenvolvimento"}
{"source": "Inteligência artificial generativa", "chunk_id": "Inteligência artificial generativa_5", "text": "notável é a geração automatizada de código, onde modelos como o OpenAI Codex são capazes de criar código-fonte a partir de comandos de linguagem natural. Isso acelera o processo de desenvolvimento e reduz a ocorrência de erros humanos. Além disso, a IA generativa pode ser usada para depurar e revisar códigos, identificar e corrigir bugs e sugerir melhorias e simplificações que podem não ser óbvias para os desenvolvedores. Esse recurso de análise aprofundada ajuda a manter a qualidade do software. Outra aplicação relacionada é a criação de testes automatizados, onde a inteligência artificial pode gerar automaticamente casos de teste para garantir que o código seja robusto e menos sujeito a falhas quando implementado em produção. Essa automação é fundamental para manter a confiabilidade e a funcionalidade do software em diferentes cenários. Por fim, ferramentas como o GitHub Copilot atuam como assistentes de programação, fornecendo sugestões contextuais à medida que os desenvolvedores"}
{"source": "Inteligência artificial generativa", "chunk_id": "Inteligência artificial generativa_6", "text": "a funcionalidade do software em diferentes cenários. Por fim, ferramentas como o GitHub Copilot atuam como assistentes de programação, fornecendo sugestões contextuais à medida que os desenvolvedores escrevem o código. Isso não apenas acelera a solução de problemas, mas também mantém o fluxo de trabalho, permitindo que os desenvolvedores sejam mais produtivos e criativos. Imagens: Sistemas generativos de IA treinados em conjuntos de imagens com legendas de texto incluem Imagen, DALL-E, Midjourney, Stable Diffusion e outros. São comumente usados para geração de texto para imagem e transferência de estilo neural. Os conjuntos de dados incluem LAION-5B e outros. De forma geral, existe uma infinidade de aplicações para essa modalidade, em diversos campos, por exemplo para meios de entretenimento, seja animações ou filmes, facilitar a visualização dos roteiristas de um ambiente, de uma pessoa ou de um objeto. Ou até no meio do marketing de criar uma campanha mais customizada ou para"}
{"source": "Inteligência artificial generativa", "chunk_id": "Inteligência artificial generativa_7", "text": "seja animações ou filmes, facilitar a visualização dos roteiristas de um ambiente, de uma pessoa ou de um objeto. Ou até no meio do marketing de criar uma campanha mais customizada ou para visualização do produto. De forma análoga podemos pensar em situação para Arquitetura, Esporte ou Ciências. Vídeo: De forma similar ao caso de geração de imagens também temos para a modalidade de vídeo, no qual a partir de um prompt, é possível gerar um vídeo, que apresenta uma coerência temporal, com bastantes detalhes e bem realista. Um dos mais famosos da área é o Sora da OpenAI, com potencial de revolucionar diversas áreas. Áudio: Sistemas de IA generativos treinados em dados de áudio podem gerar uma ampla variedade de sons, desde música e efeitos sonoros até vozes humanas realistas. Essa capacidade tem sido explorada para diversas aplicações, como composição musical, dublagem e produção de podcasts. Cada vez mais fácil de ser possível encontrar online plataformas que oferecem a criação de"}
{"source": "Inteligência artificial generativa", "chunk_id": "Inteligência artificial generativa_8", "text": "tem sido explorada para diversas aplicações, como composição musical, dublagem e produção de podcasts. Cada vez mais fácil de ser possível encontrar online plataformas que oferecem a criação de músicas geradas por IA. Jogos: Sistemas de IA generativos também são capazes de abranger várias áreas do desenvolvimento de jogos como na criação de personagens e do diálogo entre eles, também na geração procedural de conteúdo, na criação de narrativas interativas além de outras áreas de desenvolvimento. Inclusive já temos cada vez mais o uso da IA na indústria de desenvolvimento de games e exemplos como no Man's Sky na qual foi usado geração procedural para criação de ambientes dentro do jogo e da Ubisoft grande empresa no setor de desenvolvimento de jogos que tem usado ferramentas de IA baseado em modelo de linguagem grande (Ghostwriter) para escrita de diálogo básicos dos NPCs em seus jogos são cada vez mais comuns. Moléculas: Os sistemas generativos de IA podem ser treinados em sequências"}
{"source": "Inteligência artificial generativa", "chunk_id": "Inteligência artificial generativa_9", "text": "em modelo de linguagem grande (Ghostwriter) para escrita de diálogo básicos dos NPCs em seus jogos são cada vez mais comuns. Moléculas: Os sistemas generativos de IA podem ser treinados em sequências de aminoácidos ou representações moleculares, como SMILES representando DNA ou proteínas. Esses sistemas, como o AlphaFold, são usados para previsão da estrutura de proteínas e descoberta de medicamentos. Conjuntos de dados incluem vários conjuntos de dados biológicos. Multimodal: um sistema de IA generativo pode ser construído a partir de vários modelos generativos ou um modelo treinado em vários tipos de dados. Por exemplo, uma versão do GPT-4 da OpenAI aceita entradas de texto e imagem. A Inteligência Artificial Generativa tem demonstrado um potencial transformador em diversos setores da sociedade, impulsionando avanços significativos em áreas que giram em torno da tecnologia. No entanto, o rápido desenvolvimento dessa tecnologia também tem levantado preocupações sobre seus possíveis"}
{"source": "Inteligência artificial generativa", "chunk_id": "Inteligência artificial generativa_10", "text": "sociedade, impulsionando avanços significativos em áreas que giram em torno da tecnologia. No entanto, o rápido desenvolvimento dessa tecnologia também tem levantado preocupações sobre seus possíveis impactos negativos. Como os descritos a seguir: A IA pode ser usada para criação de conteúdo como textos, imagens, áudio e outros tipos de mídias fictícias que podem ser usadas de maneira a divulgar conteúdo falso na rede se usada de forma tendenciosa, ou seja gerando preocupações com a divulgação de fake news como em casos de divulgação de conteúdo fictício para impacto eleitoral cada vez mais comuns por exemplo que tornam cada vez mais difíceis distinguir o que é verdadeiro do que é gerado por IA. A capacidade de criar deepfakes levanta preocupações significativas sobre a integridade da informação e a confiança nas instituições. A disseminação de deepfakes com fins políticos, como a criação de vídeos falsos de políticos fazendo declarações controversas, pode minar a confiança na"}
{"source": "Inteligência artificial generativa", "chunk_id": "Inteligência artificial generativa_11", "text": "da informação e a confiança nas instituições. A disseminação de deepfakes com fins políticos, como a criação de vídeos falsos de políticos fazendo declarações controversas, pode minar a confiança na democracia e polarizar a sociedade. Além disso, os deepfakes podem ser utilizados para fins de chantagem, extorsão e difamação, causando danos irreparáveis à reputação de indivíduos e organizações. O uso da IA pode vir a substituir alguns profissionais dos setores criativos e de geração de conteúdo como redatores, designers, artistas, dubladores e entre outros. Tornando o trabalho de milhares de pessoas obsoleto e podendo gerar uma desigualdade social visto que muitos trabalhadores podem perder oportunidades no mercado se empresas adotarem o uso da IA na geração de conteúdo. Já temos inclusive impacto recente quando atores e roteiristas de Hollywood entraram em greve por alguns motivos e entre eles por conta do uso de suas imagens e voz sem a devida proteção e consentimento pela"}
{"source": "Inteligência artificial generativa", "chunk_id": "Inteligência artificial generativa_12", "text": "inclusive impacto recente quando atores e roteiristas de Hollywood entraram em greve por alguns motivos e entre eles por conta do uso de suas imagens e voz sem a devida proteção e consentimento pela Inteligência Artificial. A regulamentação da inteligência artificial tem sido constantemente debatida, principalmente ao que se trata sobre a substituição do trabalho humano por IA e as fontes que são utilizadas para treinar as máquinas. Em maio de 2023 o Sindicato de Roteiristas da America (WGA, em inglês) entrou em greve em busca de maiores salários e regulamentação da utilização treinamento de IA. A preocupação é para que trabalhos literários não pudessem ser produzidos por IA generativa, e que os textos escritos por roteiristas não pudessem ser utilizados para treinar IA generativa. Em setembro desse mesmo ano a greve teve fim com os seguintes tópicos aprovação dos itens a seguir: Estúdios e produtoras deverão informar sempre ao repassar qualquer material produzido por IA IA não poderá"}
{"source": "Inteligência artificial generativa", "chunk_id": "Inteligência artificial generativa_13", "text": "desse mesmo ano a greve teve fim com os seguintes tópicos aprovação dos itens a seguir: Estúdios e produtoras deverão informar sempre ao repassar qualquer material produzido por IA IA não poderá receber créditos de escritor IA não poderá escrever ou reescrever “material literário” Escritores podem utilizar IA em seu trabalho caso a produtora consinta; porém eles não podem ser obrigados por seus superiores a utilizar essas ferramentas Em julho de 2024, novamente em Hollywood, O sindicato SAG-AFTRA (The Screen Actors Guild-American Federation of Television and Radio Artists) convocou um acordo de greve com IA sendo seu principal ponto de discussão. Dessa vez a greve foi aderida por dubladores e artistas de captura de movimento para videojogos, com preocupação pela segurança dos seus empregos. Há uma crescente preocupação, principalmente no meio artístico, de como a IA generativa pode ser utilizada para substituir a mão de obra humana, e como os trabalhos anteriores realizados pelos"}
{"source": "Inteligência artificial generativa", "chunk_id": "Inteligência artificial generativa_14", "text": "Há uma crescente preocupação, principalmente no meio artístico, de como a IA generativa pode ser utilizada para substituir a mão de obra humana, e como os trabalhos anteriores realizados pelos profissionais não estão protegidos quando se trata de treinamento de máquinas, e por isso entende-se que há uma necessidade de regulamentar como a IA generativa pode ser utilizada no meio artístico. A origem dos dados utilizados para treinar modelos de IA muitas vezes é complexa e envolve a coleta de informações de diversas fontes, incluindo dados pessoais. As questões de propriedade intelectual e direitos autorais sobre esses dados são complexas e ainda não estão completamente resolvidas."}
{"source": "BERT (modelo de linguagem)", "chunk_id": "BERT (modelo de linguagem)_0", "text": "Bidirecional Encoder Representations from Transformers (BERT) é uma família de modelos de linguagem introduzida em 2018 por pesquisadores do Google. Uma pesquisa da literatura em 2020 concluiu que \"em pouco mais de um ano, o BERT se tornou onipresente em experimentos de Processamento de Linguagem Natural (NLP), contando com mais de 150 publicações\". O BERT foi originalmente implementado para o inglês em dois tamanhos de modelo: (1) BERT BASE : 12 encoders com 12 cabeças de auto-atenção bidirecionais totalizando 110 milhões de parâmetros, e (2) BERT LARGE : 24 encoders com 16 auto-atendimento bidirecionais cabeças de atenção totalizando 340 milhões de parâmetros. Ambos os modelos foram pré-treinados no Toronto BookCorpus (800 milhões de palavras) e na Wikipédia em inglês (2.500 milhões de palavras). O BERT é baseado na arquitetura transformer, sendo pré-treinado simultaneamente em duas tarefas: modelagem de linguagem (15% dos tokens foram mascarados e o objetivo do treinamento foi"}
{"source": "BERT (modelo de linguagem)", "chunk_id": "BERT (modelo de linguagem)_1", "text": "de palavras). O BERT é baseado na arquitetura transformer, sendo pré-treinado simultaneamente em duas tarefas: modelagem de linguagem (15% dos tokens foram mascarados e o objetivo do treinamento foi prever o token original, dado seu contexto) e previsão da próxima frase (o objetivo do treinamento foi classificar se dois trechos de texto apareceu sequencialmente no corpus de treinamento). Como resultado desse processo de treinamento, o BERT aprende representações latentes de palavras e frases em contexto. Após o pré-treinamento, é possivél fazer um ajuste fino com menos recursos em conjuntos de dados menores para otimizar seu desempenho em tarefas específicas, como tarefas de PLN (inferência de linguagem, classificação de texto) e tarefas de geração de linguagem baseadas em sequência (resposta a perguntas, geração de resposta conversacional). O estágio de pré-treinamento é significativamente mais caro computacionalmente do que o ajuste fino. Quando o BERT foi publicado, ele alcançou"}
{"source": "BERT (modelo de linguagem)", "chunk_id": "BERT (modelo de linguagem)_2", "text": "a perguntas, geração de resposta conversacional). O estágio de pré-treinamento é significativamente mais caro computacionalmente do que o ajuste fino. Quando o BERT foi publicado, ele alcançou desempenho de estado da arte em várias tarefas de compreensão de linguagem natural : Conjunto de tarefas GLUE ( Avaliação de Compreensão Geral de Linguagem ) (composto por 9 tarefas) SQuAD (Stanford Question Answering Dataset ) v1.1 e v2.0 SWAG (Situações com Gerações Adversárias ) BERT foi originalmente publicado pelos pesquisadores do Google Jacob Devlin, Ming-Wei Chang, Kenton Lee e Kristina Toutanova. O design tem suas origens em representações contextuais de pré-treinamento, incluindo aprendizado de sequência semi-supervisionado, pré-treinamento generativo, ELMo, e ULMFit. Ao contrário dos modelos anteriores, o BERT é uma representação profunda de linguagem bidirecional e não supervisionada, pré-treinada usando apenas um corpus de texto simples. Modelos livres de contexto, como word2vec ou"}
{"source": "BERT (modelo de linguagem)", "chunk_id": "BERT (modelo de linguagem)_3", "text": "anteriores, o BERT é uma representação profunda de linguagem bidirecional e não supervisionada, pré-treinada usando apenas um corpus de texto simples. Modelos livres de contexto, como word2vec ou GloVe, geram uma representação de incorporação de palavra única para cada palavra no vocabulário, onde o BERT leva em consideração o contexto para cada ocorrência de uma determinada palavra. Por exemplo, enquanto o vetor para \"rodando\" terá a mesma representação do vetor word2vec para ambas as ocorrências nas sentenças \"Ele está rodando o programa\" e \"O pneu está rodando\", o BERT fornecerá uma incorporação contextualizada que será diferentes de acordo com a frase. Em 25 de outubro de 2019, o Google anunciou que havia começado a aplicar modelos BERT para consultas de pesquisa em inglês nos EUA. Em 9 de dezembro de 2019, foi relatado que o BERT havia sido adotado pela Pesquisa do Google em mais de 70 idiomas. Em outubro de 2020, quase todas as consultas em inglês foram processadas por um modelo"}
{"source": "BERT (modelo de linguagem)", "chunk_id": "BERT (modelo de linguagem)_4", "text": "9 de dezembro de 2019, foi relatado que o BERT havia sido adotado pela Pesquisa do Google em mais de 70 idiomas. Em outubro de 2020, quase todas as consultas em inglês foram processadas por um modelo BERT. O trabalho de pesquisa que descreve o BERT ganhou o Prêmio de Melhor Artigo Longo na Conferência Anual de 2019 do Capítulo Norte-Americano da Associação de Linguística Computacional (NAACL)."}
{"source": "Modelos de linguagem de grande escala", "chunk_id": "Modelos de linguagem de grande escala_0", "text": "Modelos de linguagem de grande escala (em inglês: Large Language Model ou LLM) são modelos de linguagem compostos por uma rede neural com muitos parâmetros (tipicamente bilhões ou possivelmente mais). São treinados com grandes quantidades de textos não rotulado usando aprendizado de máquina não-supervisionado. Os LLM surgiram por volta de 2018, com o modelo BERT. Estes têm bom desempenho em uma ampla variedade de tarefas. Isso mudou o foco da pesquisa em processamento de linguagem natural, afastando-se do paradigma anterior de treinar modelos supervisionados especializados para tarefas específicas. Embora o termo não tenha uma definição formal, ele geralmente se refere a modelos de aprendizado profundo que possuem uma contagem de parâmetros da ordem de bilhões ou mais. MLLs são modelos de propósito geral que se destacam em uma ampla gama de tarefas, em vez de serem treinados para uma tarefa específica (como análise de sentimento, reconhecimento de entidades nomeadas ou raciocínio"}
{"source": "Modelos de linguagem de grande escala", "chunk_id": "Modelos de linguagem de grande escala_1", "text": "de propósito geral que se destacam em uma ampla gama de tarefas, em vez de serem treinados para uma tarefa específica (como análise de sentimento, reconhecimento de entidades nomeadas ou raciocínio matemático). Embora treinados em tarefas simples, como prever a próxima palavra em uma frase, modelos de linguagem neural com treinamento e contagem de parâmetros suficientes são capazes de capturar grande parte da sintaxe e semântica da linguagem humana. Além disso, grandes modelos de linguagem demonstram considerável conhecimento geral sobre o mundo e são capazes de \"memorizar\" uma grande quantidade de fatos durante o treinamento. Os modelos grandes de linguagem geralmente usam a arquitetura do transformador, que se tornou a técnica padrão de aprendizado profundo para dados sequenciais desde 2018 (anteriormente, arquiteturas recorrentes como a LSTM eram mais comuns). Os MLLs são treinados de maneira não supervisionada em texto não anotado. Um transformador da esquerda para a direita é"}
{"source": "Modelos de linguagem de grande escala", "chunk_id": "Modelos de linguagem de grande escala_2", "text": "2018 (anteriormente, arquiteturas recorrentes como a LSTM eram mais comuns). Os MLLs são treinados de maneira não supervisionada em texto não anotado. Um transformador da esquerda para a direita é treinado para maximizar a probabilidade atribuída à próxima palavra nos dados de treinamento, dada o contexto anterior. Alternativamente, um MLL pode usar um transformador bidirecional (como no exemplo do BERT), que atribui uma distribuição de probabilidade sobre as palavras com acesso tanto ao contexto anterior quanto posterior. Além da tarefa de prever a próxima palavra ou \"preencher as lacunas\", os MLLs podem ser treinados em tarefas auxiliares que testam sua compreensão da distribuição de dados, como a Predição de Próxima Sentença (NSP), na qual pares de frases são apresentados e o modelo deve prever se eles aparecem lado a lado no corpus de treinamento. Os primeiros MLLs foram treinados em corpora com bilhões de palavras. A versão inicial do GPT foi treinada em 2018 no BookCorpus, que"}
{"source": "Modelos de linguagem de grande escala", "chunk_id": "Modelos de linguagem de grande escala_3", "text": "prever se eles aparecem lado a lado no corpus de treinamento. Os primeiros MLLs foram treinados em corpora com bilhões de palavras. A versão inicial do GPT foi treinada em 2018 no BookCorpus, que consiste em 985 milhões de palavras. No mesmo ano, o BERT foi treinado em uma combinação de BookCorpus e Wikipedia em inglês, totalizando 3,3 bilhões de palavras. Nos anos seguintes, os corpora de treinamento para MLLs aumentaram em ordens de magnitude, atingindo centenas de bilhões ou trilhões de tokens. MLLs são caros em termos computacionais para serem treinados. Um estudo de 2020 estimou o custo do treinamento de um modelo com 1.5 bilhão de parâmetros (de 1 a 2 ordens de magnitude menores que o estado da arte na época) em US$ 1.6 milhão. Uma análise de 2020 constatou que a capacidade dos modelos de linguagem neural (medida pela perda de treinamento) aumentou suavemente em uma relação de lei de potência com o número de parâmetros, quantidade de dados de treinamento e computação usada para"}
{"source": "Modelos de linguagem de grande escala", "chunk_id": "Modelos de linguagem de grande escala_4", "text": "de linguagem neural (medida pela perda de treinamento) aumentou suavemente em uma relação de lei de potência com o número de parâmetros, quantidade de dados de treinamento e computação usada para treinamento. Essas relações foram testadas em uma ampla gama de valores (até sete ordens de magnitude) e nenhuma atenuação da relação foi observada no extremo superior da faixa (incluindo tamanhos de rede de até trilhões de parâmetros). Entre 2018 e 2020, o método padrão para utilizar um MLL em uma tarefa específica de processamento de linguagem natural era ajustar o modelo com treinamento adicional específico para a tarefa. Posteriormente, descobriu-se que MLLs mais poderosos, como o GPT-3, podem resolver tarefas sem treinamento adicional por meio de técnicas de \"prompting\", nas quais o problema a ser resolvido é apresentado ao modelo como um prompt de texto, possivelmente com alguns exemplos textuais de problemas semelhantes e suas soluções. O ajuste fino é a prática de modificar um modelo"}
{"source": "Modelos de linguagem de grande escala", "chunk_id": "Modelos de linguagem de grande escala_5", "text": "a ser resolvido é apresentado ao modelo como um prompt de texto, possivelmente com alguns exemplos textuais de problemas semelhantes e suas soluções. O ajuste fino é a prática de modificar um modelo de linguagem pré-treinado existente, treinando-o (de forma supervisionada) em uma tarefa específica (por exemplo, análise de sentimento, reconhecimento de entidade nomeada ou marcação de partes do discurso). É uma forma de aprendizado por transferência. Geralmente envolve a introdução de um novo conjunto de pesos conectando a camada final do modelo de linguagem à saída da tarefa secundária. Os pesos originais do modelo de linguagem podem ser \"congelados\", de modo que apenas a nova camada de pesos conectando-os à saída seja aprendida durante o treinamento. Alternativamente, os pesos originais podem receber pequenas atualizações (possivelmente com camadas anteriores congeladas). Inteligência artificial generativa Modelos de linguagem de pequena escala Alucinação (inteligência artificial)"}
{"source": "Modelos de linguagem de pequena escala", "chunk_id": "Modelos de linguagem de pequena escala_0", "text": "Modelos de linguagem de pequena escala ou modelos de linguagem pequenos (SLMs, do inglês small language models) são modelos de linguagem desenvolvidos para tarefas humanas de processamento de linguagem natural (natural language processing, ou NLP), como geração e classificação de texto. Ao contrário dos modelos de linguagem de grande escala (large language models, ou LLMs), os SLMs são consideravelmente menores em termos de escala (tamanho do modelo) e escopo (capacidade e complexidade das tarefas que conseguem executar). Normalmente, o número de parâmetros de treinamento (valores ajustáveis que definem o comportamento do modelo) de um LLM está na casa das centenas de bilhões, com alguns modelos ultrapassando um trilhão de parâmetros. O tamanho de qualquer LLM é vasto porque ele contém uma grande quantidade de informação aprendida durante o treinamento, o que permite gerar conteúdos de maior qualidade. No entanto, isso requer enorme poder computacional (capacidade de processamento de"}
{"source": "Modelos de linguagem de pequena escala", "chunk_id": "Modelos de linguagem de pequena escala_1", "text": "grande quantidade de informação aprendida durante o treinamento, o que permite gerar conteúdos de maior qualidade. No entanto, isso requer enorme poder computacional (capacidade de processamento de dados), tornando inviável para uma pessoa treinar um modelo de linguagem grande usando somente um computador pessoal e uma GPU (graphics processing unit, unidade de processamento gráfico usada para acelerar cálculos intensivos). Por outro lado, modelos de linguagem de pequena escala utilizam muito menos parâmetros, variando geralmente entre alguns milhões e alguns bilhões, o que os torna mais viáveis para treinamento (ajustar os parâmetros com dados) e hospedar (executar o modelo) em ambientes com recursos limitados, como um único computador ou até mesmo um dispositivo móvel. Um exemplo de implementação de SLMs é utilizando linguagem de programação Python e bibliotecas amplamente utilizadas como: Hugging Face Transformers (biblioteca que permite treinar ou adaptar modelos pequenos como"}
{"source": "Modelos de linguagem de pequena escala", "chunk_id": "Modelos de linguagem de pequena escala_2", "text": "implementação de SLMs é utilizando linguagem de programação Python e bibliotecas amplamente utilizadas como: Hugging Face Transformers (biblioteca que permite treinar ou adaptar modelos pequenos como DistilBERT, TinyBERT, ALBERT, entre outros), PyTorch e TensorFlow (estruturas de aprendizado de máquina profundo que fornecem infraestrutura para construir SLMs) e Optimum (ferramenta de otimização para implantar modelos eficientes em diferentes hardwares). Inteligência artificial generativa Alucinação (inteligência artificial) Modelo de linguagem Modelos de linguagem de grande escala Aprendizado de máquina Redes neurais artificiais Processamento de linguagem natural"}
{"source": "Inteligência artificial generativa", "chunk_id": "Inteligência artificial generativa_0", "text": "Inteligência artificial generativa ou IA generativa é um ramo da inteligência artificial focado na criação de conteúdo novo, baseado em padrões identificados nos conjuntos de dados de treinamento. É possível criar conteúdo como texto, imagens, áudio, vídeo, código de software, podendo ser gerados a partir de pedidos (ou prompts) em linguagem natural, ou até através de imagens para imagens, e de vídeos para vídeos. Essa forma de visualizar esses modelos é uma categorização baseado em formato de entrada e saída, de texto para texto (text-to-text), texto para imagem (text-to-image), entre vários outros. Sistemas de IA generativa incluem Stable Diffusion e DALL-E, modelos de imagens de inteligência artificial, assim como modelos de texto como o ChatGPT, um chatbot construído pela OpenAI usando os modelos de linguagem de grande escala GPT-3 e GPT-4, Bard, um chatbot construído pelo Google usando o modelo LaMDA, e o Microsoft Copilot , chatbot construído pela Microsoft que é uma extensão do"}
{"source": "Inteligência artificial generativa", "chunk_id": "Inteligência artificial generativa_1", "text": "os modelos de linguagem de grande escala GPT-3 e GPT-4, Bard, um chatbot construído pelo Google usando o modelo LaMDA, e o Microsoft Copilot , chatbot construído pela Microsoft que é uma extensão do modelo de linguagem GPT-4 da OpenAI e que foi pensada para uso vinculado aos serviços da Microsoft e sistema operacional Windows. IA generativa tem aplicações potenciais numa ampla gama de setores, incluindo desenvolvimento de software, marketing e moda. O investimento em IA generativa aumentou durante o início da década de 2020, com grandes empresas como Microsoft, Google e Baidu, bem como várias outras empresas menores a desenvolver modelos de IA generativa. E a Nvidia foi uma das empresas que mais cresceram nesse meio tempo, uma vez que começou a utilizar suas GPUs para o treinamento de grandes modelos de linguagem cada vez mais poderosos. Na saúde, a IA generativa também tem transformado e impactado significativamente o cuidado ao paciente, educação em saúde e pesquisas na área. As"}
{"source": "Inteligência artificial generativa", "chunk_id": "Inteligência artificial generativa_2", "text": "grandes modelos de linguagem cada vez mais poderosos. Na saúde, a IA generativa também tem transformado e impactado significativamente o cuidado ao paciente, educação em saúde e pesquisas na área. As oportunidades de desenvolvimento são grandes, no entanto, há desafios éticos que precisam ser considerados. Como um exemplo das aplicações da IA generativa, tem-se a transformação no campo da medicina, onde essa tecnologia tem expandido suas possibilidades, alterando a maneira como o cuidado é prestado, as funções dos profissionais de saúde e a comunicação entre pacientes e médicos. Além disso, a IA generativa tem mostrado grande potencial na melhoria da descoberta científica, como em ensaios clínicos e pesquisas observacionais, além de contribuir para a educação médica. Esses avanços são resultado do aprimoramento técnico da IA, que agora é capaz de gerar linguagem e imagens realistas, gerando discussões sobre a melhor forma de integrar esses modelos no contexto médico. Um sistema de IA"}
{"source": "Inteligência artificial generativa", "chunk_id": "Inteligência artificial generativa_3", "text": "do aprimoramento técnico da IA, que agora é capaz de gerar linguagem e imagens realistas, gerando discussões sobre a melhor forma de integrar esses modelos no contexto médico. Um sistema de IA generativo é construído aplicando aprendizado de máquina não supervisionado ou autossupervisionado a um conjunto de dados. As capacidades e aplicações de um sistema de IA generativo variam conforme a modalidade, ou seja, o tipo de dados e a tarefa específica para a qual foi treinado. A seguir, são descritas algumas das principais modalidades da IA generativa: Texto: sistemas de IA generativos treinados em palavras ou tokens de palavras incluem GPT-3, LaMDA, LLaMA, BLOOM, GPT-4 e outros (veja lista de modelos de linguagem grandes). Eles são capazes de processamento de linguagem natural, tradução automática e geração de linguagem natural e podem ser usados como modelos básicos para outras tarefas. Conjuntos de dados incluem BookCorpus, Wikipedia e outros. Modelos de textos são versáteis e têm"}
{"source": "Inteligência artificial generativa", "chunk_id": "Inteligência artificial generativa_4", "text": "automática e geração de linguagem natural e podem ser usados como modelos básicos para outras tarefas. Conjuntos de dados incluem BookCorpus, Wikipedia e outros. Modelos de textos são versáteis e têm demonstrado a capacidade de resolver diversas tarefas: de criar textos coerentes de diversas formatações, resumir textos longos extraindo informações-chave, são capazes de traduzir textos entre diversos idiomas com alta precisão, cada vez demonstrando ser mais úteis para a automação de tarefas do cotidiano, sendo poderosas e adaptáveis a uma ampla gama de aplicações práticas e criativas. Código: além do texto em linguagem natural, grandes modelos de linguagem podem ser treinados em texto de linguagem de programação, permitindo que gerem código-fonte para novos programas de computador. Um exemplo notável é a geração automatizada de código, onde modelos como o OpenAI Codex são capazes de criar código-fonte a partir de comandos de linguagem natural. Isso acelera o processo de desenvolvimento"}
{"source": "Inteligência artificial generativa", "chunk_id": "Inteligência artificial generativa_5", "text": "notável é a geração automatizada de código, onde modelos como o OpenAI Codex são capazes de criar código-fonte a partir de comandos de linguagem natural. Isso acelera o processo de desenvolvimento e reduz a ocorrência de erros humanos. Além disso, a IA generativa pode ser usada para depurar e revisar códigos, identificar e corrigir bugs e sugerir melhorias e simplificações que podem não ser óbvias para os desenvolvedores. Esse recurso de análise aprofundada ajuda a manter a qualidade do software. Outra aplicação relacionada é a criação de testes automatizados, onde a inteligência artificial pode gerar automaticamente casos de teste para garantir que o código seja robusto e menos sujeito a falhas quando implementado em produção. Essa automação é fundamental para manter a confiabilidade e a funcionalidade do software em diferentes cenários. Por fim, ferramentas como o GitHub Copilot atuam como assistentes de programação, fornecendo sugestões contextuais à medida que os desenvolvedores"}
{"source": "Inteligência artificial generativa", "chunk_id": "Inteligência artificial generativa_6", "text": "a funcionalidade do software em diferentes cenários. Por fim, ferramentas como o GitHub Copilot atuam como assistentes de programação, fornecendo sugestões contextuais à medida que os desenvolvedores escrevem o código. Isso não apenas acelera a solução de problemas, mas também mantém o fluxo de trabalho, permitindo que os desenvolvedores sejam mais produtivos e criativos. Imagens: Sistemas generativos de IA treinados em conjuntos de imagens com legendas de texto incluem Imagen, DALL-E, Midjourney, Stable Diffusion e outros. São comumente usados para geração de texto para imagem e transferência de estilo neural. Os conjuntos de dados incluem LAION-5B e outros. De forma geral, existe uma infinidade de aplicações para essa modalidade, em diversos campos, por exemplo para meios de entretenimento, seja animações ou filmes, facilitar a visualização dos roteiristas de um ambiente, de uma pessoa ou de um objeto. Ou até no meio do marketing de criar uma campanha mais customizada ou para"}
{"source": "Inteligência artificial generativa", "chunk_id": "Inteligência artificial generativa_7", "text": "seja animações ou filmes, facilitar a visualização dos roteiristas de um ambiente, de uma pessoa ou de um objeto. Ou até no meio do marketing de criar uma campanha mais customizada ou para visualização do produto. De forma análoga podemos pensar em situação para Arquitetura, Esporte ou Ciências. Vídeo: De forma similar ao caso de geração de imagens também temos para a modalidade de vídeo, no qual a partir de um prompt, é possível gerar um vídeo, que apresenta uma coerência temporal, com bastantes detalhes e bem realista. Um dos mais famosos da área é o Sora da OpenAI, com potencial de revolucionar diversas áreas. Áudio: Sistemas de IA generativos treinados em dados de áudio podem gerar uma ampla variedade de sons, desde música e efeitos sonoros até vozes humanas realistas. Essa capacidade tem sido explorada para diversas aplicações, como composição musical, dublagem e produção de podcasts. Cada vez mais fácil de ser possível encontrar online plataformas que oferecem a criação de"}
{"source": "Inteligência artificial generativa", "chunk_id": "Inteligência artificial generativa_8", "text": "tem sido explorada para diversas aplicações, como composição musical, dublagem e produção de podcasts. Cada vez mais fácil de ser possível encontrar online plataformas que oferecem a criação de músicas geradas por IA. Jogos: Sistemas de IA generativos também são capazes de abranger várias áreas do desenvolvimento de jogos como na criação de personagens e do diálogo entre eles, também na geração procedural de conteúdo, na criação de narrativas interativas além de outras áreas de desenvolvimento. Inclusive já temos cada vez mais o uso da IA na indústria de desenvolvimento de games e exemplos como no Man's Sky na qual foi usado geração procedural para criação de ambientes dentro do jogo e da Ubisoft grande empresa no setor de desenvolvimento de jogos que tem usado ferramentas de IA baseado em modelo de linguagem grande (Ghostwriter) para escrita de diálogo básicos dos NPCs em seus jogos são cada vez mais comuns. Moléculas: Os sistemas generativos de IA podem ser treinados em sequências"}
{"source": "Inteligência artificial generativa", "chunk_id": "Inteligência artificial generativa_9", "text": "em modelo de linguagem grande (Ghostwriter) para escrita de diálogo básicos dos NPCs em seus jogos são cada vez mais comuns. Moléculas: Os sistemas generativos de IA podem ser treinados em sequências de aminoácidos ou representações moleculares, como SMILES representando DNA ou proteínas. Esses sistemas, como o AlphaFold, são usados para previsão da estrutura de proteínas e descoberta de medicamentos. Conjuntos de dados incluem vários conjuntos de dados biológicos. Multimodal: um sistema de IA generativo pode ser construído a partir de vários modelos generativos ou um modelo treinado em vários tipos de dados. Por exemplo, uma versão do GPT-4 da OpenAI aceita entradas de texto e imagem. A Inteligência Artificial Generativa tem demonstrado um potencial transformador em diversos setores da sociedade, impulsionando avanços significativos em áreas que giram em torno da tecnologia. No entanto, o rápido desenvolvimento dessa tecnologia também tem levantado preocupações sobre seus possíveis"}
{"source": "Inteligência artificial generativa", "chunk_id": "Inteligência artificial generativa_10", "text": "sociedade, impulsionando avanços significativos em áreas que giram em torno da tecnologia. No entanto, o rápido desenvolvimento dessa tecnologia também tem levantado preocupações sobre seus possíveis impactos negativos. Como os descritos a seguir: A IA pode ser usada para criação de conteúdo como textos, imagens, áudio e outros tipos de mídias fictícias que podem ser usadas de maneira a divulgar conteúdo falso na rede se usada de forma tendenciosa, ou seja gerando preocupações com a divulgação de fake news como em casos de divulgação de conteúdo fictício para impacto eleitoral cada vez mais comuns por exemplo que tornam cada vez mais difíceis distinguir o que é verdadeiro do que é gerado por IA. A capacidade de criar deepfakes levanta preocupações significativas sobre a integridade da informação e a confiança nas instituições. A disseminação de deepfakes com fins políticos, como a criação de vídeos falsos de políticos fazendo declarações controversas, pode minar a confiança na"}
{"source": "Inteligência artificial generativa", "chunk_id": "Inteligência artificial generativa_11", "text": "da informação e a confiança nas instituições. A disseminação de deepfakes com fins políticos, como a criação de vídeos falsos de políticos fazendo declarações controversas, pode minar a confiança na democracia e polarizar a sociedade. Além disso, os deepfakes podem ser utilizados para fins de chantagem, extorsão e difamação, causando danos irreparáveis à reputação de indivíduos e organizações. O uso da IA pode vir a substituir alguns profissionais dos setores criativos e de geração de conteúdo como redatores, designers, artistas, dubladores e entre outros. Tornando o trabalho de milhares de pessoas obsoleto e podendo gerar uma desigualdade social visto que muitos trabalhadores podem perder oportunidades no mercado se empresas adotarem o uso da IA na geração de conteúdo. Já temos inclusive impacto recente quando atores e roteiristas de Hollywood entraram em greve por alguns motivos e entre eles por conta do uso de suas imagens e voz sem a devida proteção e consentimento pela"}
{"source": "Inteligência artificial generativa", "chunk_id": "Inteligência artificial generativa_12", "text": "inclusive impacto recente quando atores e roteiristas de Hollywood entraram em greve por alguns motivos e entre eles por conta do uso de suas imagens e voz sem a devida proteção e consentimento pela Inteligência Artificial. A regulamentação da inteligência artificial tem sido constantemente debatida, principalmente ao que se trata sobre a substituição do trabalho humano por IA e as fontes que são utilizadas para treinar as máquinas. Em maio de 2023 o Sindicato de Roteiristas da America (WGA, em inglês) entrou em greve em busca de maiores salários e regulamentação da utilização treinamento de IA. A preocupação é para que trabalhos literários não pudessem ser produzidos por IA generativa, e que os textos escritos por roteiristas não pudessem ser utilizados para treinar IA generativa. Em setembro desse mesmo ano a greve teve fim com os seguintes tópicos aprovação dos itens a seguir: Estúdios e produtoras deverão informar sempre ao repassar qualquer material produzido por IA IA não poderá"}
{"source": "Inteligência artificial generativa", "chunk_id": "Inteligência artificial generativa_13", "text": "desse mesmo ano a greve teve fim com os seguintes tópicos aprovação dos itens a seguir: Estúdios e produtoras deverão informar sempre ao repassar qualquer material produzido por IA IA não poderá receber créditos de escritor IA não poderá escrever ou reescrever “material literário” Escritores podem utilizar IA em seu trabalho caso a produtora consinta; porém eles não podem ser obrigados por seus superiores a utilizar essas ferramentas Em julho de 2024, novamente em Hollywood, O sindicato SAG-AFTRA (The Screen Actors Guild-American Federation of Television and Radio Artists) convocou um acordo de greve com IA sendo seu principal ponto de discussão. Dessa vez a greve foi aderida por dubladores e artistas de captura de movimento para videojogos, com preocupação pela segurança dos seus empregos. Há uma crescente preocupação, principalmente no meio artístico, de como a IA generativa pode ser utilizada para substituir a mão de obra humana, e como os trabalhos anteriores realizados pelos"}
{"source": "Inteligência artificial generativa", "chunk_id": "Inteligência artificial generativa_14", "text": "Há uma crescente preocupação, principalmente no meio artístico, de como a IA generativa pode ser utilizada para substituir a mão de obra humana, e como os trabalhos anteriores realizados pelos profissionais não estão protegidos quando se trata de treinamento de máquinas, e por isso entende-se que há uma necessidade de regulamentar como a IA generativa pode ser utilizada no meio artístico. A origem dos dados utilizados para treinar modelos de IA muitas vezes é complexa e envolve a coleta de informações de diversas fontes, incluindo dados pessoais. As questões de propriedade intelectual e direitos autorais sobre esses dados são complexas e ainda não estão completamente resolvidas."}
{"source": "Transformador (arquitetura de aprendizagem profunda)", "chunk_id": "Transformador (arquitetura de aprendizagem profunda)_0", "text": "O Transformer é uma arquitetura de aprendizado profundo introduzida por pesquisadores do Google em 2017. Baseado no mecanismo de atenção, o Transformer tornou-se um modelo fundamental no campo da Inteligência artificial, especialmente para tarefas de processamento de linguagem natural (NLP). Diferentemente de modelos anteriores que utilizavam redes neurais recorrentes (RNNs) ou redes neurais convolucionais (CNNs), o Transformer processa dados de entrada em paralelo, tornando-o mais eficiente e escalável. Essa arquitetura possibilitou avanços significativos em Tradução automática, geração de texto e outras tarefas baseadas em sequências, sendo também adaptada para domínios além do texto, como Visão computacional e processamento de áudio. O Transformer foi apresentado pela primeira vez no artigo Attention Is All You Need (Vaswani et al., 2017), publicado em junho de 2017 por uma equipe de pesquisadores do Google Brain e Google Research. Os autores — Ashish Vaswani, Noam Shazeer, Niki"}
{"source": "Transformador (arquitetura de aprendizagem profunda)", "chunk_id": "Transformador (arquitetura de aprendizagem profunda)_1", "text": "artigo Attention Is All You Need (Vaswani et al., 2017), publicado em junho de 2017 por uma equipe de pesquisadores do Google Brain e Google Research. Os autores — Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser e Illia Polosukhin — propuseram a arquitetura como uma solução para as limitações das RNNs e CNNs no manejo de dependências de longo alcance em dados sequenciais. O artigo demonstrou que o Transformer superava os modelos existentes em tarefas de tradução automática, sendo mais paralelizado e exigindo menos tempo de treinamento. Em 2018, o Google começou a utilizar modelos baseados em Transformer, como o BERT (BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding), para melhorar a compreensão de consultas de busca. Até 2020, o Google Translate substituiu seus modelos baseados em RNN por uma arquitetura híbrida Transformer-encodificador-RNN-decodificador, consolidando ainda mais o papel do"}
{"source": "Transformador (arquitetura de aprendizagem profunda)", "chunk_id": "Transformador (arquitetura de aprendizagem profunda)_2", "text": "de consultas de busca. Até 2020, o Google Translate substituiu seus modelos baseados em RNN por uma arquitetura híbrida Transformer-encodificador-RNN-decodificador, consolidando ainda mais o papel do Transformer no avanço das capacidades de IA. A arquitetura do Transformer é construída em torno do conceito de autoatenção (self-attention), que permite ao modelo ponderar a importância de diferentes partes da sequência de entrada em relação umas às outras. Isso difere das RNNs, que processam dados sequencialmente, e das CNNs, que dependem de janelas de tamanho fixo. Os principais componentes do Transformer incluem: Mecanismo de Autoatenção: Calcula pontuações de atenção para cada elemento da sequência de entrada, utilizando atenção de produto escalar escalonada. Atenção Multi-Cabeça: Permite ao modelo capturar relações complexas nos dados, executando múltiplos mecanismos de atenção em paralelo. Codificação Posicional: Como o Transformer não processa dados sequencialmente, utiliza"}
{"source": "Transformador (arquitetura de aprendizagem profunda)", "chunk_id": "Transformador (arquitetura de aprendizagem profunda)_3", "text": "Permite ao modelo capturar relações complexas nos dados, executando múltiplos mecanismos de atenção em paralelo. Codificação Posicional: Como o Transformer não processa dados sequencialmente, utiliza codificações senoidais posicionais (ver exemplo) para fornecer informações sobre a ordem dos elementos na sequência. Estrutura Codificador-Decodificador: O Transformer original é composto por camadas de autoatenção e redes neurais feed-forward tanto no codificador quanto no decodificador. A arquitetura Transformer tem sido aplicada a uma ampla gama de tarefas, incluindo: Tradução Automática: A aplicação original do Transformer, onde alcançou resultados de ponta em benchmarks como o WMT . Geração de Texto: Modelos como o GPT (Generative Pre-trained Transformer) da OpenAI usam Transformers apenas com decodificador para gerar textos coerentes e contextuais. Resposta a Perguntas e Sumarização: Modelos como BERT e o T5 (Exploring the Limits of Transfer Learning with a Unified Text-to-Text"}
{"source": "Transformador (arquitetura de aprendizagem profunda)", "chunk_id": "Transformador (arquitetura de aprendizagem profunda)_4", "text": "apenas com decodificador para gerar textos coerentes e contextuais. Resposta a Perguntas e Sumarização: Modelos como BERT e o T5 (Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer) têm se destacado em tarefas que exigem compreensão semântica. Visão Computacional: Os Vision Transformers (ViTs) adaptam a arquitetura para tarefas de imagem como classificação e detecção. Processamento de Fala: Transformers têm sido utilizados em modelos como o Whisper da OpenAI para transcrição automática. A introdução do Transformer levou ao desenvolvimento de diversos modelos de grande influência: BERT (2018): Codificador bidirecional usado em tarefas de NLP. GPT (2018–atual): Decodificador Transformer criado pela OpenAI com foco em geração de texto. T5 (Text-to-Text Transfer Transformer): Modelo do Google que trata toda tarefa de NLP como um problema de texto para texto. Esses modelos são considerados modelos fundacionais, ou seja, grandes modelos pré-treinados capazes"}
{"source": "Transformador (arquitetura de aprendizagem profunda)", "chunk_id": "Transformador (arquitetura de aprendizagem profunda)_5", "text": "Transformer): Modelo do Google que trata toda tarefa de NLP como um problema de texto para texto. Esses modelos são considerados modelos fundacionais, ou seja, grandes modelos pré-treinados capazes de serem ajustados para tarefas específicas com pouco treinamento adicional. Apesar de seu sucesso, o Transformer apresenta limitações: Requisitos Computacionais: Modelos grandes como GPT e T5 exigem múltiplas GPUs ou TPUs, tornando-os inacessíveis para muitos pesquisadores. Ver Efficient Transformers: A Survey. Interpretabilidade: A complexidade do mecanismo de atenção torna difícil entender o raciocínio do modelo. Eficiência de Dados: O desempenho ótimo requer grandes volumes de dados. Pesquisas estão em andamento com variantes como o DistilBERT, Longformer, e ALBERT para mitigar esses problemas. Vaswani, A., et al. (2017). Attention Is All You Need. Devlin, J., et al. (2018). BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. Radford, A., et al. (2018)."}
{"source": "Transformador (arquitetura de aprendizagem profunda)", "chunk_id": "Transformador (arquitetura de aprendizagem profunda)_6", "text": "Vaswani, A., et al. (2017). Attention Is All You Need. Devlin, J., et al. (2018). BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. Radford, A., et al. (2018). Improving Language Understanding by Generative Pre-Training. Raffel, C., et al. (2019). Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer. Inteligência artificial Processamento de linguagem natural Redes neurais artificiais ChatGPT"}
